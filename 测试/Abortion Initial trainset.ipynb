{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25b6e3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import pdb\n",
    "import logging\n",
    "import re\n",
    "from gensim import parsing\n",
    "import gensim\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3281396",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baal.active import get_heuristic\n",
    "from baal.active.active_loop import ActiveLearningLoop\n",
    "from baal.active.dataset.nlp_datasets import active_huggingface_dataset, HuggingFaceDatasets\n",
    "from baal.bayesian.dropout import patch_module\n",
    "from baal.transformers_trainer_wrapper import BaalTransformersTrainer\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a474ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d1de94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-tiny\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1f96a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"transformer_checkpoints\",  # specify the directory where models weights will be saved a certain points during training (checkpoints)\n",
    "    num_train_epochs=1,  # change this if it is taking too long on your computer\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f427384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(a):\n",
    "    rotated = list(zip(*a[::-1]))\n",
    "    median0 = []\n",
    "    min0 = []\n",
    "    max0 = []\n",
    "    for i in range(len(rotated)):\n",
    "        median0.append(np.median(rotated[i]))\n",
    "        min0.append(np.min(rotated[i]))\n",
    "        max0.append(np.max(rotated[i]))\n",
    "    return median0,min0,max0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6070f20",
   "metadata": {},
   "source": [
    "# Abortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cb7a734",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_abortion\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset with 587 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_abortion\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset with 66 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_abortion\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset with 280 instances loaded\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "cache_dir = \"./data_cache\"\n",
    "\n",
    "train_dataset_abortion = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_abortion\",\n",
    "    split=\"train\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Training dataset with {len(train_dataset_abortion)} instances loaded\")\n",
    "\n",
    "val_dataset_abortion = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_abortion\",\n",
    "    split=\"validation\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Validation dataset with {len(val_dataset_abortion)} instances loaded\")\n",
    "\n",
    "test_dataset_abortion = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_abortion\",\n",
    "    split=\"test\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Test dataset with {len(test_dataset_abortion)} instances loaded\")\n",
    "\n",
    "num_classes = np.unique(train_dataset_abortion['label']).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a88d307",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_original = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\", num_labels=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2acdd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[554 333 154]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 02:58]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:51:14.276197Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 33.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:51:18.523825Z [info     ] Start Predict                  dataset=564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:01<00:00, 37.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:51:22.699066Z [info     ] Start Predict                  dataset=544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:01<00:00, 37.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:51:27.015710Z [info     ] Start Predict                  dataset=524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 33.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:51:31.798692Z [info     ] Start Predict                  dataset=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 39.89it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:51:36.229579Z [info     ] Start Predict                  dataset=484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 39.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:51:40.907448Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 34.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:51:45.835992Z [info     ] Start Predict                  dataset=444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 38.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:51:50.970789Z [info     ] Start Predict                  dataset=424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 37.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:51:56.011818Z [info     ] Start Predict                  dataset=404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 39.66it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:52:01.490360Z [info     ] Start Predict                  dataset=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 35.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:52:07.032174Z [info     ] Start Predict                  dataset=364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 36.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:52:12.836967Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 41.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:52:18.370350Z [info     ] Start Predict                  dataset=324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 36.03it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:52:24.502957Z [info     ] Start Predict                  dataset=304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 40.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:52:30.286851Z [info     ] Start Predict                  dataset=284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 39.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:52:36.086757Z [info     ] Start Predict                  dataset=264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 39.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:52:42.244512Z [info     ] Start Predict                  dataset=244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 41.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:52:48.359479Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 38.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:52:54.795927Z [info     ] Start Predict                  dataset=204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 41.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:53:01.607689Z [info     ] Start Predict                  dataset=184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 38.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:53:08.364118Z [info     ] Start Predict                  dataset=164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 42.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:53:15.318214Z [info     ] Start Predict                  dataset=144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 40.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:53:22.372610Z [info     ] Start Predict                  dataset=124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 39.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:53:29.959801Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 36.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:53:37.866475Z [info     ] Start Predict                  dataset=84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 35.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:53:45.827186Z [info     ] Start Predict                  dataset=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 38.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:53:53.435858Z [info     ] Start Predict                  dataset=44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 41.89it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:54:01.301793Z [info     ] Start Predict                  dataset=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 25.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:54:09.647412Z [info     ] Start Predict                  dataset=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 41.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65, 0.6285714285714286, 0.6607142857142857, 0.6535714285714286, 0.675, 0.675, 0.675, 0.6678571428571428, 0.675, 0.675, 0.675, 0.6785714285714286, 0.675, 0.675, 0.675, 0.675, 0.675, 0.6678571428571428, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675]\n",
      "[535  69 215]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:54:12.810974Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:01<00:00, 36.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:54:16.606504Z [info     ] Start Predict                  dataset=564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:02<00:00, 34.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:54:20.680165Z [info     ] Start Predict                  dataset=544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:01<00:00, 38.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:54:24.668624Z [info     ] Start Predict                  dataset=524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 37.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:54:29.316860Z [info     ] Start Predict                  dataset=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 38.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:54:33.646665Z [info     ] Start Predict                  dataset=484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 39.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:54:38.430337Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 36.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:54:43.439102Z [info     ] Start Predict                  dataset=444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 39.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:54:48.355315Z [info     ] Start Predict                  dataset=424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 37.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:54:53.364312Z [info     ] Start Predict                  dataset=404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 39.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:54:58.532964Z [info     ] Start Predict                  dataset=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 32.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:55:04.679015Z [info     ] Start Predict                  dataset=364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 34.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:55:10.706517Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 40.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:55:17.728236Z [info     ] Start Predict                  dataset=324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 37.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:55:25.490032Z [info     ] Start Predict                  dataset=304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 29.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:55:33.924893Z [info     ] Start Predict                  dataset=284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 37.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:55:40.573926Z [info     ] Start Predict                  dataset=264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 35.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:55:47.481876Z [info     ] Start Predict                  dataset=244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 38.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:55:54.303122Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 38.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:56:01.068978Z [info     ] Start Predict                  dataset=204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 37.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:56:07.953182Z [info     ] Start Predict                  dataset=184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 38.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:56:15.080079Z [info     ] Start Predict                  dataset=164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 38.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:56:22.221353Z [info     ] Start Predict                  dataset=144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 36.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:56:29.503827Z [info     ] Start Predict                  dataset=124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 37.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:56:37.104283Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 36.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:56:44.594605Z [info     ] Start Predict                  dataset=84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 32.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:56:52.167867Z [info     ] Start Predict                  dataset=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 37.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:56:59.665820Z [info     ] Start Predict                  dataset=44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 39.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:57:08.028702Z [info     ] Start Predict                  dataset=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 42.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:57:16.092583Z [info     ] Start Predict                  dataset=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 63.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6571428571428571, 0.6642857142857143, 0.6678571428571428, 0.6642857142857143, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.6714285714285714, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675]\n",
      "[535  69 215]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:57:19.448709Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:01<00:00, 38.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:57:23.090569Z [info     ] Start Predict                  dataset=564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:01<00:00, 38.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:57:26.948433Z [info     ] Start Predict                  dataset=544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:01<00:00, 39.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:57:31.032501Z [info     ] Start Predict                  dataset=524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 36.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:57:35.327436Z [info     ] Start Predict                  dataset=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 39.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:57:39.506843Z [info     ] Start Predict                  dataset=484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 36.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:57:44.149170Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 37.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:57:48.769454Z [info     ] Start Predict                  dataset=444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 38.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:57:53.742233Z [info     ] Start Predict                  dataset=424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 34.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:57:59.063709Z [info     ] Start Predict                  dataset=404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 35.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:58:04.825967Z [info     ] Start Predict                  dataset=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 35.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:58:10.503240Z [info     ] Start Predict                  dataset=364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 37.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:58:16.504676Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 40.66it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:58:22.167235Z [info     ] Start Predict                  dataset=324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 40.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:58:27.994727Z [info     ] Start Predict                  dataset=304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 38.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:58:33.890186Z [info     ] Start Predict                  dataset=284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 36.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:58:40.284678Z [info     ] Start Predict                  dataset=264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 33.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:58:46.882235Z [info     ] Start Predict                  dataset=244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 37.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:58:53.026645Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 39.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:58:59.278035Z [info     ] Start Predict                  dataset=204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 36.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:59:06.732971Z [info     ] Start Predict                  dataset=184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 36.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:59:13.971464Z [info     ] Start Predict                  dataset=164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 37.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:59:21.462683Z [info     ] Start Predict                  dataset=144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 33.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:59:29.079882Z [info     ] Start Predict                  dataset=124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 33.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:59:37.167405Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 39.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:59:45.207591Z [info     ] Start Predict                  dataset=84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 33.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T17:59:53.432396Z [info     ] Start Predict                  dataset=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 42.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:00:01.272197Z [info     ] Start Predict                  dataset=44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 37.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:00:09.977921Z [info     ] Start Predict                  dataset=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 30.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:00:18.659899Z [info     ] Start Predict                  dataset=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 64.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6571428571428571, 0.6642857142857143, 0.6678571428571428, 0.6642857142857143, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.6714285714285714, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675]\n",
      "[535  69 215]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:00:22.235679Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 33.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:00:26.275677Z [info     ] Start Predict                  dataset=564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:02<00:00, 34.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:00:30.408721Z [info     ] Start Predict                  dataset=544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:01<00:00, 36.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:00:34.596113Z [info     ] Start Predict                  dataset=524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:02<00:00, 32.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:00:39.404498Z [info     ] Start Predict                  dataset=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 35.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:00:44.089550Z [info     ] Start Predict                  dataset=484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 37.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:00:48.676523Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 39.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:00:53.099233Z [info     ] Start Predict                  dataset=444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 40.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:00:58.727438Z [info     ] Start Predict                  dataset=424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 30.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:01:05.400512Z [info     ] Start Predict                  dataset=404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 32.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:01:12.125148Z [info     ] Start Predict                  dataset=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 27.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:01:18.810960Z [info     ] Start Predict                  dataset=364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 32.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:01:25.338461Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 32.51it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:01:32.268135Z [info     ] Start Predict                  dataset=324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 31.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:01:39.395107Z [info     ] Start Predict                  dataset=304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 33.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:01:46.274835Z [info     ] Start Predict                  dataset=284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 30.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:01:53.206534Z [info     ] Start Predict                  dataset=264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 32.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:02:00.012425Z [info     ] Start Predict                  dataset=244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 36.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:02:06.762722Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 39.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:02:13.071898Z [info     ] Start Predict                  dataset=204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 40.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:02:19.561555Z [info     ] Start Predict                  dataset=184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 41.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:02:26.087156Z [info     ] Start Predict                  dataset=164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 37.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:02:33.237478Z [info     ] Start Predict                  dataset=144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 38.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:02:40.096257Z [info     ] Start Predict                  dataset=124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 41.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:02:47.376833Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 43.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:02:54.446106Z [info     ] Start Predict                  dataset=84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 41.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:03:01.719683Z [info     ] Start Predict                  dataset=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 39.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:03:09.401040Z [info     ] Start Predict                  dataset=44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 39.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:03:17.143982Z [info     ] Start Predict                  dataset=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 32.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:03:24.936996Z [info     ] Start Predict                  dataset=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 63.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6571428571428571, 0.6642857142857143, 0.6678571428571428, 0.6642857142857143, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.6714285714285714, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675]\n",
      "[535  69 215]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 02:55]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:03:28.057379Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 36.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:03:31.793007Z [info     ] Start Predict                  dataset=564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:01<00:00, 37.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:03:35.766725Z [info     ] Start Predict                  dataset=544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:01<00:00, 35.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:03:39.952958Z [info     ] Start Predict                  dataset=524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 36.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:03:44.168848Z [info     ] Start Predict                  dataset=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 37.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:03:48.873204Z [info     ] Start Predict                  dataset=484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 40.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:03:53.136794Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 39.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:03:57.839899Z [info     ] Start Predict                  dataset=444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 38.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:04:02.588583Z [info     ] Start Predict                  dataset=424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 38.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:04:07.494914Z [info     ] Start Predict                  dataset=404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 38.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:04:12.623850Z [info     ] Start Predict                  dataset=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 37.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:04:17.668147Z [info     ] Start Predict                  dataset=364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 39.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:04:23.075135Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 40.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:04:28.640979Z [info     ] Start Predict                  dataset=324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 36.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:04:35.162237Z [info     ] Start Predict                  dataset=304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 40.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:04:41.151533Z [info     ] Start Predict                  dataset=284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 38.03it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:04:47.278483Z [info     ] Start Predict                  dataset=264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 40.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:04:53.455287Z [info     ] Start Predict                  dataset=244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 39.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:04:59.798101Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 37.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:05:06.262104Z [info     ] Start Predict                  dataset=204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 39.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:05:12.986937Z [info     ] Start Predict                  dataset=184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 37.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:05:19.835831Z [info     ] Start Predict                  dataset=164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 39.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:05:26.861058Z [info     ] Start Predict                  dataset=144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 38.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:05:33.975718Z [info     ] Start Predict                  dataset=124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 39.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:05:41.389875Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 41.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:05:48.929963Z [info     ] Start Predict                  dataset=84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 41.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:05:56.674836Z [info     ] Start Predict                  dataset=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 39.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:06:04.454334Z [info     ] Start Predict                  dataset=44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 42.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:06:12.270901Z [info     ] Start Predict                  dataset=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 31.51it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:06:20.672345Z [info     ] Start Predict                  dataset=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 32.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6571428571428571, 0.6642857142857143, 0.6678571428571428, 0.6642857142857143, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.6714285714285714, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675]\n"
     ]
    }
   ],
   "source": [
    "active_mc_abortion1= []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "while mcrun != 5:\n",
    "    n_labeled_examples = np.unique(train_dataset_abortion['text']).size\n",
    "    training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "    print(training_indices0)\n",
    "    active_set_abortion =active_huggingface_dataset(train_dataset_abortion,tokenizer,'label','text')\n",
    "    valid_set_abortion = HuggingFaceDatasets(test_dataset_abortion,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_abortion.can_label = False\n",
    "    active_set_abortion.label(training_indices0)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_abortion,\n",
    "            eval_dataset=valid_set_abortion,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_abortion = ActiveLearningLoop(active_set_abortion,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_abortion=[unqueried_score]\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_abortion.step()\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_abortion.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_abortion),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_abortion.append(eval_metrics['eval_accuracy'])\n",
    "    print(performance_history_abortion)\n",
    "    active_mc_abortion1.append(performance_history_abortion)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b89378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_abortion1, min_abortion1,max_abortion1 = calculate(active_mc_abortion1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f15a7d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 98 248 342 190 289 495 102 318 349 429  79  69 346 182 456 250 563 230\n",
      " 272 348]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 20\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 02:59]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 20\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:06:23.971914Z [info     ] Start Predict                  dataset=567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:01<00:00, 39.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 40\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:06:27.711212Z [info     ] Start Predict                  dataset=547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [00:01<00:00, 40.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 60\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:06:31.521483Z [info     ] Start Predict                  dataset=527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 38.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 80\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:06:35.611971Z [info     ] Start Predict                  dataset=507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:01<00:00, 40.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 100\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:06:39.780734Z [info     ] Start Predict                  dataset=487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 37.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 120\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:06:44.219482Z [info     ] Start Predict                  dataset=467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:01<00:00, 40.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 140\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:06:48.779891Z [info     ] Start Predict                  dataset=447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 40.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 160\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:06:53.420868Z [info     ] Start Predict                  dataset=427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 39.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 180\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:06:58.263271Z [info     ] Start Predict                  dataset=407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 38.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 200\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:07:03.185688Z [info     ] Start Predict                  dataset=387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 39.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 220\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:07:08.217060Z [info     ] Start Predict                  dataset=367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 39.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 240\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:07:13.296344Z [info     ] Start Predict                  dataset=347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 39.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 260\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:07:18.705621Z [info     ] Start Predict                  dataset=327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 40.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 280\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:07:24.315515Z [info     ] Start Predict                  dataset=307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 42.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 300\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:07:30.108487Z [info     ] Start Predict                  dataset=287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 42.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 320\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 40\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:07:35.892393Z [info     ] Start Predict                  dataset=267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 42.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 340\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:07:41.778945Z [info     ] Start Predict                  dataset=247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 39.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 360\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:07:48.002001Z [info     ] Start Predict                  dataset=227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 380\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:07:54.993800Z [info     ] Start Predict                  dataset=207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 36.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 400\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:08:02.031447Z [info     ] Start Predict                  dataset=187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 35.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 420\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:08:09.179478Z [info     ] Start Predict                  dataset=167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 40.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 440\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 55\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='55' max='55' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [55/55 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:08:16.247986Z [info     ] Start Predict                  dataset=147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 40.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 460\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:08:23.851764Z [info     ] Start Predict                  dataset=127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 39.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 480\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 60\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:08:31.329208Z [info     ] Start Predict                  dataset=107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 38.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 500\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:08:38.822244Z [info     ] Start Predict                  dataset=87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 36.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 520\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 65\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [65/65 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:08:46.502568Z [info     ] Start Predict                  dataset=67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 40.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 540\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:08:54.176512Z [info     ] Start Predict                  dataset=47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 42.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 560\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 70\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:09:03.203738Z [info     ] Start Predict                  dataset=27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 33.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 580\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:09:12.113552Z [info     ] Start Predict                  dataset=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 27.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6571428571428571, 0.6642857142857143, 0.6607142857142857, 0.6714285714285714, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675]\n",
      "[365  93 372 338 436 335 491  39 358 573 253 580 397 169 510 259 583 458\n",
      " 528 340]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 20\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 20\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:09:25.453455Z [info     ] Start Predict                  dataset=567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:02<00:00, 31.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 40\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:09:29.732521Z [info     ] Start Predict                  dataset=547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [00:02<00:00, 33.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 60\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:09:34.149441Z [info     ] Start Predict                  dataset=527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:02<00:00, 31.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 80\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:09:39.345441Z [info     ] Start Predict                  dataset=507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:02<00:00, 31.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 100\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:09:44.422440Z [info     ] Start Predict                  dataset=487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 34.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 120\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:09:49.009512Z [info     ] Start Predict                  dataset=467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:01<00:00, 32.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 140\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:09:54.244405Z [info     ] Start Predict                  dataset=447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 33.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 160\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:09:59.288001Z [info     ] Start Predict                  dataset=427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 30.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 180\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:10:06.090172Z [info     ] Start Predict                  dataset=407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 31.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 200\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:10:12.135036Z [info     ] Start Predict                  dataset=387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 28.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 220\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:10:20.294037Z [info     ] Start Predict                  dataset=367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 30.73it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 240\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:10:26.910737Z [info     ] Start Predict                  dataset=347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 31.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 260\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:10:33.341107Z [info     ] Start Predict                  dataset=327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 34.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 280\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:10:40.467703Z [info     ] Start Predict                  dataset=307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 35.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 300\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:10:47.009117Z [info     ] Start Predict                  dataset=287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 34.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 320\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 40\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:10:53.401494Z [info     ] Start Predict                  dataset=267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 36.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 340\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:11:00.203949Z [info     ] Start Predict                  dataset=247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 33.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 360\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:11:06.755971Z [info     ] Start Predict                  dataset=227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 380\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:11:13.801276Z [info     ] Start Predict                  dataset=207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 32.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 400\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:11:21.890127Z [info     ] Start Predict                  dataset=187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 27.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 420\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:11:29.993442Z [info     ] Start Predict                  dataset=167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 31.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 440\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 55\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='55' max='55' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [55/55 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:11:38.458883Z [info     ] Start Predict                  dataset=147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 35.66it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 460\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:11:47.650139Z [info     ] Start Predict                  dataset=127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 20.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 480\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 60\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:11:56.595474Z [info     ] Start Predict                  dataset=107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 33.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 500\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:12:04.779115Z [info     ] Start Predict                  dataset=87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 35.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 520\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 65\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [65/65 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:12:13.275564Z [info     ] Start Predict                  dataset=67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 36.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 540\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:12:22.053317Z [info     ] Start Predict                  dataset=47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 34.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 560\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 70\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:12:31.268844Z [info     ] Start Predict                  dataset=27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 27.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 580\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:12:40.157776Z [info     ] Start Predict                  dataset=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 40.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6428571428571429, 0.6571428571428571, 0.6571428571428571, 0.6678571428571428, 0.675, 0.675, 0.675, 0.675, 0.6785714285714286, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675]\n",
      "[365  93 372 338 436 335 491  39 358 573 253 580 397 169 510 259 583 458\n",
      " 528 340]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 20\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 20\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:12:52.309510Z [info     ] Start Predict                  dataset=567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:02<00:00, 35.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 40\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:12:56.384532Z [info     ] Start Predict                  dataset=547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [00:01<00:00, 36.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 60\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:13:00.735092Z [info     ] Start Predict                  dataset=527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 36.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 80\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:13:05.158615Z [info     ] Start Predict                  dataset=507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:01<00:00, 33.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 100\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:13:11.092231Z [info     ] Start Predict                  dataset=487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:02<00:00, 28.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 120\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:13:16.634754Z [info     ] Start Predict                  dataset=467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:01<00:00, 35.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 140\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:13:21.691794Z [info     ] Start Predict                  dataset=447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 37.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 160\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:13:26.783524Z [info     ] Start Predict                  dataset=427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 37.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 180\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:13:32.012400Z [info     ] Start Predict                  dataset=407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 35.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 200\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:13:37.400704Z [info     ] Start Predict                  dataset=387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 36.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 220\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:13:43.105062Z [info     ] Start Predict                  dataset=367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 33.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 240\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:13:48.970122Z [info     ] Start Predict                  dataset=347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 33.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 260\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:13:55.118732Z [info     ] Start Predict                  dataset=327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 35.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 280\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:14:01.771932Z [info     ] Start Predict                  dataset=307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 34.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 300\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:14:08.359027Z [info     ] Start Predict                  dataset=287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 36.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 320\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 40\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:14:14.695668Z [info     ] Start Predict                  dataset=267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 32.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 340\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:14:21.651324Z [info     ] Start Predict                  dataset=247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 35.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 360\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:14:28.319309Z [info     ] Start Predict                  dataset=227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 380\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:14:36.257182Z [info     ] Start Predict                  dataset=207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 33.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 400\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:14:44.237051Z [info     ] Start Predict                  dataset=187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 35.66it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 420\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:14:51.347133Z [info     ] Start Predict                  dataset=167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 38.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 440\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 55\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='55' max='55' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [55/55 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:14:58.190017Z [info     ] Start Predict                  dataset=147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 40.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 460\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:15:05.578515Z [info     ] Start Predict                  dataset=127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 31.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 480\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 60\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:15:13.544564Z [info     ] Start Predict                  dataset=107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 38.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 500\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:15:21.021291Z [info     ] Start Predict                  dataset=87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 46.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 520\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 65\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [65/65 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:15:28.624730Z [info     ] Start Predict                  dataset=67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 44.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 540\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:15:36.431592Z [info     ] Start Predict                  dataset=47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 42.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 560\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 70\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:15:44.358094Z [info     ] Start Predict                  dataset=27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 50.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 580\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:15:53.256738Z [info     ] Start Predict                  dataset=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 38.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6428571428571429, 0.6571428571428571, 0.6571428571428571, 0.6678571428571428, 0.675, 0.675, 0.675, 0.675, 0.6785714285714286, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675]\n",
      "[365  93 372 338 436 335 491  39 358 573 253 580 397 169 510 259 583 458\n",
      " 528 340]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 20\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 20\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:16:05.575901Z [info     ] Start Predict                  dataset=567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:02<00:00, 34.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 40\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:16:10.291410Z [info     ] Start Predict                  dataset=547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [00:02<00:00, 29.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 60\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:16:15.069987Z [info     ] Start Predict                  dataset=527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:02<00:00, 32.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 80\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:16:21.155151Z [info     ] Start Predict                  dataset=507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:01<00:00, 35.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 100\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:16:26.258335Z [info     ] Start Predict                  dataset=487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:02<00:00, 27.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 120\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:16:32.559940Z [info     ] Start Predict                  dataset=467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:02<00:00, 28.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 140\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:16:38.776178Z [info     ] Start Predict                  dataset=447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:02<00:00, 23.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 160\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:16:45.414036Z [info     ] Start Predict                  dataset=427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 28.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 180\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:16:51.552125Z [info     ] Start Predict                  dataset=407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 37.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 200\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:16:57.206461Z [info     ] Start Predict                  dataset=387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 37.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 220\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:17:02.921083Z [info     ] Start Predict                  dataset=367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 31.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 240\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:17:08.779634Z [info     ] Start Predict                  dataset=347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 39.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 260\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:17:14.439048Z [info     ] Start Predict                  dataset=327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 35.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 280\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:17:20.691873Z [info     ] Start Predict                  dataset=307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 36.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 300\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:17:28.547346Z [info     ] Start Predict                  dataset=287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 29.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 320\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 40\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:17:36.289657Z [info     ] Start Predict                  dataset=267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 36.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 340\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:17:42.696140Z [info     ] Start Predict                  dataset=247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 39.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 360\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:17:49.233690Z [info     ] Start Predict                  dataset=227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 380\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:17:55.858450Z [info     ] Start Predict                  dataset=207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 38.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 400\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:18:03.049126Z [info     ] Start Predict                  dataset=187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 37.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 420\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:18:10.009791Z [info     ] Start Predict                  dataset=167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 37.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 440\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 55\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='55' max='55' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [55/55 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:18:18.269232Z [info     ] Start Predict                  dataset=147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 33.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 460\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:18:26.691420Z [info     ] Start Predict                  dataset=127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 32.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 480\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 60\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:18:34.734600Z [info     ] Start Predict                  dataset=107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 33.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 500\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:18:43.389208Z [info     ] Start Predict                  dataset=87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 37.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 520\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 65\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [65/65 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:18:51.336438Z [info     ] Start Predict                  dataset=67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 40.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 540\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:18:59.801329Z [info     ] Start Predict                  dataset=47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 40.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 560\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 70\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:19:08.042364Z [info     ] Start Predict                  dataset=27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 47.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 580\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:19:17.045842Z [info     ] Start Predict                  dataset=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 40.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6428571428571429, 0.6571428571428571, 0.6571428571428571, 0.6678571428571428, 0.675, 0.675, 0.675, 0.675, 0.6785714285714286, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675]\n",
      "[365  93 372 338 436 335 491  39 358 573 253 580 397 169 510 259 583 458\n",
      " 528 340]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 20\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 20\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:19:29.252813Z [info     ] Start Predict                  dataset=567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:01<00:00, 37.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 40\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:19:33.140203Z [info     ] Start Predict                  dataset=547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [00:01<00:00, 37.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 60\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:19:37.318497Z [info     ] Start Predict                  dataset=527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 39.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 80\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:19:41.564319Z [info     ] Start Predict                  dataset=507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:01<00:00, 39.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 100\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:19:46.080515Z [info     ] Start Predict                  dataset=487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 37.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 120\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:19:50.887686Z [info     ] Start Predict                  dataset=467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:01<00:00, 35.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 140\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:19:55.975200Z [info     ] Start Predict                  dataset=447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 37.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 160\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:20:01.025450Z [info     ] Start Predict                  dataset=427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 38.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 180\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:20:06.191047Z [info     ] Start Predict                  dataset=407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 38.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 200\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:20:11.503922Z [info     ] Start Predict                  dataset=387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 38.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 220\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:20:16.939358Z [info     ] Start Predict                  dataset=367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 29.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 240\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:20:23.129386Z [info     ] Start Predict                  dataset=347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 34.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 260\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:20:29.099328Z [info     ] Start Predict                  dataset=327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 36.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 280\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:20:35.676192Z [info     ] Start Predict                  dataset=307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 27.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 300\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:20:43.863996Z [info     ] Start Predict                  dataset=287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 34.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 320\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 40\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:20:50.794252Z [info     ] Start Predict                  dataset=267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 22.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 340\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:21:00.565339Z [info     ] Start Predict                  dataset=247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 31.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 360\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:21:08.313313Z [info     ] Start Predict                  dataset=227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 380\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:21:15.770491Z [info     ] Start Predict                  dataset=207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 34.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 400\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:21:22.880152Z [info     ] Start Predict                  dataset=187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 39.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 420\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:21:29.849656Z [info     ] Start Predict                  dataset=167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 31.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 440\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 55\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='55' max='55' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [55/55 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:21:37.516827Z [info     ] Start Predict                  dataset=147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 33.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 460\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:21:45.582946Z [info     ] Start Predict                  dataset=127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 37.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 480\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 60\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:21:52.903651Z [info     ] Start Predict                  dataset=107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 39.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 500\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:22:00.614309Z [info     ] Start Predict                  dataset=87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 37.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 520\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 65\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [65/65 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:22:08.514309Z [info     ] Start Predict                  dataset=67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 31.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 540\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:22:18.292178Z [info     ] Start Predict                  dataset=47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 34.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 560\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 70\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:22:26.737115Z [info     ] Start Predict                  dataset=27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 41.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 580\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:22:35.556100Z [info     ] Start Predict                  dataset=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 28.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6428571428571429, 0.6571428571428571, 0.6571428571428571, 0.6678571428571428, 0.675, 0.675, 0.675, 0.675, 0.6785714285714286, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675]\n"
     ]
    }
   ],
   "source": [
    "active_mc_abortion2= []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "while mcrun != 5:\n",
    "    n_labeled_examples = np.unique(train_dataset_abortion['text']).size\n",
    "    training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=20)\n",
    "    print(training_indices0)\n",
    "    active_set_abortion =active_huggingface_dataset(train_dataset_abortion,tokenizer,'label','text')\n",
    "    valid_set_abortion = HuggingFaceDatasets(test_dataset_abortion,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_abortion.can_label = False\n",
    "    active_set_abortion.label(training_indices0)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_abortion,\n",
    "            eval_dataset=valid_set_abortion,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_abortion = ActiveLearningLoop(active_set_abortion,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_abortion=[unqueried_score]\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_abortion.step()\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_abortion.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_abortion),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_abortion.append(eval_metrics['eval_accuracy'])\n",
    "    print(performance_history_abortion)\n",
    "    active_mc_abortion2.append(performance_history_abortion)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e399b121",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_abortion2, min_abortion2,max_abortion2 = calculate(active_mc_abortion2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81d540ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[503  42 471 447 105 538  58 248 190 115 301 558 274 496 349 410 133 560\n",
      " 555 456 246 215 313 217 228 392 218 243 306 397 231 560 219 207 343 297\n",
      " 156 141  51 120 154 349 111 526 303  46  35 475 528 275]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 48\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1015' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 48\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:22:49.049340Z [info     ] Start Predict                  dataset=539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:01<00:00, 34.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 68\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:22:53.382887Z [info     ] Start Predict                  dataset=519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:02<00:00, 32.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 88\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:22:58.281313Z [info     ] Start Predict                  dataset=499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 35.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 108\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:23:03.432198Z [info     ] Start Predict                  dataset=479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 33.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 128\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:23:09.654245Z [info     ] Start Predict                  dataset=459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 36.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 148\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:23:14.725502Z [info     ] Start Predict                  dataset=439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 34.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 168\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:23:20.247499Z [info     ] Start Predict                  dataset=419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 37.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 188\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:23:25.715523Z [info     ] Start Predict                  dataset=399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 34.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 208\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:23:31.219828Z [info     ] Start Predict                  dataset=379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 36.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 228\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:23:37.037486Z [info     ] Start Predict                  dataset=359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 34.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 248\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:23:43.206347Z [info     ] Start Predict                  dataset=339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 36.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 268\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:23:49.576404Z [info     ] Start Predict                  dataset=319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 37.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 288\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:23:55.614851Z [info     ] Start Predict                  dataset=299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 36.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 308\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:24:02.159966Z [info     ] Start Predict                  dataset=279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:00<00:00, 37.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 328\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:24:08.842800Z [info     ] Start Predict                  dataset=259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 35.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 348\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:24:15.860238Z [info     ] Start Predict                  dataset=239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 34.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 368\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:24:22.698403Z [info     ] Start Predict                  dataset=219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 35.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 388\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:24:29.583364Z [info     ] Start Predict                  dataset=199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 38.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 408\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:24:36.254743Z [info     ] Start Predict                  dataset=179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 38.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 428\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:24:43.403967Z [info     ] Start Predict                  dataset=159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 35.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 448\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:24:50.753939Z [info     ] Start Predict                  dataset=139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 35.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 468\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:24:58.816383Z [info     ] Start Predict                  dataset=119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 36.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 488\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:25:06.295805Z [info     ] Start Predict                  dataset=99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 40.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 508\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:25:13.892315Z [info     ] Start Predict                  dataset=79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 37.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 528\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:25:21.876172Z [info     ] Start Predict                  dataset=59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 42.66it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 548\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:25:31.069285Z [info     ] Start Predict                  dataset=39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 31.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 568\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:10, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:25:44.455061Z [info     ] Start Predict                  dataset=19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 37.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.675, 0.675, 0.6714285714285714, 0.6714285714285714, 0.675, 0.675, 0.6785714285714286, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675]\n",
      "[202 416 415 447 511  84 166 383 467  71 520 472 257 274  19 489 489 325\n",
      " 528  88 485 349  83 386  86 306 153 439 263 420 492 410 172   3 471 109\n",
      "  36 582  30 380 267  10 343 543 568 165 341 481  18 183]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1015' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:25:59.640707Z [info     ] Start Predict                  dataset=538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 31.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:26:04.789935Z [info     ] Start Predict                  dataset=518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:02<00:00, 29.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:26:10.190673Z [info     ] Start Predict                  dataset=498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 34.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:26:15.468736Z [info     ] Start Predict                  dataset=478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:02<00:00, 27.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:26:22.027908Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:02<00:00, 23.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:26:29.830712Z [info     ] Start Predict                  dataset=438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 33.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:26:36.283002Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:02<00:00, 18.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:26:47.014995Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:02<00:00, 23.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:26:54.286403Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 36.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:27:01.004344Z [info     ] Start Predict                  dataset=358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 34.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:27:10.471667Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 33.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:27:19.763884Z [info     ] Start Predict                  dataset=318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 39.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:27:27.330106Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 38.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:27:33.165566Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:00<00:00, 39.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:27:39.287584Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 38.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:27:45.735680Z [info     ] Start Predict                  dataset=238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 36.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:27:52.620324Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 36.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:27:59.492041Z [info     ] Start Predict                  dataset=198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 37.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:28:07.581477Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 34.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:28:15.841537Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 38.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:28:23.054268Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 35.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:28:30.691093Z [info     ] Start Predict                  dataset=118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 33.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:28:38.338913Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 40.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:28:46.314949Z [info     ] Start Predict                  dataset=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 41.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:28:54.616906Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 36.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:29:02.689783Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 35.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:29:11.354126Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 48.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6892857142857143, 0.6785714285714286, 0.675, 0.6714285714285714, 0.6714285714285714, 0.6785714285714286, 0.6785714285714286, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.6785714285714286, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675]\n",
      "[ 38 565 511 473 160 288 199 527 502 247 382 217  86  81  61 499  41  11\n",
      " 114 217 105 527 471 386 225 480 407 456  20 202 416 415 447 511  84 166\n",
      " 383 467  71 520 472 257 274  19 489 489 325 528  88 485]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 46\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1050' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 46\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:29:23.898650Z [info     ] Start Predict                  dataset=541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:01<00:00, 36.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 66\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:29:28.195872Z [info     ] Start Predict                  dataset=521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 37.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 86\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:29:32.519105Z [info     ] Start Predict                  dataset=501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 36.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 106\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:29:37.100919Z [info     ] Start Predict                  dataset=481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 35.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 126\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:29:42.524421Z [info     ] Start Predict                  dataset=461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 37.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 146\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:29:48.382427Z [info     ] Start Predict                  dataset=441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 37.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 166\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:29:54.255917Z [info     ] Start Predict                  dataset=421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 34.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 186\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:30:00.163032Z [info     ] Start Predict                  dataset=401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 37.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 206\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:30:07.813361Z [info     ] Start Predict                  dataset=381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 37.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 226\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:30:14.850161Z [info     ] Start Predict                  dataset=361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 36.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 246\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:30:20.429631Z [info     ] Start Predict                  dataset=341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 35.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 266\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:30:26.477636Z [info     ] Start Predict                  dataset=321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 37.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 286\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:30:32.611794Z [info     ] Start Predict                  dataset=301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 37.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 306\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:30:38.713288Z [info     ] Start Predict                  dataset=281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 38.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 326\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:30:45.818581Z [info     ] Start Predict                  dataset=261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 37.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 346\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:30:52.224724Z [info     ] Start Predict                  dataset=241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 38.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 366\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:30:59.079087Z [info     ] Start Predict                  dataset=221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 38.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 386\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:31:05.903385Z [info     ] Start Predict                  dataset=201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 39.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 406\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:31:12.940038Z [info     ] Start Predict                  dataset=181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 35.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 426\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:31:20.121024Z [info     ] Start Predict                  dataset=161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 35.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 446\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:31:27.522869Z [info     ] Start Predict                  dataset=141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 34.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 466\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:31:34.969086Z [info     ] Start Predict                  dataset=121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 37.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 486\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:31:42.732563Z [info     ] Start Predict                  dataset=101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 33.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 506\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:31:50.647850Z [info     ] Start Predict                  dataset=81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 41.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 526\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:31:58.538635Z [info     ] Start Predict                  dataset=61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 36.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 546\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:32:06.929378Z [info     ] Start Predict                  dataset=41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 42.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 566\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:32:15.288539Z [info     ] Start Predict                  dataset=21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 48.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 586\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:32:23.804790Z [info     ] Start Predict                  dataset=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 63.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.6714285714285714, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675]\n",
      "[122  32 512 203 517 516 442 338 437 444 135 386  24 505 324 337  94 544\n",
      " 145 230 494  37 424 436 367 344 159 549 540 143 575 344 268 267 168  32\n",
      " 376 213 561 439 491 392 488  28  38 172  16  55 225 557]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 48\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1015' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 02:54]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 48\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:32:36.820021Z [info     ] Start Predict                  dataset=539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:01<00:00, 38.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 68\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:32:40.929624Z [info     ] Start Predict                  dataset=519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 38.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 88\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:32:45.179358Z [info     ] Start Predict                  dataset=499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 38.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 108\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:32:49.632994Z [info     ] Start Predict                  dataset=479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 35.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 128\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:32:54.389947Z [info     ] Start Predict                  dataset=459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 36.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 148\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:32:59.336354Z [info     ] Start Predict                  dataset=439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 35.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 168\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:33:04.555126Z [info     ] Start Predict                  dataset=419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 35.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 188\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:33:09.961897Z [info     ] Start Predict                  dataset=399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 35.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 208\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:33:15.443046Z [info     ] Start Predict                  dataset=379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 37.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 228\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:33:21.091789Z [info     ] Start Predict                  dataset=359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 37.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 248\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:33:27.345644Z [info     ] Start Predict                  dataset=339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 39.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 268\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:33:32.812661Z [info     ] Start Predict                  dataset=319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 39.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 288\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:33:38.555666Z [info     ] Start Predict                  dataset=299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 38.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 308\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:33:44.992273Z [info     ] Start Predict                  dataset=279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:00<00:00, 37.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 328\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:33:51.438089Z [info     ] Start Predict                  dataset=259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 35.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 348\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:33:58.083935Z [info     ] Start Predict                  dataset=239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 37.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 368\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:34:04.505154Z [info     ] Start Predict                  dataset=219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 41.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 388\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:34:11.173674Z [info     ] Start Predict                  dataset=199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 39.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 408\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:34:18.070028Z [info     ] Start Predict                  dataset=179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 37.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 428\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:34:25.271525Z [info     ] Start Predict                  dataset=159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 34.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 448\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:34:32.889767Z [info     ] Start Predict                  dataset=139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 39.03it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 468\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:34:41.146244Z [info     ] Start Predict                  dataset=119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 39.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 488\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:34:49.257419Z [info     ] Start Predict                  dataset=99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 35.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 508\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:34:57.230085Z [info     ] Start Predict                  dataset=79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 38.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 528\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:35:05.070032Z [info     ] Start Predict                  dataset=59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 39.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 548\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:35:12.820390Z [info     ] Start Predict                  dataset=39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 45.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 568\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:35:20.718795Z [info     ] Start Predict                  dataset=19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 47.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6678571428571428, 0.6678571428571428, 0.675, 0.6714285714285714, 0.675, 0.6714285714285714, 0.6821428571428572, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675]\n",
      "[202 416 415 447 511  84 166 383 467  71 520 472 257 274  19 489 489 325\n",
      " 528  88 485 349  83 386  86 306 153 439 263 420 492 410 172   3 471 109\n",
      "  36 582  30 380 267  10 343 543 568 165 341 481  18 183]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1015' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 02:56]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:35:33.116680Z [info     ] Start Predict                  dataset=538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:01<00:00, 37.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:35:37.240947Z [info     ] Start Predict                  dataset=518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 37.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:35:41.648526Z [info     ] Start Predict                  dataset=498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 34.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:35:46.641398Z [info     ] Start Predict                  dataset=478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 36.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:35:52.281384Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 37.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:35:57.304384Z [info     ] Start Predict                  dataset=438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 37.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:36:02.296165Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 37.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:36:07.491891Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 37.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:36:12.984518Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 37.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:36:18.617513Z [info     ] Start Predict                  dataset=358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 36.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:36:24.430017Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 38.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:36:30.289138Z [info     ] Start Predict                  dataset=318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 35.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:36:36.414113Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 35.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:36:42.649405Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:00<00:00, 37.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:36:49.026999Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 35.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:36:55.570724Z [info     ] Start Predict                  dataset=238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 34.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:37:02.182957Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 38.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:37:08.915747Z [info     ] Start Predict                  dataset=198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 38.51it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:37:15.956363Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 36.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:37:23.004030Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 38.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:37:30.272021Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 38.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:37:38.007414Z [info     ] Start Predict                  dataset=118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 40.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:37:45.780821Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 39.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:37:53.581483Z [info     ] Start Predict                  dataset=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 35.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:38:01.530778Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 38.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:38:09.786551Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 53.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13764-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-26T18:38:18.255815Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 47.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6892857142857143, 0.6785714285714286, 0.675, 0.6714285714285714, 0.6714285714285714, 0.6785714285714286, 0.6785714285714286, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.6785714285714286, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675]\n"
     ]
    }
   ],
   "source": [
    "active_mc_abortion3= []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "while mcrun != 5:\n",
    "    n_labeled_examples = np.unique(train_dataset_abortion['text']).size\n",
    "    training_indices0 = np.random.randint(low=0, high=n_labeled_examples, size=50)\n",
    "    print(training_indices0)\n",
    "    active_set_abortion =active_huggingface_dataset(train_dataset_abortion,tokenizer,'label','text')\n",
    "    valid_set_abortion = HuggingFaceDatasets(test_dataset_abortion,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_abortion.can_label = False\n",
    "    active_set_abortion.label(training_indices0)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_abortion,\n",
    "            eval_dataset=valid_set_abortion,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_abortion = ActiveLearningLoop(active_set_abortion,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_abortion=[unqueried_score]\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_abortion.step()\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_abortion.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_abortion),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_abortion.append(eval_metrics['eval_accuracy'])\n",
    "    print(performance_history_abortion)\n",
    "    active_mc_abortion3.append(performance_history_abortion)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "caf16c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_abortion3, min_abortion3,max_abortion3 = calculate(active_mc_abortion3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b30e05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcc5f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_mc_abortion3= []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "while mcrun != 5:\n",
    "    n_labeled_examples = np.unique(train_dataset_abortion['text']).size\n",
    "    training_indices0 = np.random.randint(low=0, high=n_labeled_examples, size=50)\n",
    "    print(training_indices0)\n",
    "    active_set_abortion =active_huggingface_dataset(train_dataset_abortion,tokenizer,'label','text')\n",
    "    valid_set_abortion = HuggingFaceDatasets(test_dataset_abortion,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_abortion.can_label = False\n",
    "    active_set_abortion.label(training_indices0)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_abortion,\n",
    "            eval_dataset=valid_set_abortion,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_abortion = ActiveLearningLoop(active_set_abortion,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_abortion=[unqueried_score]\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_abortion.step()\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_abortion.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_abortion),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_abortion.append(eval_metrics['eval_accuracy'])\n",
    "    print(performance_history_abortion)\n",
    "    active_mc_abortion3.append(performance_history_abortion)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894caf11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a464be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb59a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1087b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb0375f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fa86336",
   "metadata": {},
   "source": [
    "# Initial training set is 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "276d1d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_abortion\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset with 587 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_abortion\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset with 66 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_abortion\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset with 280 instances loaded\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "cache_dir = \"./data_cache\"\n",
    "\n",
    "train_dataset_abortion = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_abortion\",\n",
    "    split=\"train\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Training dataset with {len(train_dataset_abortion)} instances loaded\")\n",
    "\n",
    "val_dataset_abortion = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_abortion\",\n",
    "    split=\"validation\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Validation dataset with {len(val_dataset_abortion)} instances loaded\")\n",
    "\n",
    "test_dataset_abortion = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_abortion\",\n",
    "    split=\"test\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Test dataset with {len(test_dataset_abortion)} instances loaded\")\n",
    "\n",
    "num_classes = np.unique(train_dataset_abortion['label']).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf4c2ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/config.json from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\3cf34679007e9fe5d0acd644dcc1f4b26bec5cbc9612364f6da7262aed4ef7a4.a5a11219cf90aae61ff30e1658ccf2cb4aa84d6b6e947336556f887c9828dc6d\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-tiny\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/pytorch_model.bin from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\1ee037c9e1a220d5c814779ffe697080d1e6f5b1602e16cf6061aaae41a082c5.038e1aed90492a59d2283f9c44c9fe3ee2380495ff1e7fefb3f1f04af3b685b5\n",
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at prajjwal1/bert-tiny.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/config.json from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\3cf34679007e9fe5d0acd644dcc1f4b26bec5cbc9612364f6da7262aed4ef7a4.a5a11219cf90aae61ff30e1658ccf2cb4aa84d6b6e947336556f887c9828dc6d\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-tiny\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/vocab.txt from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\585ac1c3dedc6b808dd35e8770afafe10905d3e723a02617af749d39db780e09.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/config.json from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\3cf34679007e9fe5d0acd644dcc1f4b26bec5cbc9612364f6da7262aed4ef7a4.a5a11219cf90aae61ff30e1658ccf2cb4aa84d6b6e947336556f887c9828dc6d\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-tiny\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/config.json from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\3cf34679007e9fe5d0acd644dcc1f4b26bec5cbc9612364f6da7262aed4ef7a4.a5a11219cf90aae61ff30e1658ccf2cb4aa84d6b6e947336556f887c9828dc6d\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-tiny\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/config.json from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\3cf34679007e9fe5d0acd644dcc1f4b26bec5cbc9612364f6da7262aed4ef7a4.a5a11219cf90aae61ff30e1658ccf2cb4aa84d6b6e947336556f887c9828dc6d\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-tiny\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/pytorch_model.bin from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\1ee037c9e1a220d5c814779ffe697080d1e6f5b1602e16cf6061aaae41a082c5.038e1aed90492a59d2283f9c44c9fe3ee2380495ff1e7fefb3f1f04af3b685b5\n",
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel # For BERTs\n",
    "\n",
    "model_abortion = AutoModel.from_pretrained(\"prajjwal1/bert-tiny\") \n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-tiny\") \n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_abortion = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\", num_labels=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a45f8faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "539\n"
     ]
    }
   ],
   "source": [
    "from baal.active import ActiveLearningDataset\n",
    "active_set_abortion =active_huggingface_dataset(train_dataset_abortion,tokenizer,'label','text')\n",
    "valid_set_abortion = HuggingFaceDatasets(test_dataset_abortion,tokenizer,'label','text')\n",
    "# # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "active_set_abortion.can_label = False\n",
    "active_set_abortion.label(training_indices1)\n",
    "print(len(active_set_abortion.pool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "850870ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from baal.active import get_heuristic\n",
    "\n",
    "heuristic = get_heuristic('entropy')\n",
    "model_abortion = patch_module(model_abortion)\n",
    "init_weights = deepcopy(model_abortion.state_dict())\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"transformer_checkpoints\",  # specify the directory where models weights will be saved a certain points during training (checkpoints)\n",
    "    num_train_epochs=3,  # change this if it is taking too long on your computer\n",
    ")  \n",
    "def compute_metrics(p):\n",
    "    label = p.label_ids\n",
    "    preds = np.argmax(p.predictions, axis=-1)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(label, preds),\n",
    "    }\n",
    "model_abortion = BaalTransformersTrainer(\n",
    "        model=model_abortion,\n",
    "        args=training_args,\n",
    "        train_dataset=active_set_abortion,\n",
    "        eval_dataset=valid_set_abortion,\n",
    "        tokenizer=None,\n",
    "        compute_metrics=compute_metrics)\n",
    "active_loop_abortion = ActiveLearningLoop(active_set_abortion,\n",
    "                                 model_abortion.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4368dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 48\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1015' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 06:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_abortion.train()\n",
    "unqueried_score=model_abortion.evaluate()['eval_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae61f44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 48\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:06:13.907803Z [info     ] Start Predict                  dataset=539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:01<00:00, 39.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9748324751853943, 'eval_accuracy': 0.675, 'eval_runtime': 1.105, 'eval_samples_per_second': 253.388, 'eval_steps_per_second': 31.673, 'epoch': 0, 'labeled_data': array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "       2, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "       0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "       0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 0,\n",
      "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0]), 'Next Training set size': 68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 68\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:06:20.655801Z [info     ] Start Predict                  dataset=519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 40.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9581350088119507, 'eval_accuracy': 0.675, 'eval_runtime': 1.09, 'eval_samples_per_second': 256.882, 'eval_steps_per_second': 32.11, 'epoch': 1, 'labeled_data': array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "       2, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 1, 0, 3, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "       0, 1, 0, 1, 2, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0,\n",
      "       3, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 3, 0, 0,\n",
      "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0,\n",
      "       2, 0, 0, 0, 3, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 3, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 3, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 3, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 3, 0, 3, 0, 1, 0, 0, 0, 1, 0,\n",
      "       0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       1, 0, 1, 3, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 0,\n",
      "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0]), 'Next Training set size': 88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 88\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:06:26.749576Z [info     ] Start Predict                  dataset=499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 39.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9625115394592285, 'eval_accuracy': 0.675, 'eval_runtime': 1.0907, 'eval_samples_per_second': 256.723, 'eval_steps_per_second': 32.09, 'epoch': 2, 'labeled_data': array([0, 0, 1, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "       2, 0, 4, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 1, 0, 3, 0, 0, 2, 0, 0, 0, 0, 4, 0, 0, 0, 0,\n",
      "       0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "       0, 1, 0, 1, 2, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 2, 0, 0, 4, 1, 0, 0,\n",
      "       3, 0, 3, 1, 0, 0, 4, 0, 0, 0, 0, 4, 0, 0, 1, 0, 0, 0, 0, 3, 0, 4,\n",
      "       1, 0, 0, 0, 1, 0, 0, 4, 0, 4, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 0, 4, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 4, 0, 0, 0, 0, 0, 3, 0, 0,\n",
      "       2, 0, 0, 0, 3, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 4, 4, 0, 3, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 4, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 3, 0, 4, 0, 0, 1, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 3, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 4,\n",
      "       0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 3, 0, 3, 0, 1, 0, 0, 4, 1, 0,\n",
      "       0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       1, 0, 1, 3, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 0,\n",
      "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0]), 'Next Training set size': 108}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 108\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:06:33.596967Z [info     ] Start Predict                  dataset=479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 42.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9327619075775146, 'eval_accuracy': 0.675, 'eval_runtime': 1.0859, 'eval_samples_per_second': 257.86, 'eval_steps_per_second': 32.232, 'epoch': 3, 'labeled_data': array([0, 0, 1, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "       2, 0, 4, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 5,\n",
      "       5, 0, 1, 0, 0, 0, 0, 1, 0, 3, 0, 0, 2, 0, 0, 0, 0, 4, 0, 0, 0, 5,\n",
      "       5, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "       0, 1, 0, 1, 2, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 2, 0, 0, 4, 1, 0, 0,\n",
      "       3, 0, 3, 1, 0, 0, 4, 0, 0, 0, 0, 4, 0, 0, 1, 0, 0, 0, 0, 3, 0, 4,\n",
      "       1, 0, 0, 0, 1, 0, 0, 4, 0, 4, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 0, 4, 0, 1, 5, 0, 0, 0, 0, 1, 0, 0, 4, 0, 0, 0, 0, 0, 3, 0, 5,\n",
      "       2, 0, 0, 0, 3, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 4, 4, 0, 3, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 5, 1, 0, 4, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 3, 0, 4, 0, 0, 1, 0, 4, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 4,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 5, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
      "       0, 0, 0, 5, 0, 0, 1, 1, 0, 0, 3, 0, 0, 1, 5, 0, 0, 0, 0, 1, 0, 4,\n",
      "       0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 3, 0, 3, 0, 1, 0, 0, 4, 1, 0,\n",
      "       0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 5, 5, 5, 0, 0,\n",
      "       1, 0, 1, 3, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 5, 3, 0,\n",
      "       0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 3, 1, 0, 0, 0, 5, 0, 0, 0, 2, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 2, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 0,\n",
      "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 5, 0, 0, 1, 0, 0, 0, 0, 2, 1, 5, 0, 0, 0]), 'Next Training set size': 128}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 128\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:06:41.714688Z [info     ] Start Predict                  dataset=459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 41.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9421019554138184, 'eval_accuracy': 0.675, 'eval_runtime': 1.1438, 'eval_samples_per_second': 244.8, 'eval_steps_per_second': 30.6, 'epoch': 4, 'labeled_data': array([0, 0, 1, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 0, 0,\n",
      "       2, 0, 4, 1, 0, 0, 2, 6, 0, 0, 0, 0, 0, 0, 0, 6, 3, 0, 0, 0, 0, 5,\n",
      "       5, 0, 1, 0, 0, 0, 0, 1, 0, 3, 0, 0, 2, 0, 0, 0, 0, 4, 0, 0, 0, 5,\n",
      "       5, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "       0, 1, 0, 1, 2, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 2, 0, 0, 4, 1, 0, 0,\n",
      "       3, 0, 3, 1, 6, 0, 4, 0, 0, 0, 0, 4, 0, 0, 1, 0, 0, 0, 0, 3, 0, 4,\n",
      "       1, 0, 0, 0, 1, 0, 0, 4, 0, 4, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 0, 4, 0, 1, 5, 0, 0, 0, 0, 1, 0, 0, 4, 0, 0, 0, 0, 0, 3, 0, 5,\n",
      "       2, 0, 0, 0, 3, 0, 0, 0, 6, 0, 1, 0, 0, 0, 0, 1, 4, 4, 0, 3, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 6, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 5, 1, 6, 4, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 3, 0, 4, 0, 0, 1, 0, 4, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 4,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 6, 0, 6, 0, 0, 0, 0, 6, 0, 0,\n",
      "       0, 0, 6, 0, 0, 0, 0, 0, 2, 0, 0, 0, 6, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 5, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
      "       0, 0, 0, 5, 0, 0, 1, 1, 0, 6, 3, 0, 0, 1, 5, 0, 0, 0, 0, 1, 0, 4,\n",
      "       0, 0, 0, 0, 0, 2, 1, 0, 6, 0, 0, 0, 3, 0, 3, 0, 1, 0, 0, 4, 1, 0,\n",
      "       0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 5, 5, 5, 0, 0,\n",
      "       1, 0, 1, 3, 6, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 6, 3, 0, 0, 5, 3, 0,\n",
      "       6, 0, 0, 6, 0, 5, 0, 0, 0, 0, 3, 1, 0, 0, 0, 5, 0, 0, 0, 2, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 2, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 0,\n",
      "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 5, 0, 0, 1, 0, 0, 0, 0, 2, 1, 5, 0, 0, 0]), 'Next Training set size': 148}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 148\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:04, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:06:49.470907Z [info     ] Start Predict                  dataset=439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 40.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9230004549026489, 'eval_accuracy': 0.675, 'eval_runtime': 1.0633, 'eval_samples_per_second': 263.322, 'eval_steps_per_second': 32.915, 'epoch': 5, 'labeled_data': array([0, 0, 1, 0, 0, 4, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 0, 0,\n",
      "       2, 0, 4, 1, 0, 0, 2, 6, 0, 0, 0, 0, 0, 0, 0, 6, 3, 0, 0, 0, 0, 5,\n",
      "       5, 7, 1, 0, 0, 0, 0, 1, 0, 3, 0, 0, 2, 0, 7, 7, 0, 4, 0, 0, 0, 5,\n",
      "       5, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 7, 0, 1, 0, 0, 0,\n",
      "       0, 1, 0, 1, 2, 0, 0, 0, 3, 0, 0, 0, 0, 7, 0, 2, 7, 0, 4, 1, 0, 0,\n",
      "       3, 0, 3, 1, 6, 7, 4, 0, 0, 0, 0, 4, 0, 0, 1, 0, 0, 0, 0, 3, 0, 4,\n",
      "       1, 0, 0, 0, 1, 0, 0, 4, 0, 4, 0, 0, 0, 2, 0, 0, 0, 0, 0, 7, 0, 0,\n",
      "       1, 0, 4, 0, 1, 5, 0, 0, 0, 0, 1, 0, 0, 4, 0, 0, 0, 7, 0, 3, 0, 5,\n",
      "       2, 0, 0, 0, 3, 0, 0, 0, 6, 0, 1, 0, 0, 0, 0, 1, 4, 4, 0, 3, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 6, 0, 0, 0, 0,\n",
      "       0, 0, 1, 7, 0, 0, 0, 0, 0, 0, 0, 1, 5, 1, 6, 4, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 3, 0, 4, 0, 0, 1, 0, 4, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 4,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 6, 0, 6, 0, 0, 0, 0, 6, 0, 0,\n",
      "       0, 0, 6, 0, 0, 0, 0, 0, 2, 0, 0, 0, 6, 0, 1, 0, 0, 0, 0, 7, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 5, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
      "       0, 0, 0, 5, 0, 0, 1, 1, 0, 6, 3, 0, 0, 1, 5, 0, 0, 0, 0, 1, 0, 4,\n",
      "       0, 0, 0, 0, 0, 2, 1, 0, 6, 0, 0, 0, 3, 0, 3, 0, 1, 0, 0, 4, 1, 0,\n",
      "       0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 5, 5, 5, 0, 0,\n",
      "       1, 0, 1, 3, 6, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 6, 3, 0, 0, 5, 3, 0,\n",
      "       6, 0, 0, 6, 0, 5, 0, 0, 0, 0, 3, 1, 0, 0, 0, 5, 0, 0, 0, 2, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 2, 0, 0, 7,\n",
      "       0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 6, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 0,\n",
      "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 7, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 5, 0, 0, 1, 0, 0, 0, 0, 2, 1, 5, 0, 0, 0]), 'Next Training set size': 168}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 168\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:05, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:06:58.082372Z [info     ] Start Predict                  dataset=419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 39.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9076189398765564, 'eval_accuracy': 0.675, 'eval_runtime': 1.0792, 'eval_samples_per_second': 259.451, 'eval_steps_per_second': 32.431, 'epoch': 6, 'labeled_data': array([0, 0, 1, 8, 8, 4, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 4, 0, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 0, 0,\n",
      "       2, 0, 4, 1, 0, 0, 2, 6, 0, 0, 0, 0, 0, 0, 0, 6, 3, 0, 0, 0, 0, 5,\n",
      "       5, 7, 1, 0, 0, 0, 0, 1, 0, 3, 0, 0, 2, 8, 7, 7, 0, 4, 0, 0, 0, 5,\n",
      "       5, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 7, 0, 1, 0, 0, 0,\n",
      "       0, 1, 0, 1, 2, 0, 0, 0, 3, 8, 0, 0, 0, 7, 0, 2, 7, 0, 4, 1, 0, 0,\n",
      "       3, 0, 3, 1, 6, 7, 4, 0, 0, 0, 0, 4, 0, 0, 1, 0, 0, 0, 0, 3, 0, 4,\n",
      "       1, 0, 0, 0, 1, 0, 0, 4, 0, 4, 0, 0, 0, 2, 8, 0, 8, 0, 0, 7, 0, 0,\n",
      "       1, 0, 4, 0, 1, 5, 0, 0, 0, 0, 1, 0, 0, 4, 0, 0, 0, 7, 0, 3, 0, 5,\n",
      "       2, 0, 0, 0, 3, 0, 0, 0, 6, 0, 1, 0, 0, 0, 0, 1, 4, 4, 0, 3, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 6, 0, 0, 0, 0,\n",
      "       0, 8, 1, 7, 0, 0, 0, 0, 0, 0, 0, 1, 5, 1, 6, 4, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 3, 0, 4, 0, 8, 1, 0, 4, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 4,\n",
      "       0, 0, 0, 0, 1, 0, 0, 8, 0, 0, 0, 8, 6, 0, 6, 0, 0, 0, 0, 6, 0, 0,\n",
      "       0, 0, 6, 0, 0, 0, 0, 0, 2, 0, 0, 0, 6, 0, 1, 0, 0, 0, 0, 7, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 5, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
      "       0, 0, 0, 5, 0, 0, 1, 1, 0, 6, 3, 0, 0, 1, 5, 8, 0, 0, 0, 1, 0, 4,\n",
      "       0, 8, 0, 0, 0, 2, 1, 0, 6, 0, 0, 0, 3, 0, 3, 0, 1, 0, 0, 4, 1, 0,\n",
      "       0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 5, 5, 5, 0, 0,\n",
      "       1, 0, 1, 3, 6, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 6, 3, 0, 0, 5, 3, 0,\n",
      "       6, 0, 0, 6, 0, 5, 0, 0, 0, 0, 3, 1, 0, 0, 0, 5, 0, 0, 0, 2, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
      "       1, 0, 8, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 1, 0,\n",
      "       0, 0, 8, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 8, 0, 5, 6, 0, 2, 0, 0, 7,\n",
      "       0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 6, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 0,\n",
      "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 7, 8, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 5, 0, 0, 1, 8, 0, 0, 0, 2, 1, 5, 0, 0, 0]), 'Next Training set size': 188}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 188\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:06, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:07:07.223491Z [info     ] Start Predict                  dataset=399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 40.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.926516056060791, 'eval_accuracy': 0.675, 'eval_runtime': 1.1351, 'eval_samples_per_second': 246.684, 'eval_steps_per_second': 30.836, 'epoch': 7, 'labeled_data': array([0, 0, 1, 8, 8, 4, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 4, 0, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 9, 6, 0, 0,\n",
      "       2, 0, 4, 1, 0, 0, 2, 6, 0, 0, 0, 0, 0, 0, 0, 6, 3, 0, 0, 0, 0, 5,\n",
      "       5, 7, 1, 0, 0, 0, 0, 1, 0, 3, 0, 0, 2, 8, 7, 7, 0, 4, 0, 0, 0, 5,\n",
      "       5, 2, 0, 0, 0, 0, 0, 9, 1, 0, 0, 1, 9, 0, 0, 0, 7, 0, 1, 0, 0, 0,\n",
      "       0, 1, 0, 1, 2, 0, 0, 0, 3, 8, 9, 0, 0, 7, 0, 2, 7, 9, 4, 1, 0, 0,\n",
      "       3, 0, 3, 1, 6, 7, 4, 0, 0, 0, 0, 4, 0, 0, 1, 0, 0, 0, 0, 3, 0, 4,\n",
      "       1, 0, 0, 0, 1, 0, 0, 4, 0, 4, 0, 0, 0, 2, 8, 0, 8, 0, 0, 7, 0, 0,\n",
      "       1, 0, 4, 0, 1, 5, 0, 0, 0, 0, 1, 0, 0, 4, 0, 0, 0, 7, 0, 3, 0, 5,\n",
      "       2, 0, 0, 9, 3, 0, 0, 0, 6, 0, 1, 0, 0, 0, 0, 1, 4, 4, 9, 3, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 6, 0, 0, 0, 0,\n",
      "       0, 8, 1, 7, 0, 0, 9, 0, 9, 9, 0, 1, 5, 1, 6, 4, 0, 0, 0, 0, 0, 0,\n",
      "       9, 0, 3, 9, 4, 0, 8, 1, 0, 4, 0, 9, 0, 0, 0, 0, 5, 0, 0, 0, 0, 4,\n",
      "       0, 0, 0, 0, 1, 0, 0, 8, 0, 0, 9, 8, 6, 0, 6, 0, 0, 0, 0, 6, 0, 0,\n",
      "       0, 0, 6, 0, 0, 0, 0, 0, 2, 0, 0, 0, 6, 0, 1, 0, 0, 0, 0, 7, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 9, 0, 5, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
      "       0, 0, 0, 5, 0, 0, 1, 1, 0, 6, 3, 0, 0, 1, 5, 8, 0, 0, 0, 1, 0, 4,\n",
      "       0, 8, 0, 0, 0, 2, 1, 0, 6, 0, 0, 0, 3, 0, 3, 0, 1, 0, 0, 4, 1, 0,\n",
      "       0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 5, 5, 5, 0, 0,\n",
      "       1, 0, 1, 3, 6, 0, 3, 0, 0, 9, 3, 0, 0, 0, 0, 6, 3, 0, 0, 5, 3, 0,\n",
      "       6, 0, 0, 6, 0, 5, 0, 0, 0, 0, 3, 1, 0, 0, 0, 5, 0, 0, 0, 2, 0, 0,\n",
      "       0, 0, 0, 0, 0, 9, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
      "       1, 0, 8, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 1, 0,\n",
      "       0, 0, 8, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 8, 0, 5, 6, 0, 2, 0, 0, 7,\n",
      "       0, 0, 0, 0, 9, 0, 7, 7, 0, 0, 6, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 0,\n",
      "       0, 0, 0, 0, 0, 1, 9, 0, 0, 1, 7, 8, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 5, 0, 0, 1, 8, 0, 0, 0, 2, 1, 5, 0, 0, 0]), 'Next Training set size': 208}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 208\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 78\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='78' max='78' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [78/78 00:06, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:07:17.023358Z [info     ] Start Predict                  dataset=379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 38.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9227778911590576, 'eval_accuracy': 0.675, 'eval_runtime': 1.259, 'eval_samples_per_second': 222.404, 'eval_steps_per_second': 27.8, 'epoch': 8, 'labeled_data': array([ 0,  0,  1,  8,  8,  4,  0,  7,  7,  0,  0,  0, 10,  0,  0,  0,  9,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  4,  0,  8,  8,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  1,  9,  6,  0,  0,  2,  0,  4,  1,  0,  0,  2,\n",
      "        6,  0,  0,  0,  0,  0,  0,  0,  6,  3,  0, 10,  0,  0,  5,  5,  7,\n",
      "        1,  0,  0,  0,  0,  1,  0,  3,  0,  0,  2,  8,  7,  7,  0,  4,  0,\n",
      "        0,  0,  5,  5,  2,  0,  0,  0,  0,  0,  9,  1,  0,  0,  1,  9,  0,\n",
      "        0,  0,  7,  0,  1,  0,  0,  0,  0,  1,  0,  1,  2,  0,  0,  0,  3,\n",
      "        8,  9,  0,  0,  7,  0,  2,  7,  9,  4,  1,  0, 10,  3,  0,  3,  1,\n",
      "        6,  7,  4,  0,  0,  0,  0,  4,  0,  0,  1,  0,  0,  0,  0,  3,  0,\n",
      "        4,  1,  0,  0,  0,  1,  0,  0,  4, 10,  4,  0,  0,  0,  2,  8,  0,\n",
      "        8,  0,  0,  7,  0,  0,  1,  0,  4,  0,  1,  5,  0,  0,  0,  0,  1,\n",
      "        0,  0,  4,  0,  0,  0,  7,  0,  3,  0,  5,  2,  0,  0,  9,  3,  0,\n",
      "        0,  0,  6,  0,  1,  0,  0,  0,  0,  1,  4,  4,  9,  3,  0,  0,  0,\n",
      "        0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  6,\n",
      "        0,  0,  0,  0,  0,  8,  1,  7,  0,  0,  9,  0,  9,  9,  0,  1,  5,\n",
      "        1,  6,  4,  0,  0,  0,  0,  0, 10,  9,  0,  3,  9,  4, 10,  8,  1,\n",
      "        0,  4,  0,  9,  0,  0, 10,  0,  5,  0,  0,  0,  0,  4,  0,  0,  0,\n",
      "        0,  1,  0,  0,  8,  0,  0,  9,  8,  6,  0,  6,  0,  0,  0,  0,  6,\n",
      "        0,  0,  0,  0,  6,  0,  0, 10,  0,  0,  2,  0, 10,  0,  6,  0,  1,\n",
      "        0,  0,  0,  0,  7,  0,  0,  0,  0,  0,  0,  0,  0,  9,  0,  5,  1,\n",
      "        1,  0,  0,  0,  0,  0,  0,  0,  0,  2,  0,  0, 10,  0,  0,  5,  0,\n",
      "        0,  1,  1,  0,  6,  3,  0,  0,  1,  5,  8,  0,  0,  0,  1,  0,  4,\n",
      "        0,  8,  0,  0,  0,  2,  1,  0,  6,  0,  0,  0,  3,  0,  3,  0,  1,\n",
      "        0, 10,  4,  1,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0, 10,  0,  0,\n",
      "        0,  1,  0,  1,  0,  5,  5,  5,  0,  0,  1,  0,  1,  3,  6,  0,  3,\n",
      "        0,  0,  9,  3,  0,  0, 10,  0,  6,  3,  0,  0,  5,  3,  0,  6,  0,\n",
      "        0,  6,  0,  5,  0,  0,  0,  0,  3,  1,  0,  0,  0,  5,  0,  0, 10,\n",
      "        2, 10,  0,  0,  0,  0,  0,  0,  9,  0,  0,  0,  8,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  2,  0, 10,  1, 10,  8,  0,  0,  0,  0,  0,  2,\n",
      "        0,  0,  0,  0,  0,  0,  0,  7,  0,  0,  0,  1,  0,  0,  0,  8,  0,\n",
      "        0,  0,  3,  0,  0,  0,  0,  0,  0,  8,  0,  5,  6,  0,  2,  0,  0,\n",
      "        7,  0,  0,  0,  0,  9,  0,  7,  7,  0,  0,  6,  0,  0,  0,  0,  0,\n",
      "        1,  0,  2,  0,  2,  0,  0,  0,  0, 10,  0,  1,  9, 10,  0,  1,  7,\n",
      "        8,  7,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  5,  0,  0,  1,  8,\n",
      "        0, 10,  0,  2,  1,  5,  0,  0,  0]), 'Next Training set size': 228}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 228\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 87\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='87' max='87' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [87/87 00:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:07:29.980412Z [info     ] Start Predict                  dataset=359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 33.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.93983393907547, 'eval_accuracy': 0.675, 'eval_runtime': 1.3298, 'eval_samples_per_second': 210.552, 'eval_steps_per_second': 26.319, 'epoch': 9, 'labeled_data': array([ 0,  0,  1,  8,  8,  4,  0,  7,  7,  0,  0,  0, 10,  0,  0,  0,  9,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  4,  0,  8,  8,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  1,  9,  6,  0,  0,  2,  0,  4,  1,  0,  0,  2,\n",
      "        6,  0,  0,  0,  0,  0,  0,  0,  6,  3,  0, 10,  0,  0,  5,  5,  7,\n",
      "        1,  0,  0,  0,  0,  1,  0,  3,  0,  0,  2,  8,  7,  7,  0,  4,  0,\n",
      "        0,  0,  5,  5,  2,  0,  0,  0, 11,  0,  9,  1,  0,  0,  1,  9,  0,\n",
      "        0,  0,  7,  0,  1,  0,  0,  0,  0,  1,  0,  1,  2,  0,  0,  0,  3,\n",
      "        8,  9,  0,  0,  7,  0,  2,  7,  9,  4,  1, 11, 10,  3,  0,  3,  1,\n",
      "        6,  7,  4,  0,  0,  0,  0,  4,  0,  0,  1,  0, 11,  0,  0,  3,  0,\n",
      "        4,  1,  0,  0,  0,  1,  0,  0,  4, 10,  4,  0,  0, 11,  2,  8,  0,\n",
      "        8,  0,  0,  7,  0,  0,  1,  0,  4,  0,  1,  5, 11,  0,  0,  0,  1,\n",
      "        0,  0,  4,  0,  0,  0,  7,  0,  3,  0,  5,  2,  0,  0,  9,  3,  0,\n",
      "        0,  0,  6,  0,  1,  0,  0,  0,  0,  1,  4,  4,  9,  3,  0,  0,  0,\n",
      "        0,  0, 11,  1,  0,  0,  0, 11,  0,  0,  0,  2,  0,  0,  0,  0,  6,\n",
      "        0,  0,  0,  0,  0,  8,  1,  7, 11,  0,  9,  0,  9,  9,  0,  1,  5,\n",
      "        1,  6,  4,  0,  0, 11,  0,  0, 10,  9,  0,  3,  9,  4, 10,  8,  1,\n",
      "        0,  4,  0,  9,  0,  0, 10,  0,  5,  0,  0,  0, 11,  4,  0,  0,  0,\n",
      "        0,  1,  0,  0,  8,  0,  0,  9,  8,  6,  0,  6,  0,  0,  0,  0,  6,\n",
      "        0,  0, 11,  0,  6,  0,  0, 10,  0,  0,  2,  0, 10,  0,  6,  0,  1,\n",
      "        0,  0,  0,  0,  7,  0,  0,  0,  0,  0,  0,  0,  0,  9,  0,  5,  1,\n",
      "        1,  0, 11,  0,  0,  0,  0,  0,  0,  2,  0,  0, 10,  0,  0,  5,  0,\n",
      "        0,  1,  1,  0,  6,  3,  0,  0,  1,  5,  8,  0,  0,  0,  1,  0,  4,\n",
      "        0,  8, 11,  0,  0,  2,  1,  0,  6,  0,  0,  0,  3,  0,  3,  0,  1,\n",
      "        0, 10,  4,  1,  0,  0,  2,  0,  0, 11,  0,  0,  0,  0, 10,  0,  0,\n",
      "        0,  1,  0,  1,  0,  5,  5,  5,  0,  0,  1,  0,  1,  3,  6,  0,  3,\n",
      "        0,  0,  9,  3,  0,  0, 10,  0,  6,  3,  0,  0,  5,  3,  0,  6,  0,\n",
      "        0,  6,  0,  5,  0, 11,  0,  0,  3,  1,  0,  0,  0,  5,  0,  0, 10,\n",
      "        2, 10,  0,  0,  0,  0,  0,  0,  9,  0,  0,  0,  8,  0,  0,  0, 11,\n",
      "        0,  0,  0,  0,  0,  2,  0, 10,  1, 10,  8,  0, 11,  0,  0,  0,  2,\n",
      "       11,  0,  0,  0,  0,  0,  0,  7,  0,  0,  0,  1,  0,  0,  0,  8,  0,\n",
      "        0,  0,  3,  0,  0,  0, 11,  0,  0,  8,  0,  5,  6,  0,  2,  0,  0,\n",
      "        7,  0,  0,  0,  0,  9,  0,  7,  7,  0,  0,  6,  0,  0,  0,  0,  0,\n",
      "        1,  0,  2,  0,  2,  0,  0,  0,  0, 10,  0,  1,  9, 10,  0,  1,  7,\n",
      "        8,  7,  7,  0,  0,  0,  0,  0,  0,  0,  0, 11,  5,  0,  0,  1,  8,\n",
      "        0, 10,  0,  2,  1,  5,  0,  0,  0]), 'Next Training set size': 248}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 248\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 93\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='93' max='93' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [93/93 00:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:07:42.301900Z [info     ] Start Predict                  dataset=339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 34.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9216513633728027, 'eval_accuracy': 0.675, 'eval_runtime': 1.1912, 'eval_samples_per_second': 235.057, 'eval_steps_per_second': 29.382, 'epoch': 10, 'labeled_data': array([ 0,  0,  1,  8,  8,  4,  0,  7,  7, 12,  0,  0, 10,  0,  0,  0,  9,\n",
      "        0,  0,  0, 12, 12,  0,  0, 12,  4,  0,  8,  8,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  1,  9,  6,  0,  0,  2,  0,  4,  1,  0,  0,  2,\n",
      "        6,  0,  0,  0,  0,  0,  0,  0,  6,  3,  0, 10,  0,  0,  5,  5,  7,\n",
      "        1,  0,  0,  0,  0,  1,  0,  3,  0,  0,  2,  8,  7,  7,  0,  4,  0,\n",
      "        0,  0,  5,  5,  2,  0,  0,  0, 11,  0,  9,  1,  0,  0,  1,  9,  0,\n",
      "        0,  0,  7,  0,  1,  0,  0,  0,  0,  1,  0,  1,  2, 12,  0,  0,  3,\n",
      "        8,  9, 12,  0,  7,  0,  2,  7,  9,  4,  1, 11, 10,  3,  0,  3,  1,\n",
      "        6,  7,  4,  0,  0,  0,  0,  4,  0,  0,  1, 12, 11,  0,  0,  3,  0,\n",
      "        4,  1,  0,  0,  0,  1,  0,  0,  4, 10,  4,  0,  0, 11,  2,  8,  0,\n",
      "        8,  0,  0,  7,  0,  0,  1,  0,  4,  0,  1,  5, 11,  0,  0,  0,  1,\n",
      "        0,  0,  4,  0,  0,  0,  7,  0,  3,  0,  5,  2,  0,  0,  9,  3,  0,\n",
      "        0,  0,  6,  0,  1,  0,  0,  0,  0,  1,  4,  4,  9,  3,  0,  0,  0,\n",
      "        0,  0, 11,  1,  0,  0, 12, 11,  0, 12,  0,  2,  0,  0,  0,  0,  6,\n",
      "        0,  0, 12,  0,  0,  8,  1,  7, 11,  0,  9,  0,  9,  9,  0,  1,  5,\n",
      "        1,  6,  4,  0,  0, 11,  0,  0, 10,  9,  0,  3,  9,  4, 10,  8,  1,\n",
      "        0,  4,  0,  9, 12,  0, 10,  0,  5,  0,  0,  0, 11,  4,  0,  0,  0,\n",
      "        0,  1,  0,  0,  8,  0,  0,  9,  8,  6,  0,  6,  0,  0,  0,  0,  6,\n",
      "        0,  0, 11,  0,  6,  0,  0, 10,  0,  0,  2,  0, 10,  0,  6,  0,  1,\n",
      "        0,  0,  0,  0,  7,  0,  0,  0,  0, 12,  0,  0,  0,  9,  0,  5,  1,\n",
      "        1,  0, 11,  0,  0,  0, 12,  0,  0,  2,  0,  0, 10,  0,  0,  5,  0,\n",
      "        0,  1,  1,  0,  6,  3,  0,  0,  1,  5,  8,  0,  0,  0,  1,  0,  4,\n",
      "        0,  8, 11,  0,  0,  2,  1,  0,  6,  0,  0,  0,  3,  0,  3,  0,  1,\n",
      "        0, 10,  4,  1,  0,  0,  2,  0,  0, 11,  0,  0,  0,  0, 10,  0,  0,\n",
      "        0,  1,  0,  1,  0,  5,  5,  5,  0,  0,  1,  0,  1,  3,  6,  0,  3,\n",
      "        0,  0,  9,  3,  0,  0, 10,  0,  6,  3,  0,  0,  5,  3,  0,  6,  0,\n",
      "        0,  6,  0,  5,  0, 11,  0,  0,  3,  1,  0,  0,  0,  5,  0,  0, 10,\n",
      "        2, 10,  0,  0,  0, 12,  0,  0,  9,  0,  0,  0,  8,  0,  0,  0, 11,\n",
      "        0,  0,  0,  0,  0,  2,  0, 10,  1, 10,  8, 12, 11,  0,  0,  0,  2,\n",
      "       11,  0,  0,  0,  0,  0,  0,  7,  0,  0,  0,  1,  0,  0,  0,  8, 12,\n",
      "       12,  0,  3,  0,  0,  0, 11,  0,  0,  8,  0,  5,  6,  0,  2,  0,  0,\n",
      "        7,  0,  0,  0,  0,  9, 12,  7,  7,  0,  0,  6,  0,  0, 12,  0,  0,\n",
      "        1,  0,  2,  0,  2,  0,  0,  0,  0, 10,  0,  1,  9, 10,  0,  1,  7,\n",
      "        8,  7,  7,  0,  0,  0,  0,  0,  0,  0,  0, 11,  5,  0,  0,  1,  8,\n",
      "        0, 10,  0,  2,  1,  5, 12,  0,  0]), 'Next Training set size': 268}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 268\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 102\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='102' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 00:10, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:07:55.631983Z [info     ] Start Predict                  dataset=319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 33.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9343017339706421, 'eval_accuracy': 0.675, 'eval_runtime': 1.2973, 'eval_samples_per_second': 215.832, 'eval_steps_per_second': 26.979, 'epoch': 11, 'labeled_data': array([13,  0,  1,  8,  8,  4,  0,  7,  7, 12,  0,  0, 10, 13,  0,  0,  9,\n",
      "        0,  0,  0, 12, 12,  0,  0, 12,  4,  0,  8,  8,  0,  0,  0,  0,  0,\n",
      "       13,  0,  0,  0,  0,  1,  9,  6,  0,  0,  2,  0,  4,  1,  0,  0,  2,\n",
      "        6,  0,  0,  0,  0, 13,  0,  0,  6,  3,  0, 10,  0,  0,  5,  5,  7,\n",
      "        1,  0,  0,  0,  0,  1,  0,  3,  0,  0,  2,  8,  7,  7,  0,  4,  0,\n",
      "       13,  0,  5,  5,  2,  0,  0,  0, 11,  0,  9,  1,  0,  0,  1,  9,  0,\n",
      "        0,  0,  7,  0,  1,  0,  0,  0,  0,  1,  0,  1,  2, 12,  0,  0,  3,\n",
      "        8,  9, 12,  0,  7,  0,  2,  7,  9,  4,  1, 11, 10,  3,  0,  3,  1,\n",
      "        6,  7,  4,  0,  0,  0,  0,  4,  0,  0,  1, 12, 11,  0,  0,  3,  0,\n",
      "        4,  1,  0,  0,  0,  1,  0,  0,  4, 10,  4,  0,  0, 11,  2,  8, 13,\n",
      "        8,  0,  0,  7,  0,  0,  1,  0,  4,  0,  1,  5, 11,  0,  0,  0,  1,\n",
      "        0,  0,  4,  0,  0,  0,  7,  0,  3,  0,  5,  2,  0,  0,  9,  3,  0,\n",
      "        0,  0,  6,  0,  1,  0,  0,  0,  0,  1,  4,  4,  9,  3,  0,  0,  0,\n",
      "        0,  0, 11,  1,  0,  0, 12, 11,  0, 12,  0,  2,  0,  0,  0,  0,  6,\n",
      "        0,  0, 12,  0,  0,  8,  1,  7, 11,  0,  9,  0,  9,  9,  0,  1,  5,\n",
      "        1,  6,  4,  0,  0, 11, 13,  0, 10,  9,  0,  3,  9,  4, 10,  8,  1,\n",
      "        0,  4,  0,  9, 12,  0, 10,  0,  5,  0,  0,  0, 11,  4,  0,  0,  0,\n",
      "        0,  1,  0, 13,  8,  0,  0,  9,  8,  6,  0,  6,  0,  0,  0,  0,  6,\n",
      "        0,  0, 11,  0,  6,  0,  0, 10,  0,  0,  2, 13, 10,  0,  6,  0,  1,\n",
      "        0,  0,  0,  0,  7,  0,  0,  0,  0, 12,  0, 13,  0,  9,  0,  5,  1,\n",
      "        1,  0, 11,  0, 13,  0, 12,  0,  0,  2, 13, 13, 10,  0,  0,  5,  0,\n",
      "        0,  1,  1,  0,  6,  3, 13,  0,  1,  5,  8,  0,  0,  0,  1,  0,  4,\n",
      "        0,  8, 11,  0,  0,  2,  1,  0,  6,  0,  0,  0,  3,  0,  3, 13,  1,\n",
      "        0, 10,  4,  1,  0,  0,  2,  0,  0, 11,  0,  0,  0,  0, 10,  0,  0,\n",
      "        0,  1,  0,  1,  0,  5,  5,  5,  0,  0,  1,  0,  1,  3,  6,  0,  3,\n",
      "        0,  0,  9,  3,  0,  0, 10,  0,  6,  3,  0,  0,  5,  3,  0,  6,  0,\n",
      "        0,  6,  0,  5,  0, 11,  0,  0,  3,  1,  0,  0,  0,  5,  0,  0, 10,\n",
      "        2, 10,  0,  0,  0, 12,  0,  0,  9,  0,  0,  0,  8, 13,  0,  0, 11,\n",
      "        0,  0,  0,  0,  0,  2,  0, 10,  1, 10,  8, 12, 11,  0,  0,  0,  2,\n",
      "       11,  0,  0, 13,  0,  0,  0,  7,  0,  0,  0,  1,  0,  0,  0,  8, 12,\n",
      "       12,  0,  3,  0,  0, 13, 11,  0,  0,  8,  0,  5,  6,  0,  2,  0,  0,\n",
      "        7,  0, 13,  0, 13,  9, 12,  7,  7,  0,  0,  6,  0,  0, 12,  0,  0,\n",
      "        1,  0,  2,  0,  2,  0,  0,  0,  0, 10,  0,  1,  9, 10,  0,  1,  7,\n",
      "        8,  7,  7,  0,  0,  0,  0,  0,  0,  0,  0, 11,  5,  0,  0,  1,  8,\n",
      "        0, 10,  0,  2,  1,  5, 12,  0,  0]), 'Next Training set size': 288}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 288\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 108\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 00:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:08:09.727621Z [info     ] Start Predict                  dataset=299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 35.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9148297905921936, 'eval_accuracy': 0.675, 'eval_runtime': 1.2062, 'eval_samples_per_second': 232.141, 'eval_steps_per_second': 29.018, 'epoch': 12, 'labeled_data': array([13,  0,  1,  8,  8,  4,  0,  7,  7, 12,  0,  0, 10, 13,  0, 14,  9,\n",
      "        0,  0,  0, 12, 12, 14, 14, 12,  4,  0,  8,  8,  0,  0,  0,  0, 14,\n",
      "       13,  0,  0,  0,  0,  1,  9,  6,  0,  0,  2,  0,  4,  1,  0,  0,  2,\n",
      "        6,  0,  0,  0,  0, 13, 14,  0,  6,  3,  0, 10,  0,  0,  5,  5,  7,\n",
      "        1,  0,  0,  0,  0,  1,  0,  3,  0, 14,  2,  8,  7,  7,  0,  4,  0,\n",
      "       13,  0,  5,  5,  2,  0,  0,  0, 11,  0,  9,  1,  0,  0,  1,  9,  0,\n",
      "        0,  0,  7,  0,  1,  0,  0,  0,  0,  1,  0,  1,  2, 12,  0,  0,  3,\n",
      "        8,  9, 12,  0,  7,  0,  2,  7,  9,  4,  1, 11, 10,  3,  0,  3,  1,\n",
      "        6,  7,  4,  0,  0,  0,  0,  4,  0,  0,  1, 12, 11,  0,  0,  3,  0,\n",
      "        4,  1,  0,  0,  0,  1,  0,  0,  4, 10,  4,  0,  0, 11,  2,  8, 13,\n",
      "        8,  0,  0,  7,  0,  0,  1,  0,  4,  0,  1,  5, 11,  0,  0,  0,  1,\n",
      "        0,  0,  4,  0,  0,  0,  7,  0,  3,  0,  5,  2,  0,  0,  9,  3,  0,\n",
      "        0,  0,  6, 14,  1,  0,  0,  0,  0,  1,  4,  4,  9,  3,  0,  0,  0,\n",
      "        0,  0, 11,  1,  0,  0, 12, 11,  0, 12,  0,  2,  0,  0,  0,  0,  6,\n",
      "        0,  0, 12,  0,  0,  8,  1,  7, 11,  0,  9,  0,  9,  9,  0,  1,  5,\n",
      "        1,  6,  4, 14,  0, 11, 13,  0, 10,  9, 14,  3,  9,  4, 10,  8,  1,\n",
      "        0,  4,  0,  9, 12,  0, 10,  0,  5,  0,  0,  0, 11,  4,  0,  0,  0,\n",
      "        0,  1,  0, 13,  8,  0, 14,  9,  8,  6,  0,  6,  0, 14,  0,  0,  6,\n",
      "        0,  0, 11,  0,  6,  0,  0, 10,  0,  0,  2, 13, 10,  0,  6,  0,  1,\n",
      "        0,  0,  0,  0,  7,  0,  0,  0,  0, 12,  0, 13,  0,  9,  0,  5,  1,\n",
      "        1,  0, 11,  0, 13,  0, 12,  0,  0,  2, 13, 13, 10,  0,  0,  5,  0,\n",
      "        0,  1,  1,  0,  6,  3, 13, 14,  1,  5,  8,  0,  0,  0,  1,  0,  4,\n",
      "        0,  8, 11,  0,  0,  2,  1,  0,  6,  0,  0,  0,  3,  0,  3, 13,  1,\n",
      "        0, 10,  4,  1,  0,  0,  2,  0,  0, 11,  0,  0,  0,  0, 10,  0,  0,\n",
      "        0,  1,  0,  1, 14,  5,  5,  5, 14,  0,  1,  0,  1,  3,  6,  0,  3,\n",
      "        0,  0,  9,  3,  0,  0, 10,  0,  6,  3,  0,  0,  5,  3, 14,  6,  0,\n",
      "        0,  6,  0,  5,  0, 11,  0,  0,  3,  1,  0,  0,  0,  5,  0,  0, 10,\n",
      "        2, 10,  0,  0,  0, 12,  0,  0,  9,  0,  0,  0,  8, 13,  0,  0, 11,\n",
      "       14, 14,  0,  0,  0,  2,  0, 10,  1, 10,  8, 12, 11,  0,  0,  0,  2,\n",
      "       11,  0,  0, 13,  0,  0,  0,  7,  0,  0,  0,  1,  0,  0,  0,  8, 12,\n",
      "       12,  0,  3,  0,  0, 13, 11,  0,  0,  8,  0,  5,  6,  0,  2,  0,  0,\n",
      "        7,  0, 13,  0, 13,  9, 12,  7,  7,  0,  0,  6,  0,  0, 12,  0, 14,\n",
      "        1,  0,  2, 14,  2,  0,  0,  0,  0, 10,  0,  1,  9, 10,  0,  1,  7,\n",
      "        8,  7,  7,  0,  0,  0,  0,  0,  0,  0, 14, 11,  5,  0,  0,  1,  8,\n",
      "        0, 10,  0,  2,  1,  5, 12,  0,  0]), 'Next Training set size': 308}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 308\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 117\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='117' max='117' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [117/117 00:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:08:24.322569Z [info     ] Start Predict                  dataset=279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:00<00:00, 36.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9187593460083008, 'eval_accuracy': 0.675, 'eval_runtime': 1.1718, 'eval_samples_per_second': 238.946, 'eval_steps_per_second': 29.868, 'epoch': 13, 'labeled_data': array([13,  0,  1,  8,  8,  4,  0,  7,  7, 12,  0,  0, 10, 13,  0, 14,  9,\n",
      "        0,  0,  0, 12, 12, 14, 14, 12,  4, 15,  8,  8,  0,  0,  0,  0, 14,\n",
      "       13, 15,  0, 15,  0,  1,  9,  6,  0,  0,  2,  0,  4,  1,  0,  0,  2,\n",
      "        6,  0,  0,  0,  0, 13, 14,  0,  6,  3,  0, 10,  0,  0,  5,  5,  7,\n",
      "        1,  0,  0,  0,  0,  1,  0,  3,  0, 14,  2,  8,  7,  7, 15,  4,  0,\n",
      "       13,  0,  5,  5,  2,  0,  0,  0, 11,  0,  9,  1,  0,  0,  1,  9,  0,\n",
      "        0,  0,  7, 15,  1,  0, 15,  0,  0,  1,  0,  1,  2, 12,  0, 15,  3,\n",
      "        8,  9, 12,  0,  7,  0,  2,  7,  9,  4,  1, 11, 10,  3,  0,  3,  1,\n",
      "        6,  7,  4,  0,  0,  0,  0,  4,  0,  0,  1, 12, 11,  0,  0,  3,  0,\n",
      "        4,  1,  0,  0,  0,  1,  0,  0,  4, 10,  4,  0,  0, 11,  2,  8, 13,\n",
      "        8,  0,  0,  7,  0,  0,  1,  0,  4,  0,  1,  5, 11,  0,  0,  0,  1,\n",
      "        0,  0,  4,  0, 15,  0,  7,  0,  3,  0,  5,  2, 15,  0,  9,  3,  0,\n",
      "        0, 15,  6, 14,  1,  0,  0,  0,  0,  1,  4,  4,  9,  3,  0,  0,  0,\n",
      "        0,  0, 11,  1,  0,  0, 12, 11,  0, 12,  0,  2, 15,  0,  0,  0,  6,\n",
      "        0,  0, 12,  0,  0,  8,  1,  7, 11,  0,  9,  0,  9,  9, 15,  1,  5,\n",
      "        1,  6,  4, 14,  0, 11, 13,  0, 10,  9, 14,  3,  9,  4, 10,  8,  1,\n",
      "        0,  4,  0,  9, 12,  0, 10,  0,  5,  0,  0,  0, 11,  4,  0,  0,  0,\n",
      "        0,  1,  0, 13,  8,  0, 14,  9,  8,  6,  0,  6,  0, 14,  0,  0,  6,\n",
      "        0,  0, 11,  0,  6,  0,  0, 10,  0,  0,  2, 13, 10,  0,  6,  0,  1,\n",
      "        0,  0,  0,  0,  7,  0,  0,  0,  0, 12,  0, 13,  0,  9,  0,  5,  1,\n",
      "        1,  0, 11,  0, 13,  0, 12,  0,  0,  2, 13, 13, 10,  0,  0,  5,  0,\n",
      "        0,  1,  1,  0,  6,  3, 13, 14,  1,  5,  8,  0,  0,  0,  1,  0,  4,\n",
      "        0,  8, 11,  0,  0,  2,  1,  0,  6,  0,  0,  0,  3,  0,  3, 13,  1,\n",
      "        0, 10,  4,  1,  0,  0,  2,  0,  0, 11,  0,  0,  0,  0, 10,  0,  0,\n",
      "        0,  1,  0,  1, 14,  5,  5,  5, 14,  0,  1,  0,  1,  3,  6,  0,  3,\n",
      "        0,  0,  9,  3,  0,  0, 10,  0,  6,  3,  0,  0,  5,  3, 14,  6,  0,\n",
      "        0,  6,  0,  5,  0, 11,  0,  0,  3,  1,  0,  0,  0,  5,  0,  0, 10,\n",
      "        2, 10,  0, 15,  0, 12,  0,  0,  9,  0, 15,  0,  8, 13,  0,  0, 11,\n",
      "       14, 14,  0,  0,  0,  2,  0, 10,  1, 10,  8, 12, 11,  0,  0,  0,  2,\n",
      "       11,  0,  0, 13,  0,  0,  0,  7,  0,  0, 15,  1,  0,  0,  0,  8, 12,\n",
      "       12,  0,  3,  0,  0, 13, 11,  0,  0,  8,  0,  5,  6, 15,  2,  0,  0,\n",
      "        7,  0, 13,  0, 13,  9, 12,  7,  7,  0,  0,  6,  0, 15, 12,  0, 14,\n",
      "        1,  0,  2, 14,  2, 15,  0,  0,  0, 10,  0,  1,  9, 10, 15,  1,  7,\n",
      "        8,  7,  7,  0, 15,  0,  0,  0,  0,  0, 14, 11,  5,  0,  0,  1,  8,\n",
      "        0, 10,  0,  2,  1,  5, 12,  0,  0]), 'Next Training set size': 328}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 328\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 123\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='123' max='123' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [123/123 00:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:08:38.786659Z [info     ] Start Predict                  dataset=259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 34.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9154689311981201, 'eval_accuracy': 0.675, 'eval_runtime': 1.1617, 'eval_samples_per_second': 241.024, 'eval_steps_per_second': 30.128, 'epoch': 14, 'labeled_data': array([13, 16,  1,  8,  8,  4,  0,  7,  7, 12,  0,  0, 10, 13, 16, 14,  9,\n",
      "        0,  0,  0, 12, 12, 14, 14, 12,  4, 15,  8,  8,  0,  0,  0,  0, 14,\n",
      "       13, 15,  0, 15,  0,  1,  9,  6,  0,  0,  2,  0,  4,  1, 16,  0,  2,\n",
      "        6,  0, 16,  0,  0, 13, 14,  0,  6,  3,  0, 10,  0,  0,  5,  5,  7,\n",
      "        1,  0,  0,  0,  0,  1,  0,  3,  0, 14,  2,  8,  7,  7, 15,  4,  0,\n",
      "       13,  0,  5,  5,  2,  0,  0,  0, 11,  0,  9,  1,  0,  0,  1,  9,  0,\n",
      "        0,  0,  7, 15,  1,  0, 15,  0,  0,  1,  0,  1,  2, 12,  0, 15,  3,\n",
      "        8,  9, 12,  0,  7,  0,  2,  7,  9,  4,  1, 11, 10,  3, 16,  3,  1,\n",
      "        6,  7,  4,  0,  0,  0,  0,  4,  0,  0,  1, 12, 11,  0,  0,  3,  0,\n",
      "        4,  1,  0, 16,  0,  1,  0,  0,  4, 10,  4,  0,  0, 11,  2,  8, 13,\n",
      "        8,  0,  0,  7,  0,  0,  1,  0,  4, 16,  1,  5, 11,  0,  0,  0,  1,\n",
      "        0, 16,  4,  0, 15,  0,  7,  0,  3,  0,  5,  2, 15,  0,  9,  3,  0,\n",
      "        0, 15,  6, 14,  1,  0,  0,  0,  0,  1,  4,  4,  9,  3,  0, 16,  0,\n",
      "        0,  0, 11,  1,  0, 16, 12, 11,  0, 12,  0,  2, 15, 16,  0,  0,  6,\n",
      "        0,  0, 12,  0,  0,  8,  1,  7, 11,  0,  9, 16,  9,  9, 15,  1,  5,\n",
      "        1,  6,  4, 14,  0, 11, 13,  0, 10,  9, 14,  3,  9,  4, 10,  8,  1,\n",
      "        0,  4,  0,  9, 12,  0, 10,  0,  5,  0,  0,  0, 11,  4,  0,  0,  0,\n",
      "        0,  1,  0, 13,  8,  0, 14,  9,  8,  6,  0,  6,  0, 14,  0,  0,  6,\n",
      "        0,  0, 11,  0,  6,  0,  0, 10,  0,  0,  2, 13, 10,  0,  6,  0,  1,\n",
      "        0,  0,  0,  0,  7,  0,  0,  0,  0, 12,  0, 13,  0,  9, 16,  5,  1,\n",
      "        1,  0, 11,  0, 13,  0, 12,  0,  0,  2, 13, 13, 10,  0,  0,  5,  0,\n",
      "        0,  1,  1,  0,  6,  3, 13, 14,  1,  5,  8, 16,  0,  0,  1,  0,  4,\n",
      "        0,  8, 11,  0,  0,  2,  1,  0,  6,  0,  0,  0,  3,  0,  3, 13,  1,\n",
      "        0, 10,  4,  1,  0,  0,  2,  0,  0, 11,  0,  0,  0,  0, 10,  0,  0,\n",
      "        0,  1, 16,  1, 14,  5,  5,  5, 14,  0,  1,  0,  1,  3,  6,  0,  3,\n",
      "        0,  0,  9,  3,  0,  0, 10,  0,  6,  3, 16,  0,  5,  3, 14,  6,  0,\n",
      "        0,  6,  0,  5, 16, 11,  0,  0,  3,  1,  0,  0,  0,  5,  0,  0, 10,\n",
      "        2, 10,  0, 15,  0, 12,  0,  0,  9,  0, 15,  0,  8, 13,  0,  0, 11,\n",
      "       14, 14,  0,  0,  0,  2,  0, 10,  1, 10,  8, 12, 11,  0,  0,  0,  2,\n",
      "       11,  0, 16, 13,  0,  0,  0,  7,  0,  0, 15,  1,  0,  0,  0,  8, 12,\n",
      "       12,  0,  3,  0, 16, 13, 11,  0,  0,  8,  0,  5,  6, 15,  2,  0,  0,\n",
      "        7,  0, 13,  0, 13,  9, 12,  7,  7,  0,  0,  6,  0, 15, 12, 16, 14,\n",
      "        1,  0,  2, 14,  2, 15,  0,  0,  0, 10,  0,  1,  9, 10, 15,  1,  7,\n",
      "        8,  7,  7,  0, 15,  0,  0,  0,  0,  0, 14, 11,  5,  0,  0,  1,  8,\n",
      "        0, 10,  0,  2,  1,  5, 12,  0,  0]), 'Next Training set size': 348}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 348\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 00:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:08:54.085289Z [info     ] Start Predict                  dataset=239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 38.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9111045002937317, 'eval_accuracy': 0.675, 'eval_runtime': 1.192, 'eval_samples_per_second': 234.89, 'eval_steps_per_second': 29.361, 'epoch': 15, 'labeled_data': array([13, 16,  1,  8,  8,  4, 17,  7,  7, 12,  0, 17, 10, 13, 16, 14,  9,\n",
      "        0,  0,  0, 12, 12, 14, 14, 12,  4, 15,  8,  8,  0,  0,  0,  0, 14,\n",
      "       13, 15,  0, 15,  0,  1,  9,  6,  0,  0,  2,  0,  4,  1, 16,  0,  2,\n",
      "        6,  0, 16,  0,  0, 13, 14,  0,  6,  3,  0, 10,  0,  0,  5,  5,  7,\n",
      "        1,  0,  0,  0,  0,  1,  0,  3,  0, 14,  2,  8,  7,  7, 15,  4,  0,\n",
      "       13, 17,  5,  5,  2,  0,  0,  0, 11,  0,  9,  1,  0,  0,  1,  9,  0,\n",
      "        0,  0,  7, 15,  1,  0, 15,  0,  0,  1,  0,  1,  2, 12,  0, 15,  3,\n",
      "        8,  9, 12,  0,  7,  0,  2,  7,  9,  4,  1, 11, 10,  3, 16,  3,  1,\n",
      "        6,  7,  4,  0,  0, 17,  0,  4,  0,  0,  1, 12, 11,  0,  0,  3,  0,\n",
      "        4,  1,  0, 16,  0,  1,  0,  0,  4, 10,  4,  0,  0, 11,  2,  8, 13,\n",
      "        8, 17,  0,  7,  0,  0,  1,  0,  4, 16,  1,  5, 11,  0,  0,  0,  1,\n",
      "        0, 16,  4,  0, 15,  0,  7,  0,  3,  0,  5,  2, 15,  0,  9,  3,  0,\n",
      "        0, 15,  6, 14,  1,  0,  0,  0,  0,  1,  4,  4,  9,  3,  0, 16,  0,\n",
      "        0,  0, 11,  1,  0, 16, 12, 11, 17, 12,  0,  2, 15, 16,  0,  0,  6,\n",
      "        0,  0, 12,  0,  0,  8,  1,  7, 11,  0,  9, 16,  9,  9, 15,  1,  5,\n",
      "        1,  6,  4, 14,  0, 11, 13,  0, 10,  9, 14,  3,  9,  4, 10,  8,  1,\n",
      "        0,  4,  0,  9, 12,  0, 10,  0,  5,  0,  0,  0, 11,  4,  0,  0,  0,\n",
      "        0,  1,  0, 13,  8,  0, 14,  9,  8,  6,  0,  6,  0, 14, 17,  0,  6,\n",
      "        0,  0, 11, 17,  6,  0,  0, 10,  0, 17,  2, 13, 10,  0,  6,  0,  1,\n",
      "        0,  0, 17,  0,  7,  0,  0,  0,  0, 12,  0, 13,  0,  9, 16,  5,  1,\n",
      "        1,  0, 11,  0, 13, 17, 12,  0,  0,  2, 13, 13, 10,  0,  0,  5, 17,\n",
      "        0,  1,  1, 17,  6,  3, 13, 14,  1,  5,  8, 16,  0,  0,  1,  0,  4,\n",
      "        0,  8, 11, 17,  0,  2,  1,  0,  6,  0,  0,  0,  3,  0,  3, 13,  1,\n",
      "        0, 10,  4,  1,  0,  0,  2,  0,  0, 11,  0,  0, 17,  0, 10,  0,  0,\n",
      "        0,  1, 16,  1, 14,  5,  5,  5, 14,  0,  1,  0,  1,  3,  6,  0,  3,\n",
      "        0,  0,  9,  3,  0,  0, 10,  0,  6,  3, 16,  0,  5,  3, 14,  6,  0,\n",
      "        0,  6,  0,  5, 16, 11,  0,  0,  3,  1,  0,  0,  0,  5,  0,  0, 10,\n",
      "        2, 10,  0, 15,  0, 12,  0,  0,  9,  0, 15,  0,  8, 13,  0,  0, 11,\n",
      "       14, 14,  0,  0,  0,  2, 17, 10,  1, 10,  8, 12, 11,  0,  0,  0,  2,\n",
      "       11,  0, 16, 13,  0,  0,  0,  7,  0,  0, 15,  1,  0, 17,  0,  8, 12,\n",
      "       12,  0,  3,  0, 16, 13, 11,  0,  0,  8,  0,  5,  6, 15,  2,  0,  0,\n",
      "        7,  0, 13, 17, 13,  9, 12,  7,  7, 17,  0,  6,  0, 15, 12, 16, 14,\n",
      "        1,  0,  2, 14,  2, 15,  0,  0,  0, 10, 17,  1,  9, 10, 15,  1,  7,\n",
      "        8,  7,  7,  0, 15,  0,  0,  0,  0,  0, 14, 11,  5,  0,  0,  1,  8,\n",
      "        0, 10,  0,  2,  1,  5, 12,  0,  0]), 'Next Training set size': 368}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 368\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 138\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='138' max='138' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [138/138 00:13, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:09:09.840659Z [info     ] Start Predict                  dataset=219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 36.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9201644062995911, 'eval_accuracy': 0.675, 'eval_runtime': 1.2058, 'eval_samples_per_second': 232.209, 'eval_steps_per_second': 29.026, 'epoch': 16, 'labeled_data': array([13, 16,  1,  8,  8,  4, 17,  7,  7, 12,  0, 17, 10, 13, 16, 14,  9,\n",
      "        0,  0, 18, 12, 12, 14, 14, 12,  4, 15,  8,  8,  0,  0,  0,  0, 14,\n",
      "       13, 15,  0, 15,  0,  1,  9,  6,  0,  0,  2,  0,  4,  1, 16,  0,  2,\n",
      "        6,  0, 16,  0,  0, 13, 14,  0,  6,  3,  0, 10,  0,  0,  5,  5,  7,\n",
      "        1,  0, 18,  0, 18,  1, 18,  3,  0, 14,  2,  8,  7,  7, 15,  4,  0,\n",
      "       13, 17,  5,  5,  2,  0,  0,  0, 11,  0,  9,  1,  0,  0,  1,  9,  0,\n",
      "       18,  0,  7, 15,  1,  0, 15,  0,  0,  1,  0,  1,  2, 12,  0, 15,  3,\n",
      "        8,  9, 12,  0,  7,  0,  2,  7,  9,  4,  1, 11, 10,  3, 16,  3,  1,\n",
      "        6,  7,  4,  0, 18, 17,  0,  4,  0,  0,  1, 12, 11,  0,  0,  3,  0,\n",
      "        4,  1,  0, 16,  0,  1,  0,  0,  4, 10,  4,  0, 18, 11,  2,  8, 13,\n",
      "        8, 17,  0,  7,  0,  0,  1,  0,  4, 16,  1,  5, 11,  0,  0,  0,  1,\n",
      "        0, 16,  4,  0, 15,  0,  7,  0,  3,  0,  5,  2, 15, 18,  9,  3,  0,\n",
      "        0, 15,  6, 14,  1,  0,  0,  0,  0,  1,  4,  4,  9,  3,  0, 16,  0,\n",
      "        0,  0, 11,  1,  0, 16, 12, 11, 17, 12,  0,  2, 15, 16,  0,  0,  6,\n",
      "        0,  0, 12,  0,  0,  8,  1,  7, 11,  0,  9, 16,  9,  9, 15,  1,  5,\n",
      "        1,  6,  4, 14,  0, 11, 13,  0, 10,  9, 14,  3,  9,  4, 10,  8,  1,\n",
      "        0,  4,  0,  9, 12,  0, 10,  0,  5,  0,  0,  0, 11,  4,  0,  0,  0,\n",
      "        0,  1,  0, 13,  8,  0, 14,  9,  8,  6,  0,  6,  0, 14, 17,  0,  6,\n",
      "        0,  0, 11, 17,  6,  0,  0, 10,  0, 17,  2, 13, 10,  0,  6,  0,  1,\n",
      "        0,  0, 17,  0,  7,  0,  0,  0,  0, 12,  0, 13, 18,  9, 16,  5,  1,\n",
      "        1,  0, 11,  0, 13, 17, 12,  0,  0,  2, 13, 13, 10,  0,  0,  5, 17,\n",
      "        0,  1,  1, 17,  6,  3, 13, 14,  1,  5,  8, 16,  0,  0,  1,  0,  4,\n",
      "        0,  8, 11, 17,  0,  2,  1,  0,  6,  0,  0,  0,  3,  0,  3, 13,  1,\n",
      "       18, 10,  4,  1,  0,  0,  2,  0,  0, 11,  0,  0, 17, 18, 10,  0,  0,\n",
      "        0,  1, 16,  1, 14,  5,  5,  5, 14,  0,  1,  0,  1,  3,  6,  0,  3,\n",
      "       18,  0,  9,  3,  0,  0, 10,  0,  6,  3, 16,  0,  5,  3, 14,  6,  0,\n",
      "        0,  6,  0,  5, 16, 11, 18,  0,  3,  1,  0,  0, 18,  5,  0,  0, 10,\n",
      "        2, 10, 18, 15,  0, 12,  0,  0,  9,  0, 15,  0,  8, 13,  0,  0, 11,\n",
      "       14, 14,  0,  0,  0,  2, 17, 10,  1, 10,  8, 12, 11,  0,  0,  0,  2,\n",
      "       11,  0, 16, 13,  0,  0,  0,  7,  0,  0, 15,  1,  0, 17,  0,  8, 12,\n",
      "       12,  0,  3,  0, 16, 13, 11,  0,  0,  8,  0,  5,  6, 15,  2,  0,  0,\n",
      "        7,  0, 13, 17, 13,  9, 12,  7,  7, 17,  0,  6,  0, 15, 12, 16, 14,\n",
      "        1,  0,  2, 14,  2, 15,  0,  0,  0, 10, 17,  1,  9, 10, 15,  1,  7,\n",
      "        8,  7,  7, 18, 15,  0, 18,  0,  0,  0, 14, 11,  5,  0,  0,  1,  8,\n",
      "       18, 10, 18,  2,  1,  5, 12,  0, 18]), 'Next Training set size': 388}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 388\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 147\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 00:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:09:26.389980Z [info     ] Start Predict                  dataset=199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 35.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9207770228385925, 'eval_accuracy': 0.675, 'eval_runtime': 1.1921, 'eval_samples_per_second': 234.873, 'eval_steps_per_second': 29.359, 'epoch': 17, 'labeled_data': array([13, 16,  1,  8,  8,  4, 17,  7,  7, 12,  0, 17, 10, 13, 16, 14,  9,\n",
      "        0,  0, 18, 12, 12, 14, 14, 12,  4, 15,  8,  8,  0,  0,  0,  0, 14,\n",
      "       13, 15,  0, 15,  0,  1,  9,  6,  0,  0,  2,  0,  4,  1, 16,  0,  2,\n",
      "        6, 19, 16,  0,  0, 13, 14,  0,  6,  3,  0, 10,  0,  0,  5,  5,  7,\n",
      "        1,  0, 18,  0, 18,  1, 18,  3,  0, 14,  2,  8,  7,  7, 15,  4,  0,\n",
      "       13, 17,  5,  5,  2,  0,  0,  0, 11,  0,  9,  1,  0,  0,  1,  9,  0,\n",
      "       18,  0,  7, 15,  1,  0, 15,  0,  0,  1,  0,  1,  2, 12,  0, 15,  3,\n",
      "        8,  9, 12,  0,  7,  0,  2,  7,  9,  4,  1, 11, 10,  3, 16,  3,  1,\n",
      "        6,  7,  4,  0, 18, 17,  0,  4,  0,  0,  1, 12, 11,  0,  0,  3,  0,\n",
      "        4,  1,  0, 16,  0,  1,  0, 19,  4, 10,  4,  0, 18, 11,  2,  8, 13,\n",
      "        8, 17,  0,  7,  0,  0,  1,  0,  4, 16,  1,  5, 11,  0,  0,  0,  1,\n",
      "        0, 16,  4, 19, 15,  0,  7,  0,  3,  0,  5,  2, 15, 18,  9,  3,  0,\n",
      "        0, 15,  6, 14,  1,  0,  0,  0,  0,  1,  4,  4,  9,  3,  0, 16,  0,\n",
      "        0,  0, 11,  1,  0, 16, 12, 11, 17, 12,  0,  2, 15, 16,  0,  0,  6,\n",
      "        0,  0, 12,  0,  0,  8,  1,  7, 11,  0,  9, 16,  9,  9, 15,  1,  5,\n",
      "        1,  6,  4, 14,  0, 11, 13,  0, 10,  9, 14,  3,  9,  4, 10,  8,  1,\n",
      "        0,  4,  0,  9, 12,  0, 10,  0,  5,  0, 19,  0, 11,  4,  0,  0,  0,\n",
      "        0,  1,  0, 13,  8, 19, 14,  9,  8,  6,  0,  6,  0, 14, 17,  0,  6,\n",
      "        0,  0, 11, 17,  6, 19,  0, 10,  0, 17,  2, 13, 10,  0,  6,  0,  1,\n",
      "        0,  0, 17, 19,  7,  0,  0,  0,  0, 12,  0, 13, 18,  9, 16,  5,  1,\n",
      "        1,  0, 11,  0, 13, 17, 12,  0, 19,  2, 13, 13, 10,  0,  0,  5, 17,\n",
      "        0,  1,  1, 17,  6,  3, 13, 14,  1,  5,  8, 16,  0,  0,  1,  0,  4,\n",
      "        0,  8, 11, 17,  0,  2,  1,  0,  6,  0,  0,  0,  3, 19,  3, 13,  1,\n",
      "       18, 10,  4,  1,  0, 19,  2,  0,  0, 11,  0, 19, 17, 18, 10,  0,  0,\n",
      "       19,  1, 16,  1, 14,  5,  5,  5, 14, 19,  1,  0,  1,  3,  6,  0,  3,\n",
      "       18,  0,  9,  3,  0,  0, 10,  0,  6,  3, 16,  0,  5,  3, 14,  6, 19,\n",
      "        0,  6,  0,  5, 16, 11, 18, 19,  3,  1,  0,  0, 18,  5, 19,  0, 10,\n",
      "        2, 10, 18, 15,  0, 12,  0,  0,  9,  0, 15,  0,  8, 13,  0,  0, 11,\n",
      "       14, 14,  0,  0,  0,  2, 17, 10,  1, 10,  8, 12, 11,  0,  0,  0,  2,\n",
      "       11,  0, 16, 13,  0,  0,  0,  7,  0,  0, 15,  1,  0, 17,  0,  8, 12,\n",
      "       12,  0,  3,  0, 16, 13, 11, 19, 19,  8,  0,  5,  6, 15,  2,  0,  0,\n",
      "        7,  0, 13, 17, 13,  9, 12,  7,  7, 17,  0,  6,  0, 15, 12, 16, 14,\n",
      "        1,  0,  2, 14,  2, 15,  0, 19,  0, 10, 17,  1,  9, 10, 15,  1,  7,\n",
      "        8,  7,  7, 18, 15,  0, 18,  0,  0, 19, 14, 11,  5,  0,  0,  1,  8,\n",
      "       18, 10, 18,  2,  1,  5, 12,  0, 18]), 'Next Training set size': 408}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 408\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 153\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='153' max='153' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [153/153 00:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:09:43.574427Z [info     ] Start Predict                  dataset=179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 37.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9140145182609558, 'eval_accuracy': 0.675, 'eval_runtime': 1.197, 'eval_samples_per_second': 233.923, 'eval_steps_per_second': 29.24, 'epoch': 18, 'labeled_data': array([13, 16,  1,  8,  8,  4, 17,  7,  7, 12,  0, 17, 10, 13, 16, 14,  9,\n",
      "       20,  0, 18, 12, 12, 14, 14, 12,  4, 15,  8,  8,  0,  0,  0,  0, 14,\n",
      "       13, 15,  0, 15,  0,  1,  9,  6,  0,  0,  2,  0,  4,  1, 16, 20,  2,\n",
      "        6, 19, 16,  0, 20, 13, 14,  0,  6,  3,  0, 10, 20,  0,  5,  5,  7,\n",
      "        1,  0, 18,  0, 18,  1, 18,  3,  0, 14,  2,  8,  7,  7, 15,  4,  0,\n",
      "       13, 17,  5,  5,  2,  0,  0,  0, 11, 20,  9,  1,  0,  0,  1,  9,  0,\n",
      "       18,  0,  7, 15,  1,  0, 15,  0,  0,  1,  0,  1,  2, 12,  0, 15,  3,\n",
      "        8,  9, 12,  0,  7,  0,  2,  7,  9,  4,  1, 11, 10,  3, 16,  3,  1,\n",
      "        6,  7,  4,  0, 18, 17,  0,  4,  0,  0,  1, 12, 11,  0,  0,  3,  0,\n",
      "        4,  1,  0, 16,  0,  1,  0, 19,  4, 10,  4,  0, 18, 11,  2,  8, 13,\n",
      "        8, 17,  0,  7,  0, 20,  1,  0,  4, 16,  1,  5, 11,  0,  0,  0,  1,\n",
      "        0, 16,  4, 19, 15,  0,  7,  0,  3,  0,  5,  2, 15, 18,  9,  3,  0,\n",
      "        0, 15,  6, 14,  1,  0,  0,  0,  0,  1,  4,  4,  9,  3,  0, 16,  0,\n",
      "        0, 20, 11,  1, 20, 16, 12, 11, 17, 12,  0,  2, 15, 16,  0,  0,  6,\n",
      "        0,  0, 12,  0,  0,  8,  1,  7, 11,  0,  9, 16,  9,  9, 15,  1,  5,\n",
      "        1,  6,  4, 14,  0, 11, 13, 20, 10,  9, 14,  3,  9,  4, 10,  8,  1,\n",
      "        0,  4,  0,  9, 12,  0, 10,  0,  5,  0, 19,  0, 11,  4,  0,  0,  0,\n",
      "       20,  1, 20, 13,  8, 19, 14,  9,  8,  6,  0,  6,  0, 14, 17,  0,  6,\n",
      "        0,  0, 11, 17,  6, 19, 20, 10,  0, 17,  2, 13, 10,  0,  6,  0,  1,\n",
      "        0,  0, 17, 19,  7,  0,  0,  0,  0, 12, 20, 13, 18,  9, 16,  5,  1,\n",
      "        1,  0, 11,  0, 13, 17, 12, 20, 19,  2, 13, 13, 10, 20,  0,  5, 17,\n",
      "        0,  1,  1, 17,  6,  3, 13, 14,  1,  5,  8, 16,  0,  0,  1,  0,  4,\n",
      "        0,  8, 11, 17,  0,  2,  1,  0,  6,  0,  0,  0,  3, 19,  3, 13,  1,\n",
      "       18, 10,  4,  1,  0, 19,  2,  0,  0, 11,  0, 19, 17, 18, 10, 20,  0,\n",
      "       19,  1, 16,  1, 14,  5,  5,  5, 14, 19,  1,  0,  1,  3,  6,  0,  3,\n",
      "       18,  0,  9,  3,  0,  0, 10,  0,  6,  3, 16,  0,  5,  3, 14,  6, 19,\n",
      "        0,  6,  0,  5, 16, 11, 18, 19,  3,  1,  0, 20, 18,  5, 19,  0, 10,\n",
      "        2, 10, 18, 15,  0, 12,  0,  0,  9,  0, 15, 20,  8, 13,  0, 20, 11,\n",
      "       14, 14,  0,  0,  0,  2, 17, 10,  1, 10,  8, 12, 11,  0,  0,  0,  2,\n",
      "       11,  0, 16, 13,  0,  0,  0,  7,  0,  0, 15,  1,  0, 17,  0,  8, 12,\n",
      "       12,  0,  3,  0, 16, 13, 11, 19, 19,  8,  0,  5,  6, 15,  2,  0,  0,\n",
      "        7,  0, 13, 17, 13,  9, 12,  7,  7, 17,  0,  6,  0, 15, 12, 16, 14,\n",
      "        1,  0,  2, 14,  2, 15,  0, 19,  0, 10, 17,  1,  9, 10, 15,  1,  7,\n",
      "        8,  7,  7, 18, 15,  0, 18,  0,  0, 19, 14, 11,  5,  0, 20,  1,  8,\n",
      "       18, 10, 18,  2,  1,  5, 12,  0, 18]), 'Next Training set size': 428}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 428\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 162\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='162' max='162' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [162/162 00:15, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:10:01.358986Z [info     ] Start Predict                  dataset=159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 37.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9187417030334473, 'eval_accuracy': 0.675, 'eval_runtime': 1.1995, 'eval_samples_per_second': 233.428, 'eval_steps_per_second': 29.179, 'epoch': 19, 'labeled_data': array([13, 16,  1,  8,  8,  4, 17,  7,  7, 12,  0, 17, 10, 13, 16, 14,  9,\n",
      "       20, 21, 18, 12, 12, 14, 14, 12,  4, 15,  8,  8,  0,  0,  0,  0, 14,\n",
      "       13, 15, 21, 15,  0,  1,  9,  6,  0,  0,  2, 21,  4,  1, 16, 20,  2,\n",
      "        6, 19, 16,  0, 20, 13, 14, 21,  6,  3,  0, 10, 20,  0,  5,  5,  7,\n",
      "        1,  0, 18,  0, 18,  1, 18,  3,  0, 14,  2,  8,  7,  7, 15,  4,  0,\n",
      "       13, 17,  5,  5,  2, 21, 21,  0, 11, 20,  9,  1, 21,  0,  1,  9,  0,\n",
      "       18,  0,  7, 15,  1,  0, 15,  0,  0,  1,  0,  1,  2, 12,  0, 15,  3,\n",
      "        8,  9, 12,  0,  7, 21,  2,  7,  9,  4,  1, 11, 10,  3, 16,  3,  1,\n",
      "        6,  7,  4,  0, 18, 17,  0,  4,  0,  0,  1, 12, 11,  0,  0,  3,  0,\n",
      "        4,  1, 21, 16,  0,  1,  0, 19,  4, 10,  4,  0, 18, 11,  2,  8, 13,\n",
      "        8, 17,  0,  7,  0, 20,  1, 21,  4, 16,  1,  5, 11,  0,  0,  0,  1,\n",
      "       21, 16,  4, 19, 15,  0,  7,  0,  3, 21,  5,  2, 15, 18,  9,  3,  0,\n",
      "        0, 15,  6, 14,  1,  0, 21,  0,  0,  1,  4,  4,  9,  3,  0, 16,  0,\n",
      "        0, 20, 11,  1, 20, 16, 12, 11, 17, 12,  0,  2, 15, 16,  0,  0,  6,\n",
      "        0,  0, 12,  0,  0,  8,  1,  7, 11,  0,  9, 16,  9,  9, 15,  1,  5,\n",
      "        1,  6,  4, 14,  0, 11, 13, 20, 10,  9, 14,  3,  9,  4, 10,  8,  1,\n",
      "        0,  4,  0,  9, 12,  0, 10,  0,  5,  0, 19,  0, 11,  4,  0,  0,  0,\n",
      "       20,  1, 20, 13,  8, 19, 14,  9,  8,  6,  0,  6,  0, 14, 17,  0,  6,\n",
      "        0,  0, 11, 17,  6, 19, 20, 10,  0, 17,  2, 13, 10,  0,  6,  0,  1,\n",
      "        0,  0, 17, 19,  7,  0,  0,  0,  0, 12, 20, 13, 18,  9, 16,  5,  1,\n",
      "        1,  0, 11,  0, 13, 17, 12, 20, 19,  2, 13, 13, 10, 20,  0,  5, 17,\n",
      "       21,  1,  1, 17,  6,  3, 13, 14,  1,  5,  8, 16,  0,  0,  1,  0,  4,\n",
      "        0,  8, 11, 17,  0,  2,  1,  0,  6,  0,  0,  0,  3, 19,  3, 13,  1,\n",
      "       18, 10,  4,  1,  0, 19,  2,  0,  0, 11,  0, 19, 17, 18, 10, 20,  0,\n",
      "       19,  1, 16,  1, 14,  5,  5,  5, 14, 19,  1,  0,  1,  3,  6,  0,  3,\n",
      "       18, 21,  9,  3,  0,  0, 10,  0,  6,  3, 16,  0,  5,  3, 14,  6, 19,\n",
      "        0,  6, 21,  5, 16, 11, 18, 19,  3,  1,  0, 20, 18,  5, 19,  0, 10,\n",
      "        2, 10, 18, 15,  0, 12,  0,  0,  9,  0, 15, 20,  8, 13, 21, 20, 11,\n",
      "       14, 14,  0,  0, 21,  2, 17, 10,  1, 10,  8, 12, 11,  0,  0,  0,  2,\n",
      "       11,  0, 16, 13,  0,  0,  0,  7,  0,  0, 15,  1,  0, 17,  0,  8, 12,\n",
      "       12, 21,  3,  0, 16, 13, 11, 19, 19,  8,  0,  5,  6, 15,  2,  0, 21,\n",
      "        7,  0, 13, 17, 13,  9, 12,  7,  7, 17,  0,  6,  0, 15, 12, 16, 14,\n",
      "        1,  0,  2, 14,  2, 15,  0, 19,  0, 10, 17,  1,  9, 10, 15,  1,  7,\n",
      "        8,  7,  7, 18, 15,  0, 18,  0,  0, 19, 14, 11,  5,  0, 20,  1,  8,\n",
      "       18, 10, 18,  2,  1,  5, 12,  0, 18]), 'Next Training set size': 448}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 448\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 168\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='168' max='168' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [168/168 00:16, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:10:19.885420Z [info     ] Start Predict                  dataset=139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 36.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9012268781661987, 'eval_accuracy': 0.675, 'eval_runtime': 1.2259, 'eval_samples_per_second': 228.406, 'eval_steps_per_second': 28.551, 'epoch': 20, 'labeled_data': array([13, 16,  1,  8,  8,  4, 17,  7,  7, 12, 22, 17, 10, 13, 16, 14,  9,\n",
      "       20, 21, 18, 12, 12, 14, 14, 12,  4, 15,  8,  8,  0, 22,  0, 22, 14,\n",
      "       13, 15, 21, 15,  0,  1,  9,  6,  0,  0,  2, 21,  4,  1, 16, 20,  2,\n",
      "        6, 19, 16, 22, 20, 13, 14, 21,  6,  3,  0, 10, 20,  0,  5,  5,  7,\n",
      "        1,  0, 18,  0, 18,  1, 18,  3,  0, 14,  2,  8,  7,  7, 15,  4,  0,\n",
      "       13, 17,  5,  5,  2, 21, 21,  0, 11, 20,  9,  1, 21,  0,  1,  9,  0,\n",
      "       18,  0,  7, 15,  1, 22, 15,  0,  0,  1,  0,  1,  2, 12,  0, 15,  3,\n",
      "        8,  9, 12,  0,  7, 21,  2,  7,  9,  4,  1, 11, 10,  3, 16,  3,  1,\n",
      "        6,  7,  4,  0, 18, 17,  0,  4,  0, 22,  1, 12, 11,  0,  0,  3,  0,\n",
      "        4,  1, 21, 16,  0,  1,  0, 19,  4, 10,  4,  0, 18, 11,  2,  8, 13,\n",
      "        8, 17,  0,  7,  0, 20,  1, 21,  4, 16,  1,  5, 11,  0,  0,  0,  1,\n",
      "       21, 16,  4, 19, 15,  0,  7,  0,  3, 21,  5,  2, 15, 18,  9,  3, 22,\n",
      "        0, 15,  6, 14,  1,  0, 21,  0,  0,  1,  4,  4,  9,  3,  0, 16,  0,\n",
      "        0, 20, 11,  1, 20, 16, 12, 11, 17, 12,  0,  2, 15, 16,  0,  0,  6,\n",
      "       22,  0, 12, 22,  0,  8,  1,  7, 11,  0,  9, 16,  9,  9, 15,  1,  5,\n",
      "        1,  6,  4, 14,  0, 11, 13, 20, 10,  9, 14,  3,  9,  4, 10,  8,  1,\n",
      "        0,  4,  0,  9, 12,  0, 10,  0,  5,  0, 19,  0, 11,  4,  0,  0,  0,\n",
      "       20,  1, 20, 13,  8, 19, 14,  9,  8,  6,  0,  6, 22, 14, 17,  0,  6,\n",
      "        0,  0, 11, 17,  6, 19, 20, 10, 22, 17,  2, 13, 10, 22,  6,  0,  1,\n",
      "        0,  0, 17, 19,  7,  0,  0, 22,  0, 12, 20, 13, 18,  9, 16,  5,  1,\n",
      "        1,  0, 11,  0, 13, 17, 12, 20, 19,  2, 13, 13, 10, 20,  0,  5, 17,\n",
      "       21,  1,  1, 17,  6,  3, 13, 14,  1,  5,  8, 16,  0,  0,  1,  0,  4,\n",
      "        0,  8, 11, 17,  0,  2,  1,  0,  6,  0,  0,  0,  3, 19,  3, 13,  1,\n",
      "       18, 10,  4,  1,  0, 19,  2,  0,  0, 11, 22, 19, 17, 18, 10, 20,  0,\n",
      "       19,  1, 16,  1, 14,  5,  5,  5, 14, 19,  1,  0,  1,  3,  6,  0,  3,\n",
      "       18, 21,  9,  3,  0,  0, 10,  0,  6,  3, 16,  0,  5,  3, 14,  6, 19,\n",
      "        0,  6, 21,  5, 16, 11, 18, 19,  3,  1, 22, 20, 18,  5, 19,  0, 10,\n",
      "        2, 10, 18, 15,  0, 12,  0,  0,  9,  0, 15, 20,  8, 13, 21, 20, 11,\n",
      "       14, 14,  0, 22, 21,  2, 17, 10,  1, 10,  8, 12, 11,  0,  0,  0,  2,\n",
      "       11,  0, 16, 13,  0,  0,  0,  7,  0,  0, 15,  1,  0, 17,  0,  8, 12,\n",
      "       12, 21,  3,  0, 16, 13, 11, 19, 19,  8, 22,  5,  6, 15,  2,  0, 21,\n",
      "        7,  0, 13, 17, 13,  9, 12,  7,  7, 17, 22,  6, 22, 15, 12, 16, 14,\n",
      "        1,  0,  2, 14,  2, 15,  0, 19, 22, 10, 17,  1,  9, 10, 15,  1,  7,\n",
      "        8,  7,  7, 18, 15,  0, 18,  0,  0, 19, 14, 11,  5,  0, 20,  1,  8,\n",
      "       18, 10, 18,  2,  1,  5, 12,  0, 18]), 'Next Training set size': 468}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 468\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 177\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='177' max='177' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [177/177 00:17, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:10:39.100562Z [info     ] Start Predict                  dataset=119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 39.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9087386131286621, 'eval_accuracy': 0.675, 'eval_runtime': 1.1743, 'eval_samples_per_second': 238.434, 'eval_steps_per_second': 29.804, 'epoch': 21, 'labeled_data': array([13, 16,  1,  8,  8,  4, 17,  7,  7, 12, 22, 17, 10, 13, 16, 14,  9,\n",
      "       20, 21, 18, 12, 12, 14, 14, 12,  4, 15,  8,  8, 23, 22, 23, 22, 14,\n",
      "       13, 15, 21, 15,  0,  1,  9,  6,  0, 23,  2, 21,  4,  1, 16, 20,  2,\n",
      "        6, 19, 16, 22, 20, 13, 14, 21,  6,  3, 23, 10, 20,  0,  5,  5,  7,\n",
      "        1,  0, 18,  0, 18,  1, 18,  3,  0, 14,  2,  8,  7,  7, 15,  4,  0,\n",
      "       13, 17,  5,  5,  2, 21, 21,  0, 11, 20,  9,  1, 21, 23,  1,  9,  0,\n",
      "       18,  0,  7, 15,  1, 22, 15, 23,  0,  1,  0,  1,  2, 12,  0, 15,  3,\n",
      "        8,  9, 12,  0,  7, 21,  2,  7,  9,  4,  1, 11, 10,  3, 16,  3,  1,\n",
      "        6,  7,  4,  0, 18, 17,  0,  4,  0, 22,  1, 12, 11, 23,  0,  3,  0,\n",
      "        4,  1, 21, 16,  0,  1,  0, 19,  4, 10,  4,  0, 18, 11,  2,  8, 13,\n",
      "        8, 17,  0,  7,  0, 20,  1, 21,  4, 16,  1,  5, 11,  0,  0,  0,  1,\n",
      "       21, 16,  4, 19, 15,  0,  7, 23,  3, 21,  5,  2, 15, 18,  9,  3, 22,\n",
      "        0, 15,  6, 14,  1, 23, 21,  0,  0,  1,  4,  4,  9,  3,  0, 16,  0,\n",
      "       23, 20, 11,  1, 20, 16, 12, 11, 17, 12,  0,  2, 15, 16,  0, 23,  6,\n",
      "       22,  0, 12, 22,  0,  8,  1,  7, 11,  0,  9, 16,  9,  9, 15,  1,  5,\n",
      "        1,  6,  4, 14,  0, 11, 13, 20, 10,  9, 14,  3,  9,  4, 10,  8,  1,\n",
      "        0,  4, 23,  9, 12,  0, 10,  0,  5,  0, 19,  0, 11,  4,  0, 23,  0,\n",
      "       20,  1, 20, 13,  8, 19, 14,  9,  8,  6,  0,  6, 22, 14, 17, 23,  6,\n",
      "        0,  0, 11, 17,  6, 19, 20, 10, 22, 17,  2, 13, 10, 22,  6,  0,  1,\n",
      "        0,  0, 17, 19,  7,  0,  0, 22,  0, 12, 20, 13, 18,  9, 16,  5,  1,\n",
      "        1,  0, 11,  0, 13, 17, 12, 20, 19,  2, 13, 13, 10, 20,  0,  5, 17,\n",
      "       21,  1,  1, 17,  6,  3, 13, 14,  1,  5,  8, 16,  0,  0,  1,  0,  4,\n",
      "        0,  8, 11, 17,  0,  2,  1,  0,  6,  0,  0,  0,  3, 19,  3, 13,  1,\n",
      "       18, 10,  4,  1,  0, 19,  2, 23,  0, 11, 22, 19, 17, 18, 10, 20,  0,\n",
      "       19,  1, 16,  1, 14,  5,  5,  5, 14, 19,  1,  0,  1,  3,  6,  0,  3,\n",
      "       18, 21,  9,  3,  0,  0, 10,  0,  6,  3, 16,  0,  5,  3, 14,  6, 19,\n",
      "       23,  6, 21,  5, 16, 11, 18, 19,  3,  1, 22, 20, 18,  5, 19,  0, 10,\n",
      "        2, 10, 18, 15,  0, 12, 23,  0,  9,  0, 15, 20,  8, 13, 21, 20, 11,\n",
      "       14, 14,  0, 22, 21,  2, 17, 10,  1, 10,  8, 12, 11,  0, 23,  0,  2,\n",
      "       11,  0, 16, 13,  0,  0,  0,  7, 23,  0, 15,  1,  0, 17, 23,  8, 12,\n",
      "       12, 21,  3,  0, 16, 13, 11, 19, 19,  8, 22,  5,  6, 15,  2,  0, 21,\n",
      "        7,  0, 13, 17, 13,  9, 12,  7,  7, 17, 22,  6, 22, 15, 12, 16, 14,\n",
      "        1,  0,  2, 14,  2, 15,  0, 19, 22, 10, 17,  1,  9, 10, 15,  1,  7,\n",
      "        8,  7,  7, 18, 15,  0, 18,  0,  0, 19, 14, 11,  5,  0, 20,  1,  8,\n",
      "       18, 10, 18,  2,  1,  5, 12,  0, 18]), 'Next Training set size': 488}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 488\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 183\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='183' max='183' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [183/183 00:17, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:10:59.067838Z [info     ] Start Predict                  dataset=99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 36.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9079497456550598, 'eval_accuracy': 0.675, 'eval_runtime': 1.226, 'eval_samples_per_second': 228.376, 'eval_steps_per_second': 28.547, 'epoch': 22, 'labeled_data': array([13, 16,  1,  8,  8,  4, 17,  7,  7, 12, 22, 17, 10, 13, 16, 14,  9,\n",
      "       20, 21, 18, 12, 12, 14, 14, 12,  4, 15,  8,  8, 23, 22, 23, 22, 14,\n",
      "       13, 15, 21, 15,  0,  1,  9,  6,  0, 23,  2, 21,  4,  1, 16, 20,  2,\n",
      "        6, 19, 16, 22, 20, 13, 14, 21,  6,  3, 23, 10, 20,  0,  5,  5,  7,\n",
      "        1,  0, 18,  0, 18,  1, 18,  3,  0, 14,  2,  8,  7,  7, 15,  4,  0,\n",
      "       13, 17,  5,  5,  2, 21, 21,  0, 11, 20,  9,  1, 21, 23,  1,  9,  0,\n",
      "       18,  0,  7, 15,  1, 22, 15, 23,  0,  1, 24,  1,  2, 12,  0, 15,  3,\n",
      "        8,  9, 12, 24,  7, 21,  2,  7,  9,  4,  1, 11, 10,  3, 16,  3,  1,\n",
      "        6,  7,  4, 24, 18, 17, 24,  4, 24, 22,  1, 12, 11, 23,  0,  3,  0,\n",
      "        4,  1, 21, 16, 24,  1, 24, 19,  4, 10,  4,  0, 18, 11,  2,  8, 13,\n",
      "        8, 17,  0,  7,  0, 20,  1, 21,  4, 16,  1,  5, 11, 24,  0,  0,  1,\n",
      "       21, 16,  4, 19, 15, 24,  7, 23,  3, 21,  5,  2, 15, 18,  9,  3, 22,\n",
      "        0, 15,  6, 14,  1, 23, 21,  0,  0,  1,  4,  4,  9,  3, 24, 16,  0,\n",
      "       23, 20, 11,  1, 20, 16, 12, 11, 17, 12,  0,  2, 15, 16,  0, 23,  6,\n",
      "       22,  0, 12, 22,  0,  8,  1,  7, 11,  0,  9, 16,  9,  9, 15,  1,  5,\n",
      "        1,  6,  4, 14,  0, 11, 13, 20, 10,  9, 14,  3,  9,  4, 10,  8,  1,\n",
      "        0,  4, 23,  9, 12,  0, 10,  0,  5,  0, 19,  0, 11,  4,  0, 23,  0,\n",
      "       20,  1, 20, 13,  8, 19, 14,  9,  8,  6,  0,  6, 22, 14, 17, 23,  6,\n",
      "       24, 24, 11, 17,  6, 19, 20, 10, 22, 17,  2, 13, 10, 22,  6,  0,  1,\n",
      "       24,  0, 17, 19,  7,  0,  0, 22,  0, 12, 20, 13, 18,  9, 16,  5,  1,\n",
      "        1,  0, 11,  0, 13, 17, 12, 20, 19,  2, 13, 13, 10, 20,  0,  5, 17,\n",
      "       21,  1,  1, 17,  6,  3, 13, 14,  1,  5,  8, 16,  0,  0,  1,  0,  4,\n",
      "        0,  8, 11, 17,  0,  2,  1, 24,  6,  0,  0,  0,  3, 19,  3, 13,  1,\n",
      "       18, 10,  4,  1, 24, 19,  2, 23, 24, 11, 22, 19, 17, 18, 10, 20,  0,\n",
      "       19,  1, 16,  1, 14,  5,  5,  5, 14, 19,  1,  0,  1,  3,  6,  0,  3,\n",
      "       18, 21,  9,  3,  0,  0, 10,  0,  6,  3, 16,  0,  5,  3, 14,  6, 19,\n",
      "       23,  6, 21,  5, 16, 11, 18, 19,  3,  1, 22, 20, 18,  5, 19,  0, 10,\n",
      "        2, 10, 18, 15,  0, 12, 23,  0,  9,  0, 15, 20,  8, 13, 21, 20, 11,\n",
      "       14, 14,  0, 22, 21,  2, 17, 10,  1, 10,  8, 12, 11,  0, 23,  0,  2,\n",
      "       11,  0, 16, 13, 24, 24,  0,  7, 23,  0, 15,  1,  0, 17, 23,  8, 12,\n",
      "       12, 21,  3,  0, 16, 13, 11, 19, 19,  8, 22,  5,  6, 15,  2, 24, 21,\n",
      "        7,  0, 13, 17, 13,  9, 12,  7,  7, 17, 22,  6, 22, 15, 12, 16, 14,\n",
      "        1,  0,  2, 14,  2, 15,  0, 19, 22, 10, 17,  1,  9, 10, 15,  1,  7,\n",
      "        8,  7,  7, 18, 15, 24, 18,  0,  0, 19, 14, 11,  5,  0, 20,  1,  8,\n",
      "       18, 10, 18,  2,  1,  5, 12,  0, 18]), 'Next Training set size': 508}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 508\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [192/192 00:18, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:11:19.564012Z [info     ] Start Predict                  dataset=79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 38.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8984217643737793, 'eval_accuracy': 0.675, 'eval_runtime': 1.2091, 'eval_samples_per_second': 231.569, 'eval_steps_per_second': 28.946, 'epoch': 23, 'labeled_data': array([13, 16,  1,  8,  8,  4, 17,  7,  7, 12, 22, 17, 10, 13, 16, 14,  9,\n",
      "       20, 21, 18, 12, 12, 14, 14, 12,  4, 15,  8,  8, 23, 22, 23, 22, 14,\n",
      "       13, 15, 21, 15, 25,  1,  9,  6, 25, 23,  2, 21,  4,  1, 16, 20,  2,\n",
      "        6, 19, 16, 22, 20, 13, 14, 21,  6,  3, 23, 10, 20,  0,  5,  5,  7,\n",
      "        1,  0, 18,  0, 18,  1, 18,  3,  0, 14,  2,  8,  7,  7, 15,  4,  0,\n",
      "       13, 17,  5,  5,  2, 21, 21,  0, 11, 20,  9,  1, 21, 23,  1,  9,  0,\n",
      "       18, 25,  7, 15,  1, 22, 15, 23, 25,  1, 24,  1,  2, 12,  0, 15,  3,\n",
      "        8,  9, 12, 24,  7, 21,  2,  7,  9,  4,  1, 11, 10,  3, 16,  3,  1,\n",
      "        6,  7,  4, 24, 18, 17, 24,  4, 24, 22,  1, 12, 11, 23,  0,  3,  0,\n",
      "        4,  1, 21, 16, 24,  1, 24, 19,  4, 10,  4, 25, 18, 11,  2,  8, 13,\n",
      "        8, 17,  0,  7, 25, 20,  1, 21,  4, 16,  1,  5, 11, 24, 25,  0,  1,\n",
      "       21, 16,  4, 19, 15, 24,  7, 23,  3, 21,  5,  2, 15, 18,  9,  3, 22,\n",
      "        0, 15,  6, 14,  1, 23, 21,  0, 25,  1,  4,  4,  9,  3, 24, 16,  0,\n",
      "       23, 20, 11,  1, 20, 16, 12, 11, 17, 12,  0,  2, 15, 16, 25, 23,  6,\n",
      "       22, 25, 12, 22,  0,  8,  1,  7, 11, 25,  9, 16,  9,  9, 15,  1,  5,\n",
      "        1,  6,  4, 14,  0, 11, 13, 20, 10,  9, 14,  3,  9,  4, 10,  8,  1,\n",
      "        0,  4, 23,  9, 12, 25, 10,  0,  5, 25, 19,  0, 11,  4,  0, 23,  0,\n",
      "       20,  1, 20, 13,  8, 19, 14,  9,  8,  6,  0,  6, 22, 14, 17, 23,  6,\n",
      "       24, 24, 11, 17,  6, 19, 20, 10, 22, 17,  2, 13, 10, 22,  6, 25,  1,\n",
      "       24,  0, 17, 19,  7,  0,  0, 22,  0, 12, 20, 13, 18,  9, 16,  5,  1,\n",
      "        1,  0, 11, 25, 13, 17, 12, 20, 19,  2, 13, 13, 10, 20,  0,  5, 17,\n",
      "       21,  1,  1, 17,  6,  3, 13, 14,  1,  5,  8, 16,  0,  0,  1,  0,  4,\n",
      "        0,  8, 11, 17, 25,  2,  1, 24,  6,  0,  0,  0,  3, 19,  3, 13,  1,\n",
      "       18, 10,  4,  1, 24, 19,  2, 23, 24, 11, 22, 19, 17, 18, 10, 20,  0,\n",
      "       19,  1, 16,  1, 14,  5,  5,  5, 14, 19,  1,  0,  1,  3,  6,  0,  3,\n",
      "       18, 21,  9,  3,  0,  0, 10, 25,  6,  3, 16,  0,  5,  3, 14,  6, 19,\n",
      "       23,  6, 21,  5, 16, 11, 18, 19,  3,  1, 22, 20, 18,  5, 19, 25, 10,\n",
      "        2, 10, 18, 15,  0, 12, 23,  0,  9,  0, 15, 20,  8, 13, 21, 20, 11,\n",
      "       14, 14,  0, 22, 21,  2, 17, 10,  1, 10,  8, 12, 11,  0, 23,  0,  2,\n",
      "       11,  0, 16, 13, 24, 24,  0,  7, 23, 25, 15,  1,  0, 17, 23,  8, 12,\n",
      "       12, 21,  3,  0, 16, 13, 11, 19, 19,  8, 22,  5,  6, 15,  2, 24, 21,\n",
      "        7,  0, 13, 17, 13,  9, 12,  7,  7, 17, 22,  6, 22, 15, 12, 16, 14,\n",
      "        1,  0,  2, 14,  2, 15,  0, 19, 22, 10, 17,  1,  9, 10, 15,  1,  7,\n",
      "        8,  7,  7, 18, 15, 24, 18,  0,  0, 19, 14, 11,  5, 25, 20,  1,  8,\n",
      "       18, 10, 18,  2,  1,  5, 12,  0, 18]), 'Next Training set size': 528}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 528\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 198\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='198' max='198' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [198/198 00:19, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:11:40.697078Z [info     ] Start Predict                  dataset=59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 37.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9111055135726929, 'eval_accuracy': 0.675, 'eval_runtime': 1.2088, 'eval_samples_per_second': 231.644, 'eval_steps_per_second': 28.956, 'epoch': 24, 'labeled_data': array([13, 16,  1,  8,  8,  4, 17,  7,  7, 12, 22, 17, 10, 13, 16, 14,  9,\n",
      "       20, 21, 18, 12, 12, 14, 14, 12,  4, 15,  8,  8, 23, 22, 23, 22, 14,\n",
      "       13, 15, 21, 15, 25,  1,  9,  6, 25, 23,  2, 21,  4,  1, 16, 20,  2,\n",
      "        6, 19, 16, 22, 20, 13, 14, 21,  6,  3, 23, 10, 20,  0,  5,  5,  7,\n",
      "        1, 26, 18,  0, 18,  1, 18,  3,  0, 14,  2,  8,  7,  7, 15,  4, 26,\n",
      "       13, 17,  5,  5,  2, 21, 21,  0, 11, 20,  9,  1, 21, 23,  1,  9, 26,\n",
      "       18, 25,  7, 15,  1, 22, 15, 23, 25,  1, 24,  1,  2, 12,  0, 15,  3,\n",
      "        8,  9, 12, 24,  7, 21,  2,  7,  9,  4,  1, 11, 10,  3, 16,  3,  1,\n",
      "        6,  7,  4, 24, 18, 17, 24,  4, 24, 22,  1, 12, 11, 23,  0,  3, 26,\n",
      "        4,  1, 21, 16, 24,  1, 24, 19,  4, 10,  4, 25, 18, 11,  2,  8, 13,\n",
      "        8, 17,  0,  7, 25, 20,  1, 21,  4, 16,  1,  5, 11, 24, 25, 26,  1,\n",
      "       21, 16,  4, 19, 15, 24,  7, 23,  3, 21,  5,  2, 15, 18,  9,  3, 22,\n",
      "        0, 15,  6, 14,  1, 23, 21, 26, 25,  1,  4,  4,  9,  3, 24, 16,  0,\n",
      "       23, 20, 11,  1, 20, 16, 12, 11, 17, 12,  0,  2, 15, 16, 25, 23,  6,\n",
      "       22, 25, 12, 22, 26,  8,  1,  7, 11, 25,  9, 16,  9,  9, 15,  1,  5,\n",
      "        1,  6,  4, 14, 26, 11, 13, 20, 10,  9, 14,  3,  9,  4, 10,  8,  1,\n",
      "        0,  4, 23,  9, 12, 25, 10,  0,  5, 25, 19,  0, 11,  4, 26, 23,  0,\n",
      "       20,  1, 20, 13,  8, 19, 14,  9,  8,  6,  0,  6, 22, 14, 17, 23,  6,\n",
      "       24, 24, 11, 17,  6, 19, 20, 10, 22, 17,  2, 13, 10, 22,  6, 25,  1,\n",
      "       24,  0, 17, 19,  7,  0, 26, 22,  0, 12, 20, 13, 18,  9, 16,  5,  1,\n",
      "        1, 26, 11, 25, 13, 17, 12, 20, 19,  2, 13, 13, 10, 20,  0,  5, 17,\n",
      "       21,  1,  1, 17,  6,  3, 13, 14,  1,  5,  8, 16,  0,  0,  1, 26,  4,\n",
      "       26,  8, 11, 17, 25,  2,  1, 24,  6,  0,  0,  0,  3, 19,  3, 13,  1,\n",
      "       18, 10,  4,  1, 24, 19,  2, 23, 24, 11, 22, 19, 17, 18, 10, 20,  0,\n",
      "       19,  1, 16,  1, 14,  5,  5,  5, 14, 19,  1, 26,  1,  3,  6,  0,  3,\n",
      "       18, 21,  9,  3, 26,  0, 10, 25,  6,  3, 16,  0,  5,  3, 14,  6, 19,\n",
      "       23,  6, 21,  5, 16, 11, 18, 19,  3,  1, 22, 20, 18,  5, 19, 25, 10,\n",
      "        2, 10, 18, 15,  0, 12, 23,  0,  9,  0, 15, 20,  8, 13, 21, 20, 11,\n",
      "       14, 14,  0, 22, 21,  2, 17, 10,  1, 10,  8, 12, 11,  0, 23, 26,  2,\n",
      "       11, 26, 16, 13, 24, 24,  0,  7, 23, 25, 15,  1, 26, 17, 23,  8, 12,\n",
      "       12, 21,  3,  0, 16, 13, 11, 19, 19,  8, 22,  5,  6, 15,  2, 24, 21,\n",
      "        7,  0, 13, 17, 13,  9, 12,  7,  7, 17, 22,  6, 22, 15, 12, 16, 14,\n",
      "        1,  0,  2, 14,  2, 15, 26, 19, 22, 10, 17,  1,  9, 10, 15,  1,  7,\n",
      "        8,  7,  7, 18, 15, 24, 18, 26,  0, 19, 14, 11,  5, 25, 20,  1,  8,\n",
      "       18, 10, 18,  2,  1,  5, 12,  0, 18]), 'Next Training set size': 548}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 548\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 207\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='207' max='207' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [207/207 00:19, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:12:02.495845Z [info     ] Start Predict                  dataset=39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 33.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9009409546852112, 'eval_accuracy': 0.675, 'eval_runtime': 1.2562, 'eval_samples_per_second': 222.887, 'eval_steps_per_second': 27.861, 'epoch': 25, 'labeled_data': array([13, 16,  1,  8,  8,  4, 17,  7,  7, 12, 22, 17, 10, 13, 16, 14,  9,\n",
      "       20, 21, 18, 12, 12, 14, 14, 12,  4, 15,  8,  8, 23, 22, 23, 22, 14,\n",
      "       13, 15, 21, 15, 25,  1,  9,  6, 25, 23,  2, 21,  4,  1, 16, 20,  2,\n",
      "        6, 19, 16, 22, 20, 13, 14, 21,  6,  3, 23, 10, 20,  0,  5,  5,  7,\n",
      "        1, 26, 18,  0, 18,  1, 18,  3,  0, 14,  2,  8,  7,  7, 15,  4, 26,\n",
      "       13, 17,  5,  5,  2, 21, 21,  0, 11, 20,  9,  1, 21, 23,  1,  9, 26,\n",
      "       18, 25,  7, 15,  1, 22, 15, 23, 25,  1, 24,  1,  2, 12, 27, 15,  3,\n",
      "        8,  9, 12, 24,  7, 21,  2,  7,  9,  4,  1, 11, 10,  3, 16,  3,  1,\n",
      "        6,  7,  4, 24, 18, 17, 24,  4, 24, 22,  1, 12, 11, 23,  0,  3, 26,\n",
      "        4,  1, 21, 16, 24,  1, 24, 19,  4, 10,  4, 25, 18, 11,  2,  8, 13,\n",
      "        8, 17, 27,  7, 25, 20,  1, 21,  4, 16,  1,  5, 11, 24, 25, 26,  1,\n",
      "       21, 16,  4, 19, 15, 24,  7, 23,  3, 21,  5,  2, 15, 18,  9,  3, 22,\n",
      "       27, 15,  6, 14,  1, 23, 21, 26, 25,  1,  4,  4,  9,  3, 24, 16, 27,\n",
      "       23, 20, 11,  1, 20, 16, 12, 11, 17, 12, 27,  2, 15, 16, 25, 23,  6,\n",
      "       22, 25, 12, 22, 26,  8,  1,  7, 11, 25,  9, 16,  9,  9, 15,  1,  5,\n",
      "        1,  6,  4, 14, 26, 11, 13, 20, 10,  9, 14,  3,  9,  4, 10,  8,  1,\n",
      "       27,  4, 23,  9, 12, 25, 10,  0,  5, 25, 19,  0, 11,  4, 26, 23, 27,\n",
      "       20,  1, 20, 13,  8, 19, 14,  9,  8,  6,  0,  6, 22, 14, 17, 23,  6,\n",
      "       24, 24, 11, 17,  6, 19, 20, 10, 22, 17,  2, 13, 10, 22,  6, 25,  1,\n",
      "       24,  0, 17, 19,  7,  0, 26, 22, 27, 12, 20, 13, 18,  9, 16,  5,  1,\n",
      "        1, 26, 11, 25, 13, 17, 12, 20, 19,  2, 13, 13, 10, 20, 27,  5, 17,\n",
      "       21,  1,  1, 17,  6,  3, 13, 14,  1,  5,  8, 16,  0,  0,  1, 26,  4,\n",
      "       26,  8, 11, 17, 25,  2,  1, 24,  6,  0, 27,  0,  3, 19,  3, 13,  1,\n",
      "       18, 10,  4,  1, 24, 19,  2, 23, 24, 11, 22, 19, 17, 18, 10, 20,  0,\n",
      "       19,  1, 16,  1, 14,  5,  5,  5, 14, 19,  1, 26,  1,  3,  6, 27,  3,\n",
      "       18, 21,  9,  3, 26, 27, 10, 25,  6,  3, 16, 27,  5,  3, 14,  6, 19,\n",
      "       23,  6, 21,  5, 16, 11, 18, 19,  3,  1, 22, 20, 18,  5, 19, 25, 10,\n",
      "        2, 10, 18, 15, 27, 12, 23, 27,  9, 27, 15, 20,  8, 13, 21, 20, 11,\n",
      "       14, 14, 27, 22, 21,  2, 17, 10,  1, 10,  8, 12, 11, 27, 23, 26,  2,\n",
      "       11, 26, 16, 13, 24, 24,  0,  7, 23, 25, 15,  1, 26, 17, 23,  8, 12,\n",
      "       12, 21,  3,  0, 16, 13, 11, 19, 19,  8, 22,  5,  6, 15,  2, 24, 21,\n",
      "        7, 27, 13, 17, 13,  9, 12,  7,  7, 17, 22,  6, 22, 15, 12, 16, 14,\n",
      "        1, 27,  2, 14,  2, 15, 26, 19, 22, 10, 17,  1,  9, 10, 15,  1,  7,\n",
      "        8,  7,  7, 18, 15, 24, 18, 26,  0, 19, 14, 11,  5, 25, 20,  1,  8,\n",
      "       18, 10, 18,  2,  1,  5, 12,  0, 18]), 'Next Training set size': 568}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 568\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 213\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='213' max='213' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [213/213 00:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:12:25.030704Z [info     ] Start Predict                  dataset=19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 40.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9057231545448303, 'eval_accuracy': 0.675, 'eval_runtime': 1.3882, 'eval_samples_per_second': 201.698, 'eval_steps_per_second': 25.212, 'epoch': 26, 'labeled_data': array([13, 16,  1,  8,  8,  4, 17,  7,  7, 12, 22, 17, 10, 13, 16, 14,  9,\n",
      "       20, 21, 18, 12, 12, 14, 14, 12,  4, 15,  8,  8, 23, 22, 23, 22, 14,\n",
      "       13, 15, 21, 15, 25,  1,  9,  6, 25, 23,  2, 21,  4,  1, 16, 20,  2,\n",
      "        6, 19, 16, 22, 20, 13, 14, 21,  6,  3, 23, 10, 20, 28,  5,  5,  7,\n",
      "        1, 26, 18, 28, 18,  1, 18,  3, 28, 14,  2,  8,  7,  7, 15,  4, 26,\n",
      "       13, 17,  5,  5,  2, 21, 21, 28, 11, 20,  9,  1, 21, 23,  1,  9, 26,\n",
      "       18, 25,  7, 15,  1, 22, 15, 23, 25,  1, 24,  1,  2, 12, 27, 15,  3,\n",
      "        8,  9, 12, 24,  7, 21,  2,  7,  9,  4,  1, 11, 10,  3, 16,  3,  1,\n",
      "        6,  7,  4, 24, 18, 17, 24,  4, 24, 22,  1, 12, 11, 23, 28,  3, 26,\n",
      "        4,  1, 21, 16, 24,  1, 24, 19,  4, 10,  4, 25, 18, 11,  2,  8, 13,\n",
      "        8, 17, 27,  7, 25, 20,  1, 21,  4, 16,  1,  5, 11, 24, 25, 26,  1,\n",
      "       21, 16,  4, 19, 15, 24,  7, 23,  3, 21,  5,  2, 15, 18,  9,  3, 22,\n",
      "       27, 15,  6, 14,  1, 23, 21, 26, 25,  1,  4,  4,  9,  3, 24, 16, 27,\n",
      "       23, 20, 11,  1, 20, 16, 12, 11, 17, 12, 27,  2, 15, 16, 25, 23,  6,\n",
      "       22, 25, 12, 22, 26,  8,  1,  7, 11, 25,  9, 16,  9,  9, 15,  1,  5,\n",
      "        1,  6,  4, 14, 26, 11, 13, 20, 10,  9, 14,  3,  9,  4, 10,  8,  1,\n",
      "       27,  4, 23,  9, 12, 25, 10, 28,  5, 25, 19, 28, 11,  4, 26, 23, 27,\n",
      "       20,  1, 20, 13,  8, 19, 14,  9,  8,  6, 28,  6, 22, 14, 17, 23,  6,\n",
      "       24, 24, 11, 17,  6, 19, 20, 10, 22, 17,  2, 13, 10, 22,  6, 25,  1,\n",
      "       24, 28, 17, 19,  7, 28, 26, 22, 27, 12, 20, 13, 18,  9, 16,  5,  1,\n",
      "        1, 26, 11, 25, 13, 17, 12, 20, 19,  2, 13, 13, 10, 20, 27,  5, 17,\n",
      "       21,  1,  1, 17,  6,  3, 13, 14,  1,  5,  8, 16, 28, 28,  1, 26,  4,\n",
      "       26,  8, 11, 17, 25,  2,  1, 24,  6, 28, 27, 28,  3, 19,  3, 13,  1,\n",
      "       18, 10,  4,  1, 24, 19,  2, 23, 24, 11, 22, 19, 17, 18, 10, 20, 28,\n",
      "       19,  1, 16,  1, 14,  5,  5,  5, 14, 19,  1, 26,  1,  3,  6, 27,  3,\n",
      "       18, 21,  9,  3, 26, 27, 10, 25,  6,  3, 16, 27,  5,  3, 14,  6, 19,\n",
      "       23,  6, 21,  5, 16, 11, 18, 19,  3,  1, 22, 20, 18,  5, 19, 25, 10,\n",
      "        2, 10, 18, 15, 27, 12, 23, 27,  9, 27, 15, 20,  8, 13, 21, 20, 11,\n",
      "       14, 14, 27, 22, 21,  2, 17, 10,  1, 10,  8, 12, 11, 27, 23, 26,  2,\n",
      "       11, 26, 16, 13, 24, 24, 28,  7, 23, 25, 15,  1, 26, 17, 23,  8, 12,\n",
      "       12, 21,  3, 28, 16, 13, 11, 19, 19,  8, 22,  5,  6, 15,  2, 24, 21,\n",
      "        7, 27, 13, 17, 13,  9, 12,  7,  7, 17, 22,  6, 22, 15, 12, 16, 14,\n",
      "        1, 27,  2, 14,  2, 15, 26, 19, 22, 10, 17,  1,  9, 10, 15,  1,  7,\n",
      "        8,  7,  7, 18, 15, 24, 18, 26, 28, 19, 14, 11,  5, 25, 20,  1,  8,\n",
      "       18, 10, 18,  2,  1,  5, 12, 28, 18]), 'Next Training set size': 587}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 222\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='222' max='222' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [222/222 00:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    }
   ],
   "source": [
    "al_epochs=30\n",
    "performance_history_abortion1=[unqueried_score]\n",
    "for epoch in range(al_epochs):\n",
    "    model_abortion.train()\n",
    "    eval_metrics = model_abortion.evaluate()\n",
    "    should_continue = active_loop_abortion.step()\n",
    "    model_abortion.load_state_dict(init_weights)\n",
    "    model_abortion.lr_scheduler = None\n",
    "    if not should_continue:\n",
    "            break\n",
    "    active_logs = {\n",
    "        \"epoch\": epoch,\n",
    "        \"labeled_data\": active_set_abortion.labelled_map,\n",
    "        \"Next Training set size\": len(active_set_abortion),\n",
    "    }\n",
    "\n",
    "    logs = {**eval_metrics, **active_logs}\n",
    "    performance_history_abortion1.append(eval_metrics['eval_accuracy'])\n",
    "    print(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d82d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4337515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613057a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e7209b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0f3fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc9cb00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b343b178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cefa69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcce576a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2597d80b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e9a37e3",
   "metadata": {},
   "source": [
    "# Initial training set is 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66092d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_abortion\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset with 587 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_abortion\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset with 66 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_abortion\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset with 280 instances loaded\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "cache_dir = \"./data_cache\"\n",
    "\n",
    "train_dataset_abortion = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_abortion\",\n",
    "    split=\"train\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Training dataset with {len(train_dataset_abortion)} instances loaded\")\n",
    "\n",
    "val_dataset_abortion = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_abortion\",\n",
    "    split=\"validation\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Validation dataset with {len(val_dataset_abortion)} instances loaded\")\n",
    "\n",
    "test_dataset_abortion = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_abortion\",\n",
    "    split=\"test\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Test dataset with {len(test_dataset_abortion)} instances loaded\")\n",
    "\n",
    "num_classes = np.unique(train_dataset_abortion['label']).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b42e2185",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/config.json from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\3cf34679007e9fe5d0acd644dcc1f4b26bec5cbc9612364f6da7262aed4ef7a4.a5a11219cf90aae61ff30e1658ccf2cb4aa84d6b6e947336556f887c9828dc6d\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-tiny\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/pytorch_model.bin from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\1ee037c9e1a220d5c814779ffe697080d1e6f5b1602e16cf6061aaae41a082c5.038e1aed90492a59d2283f9c44c9fe3ee2380495ff1e7fefb3f1f04af3b685b5\n",
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at prajjwal1/bert-tiny.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/config.json from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\3cf34679007e9fe5d0acd644dcc1f4b26bec5cbc9612364f6da7262aed4ef7a4.a5a11219cf90aae61ff30e1658ccf2cb4aa84d6b6e947336556f887c9828dc6d\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-tiny\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/vocab.txt from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\585ac1c3dedc6b808dd35e8770afafe10905d3e723a02617af749d39db780e09.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/config.json from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\3cf34679007e9fe5d0acd644dcc1f4b26bec5cbc9612364f6da7262aed4ef7a4.a5a11219cf90aae61ff30e1658ccf2cb4aa84d6b6e947336556f887c9828dc6d\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-tiny\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/config.json from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\3cf34679007e9fe5d0acd644dcc1f4b26bec5cbc9612364f6da7262aed4ef7a4.a5a11219cf90aae61ff30e1658ccf2cb4aa84d6b6e947336556f887c9828dc6d\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-tiny\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/config.json from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\3cf34679007e9fe5d0acd644dcc1f4b26bec5cbc9612364f6da7262aed4ef7a4.a5a11219cf90aae61ff30e1658ccf2cb4aa84d6b6e947336556f887c9828dc6d\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-tiny\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/pytorch_model.bin from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\1ee037c9e1a220d5c814779ffe697080d1e6f5b1602e16cf6061aaae41a082c5.038e1aed90492a59d2283f9c44c9fe3ee2380495ff1e7fefb3f1f04af3b685b5\n",
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel # For BERTs\n",
    "\n",
    "model_abortion = AutoModel.from_pretrained(\"prajjwal1/bert-tiny\") \n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-tiny\") \n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_abortion = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\", num_labels=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1640fc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495\n"
     ]
    }
   ],
   "source": [
    "from baal.active import ActiveLearningDataset\n",
    "active_set_abortion =active_huggingface_dataset(train_dataset_abortion,tokenizer,'label','text')\n",
    "valid_set_abortion = HuggingFaceDatasets(test_dataset_abortion,tokenizer,'label','text')\n",
    "# # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "active_set_abortion.can_label = False\n",
    "active_set_abortion.label(training_indices2)\n",
    "print(len(active_set_abortion.pool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d32415d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from baal.active import get_heuristic\n",
    "\n",
    "heuristic = get_heuristic('entropy')\n",
    "model_abortion = patch_module(model_abortion)\n",
    "init_weights = deepcopy(model_abortion.state_dict())\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"transformer_checkpoints\",  # specify the directory where models weights will be saved a certain points during training (checkpoints)\n",
    "    num_train_epochs=3,  # change this if it is taking too long on your computer\n",
    ")  \n",
    "def compute_metrics(p):\n",
    "    label = p.label_ids\n",
    "    preds = np.argmax(p.predictions, axis=-1)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(label, preds),\n",
    "    }\n",
    "model_abortion = BaalTransformersTrainer(\n",
    "        model=model_abortion,\n",
    "        args=training_args,\n",
    "        train_dataset=active_set_abortion,\n",
    "        eval_dataset=valid_set_abortion,\n",
    "        tokenizer=None,\n",
    "        compute_metrics=compute_metrics)\n",
    "active_loop_abortion = ActiveLearningLoop(active_set_abortion,\n",
    "                                 model_abortion.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8baad56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 92\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='945' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 06:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_abortion.train()\n",
    "unqueried_score=model_abortion.evaluate()['eval_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ed59127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 92\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:13:21.887574Z [info     ] Start Predict                  dataset=495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [00:01<00:00, 36.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0412324666976929, 'eval_accuracy': 0.6285714285714286, 'eval_runtime': 1.2151, 'eval_samples_per_second': 230.43, 'eval_steps_per_second': 28.804, 'epoch': 0, 'labeled_data': array([2, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 2, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
      "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "       1, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 1,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
      "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 2, 0,\n",
      "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2, 0, 1, 1, 0, 0, 0, 1, 0,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "       2, 2, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'Next Training set size': 112}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 112\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:13:29.199842Z [info     ] Start Predict                  dataset=475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 37.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0248537063598633, 'eval_accuracy': 0.6642857142857143, 'eval_runtime': 1.1808, 'eval_samples_per_second': 237.122, 'eval_steps_per_second': 29.64, 'epoch': 1, 'labeled_data': array([2, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 2, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0,\n",
      "       0, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 3, 0, 0, 1,\n",
      "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "       1, 0, 0, 2, 1, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       2, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 2, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 1,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
      "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0,\n",
      "       0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 1, 0, 3, 1, 0, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 3, 0,\n",
      "       0, 2, 0, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 2, 3,\n",
      "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2, 0, 1, 1, 0, 0, 0, 1, 0,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "       2, 2, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 3, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0]), 'Next Training set size': 132}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 132\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:04, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:13:37.181519Z [info     ] Start Predict                  dataset=455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 37.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.015305995941162, 'eval_accuracy': 0.6642857142857143, 'eval_runtime': 1.2093, 'eval_samples_per_second': 231.539, 'eval_steps_per_second': 28.942, 'epoch': 2, 'labeled_data': array([2, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 4, 1, 0, 1, 1, 2, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0,\n",
      "       0, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 3, 0, 0, 1,\n",
      "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "       1, 0, 0, 2, 1, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 4, 3, 0, 4, 0, 0, 0, 0, 0, 0, 0,\n",
      "       2, 0, 0, 0, 0, 3, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 2, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 4, 0, 0, 0, 1, 0, 2, 0, 1,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 4, 4, 1, 2, 0, 2, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 4, 3, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
      "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 3, 0,\n",
      "       0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 4, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 4, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 1, 0, 3, 1, 4, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 3, 0,\n",
      "       0, 2, 0, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 2, 3,\n",
      "       0, 1, 4, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2, 0, 1, 1, 0, 0, 0, 1, 0,\n",
      "       1, 0, 0, 4, 0, 0, 0, 4, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "       2, 2, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 1, 1, 0, 4, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 3, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0,\n",
      "       0, 2, 1, 0, 0, 4, 4, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0]), 'Next Training set size': 152}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 152\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:13:45.595285Z [info     ] Start Predict                  dataset=435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 37.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0090991258621216, 'eval_accuracy': 0.675, 'eval_runtime': 1.1822, 'eval_samples_per_second': 236.851, 'eval_steps_per_second': 29.606, 'epoch': 3, 'labeled_data': array([2, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 4, 1, 0, 1, 1, 2, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0,\n",
      "       0, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 3, 0, 0, 1,\n",
      "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "       1, 0, 0, 2, 1, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 1, 0,\n",
      "       0, 5, 0, 1, 0, 0, 0, 1, 1, 1, 0, 4, 3, 0, 4, 0, 0, 0, 0, 0, 0, 0,\n",
      "       2, 0, 0, 0, 0, 3, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 2, 0, 0, 5, 3, 0, 0, 0, 3, 0, 0, 4, 0, 0, 0, 1, 0, 2, 0, 1,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 4, 4, 1, 2, 0, 2, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 4, 3, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
      "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 0, 0, 4, 0, 0, 3, 0,\n",
      "       5, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "       0, 0, 5, 0, 0, 0, 4, 1, 0, 0, 0, 1, 5, 1, 0, 1, 0, 0, 0, 4, 5, 0,\n",
      "       0, 0, 5, 0, 0, 0, 0, 0, 4, 5, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       5, 0, 1, 0, 0, 1, 0, 3, 1, 4, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 3, 0,\n",
      "       0, 2, 0, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 1, 1, 0, 1, 5, 0, 0, 2, 3,\n",
      "       0, 1, 4, 0, 0, 5, 1, 5, 0, 0, 1, 0, 0, 2, 0, 1, 1, 5, 0, 0, 1, 0,\n",
      "       1, 0, 0, 4, 0, 0, 0, 4, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "       2, 2, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 5, 0, 0, 0, 1, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 1, 1, 0, 4, 1, 0, 0, 1, 1, 0, 5, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 3, 0, 0, 5, 1, 2, 1, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0,\n",
      "       0, 2, 1, 0, 0, 4, 4, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 5, 0, 0, 0,\n",
      "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0]), 'Next Training set size': 172}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 172\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:13:54.912015Z [info     ] Start Predict                  dataset=415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 38.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9699029922485352, 'eval_accuracy': 0.675, 'eval_runtime': 1.1838, 'eval_samples_per_second': 236.526, 'eval_steps_per_second': 29.566, 'epoch': 4, 'labeled_data': array([2, 0, 0, 1, 0, 0, 0, 6, 1, 0, 0, 0, 0, 4, 1, 0, 1, 1, 2, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0,\n",
      "       0, 2, 1, 6, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 3, 0, 0, 1,\n",
      "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 6, 0, 0, 0, 0, 0, 1, 1,\n",
      "       1, 0, 0, 2, 1, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 6, 0, 0, 0, 6, 0, 0, 5, 0, 0, 1, 0,\n",
      "       0, 5, 0, 1, 0, 0, 0, 1, 1, 1, 0, 4, 3, 0, 4, 0, 6, 0, 0, 0, 0, 0,\n",
      "       2, 0, 0, 0, 0, 3, 0, 4, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 2, 0, 0, 5, 3, 0, 0, 0, 3, 0, 0, 4, 0, 0, 0, 1, 0, 2, 0, 1,\n",
      "       1, 0, 0, 0, 0, 6, 0, 0, 1, 0, 0, 0, 0, 0, 0, 4, 4, 1, 2, 0, 2, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 6, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 4, 3, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
      "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 0, 0, 4, 0, 6, 3, 0,\n",
      "       5, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "       0, 0, 5, 0, 0, 0, 4, 1, 0, 0, 0, 1, 5, 1, 0, 1, 0, 0, 0, 4, 5, 0,\n",
      "       0, 0, 5, 0, 0, 0, 0, 0, 4, 5, 1, 0, 1, 0, 0, 0, 0, 0, 0, 6, 0, 0,\n",
      "       5, 0, 1, 0, 0, 1, 6, 3, 1, 4, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 6, 6, 1, 0, 0, 6, 3, 0,\n",
      "       0, 2, 0, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 1, 1, 0, 1, 5, 0, 0, 2, 3,\n",
      "       0, 1, 4, 0, 0, 5, 1, 5, 0, 0, 1, 0, 0, 2, 0, 1, 1, 5, 0, 0, 1, 0,\n",
      "       1, 0, 0, 4, 0, 0, 0, 4, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "       2, 2, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 5, 0, 0, 0, 1, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 1, 1, 0, 4, 1, 0, 0, 1, 1, 0, 5, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 3, 0, 0, 6, 0, 3, 6, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 6, 0, 3, 0, 0, 5, 1, 2, 1, 0, 0, 0, 0, 4, 0, 6, 6, 0, 0,\n",
      "       0, 2, 1, 0, 0, 4, 4, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 5, 0, 0, 0,\n",
      "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0]), 'Next Training set size': 192}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 192\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:06, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:14:04.488188Z [info     ] Start Predict                  dataset=395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 37.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9751780033111572, 'eval_accuracy': 0.6714285714285714, 'eval_runtime': 1.1793, 'eval_samples_per_second': 237.438, 'eval_steps_per_second': 29.68, 'epoch': 5, 'labeled_data': array([2, 0, 0, 1, 0, 0, 0, 6, 1, 0, 0, 0, 0, 4, 1, 0, 1, 1, 2, 0, 7, 0,\n",
      "       0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 2, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0,\n",
      "       0, 2, 1, 6, 7, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 3, 0, 0, 1,\n",
      "       0, 1, 0, 0, 0, 0, 0, 1, 0, 7, 1, 1, 0, 0, 6, 0, 0, 0, 0, 0, 1, 1,\n",
      "       1, 0, 7, 2, 1, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 7, 2, 0, 0, 0, 0, 1,\n",
      "       0, 0, 0, 0, 7, 0, 0, 0, 3, 0, 6, 0, 0, 0, 6, 0, 0, 5, 0, 0, 1, 0,\n",
      "       0, 5, 0, 1, 0, 0, 0, 1, 1, 1, 0, 4, 3, 0, 4, 0, 6, 0, 0, 0, 0, 0,\n",
      "       2, 0, 0, 0, 0, 3, 0, 4, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 7, 2, 0, 0, 5, 3, 0, 0, 0, 3, 0, 0, 4, 0, 0, 0, 1, 0, 2, 0, 1,\n",
      "       1, 0, 0, 0, 0, 6, 0, 0, 1, 0, 0, 0, 0, 0, 0, 4, 4, 1, 2, 0, 2, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 5, 0, 0, 0, 0, 0, 6, 0,\n",
      "       0, 0, 0, 0, 0, 0, 7, 0, 4, 3, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
      "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 0, 0, 4, 0, 6, 3, 0,\n",
      "       5, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "       0, 0, 5, 0, 0, 7, 4, 1, 0, 0, 0, 1, 5, 1, 0, 1, 0, 0, 7, 4, 5, 0,\n",
      "       0, 0, 5, 0, 0, 0, 0, 0, 4, 5, 1, 0, 1, 0, 0, 0, 0, 0, 0, 6, 0, 0,\n",
      "       5, 0, 1, 0, 0, 1, 6, 3, 1, 4, 0, 3, 1, 0, 7, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 6, 6, 1, 0, 0, 6, 3, 0,\n",
      "       0, 2, 0, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 1, 1, 0, 1, 5, 0, 7, 2, 3,\n",
      "       0, 1, 4, 0, 0, 5, 1, 5, 0, 0, 1, 0, 0, 2, 0, 1, 1, 5, 0, 0, 1, 7,\n",
      "       1, 0, 0, 4, 0, 0, 0, 4, 0, 0, 2, 0, 0, 0, 0, 0, 0, 7, 0, 1, 1, 0,\n",
      "       2, 2, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 5, 0, 0, 0, 1, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 1, 1, 0, 4, 1, 0, 0, 1, 1, 0, 5, 7, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 7, 1, 3, 0, 0, 6, 0, 3, 6, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 6, 0, 3, 0, 0, 5, 1, 2, 1, 0, 0, 0, 0, 4, 0, 6, 6, 0, 0,\n",
      "       0, 2, 1, 0, 7, 4, 4, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 5, 0, 0, 0,\n",
      "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0]), 'Next Training set size': 212}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 212\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 81\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='81' max='81' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [81/81 00:07, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:14:14.936397Z [info     ] Start Predict                  dataset=375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 38.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9610133767127991, 'eval_accuracy': 0.6785714285714286, 'eval_runtime': 1.1848, 'eval_samples_per_second': 236.319, 'eval_steps_per_second': 29.54, 'epoch': 6, 'labeled_data': array([2, 0, 0, 1, 0, 8, 8, 6, 1, 0, 8, 0, 0, 4, 1, 0, 1, 1, 2, 0, 7, 0,\n",
      "       0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 2, 0, 0, 0, 0, 3, 0, 0, 8, 0, 0,\n",
      "       0, 2, 1, 6, 7, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 3, 0, 0, 1,\n",
      "       0, 1, 0, 0, 0, 0, 0, 1, 0, 7, 1, 1, 0, 0, 6, 8, 0, 0, 0, 0, 1, 1,\n",
      "       1, 0, 7, 2, 1, 0, 0, 0, 0, 3, 8, 1, 0, 0, 0, 7, 2, 0, 0, 0, 0, 1,\n",
      "       0, 0, 0, 0, 7, 0, 0, 0, 3, 0, 6, 0, 0, 0, 6, 0, 0, 5, 0, 0, 1, 0,\n",
      "       0, 5, 0, 1, 0, 0, 0, 1, 1, 1, 0, 4, 3, 0, 4, 8, 6, 0, 0, 0, 0, 8,\n",
      "       2, 0, 0, 0, 0, 3, 0, 4, 0, 0, 0, 0, 0, 8, 6, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 7, 2, 0, 0, 5, 3, 0, 0, 0, 3, 0, 0, 4, 0, 0, 0, 1, 0, 2, 0, 1,\n",
      "       1, 0, 0, 0, 0, 6, 0, 0, 1, 0, 0, 0, 0, 0, 0, 4, 4, 1, 2, 0, 2, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 7, 5, 0, 0, 0, 0, 0, 6, 0,\n",
      "       0, 0, 8, 0, 0, 0, 7, 0, 4, 3, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
      "       0, 1, 8, 0, 0, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 0, 0, 4, 0, 6, 3, 0,\n",
      "       5, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "       0, 0, 5, 0, 0, 7, 4, 1, 0, 0, 0, 1, 5, 1, 0, 1, 0, 0, 7, 4, 5, 0,\n",
      "       8, 0, 5, 0, 0, 8, 0, 0, 4, 5, 1, 0, 1, 0, 0, 0, 0, 0, 0, 6, 0, 0,\n",
      "       5, 0, 1, 0, 0, 1, 6, 3, 1, 4, 0, 3, 1, 0, 7, 0, 0, 0, 0, 8, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 6, 6, 1, 0, 0, 6, 3, 0,\n",
      "       0, 2, 0, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 1, 1, 8, 1, 5, 0, 7, 2, 3,\n",
      "       0, 1, 4, 8, 0, 5, 1, 5, 0, 0, 1, 0, 0, 2, 0, 1, 1, 5, 0, 0, 1, 7,\n",
      "       1, 0, 0, 4, 0, 0, 0, 4, 0, 0, 2, 0, 0, 0, 0, 0, 0, 7, 0, 1, 1, 0,\n",
      "       2, 2, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 5, 0, 0, 0, 1, 1, 0, 0,\n",
      "       0, 0, 1, 0, 8, 1, 1, 0, 4, 1, 0, 0, 1, 1, 0, 5, 7, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 7, 1, 3, 0, 0, 6, 0, 3, 6, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 6, 0, 3, 0, 0, 5, 1, 2, 1, 0, 8, 0, 0, 4, 0, 6, 6, 0, 0,\n",
      "       0, 2, 1, 0, 7, 4, 4, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 5, 0, 0, 0,\n",
      "       0, 0, 1, 1, 0, 0, 0, 0, 0, 8, 3, 0, 0, 0, 0]), 'Next Training set size': 232}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 232\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 87\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='87' max='87' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [87/87 00:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:14:26.643402Z [info     ] Start Predict                  dataset=355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 39.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9616681933403015, 'eval_accuracy': 0.6785714285714286, 'eval_runtime': 1.1766, 'eval_samples_per_second': 237.967, 'eval_steps_per_second': 29.746, 'epoch': 7, 'labeled_data': array([2, 0, 0, 1, 0, 8, 8, 6, 1, 0, 8, 0, 9, 4, 1, 0, 1, 1, 2, 0, 7, 0,\n",
      "       0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 2, 0, 0, 0, 0, 3, 9, 9, 8, 0, 0,\n",
      "       9, 2, 1, 6, 7, 0, 0, 1, 0, 0, 0, 0, 1, 9, 1, 0, 1, 0, 3, 0, 0, 1,\n",
      "       0, 1, 0, 0, 0, 0, 0, 1, 0, 7, 1, 1, 0, 0, 6, 8, 0, 0, 0, 0, 1, 1,\n",
      "       1, 0, 7, 2, 1, 0, 0, 0, 0, 3, 8, 1, 0, 0, 0, 7, 2, 0, 0, 0, 0, 1,\n",
      "       0, 0, 0, 0, 7, 9, 0, 0, 3, 0, 6, 9, 9, 0, 6, 0, 0, 5, 0, 0, 1, 0,\n",
      "       0, 5, 0, 1, 0, 0, 0, 1, 1, 1, 0, 4, 3, 0, 4, 8, 6, 0, 0, 0, 0, 8,\n",
      "       2, 0, 0, 0, 0, 3, 0, 4, 0, 0, 0, 0, 0, 8, 6, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 7, 2, 0, 0, 5, 3, 0, 0, 0, 3, 0, 0, 4, 0, 0, 0, 1, 0, 2, 0, 1,\n",
      "       1, 0, 0, 0, 0, 6, 0, 0, 1, 0, 0, 0, 0, 0, 0, 4, 4, 1, 2, 0, 2, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 7, 5, 0, 0, 0, 0, 0, 6, 0,\n",
      "       0, 0, 8, 0, 0, 0, 7, 0, 4, 3, 0, 9, 0, 0, 9, 1, 0, 1, 0, 0, 1, 0,\n",
      "       0, 1, 8, 0, 0, 0, 0, 1, 0, 9, 0, 5, 0, 0, 0, 0, 0, 4, 0, 6, 3, 0,\n",
      "       5, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "       0, 0, 5, 0, 0, 7, 4, 1, 0, 0, 0, 1, 5, 1, 0, 1, 0, 0, 7, 4, 5, 0,\n",
      "       8, 0, 5, 9, 0, 8, 0, 0, 4, 5, 1, 0, 1, 0, 0, 0, 0, 0, 0, 6, 0, 0,\n",
      "       5, 0, 1, 0, 0, 1, 6, 3, 1, 4, 0, 3, 1, 0, 7, 0, 0, 0, 0, 8, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 6, 6, 1, 0, 0, 6, 3, 0,\n",
      "       0, 2, 0, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 1, 1, 8, 1, 5, 0, 7, 2, 3,\n",
      "       0, 1, 4, 8, 0, 5, 1, 5, 0, 9, 1, 0, 0, 2, 0, 1, 1, 5, 9, 0, 1, 7,\n",
      "       1, 0, 0, 4, 0, 0, 0, 4, 0, 0, 2, 0, 0, 0, 0, 0, 0, 7, 0, 1, 1, 0,\n",
      "       2, 2, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 5, 0, 0, 0, 1, 1, 0, 0,\n",
      "       0, 0, 1, 9, 8, 1, 1, 0, 4, 1, 0, 0, 1, 1, 0, 5, 7, 0, 0, 1, 0, 0,\n",
      "       0, 0, 9, 0, 0, 0, 0, 1, 7, 1, 3, 0, 0, 6, 0, 3, 6, 0, 9, 0, 0, 0,\n",
      "       0, 0, 1, 6, 9, 3, 0, 0, 5, 1, 2, 1, 0, 8, 0, 0, 4, 0, 6, 6, 0, 0,\n",
      "       0, 2, 1, 0, 7, 4, 4, 1, 0, 0, 0, 0, 1, 0, 0, 0, 9, 0, 5, 0, 0, 0,\n",
      "       0, 0, 1, 1, 9, 0, 0, 0, 0, 8, 3, 0, 0, 0, 0]), 'Next Training set size': 252}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 252\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 96\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [96/96 00:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:14:38.586093Z [info     ] Start Predict                  dataset=335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 37.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9645671248435974, 'eval_accuracy': 0.675, 'eval_runtime': 1.1889, 'eval_samples_per_second': 235.506, 'eval_steps_per_second': 29.438, 'epoch': 8, 'labeled_data': array([ 2,  0,  0,  1,  0,  8,  8,  6,  1,  0,  8,  0,  9,  4,  1,  0,  1,\n",
      "        1,  2,  0,  7,  0,  0,  0,  0,  0,  0, 10,  7,  7,  0,  0,  0,  2,\n",
      "       10,  0,  0,  0,  3,  9,  9,  8,  0,  0,  9,  2,  1,  6,  7,  0,  0,\n",
      "        1,  0,  0, 10,  0,  1,  9,  1,  0,  1,  0,  3,  0, 10,  1,  0,  1,\n",
      "        0,  0,  0,  0, 10,  1, 10,  7,  1,  1,  0,  0,  6,  8,  0,  0,  0,\n",
      "        0,  1,  1,  1,  0,  7,  2,  1,  0,  0, 10,  0,  3,  8,  1,  0,  0,\n",
      "        0,  7,  2,  0,  0,  0,  0,  1,  0, 10,  0,  0,  7,  9,  0,  0,  3,\n",
      "        0,  6,  9,  9,  0,  6,  0, 10,  5,  0,  0,  1,  0,  0,  5,  0,  1,\n",
      "        0,  0, 10,  1,  1,  1,  0,  4,  3,  0,  4,  8,  6,  0,  0,  0,  0,\n",
      "        8,  2,  0,  0,  0,  0,  3,  0,  4,  0,  0,  0,  0,  0,  8,  6,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  7,  2,  0,  0,  5,  3,  0,  0,  0,  3,\n",
      "        0,  0,  4,  0,  0,  0,  1,  0,  2,  0,  1,  1,  0,  0,  0,  0,  6,\n",
      "        0,  0,  1,  0,  0,  0,  0,  0,  0,  4,  4,  1,  2,  0,  2,  0,  0,\n",
      "        0,  1,  0, 10,  0,  0,  0,  0,  0,  8,  0,  0,  7,  5,  0,  0,  0,\n",
      "        0,  0,  6,  0,  0,  0,  8,  0,  0,  0,  7,  0,  4,  3,  0,  9,  0,\n",
      "        0,  9,  1,  0,  1,  0,  0,  1,  0,  0,  1,  8, 10,  0,  0,  0,  1,\n",
      "        0,  9,  0,  5,  0,  0, 10,  0,  0,  4,  0,  6,  3,  0,  5,  0,  0,\n",
      "        0,  0, 10,  3,  0, 10,  0,  1,  0,  2,  0,  0,  1,  0,  0,  1,  1,\n",
      "        0,  0,  0,  0,  5,  0,  0,  7,  4,  1,  0,  0,  0,  1,  5,  1,  0,\n",
      "        1,  0, 10,  7,  4,  5,  0,  8,  0,  5,  9,  0,  8,  0,  0,  4,  5,\n",
      "        1,  0,  1,  0,  0,  0,  0,  0,  0,  6,  0,  0,  5,  0,  1,  0,  0,\n",
      "        1,  6,  3,  1,  4,  0,  3,  1,  0,  7,  0,  0,  0,  0,  8,  0,  0,\n",
      "        0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  6,  6,  1,\n",
      "        0,  0,  6,  3,  0,  0,  2,  0,  0,  0,  1,  0,  0,  0,  3,  0,  0,\n",
      "        0,  1,  1,  8,  1,  5,  0,  7,  2,  3,  0,  1,  4,  8,  0,  5,  1,\n",
      "        5,  0,  9,  1,  0,  0,  2,  0,  1,  1,  5,  9,  0,  1,  7,  1,  0,\n",
      "       10,  4,  0,  0,  0,  4,  0,  0,  2,  0,  0,  0,  0,  0,  0,  7,  0,\n",
      "        1,  1,  0,  2,  2,  0,  1,  0,  1,  0,  0,  0,  1,  1,  1,  0,  1,\n",
      "        5,  0,  0,  0,  1,  1,  0,  0,  0,  0,  1,  9,  8,  1,  1,  0,  4,\n",
      "        1,  0,  0,  1,  1,  0,  5,  7,  0,  0,  1,  0,  0,  0,  0,  9,  0,\n",
      "       10,  0,  0,  1,  7,  1,  3,  0,  0,  6,  0,  3,  6,  0,  9,  0,  0,\n",
      "        0,  0,  0,  1,  6,  9,  3,  0,  0,  5,  1,  2,  1,  0,  8,  0,  0,\n",
      "        4,  0,  6,  6,  0,  0,  0,  2,  1,  0,  7,  4,  4,  1,  0,  0, 10,\n",
      "        0,  1,  0,  0,  0,  9,  0,  5,  0,  0,  0,  0,  0,  1,  1,  9,  0,\n",
      "        0,  0, 10,  8,  3,  0,  0,  0,  0]), 'Next Training set size': 272}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 272\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 102\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='102' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 00:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:14:50.757688Z [info     ] Start Predict                  dataset=315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 38.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9793580174446106, 'eval_accuracy': 0.6714285714285714, 'eval_runtime': 1.2338, 'eval_samples_per_second': 226.933, 'eval_steps_per_second': 28.367, 'epoch': 9, 'labeled_data': array([ 2,  0,  0,  1, 11,  8,  8,  6,  1,  0,  8,  0,  9,  4,  1,  0,  1,\n",
      "        1,  2,  0,  7,  0,  0,  0,  0,  0,  0, 10,  7,  7,  0,  0,  0,  2,\n",
      "       10,  0,  0,  0,  3,  9,  9,  8,  0,  0,  9,  2,  1,  6,  7,  0,  0,\n",
      "        1,  0,  0, 10, 11,  1,  9,  1,  0,  1,  0,  3,  0, 10,  1,  0,  1,\n",
      "        0,  0,  0,  0, 10,  1, 10,  7,  1,  1, 11,  0,  6,  8,  0,  0,  0,\n",
      "        0,  1,  1,  1,  0,  7,  2,  1,  0,  0, 10,  0,  3,  8,  1,  0,  0,\n",
      "        0,  7,  2,  0,  0,  0,  0,  1, 11, 10, 11,  0,  7,  9,  0,  0,  3,\n",
      "        0,  6,  9,  9,  0,  6,  0, 10,  5,  0,  0,  1,  0, 11,  5,  0,  1,\n",
      "        0,  0, 10,  1,  1,  1,  0,  4,  3,  0,  4,  8,  6,  0,  0, 11,  0,\n",
      "        8,  2,  0,  0,  0,  0,  3,  0,  4, 11,  0,  0,  0,  0,  8,  6,  0,\n",
      "        0,  0,  0,  0,  0, 11,  0,  7,  2,  0,  0,  5,  3,  0,  0,  0,  3,\n",
      "        0,  0,  4,  0,  0,  0,  1,  0,  2,  0,  1,  1,  0,  0,  0,  0,  6,\n",
      "        0,  0,  1,  0,  0,  0,  0,  0,  0,  4,  4,  1,  2,  0,  2,  0,  0,\n",
      "        0,  1,  0, 10,  0,  0,  0,  0,  0,  8,  0,  0,  7,  5,  0,  0,  0,\n",
      "        0,  0,  6,  0,  0,  0,  8,  0,  0,  0,  7,  0,  4,  3,  0,  9,  0,\n",
      "        0,  9,  1,  0,  1,  0,  0,  1,  0,  0,  1,  8, 10,  0,  0,  0,  1,\n",
      "        0,  9,  0,  5,  0,  0, 10,  0,  0,  4,  0,  6,  3,  0,  5,  0,  0,\n",
      "        0,  0, 10,  3,  0, 10,  0,  1,  0,  2,  0,  0,  1, 11, 11,  1,  1,\n",
      "        0,  0,  0,  0,  5,  0, 11,  7,  4,  1,  0,  0,  0,  1,  5,  1,  0,\n",
      "        1,  0, 10,  7,  4,  5,  0,  8,  0,  5,  9,  0,  8,  0,  0,  4,  5,\n",
      "        1,  0,  1,  0,  0,  0,  0,  0,  0,  6,  0,  0,  5,  0,  1,  0,  0,\n",
      "        1,  6,  3,  1,  4,  0,  3,  1, 11,  7,  0,  0,  0,  0,  8,  0,  0,\n",
      "        0, 11,  0,  1,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  6,  6,  1,\n",
      "        0,  0,  6,  3,  0,  0,  2,  0,  0,  0,  1,  0,  0,  0,  3,  0,  0,\n",
      "        0,  1,  1,  8,  1,  5, 11,  7,  2,  3,  0,  1,  4,  8,  0,  5,  1,\n",
      "        5,  0,  9,  1,  0,  0,  2, 11,  1,  1,  5,  9,  0,  1,  7,  1,  0,\n",
      "       10,  4,  0,  0,  0,  4,  0,  0,  2, 11,  0,  0,  0,  0,  0,  7,  0,\n",
      "        1,  1,  0,  2,  2,  0,  1,  0,  1,  0,  0,  0,  1,  1,  1,  0,  1,\n",
      "        5,  0,  0,  0,  1,  1, 11,  0, 11,  0,  1,  9,  8,  1,  1,  0,  4,\n",
      "        1,  0,  0,  1,  1,  0,  5,  7,  0,  0,  1,  0,  0,  0,  0,  9,  0,\n",
      "       10,  0,  0,  1,  7,  1,  3,  0,  0,  6,  0,  3,  6,  0,  9,  0,  0,\n",
      "        0,  0,  0,  1,  6,  9,  3,  0,  0,  5,  1,  2,  1,  0,  8,  0,  0,\n",
      "        4,  0,  6,  6,  0,  0,  0,  2,  1,  0,  7,  4,  4,  1,  0,  0, 10,\n",
      "        0,  1,  0,  0,  0,  9,  0,  5,  0,  0,  0,  0, 11,  1,  1,  9,  0,\n",
      "        0,  0, 10,  8,  3,  0,  0,  0,  0]), 'Next Training set size': 292}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 292\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 111\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='111' max='111' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [111/111 00:10, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:15:03.666953Z [info     ] Start Predict                  dataset=295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:00<00:00, 37.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9656986594200134, 'eval_accuracy': 0.6785714285714286, 'eval_runtime': 1.1946, 'eval_samples_per_second': 234.392, 'eval_steps_per_second': 29.299, 'epoch': 10, 'labeled_data': array([ 2,  0,  0,  1, 11,  8,  8,  6,  1, 12,  8,  0,  9,  4,  1,  0,  1,\n",
      "        1,  2,  0,  7,  0,  0, 12,  0,  0,  0, 10,  7,  7,  0,  0,  0,  2,\n",
      "       10, 12,  0,  0,  3,  9,  9,  8,  0,  0,  9,  2,  1,  6,  7, 12,  0,\n",
      "        1,  0,  0, 10, 11,  1,  9,  1,  0,  1,  0,  3,  0, 10,  1,  0,  1,\n",
      "        0,  0,  0,  0, 10,  1, 10,  7,  1,  1, 11,  0,  6,  8,  0,  0,  0,\n",
      "        0,  1,  1,  1,  0,  7,  2,  1,  0,  0, 10,  0,  3,  8,  1,  0,  0,\n",
      "        0,  7,  2,  0,  0,  0,  0,  1, 11, 10, 11,  0,  7,  9,  0,  0,  3,\n",
      "        0,  6,  9,  9,  0,  6,  0, 10,  5,  0,  0,  1,  0, 11,  5,  0,  1,\n",
      "        0,  0, 10,  1,  1,  1,  0,  4,  3,  0,  4,  8,  6,  0,  0, 11,  0,\n",
      "        8,  2,  0,  0,  0,  0,  3,  0,  4, 11,  0,  0,  0,  0,  8,  6,  0,\n",
      "        0,  0,  0,  0,  0, 11,  0,  7,  2,  0,  0,  5,  3,  0,  0,  0,  3,\n",
      "        0,  0,  4,  0,  0,  0,  1,  0,  2,  0,  1,  1,  0,  0,  0,  0,  6,\n",
      "        0,  0,  1,  0,  0,  0,  0,  0,  0,  4,  4,  1,  2,  0,  2,  0,  0,\n",
      "        0,  1,  0, 10,  0,  0,  0,  0,  0,  8,  0,  0,  7,  5, 12,  0,  0,\n",
      "        0,  0,  6,  0,  0,  0,  8,  0,  0,  0,  7,  0,  4,  3,  0,  9,  0,\n",
      "        0,  9,  1,  0,  1,  0,  0,  1,  0, 12,  1,  8, 10,  0,  0,  0,  1,\n",
      "        0,  9,  0,  5,  0,  0, 10,  0,  0,  4,  0,  6,  3,  0,  5,  0,  0,\n",
      "        0,  0, 10,  3,  0, 10,  0,  1,  0,  2,  0,  0,  1, 11, 11,  1,  1,\n",
      "        0,  0, 12,  0,  5,  0, 11,  7,  4,  1,  0, 12,  0,  1,  5,  1,  0,\n",
      "        1,  0, 10,  7,  4,  5,  0,  8,  0,  5,  9,  0,  8, 12,  0,  4,  5,\n",
      "        1,  0,  1,  0,  0,  0,  0,  0,  0,  6,  0,  0,  5,  0,  1,  0,  0,\n",
      "        1,  6,  3,  1,  4,  0,  3,  1, 11,  7,  0,  0,  0,  0,  8,  0,  0,\n",
      "        0, 11,  0,  1,  0, 12,  0,  0,  0,  0,  0,  1,  0, 12,  6,  6,  1,\n",
      "        0, 12,  6,  3,  0,  0,  2,  0,  0,  0,  1,  0, 12,  0,  3,  0,  0,\n",
      "        0,  1,  1,  8,  1,  5, 11,  7,  2,  3,  0,  1,  4,  8,  0,  5,  1,\n",
      "        5,  0,  9,  1,  0,  0,  2, 11,  1,  1,  5,  9,  0,  1,  7,  1,  0,\n",
      "       10,  4,  0,  0,  0,  4,  0,  0,  2, 11,  0,  0,  0,  0,  0,  7,  0,\n",
      "        1,  1,  0,  2,  2,  0,  1, 12,  1,  0,  0,  0,  1,  1,  1,  0,  1,\n",
      "        5,  0,  0, 12,  1,  1, 11,  0, 11,  0,  1,  9,  8,  1,  1,  0,  4,\n",
      "        1,  0,  0,  1,  1, 12,  5,  7,  0, 12,  1,  0,  0, 12,  0,  9,  0,\n",
      "       10,  0,  0,  1,  7,  1,  3, 12,  0,  6,  0,  3,  6,  0,  9,  0,  0,\n",
      "        0,  0,  0,  1,  6,  9,  3,  0,  0,  5,  1,  2,  1,  0,  8,  0,  0,\n",
      "        4,  0,  6,  6,  0,  0,  0,  2,  1,  0,  7,  4,  4,  1,  0,  0, 10,\n",
      "        0,  1,  0,  0,  0,  9,  0,  5,  0,  0,  0,  0, 11,  1,  1,  9,  0,\n",
      "        0, 12, 10,  8,  3,  0,  0,  0,  0]), 'Next Training set size': 312}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 312\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 117\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='117' max='117' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [117/117 00:10, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:15:17.331044Z [info     ] Start Predict                  dataset=275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:00<00:00, 38.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9685006141662598, 'eval_accuracy': 0.675, 'eval_runtime': 1.194, 'eval_samples_per_second': 234.514, 'eval_steps_per_second': 29.314, 'epoch': 11, 'labeled_data': array([ 2,  0,  0,  1, 11,  8,  8,  6,  1, 12,  8,  0,  9,  4,  1, 13,  1,\n",
      "        1,  2,  0,  7,  0,  0, 12,  0,  0,  0, 10,  7,  7,  0,  0,  0,  2,\n",
      "       10, 12,  0,  0,  3,  9,  9,  8,  0,  0,  9,  2,  1,  6,  7, 12,  0,\n",
      "        1,  0,  0, 10, 11,  1,  9,  1,  0,  1,  0,  3,  0, 10,  1,  0,  1,\n",
      "        0,  0,  0,  0, 10,  1, 10,  7,  1,  1, 11,  0,  6,  8,  0, 13,  0,\n",
      "        0,  1,  1,  1,  0,  7,  2,  1, 13,  0, 10,  0,  3,  8,  1,  0,  0,\n",
      "        0,  7,  2,  0, 13,  0,  0,  1, 11, 10, 11,  0,  7,  9,  0,  0,  3,\n",
      "        0,  6,  9,  9,  0,  6,  0, 10,  5,  0,  0,  1,  0, 11,  5,  0,  1,\n",
      "       13,  0, 10,  1,  1,  1,  0,  4,  3,  0,  4,  8,  6,  0,  0, 11,  0,\n",
      "        8,  2,  0,  0,  0, 13,  3,  0,  4, 11,  0,  0,  0,  0,  8,  6,  0,\n",
      "        0,  0,  0,  0,  0, 11,  0,  7,  2,  0,  0,  5,  3,  0,  0,  0,  3,\n",
      "        0,  0,  4,  0,  0,  0,  1,  0,  2,  0,  1,  1,  0,  0,  0,  0,  6,\n",
      "        0,  0,  1,  0,  0,  0,  0,  0,  0,  4,  4,  1,  2,  0,  2,  0,  0,\n",
      "        0,  1,  0, 10,  0, 13,  0,  0,  0,  8,  0,  0,  7,  5, 12,  0,  0,\n",
      "        0,  0,  6,  0,  0,  0,  8,  0,  0,  0,  7,  0,  4,  3,  0,  9,  0,\n",
      "        0,  9,  1,  0,  1,  0,  0,  1,  0, 12,  1,  8, 10,  0,  0,  0,  1,\n",
      "        0,  9,  0,  5,  0,  0, 10,  0,  0,  4,  0,  6,  3,  0,  5,  0,  0,\n",
      "        0,  0, 10,  3,  0, 10,  0,  1,  0,  2,  0,  0,  1, 11, 11,  1,  1,\n",
      "        0,  0, 12,  0,  5,  0, 11,  7,  4,  1,  0, 12,  0,  1,  5,  1,  0,\n",
      "        1,  0, 10,  7,  4,  5,  0,  8,  0,  5,  9, 13,  8, 12, 13,  4,  5,\n",
      "        1,  0,  1,  0,  0,  0,  0,  0,  0,  6,  0,  0,  5,  0,  1,  0,  0,\n",
      "        1,  6,  3,  1,  4,  0,  3,  1, 11,  7,  0,  0,  0,  0,  8,  0, 13,\n",
      "        0, 11,  0,  1,  0, 12,  0,  0,  0,  0,  0,  1, 13, 12,  6,  6,  1,\n",
      "        0, 12,  6,  3,  0,  0,  2,  0,  0,  0,  1,  0, 12,  0,  3,  0,  0,\n",
      "        0,  1,  1,  8,  1,  5, 11,  7,  2,  3,  0,  1,  4,  8,  0,  5,  1,\n",
      "        5,  0,  9,  1,  0,  0,  2, 11,  1,  1,  5,  9,  0,  1,  7,  1,  0,\n",
      "       10,  4,  0,  0, 13,  4,  0,  0,  2, 11,  0,  0,  0,  0,  0,  7,  0,\n",
      "        1,  1, 13,  2,  2,  0,  1, 12,  1,  0,  0,  0,  1,  1,  1,  0,  1,\n",
      "        5,  0,  0, 12,  1,  1, 11,  0, 11,  0,  1,  9,  8,  1,  1,  0,  4,\n",
      "        1,  0,  0,  1,  1, 12,  5,  7,  0, 12,  1,  0,  0, 12,  0,  9,  0,\n",
      "       10,  0, 13,  1,  7,  1,  3, 12,  0,  6,  0,  3,  6,  0,  9,  0,  0,\n",
      "       13,  0,  0,  1,  6,  9,  3, 13,  0,  5,  1,  2,  1,  0,  8, 13,  0,\n",
      "        4,  0,  6,  6,  0,  0,  0,  2,  1,  0,  7,  4,  4,  1,  0,  0, 10,\n",
      "        0,  1,  0,  0,  0,  9, 13,  5,  0,  0, 13,  0, 11,  1,  1,  9,  0,\n",
      "       13, 12, 10,  8,  3,  0,  0,  0,  0]), 'Next Training set size': 332}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 332\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 126\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='126' max='126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [126/126 00:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:15:31.409609Z [info     ] Start Predict                  dataset=255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 39.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9624191522598267, 'eval_accuracy': 0.6785714285714286, 'eval_runtime': 1.1736, 'eval_samples_per_second': 238.584, 'eval_steps_per_second': 29.823, 'epoch': 12, 'labeled_data': array([ 2,  0,  0,  1, 11,  8,  8,  6,  1, 12,  8, 14,  9,  4,  1, 13,  1,\n",
      "        1,  2,  0,  7,  0,  0, 12,  0,  0,  0, 10,  7,  7,  0,  0, 14,  2,\n",
      "       10, 12,  0,  0,  3,  9,  9,  8, 14,  0,  9,  2,  1,  6,  7, 12,  0,\n",
      "        1,  0,  0, 10, 11,  1,  9,  1,  0,  1,  0,  3,  0, 10,  1,  0,  1,\n",
      "        0,  0,  0,  0, 10,  1, 10,  7,  1,  1, 11, 14,  6,  8, 14, 13,  0,\n",
      "        0,  1,  1,  1,  0,  7,  2,  1, 13,  0, 10,  0,  3,  8,  1, 14,  0,\n",
      "        0,  7,  2,  0, 13,  0,  0,  1, 11, 10, 11,  0,  7,  9,  0, 14,  3,\n",
      "        0,  6,  9,  9,  0,  6,  0, 10,  5,  0,  0,  1,  0, 11,  5,  0,  1,\n",
      "       13, 14, 10,  1,  1,  1, 14,  4,  3,  0,  4,  8,  6,  0,  0, 11,  0,\n",
      "        8,  2,  0,  0,  0, 13,  3,  0,  4, 11,  0,  0,  0,  0,  8,  6,  0,\n",
      "        0,  0,  0,  0,  0, 11, 14,  7,  2,  0,  0,  5,  3,  0,  0,  0,  3,\n",
      "        0,  0,  4,  0,  0,  0,  1,  0,  2,  0,  1,  1, 14,  0,  0,  0,  6,\n",
      "        0,  0,  1,  0,  0,  0,  0,  0,  0,  4,  4,  1,  2,  0,  2,  0,  0,\n",
      "        0,  1,  0, 10,  0, 13,  0,  0,  0,  8,  0,  0,  7,  5, 12,  0,  0,\n",
      "        0,  0,  6,  0,  0,  0,  8,  0, 14,  0,  7,  0,  4,  3,  0,  9,  0,\n",
      "        0,  9,  1,  0,  1,  0,  0,  1,  0, 12,  1,  8, 10,  0,  0,  0,  1,\n",
      "        0,  9,  0,  5,  0,  0, 10,  0,  0,  4,  0,  6,  3, 14,  5,  0,  0,\n",
      "        0,  0, 10,  3,  0, 10,  0,  1,  0,  2,  0,  0,  1, 11, 11,  1,  1,\n",
      "        0, 14, 12,  0,  5,  0, 11,  7,  4,  1,  0, 12,  0,  1,  5,  1, 14,\n",
      "        1,  0, 10,  7,  4,  5,  0,  8,  0,  5,  9, 13,  8, 12, 13,  4,  5,\n",
      "        1,  0,  1,  0,  0,  0, 14,  0,  0,  6,  0, 14,  5,  0,  1,  0,  0,\n",
      "        1,  6,  3,  1,  4,  0,  3,  1, 11,  7,  0,  0,  0,  0,  8,  0, 13,\n",
      "        0, 11,  0,  1,  0, 12,  0,  0,  0,  0,  0,  1, 13, 12,  6,  6,  1,\n",
      "        0, 12,  6,  3,  0, 14,  2,  0,  0,  0,  1,  0, 12,  0,  3,  0,  0,\n",
      "        0,  1,  1,  8,  1,  5, 11,  7,  2,  3,  0,  1,  4,  8,  0,  5,  1,\n",
      "        5,  0,  9,  1,  0,  0,  2, 11,  1,  1,  5,  9,  0,  1,  7,  1,  0,\n",
      "       10,  4,  0,  0, 13,  4,  0,  0,  2, 11,  0,  0,  0,  0,  0,  7,  0,\n",
      "        1,  1, 13,  2,  2,  0,  1, 12,  1,  0,  0,  0,  1,  1,  1,  0,  1,\n",
      "        5,  0,  0, 12,  1,  1, 11,  0, 11,  0,  1,  9,  8,  1,  1, 14,  4,\n",
      "        1,  0,  0,  1,  1, 12,  5,  7,  0, 12,  1,  0,  0, 12,  0,  9,  0,\n",
      "       10,  0, 13,  1,  7,  1,  3, 12,  0,  6,  0,  3,  6,  0,  9,  0,  0,\n",
      "       13,  0,  0,  1,  6,  9,  3, 13,  0,  5,  1,  2,  1,  0,  8, 13,  0,\n",
      "        4,  0,  6,  6,  0, 14,  0,  2,  1,  0,  7,  4,  4,  1,  0,  0, 10,\n",
      "        0,  1,  0,  0,  0,  9, 13,  5,  0,  0, 13,  0, 11,  1,  1,  9,  0,\n",
      "       13, 12, 10,  8,  3,  0,  0,  0,  0]), 'Next Training set size': 352}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 352\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 00:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:15:46.104559Z [info     ] Start Predict                  dataset=235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 39.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9621921181678772, 'eval_accuracy': 0.6785714285714286, 'eval_runtime': 1.1619, 'eval_samples_per_second': 240.981, 'eval_steps_per_second': 30.123, 'epoch': 13, 'labeled_data': array([ 2,  0,  0,  1, 11,  8,  8,  6,  1, 12,  8, 14,  9,  4,  1, 13,  1,\n",
      "        1,  2,  0,  7,  0,  0, 12,  0,  0,  0, 10,  7,  7,  0,  0, 14,  2,\n",
      "       10, 12, 15,  0,  3,  9,  9,  8, 14,  0,  9,  2,  1,  6,  7, 12,  0,\n",
      "        1,  0,  0, 10, 11,  1,  9,  1,  0,  1,  0,  3,  0, 10,  1,  0,  1,\n",
      "        0,  0,  0,  0, 10,  1, 10,  7,  1,  1, 11, 14,  6,  8, 14, 13,  0,\n",
      "        0,  1,  1,  1, 15,  7,  2,  1, 13,  0, 10,  0,  3,  8,  1, 14, 15,\n",
      "        0,  7,  2,  0, 13,  0, 15,  1, 11, 10, 11,  0,  7,  9,  0, 14,  3,\n",
      "        0,  6,  9,  9,  0,  6,  0, 10,  5,  0,  0,  1,  0, 11,  5,  0,  1,\n",
      "       13, 14, 10,  1,  1,  1, 14,  4,  3,  0,  4,  8,  6,  0, 15, 11,  0,\n",
      "        8,  2,  0,  0,  0, 13,  3,  0,  4, 11,  0,  0, 15, 15,  8,  6,  0,\n",
      "       15, 15,  0,  0,  0, 11, 14,  7,  2,  0,  0,  5,  3,  0,  0,  0,  3,\n",
      "        0,  0,  4,  0,  0,  0,  1,  0,  2,  0,  1,  1, 14,  0, 15,  0,  6,\n",
      "       15,  0,  1,  0,  0,  0,  0,  0,  0,  4,  4,  1,  2,  0,  2,  0,  0,\n",
      "        0,  1,  0, 10,  0, 13,  0, 15,  0,  8,  0,  0,  7,  5, 12,  0,  0,\n",
      "        0,  0,  6,  0,  0,  0,  8,  0, 14,  0,  7,  0,  4,  3,  0,  9, 15,\n",
      "        0,  9,  1, 15,  1,  0,  0,  1,  0, 12,  1,  8, 10,  0,  0,  0,  1,\n",
      "        0,  9,  0,  5,  0,  0, 10,  0,  0,  4,  0,  6,  3, 14,  5,  0,  0,\n",
      "        0,  0, 10,  3,  0, 10,  0,  1,  0,  2,  0, 15,  1, 11, 11,  1,  1,\n",
      "        0, 14, 12,  0,  5,  0, 11,  7,  4,  1,  0, 12,  0,  1,  5,  1, 14,\n",
      "        1,  0, 10,  7,  4,  5,  0,  8,  0,  5,  9, 13,  8, 12, 13,  4,  5,\n",
      "        1,  0,  1,  0,  0,  0, 14,  0,  0,  6,  0, 14,  5,  0,  1,  0,  0,\n",
      "        1,  6,  3,  1,  4,  0,  3,  1, 11,  7, 15,  0,  0,  0,  8,  0, 13,\n",
      "        0, 11,  0,  1,  0, 12,  0, 15,  0,  0,  0,  1, 13, 12,  6,  6,  1,\n",
      "        0, 12,  6,  3, 15, 14,  2,  0,  0,  0,  1,  0, 12,  0,  3,  0,  0,\n",
      "        0,  1,  1,  8,  1,  5, 11,  7,  2,  3,  0,  1,  4,  8,  0,  5,  1,\n",
      "        5,  0,  9,  1,  0,  0,  2, 11,  1,  1,  5,  9,  0,  1,  7,  1,  0,\n",
      "       10,  4,  0,  0, 13,  4,  0,  0,  2, 11,  0,  0,  0,  0,  0,  7,  0,\n",
      "        1,  1, 13,  2,  2,  0,  1, 12,  1,  0,  0,  0,  1,  1,  1,  0,  1,\n",
      "        5,  0,  0, 12,  1,  1, 11,  0, 11,  0,  1,  9,  8,  1,  1, 14,  4,\n",
      "        1,  0,  0,  1,  1, 12,  5,  7,  0, 12,  1,  0,  0, 12,  0,  9,  0,\n",
      "       10,  0, 13,  1,  7,  1,  3, 12,  0,  6,  0,  3,  6,  0,  9,  0,  0,\n",
      "       13,  0,  0,  1,  6,  9,  3, 13,  0,  5,  1,  2,  1,  0,  8, 13,  0,\n",
      "        4,  0,  6,  6,  0, 14,  0,  2,  1,  0,  7,  4,  4,  1,  0,  0, 10,\n",
      "       15,  1, 15,  0,  0,  9, 13,  5,  0,  0, 13,  0, 11,  1,  1,  9,  0,\n",
      "       13, 12, 10,  8,  3,  0,  0,  0,  0]), 'Next Training set size': 372}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 372\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 141\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [141/141 00:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:16:01.282871Z [info     ] Start Predict                  dataset=215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 38.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9473873972892761, 'eval_accuracy': 0.675, 'eval_runtime': 1.1825, 'eval_samples_per_second': 236.792, 'eval_steps_per_second': 29.599, 'epoch': 14, 'labeled_data': array([ 2,  0,  0,  1, 11,  8,  8,  6,  1, 12,  8, 14,  9,  4,  1, 13,  1,\n",
      "        1,  2,  0,  7,  0,  0, 12,  0,  0,  0, 10,  7,  7,  0,  0, 14,  2,\n",
      "       10, 12, 15,  0,  3,  9,  9,  8, 14,  0,  9,  2,  1,  6,  7, 12,  0,\n",
      "        1,  0,  0, 10, 11,  1,  9,  1,  0,  1, 16,  3,  0, 10,  1,  0,  1,\n",
      "        0,  0,  0,  0, 10,  1, 10,  7,  1,  1, 11, 14,  6,  8, 14, 13,  0,\n",
      "       16,  1,  1,  1, 15,  7,  2,  1, 13,  0, 10,  0,  3,  8,  1, 14, 15,\n",
      "        0,  7,  2, 16, 13,  0, 15,  1, 11, 10, 11,  0,  7,  9,  0, 14,  3,\n",
      "        0,  6,  9,  9,  0,  6,  0, 10,  5,  0,  0,  1,  0, 11,  5,  0,  1,\n",
      "       13, 14, 10,  1,  1,  1, 14,  4,  3,  0,  4,  8,  6,  0, 15, 11,  0,\n",
      "        8,  2,  0,  0,  0, 13,  3,  0,  4, 11,  0,  0, 15, 15,  8,  6,  0,\n",
      "       15, 15,  0, 16,  0, 11, 14,  7,  2,  0,  0,  5,  3,  0,  0,  0,  3,\n",
      "       16,  0,  4,  0,  0, 16,  1,  0,  2, 16,  1,  1, 14,  0, 15, 16,  6,\n",
      "       15,  0,  1,  0, 16,  0,  0,  0,  0,  4,  4,  1,  2,  0,  2,  0,  0,\n",
      "        0,  1,  0, 10,  0, 13,  0, 15,  0,  8,  0,  0,  7,  5, 12,  0,  0,\n",
      "        0,  0,  6,  0,  0, 16,  8,  0, 14,  0,  7,  0,  4,  3,  0,  9, 15,\n",
      "        0,  9,  1, 15,  1,  0,  0,  1,  0, 12,  1,  8, 10,  0,  0, 16,  1,\n",
      "        0,  9,  0,  5,  0,  0, 10,  0,  0,  4,  0,  6,  3, 14,  5,  0,  0,\n",
      "        0,  0, 10,  3, 16, 10,  0,  1,  0,  2,  0, 15,  1, 11, 11,  1,  1,\n",
      "       16, 14, 12,  0,  5,  0, 11,  7,  4,  1,  0, 12,  0,  1,  5,  1, 14,\n",
      "        1,  0, 10,  7,  4,  5,  0,  8,  0,  5,  9, 13,  8, 12, 13,  4,  5,\n",
      "        1,  0,  1,  0,  0,  0, 14,  0,  0,  6,  0, 14,  5,  0,  1, 16,  0,\n",
      "        1,  6,  3,  1,  4,  0,  3,  1, 11,  7, 15,  0,  0,  0,  8,  0, 13,\n",
      "        0, 11,  0,  1,  0, 12,  0, 15,  0,  0,  0,  1, 13, 12,  6,  6,  1,\n",
      "        0, 12,  6,  3, 15, 14,  2,  0,  0,  0,  1,  0, 12,  0,  3,  0,  0,\n",
      "        0,  1,  1,  8,  1,  5, 11,  7,  2,  3,  0,  1,  4,  8,  0,  5,  1,\n",
      "        5,  0,  9,  1,  0,  0,  2, 11,  1,  1,  5,  9,  0,  1,  7,  1,  0,\n",
      "       10,  4,  0, 16, 13,  4,  0,  0,  2, 11,  0,  0,  0,  0,  0,  7,  0,\n",
      "        1,  1, 13,  2,  2,  0,  1, 12,  1,  0,  0, 16,  1,  1,  1,  0,  1,\n",
      "        5, 16,  0, 12,  1,  1, 11,  0, 11,  0,  1,  9,  8,  1,  1, 14,  4,\n",
      "        1,  0,  0,  1,  1, 12,  5,  7,  0, 12,  1,  0,  0, 12,  0,  9,  0,\n",
      "       10,  0, 13,  1,  7,  1,  3, 12,  0,  6,  0,  3,  6,  0,  9,  0, 16,\n",
      "       13,  0,  0,  1,  6,  9,  3, 13,  0,  5,  1,  2,  1,  0,  8, 13,  0,\n",
      "        4,  0,  6,  6,  0, 14,  0,  2,  1, 16,  7,  4,  4,  1,  0,  0, 10,\n",
      "       15,  1, 15,  0,  0,  9, 13,  5,  0,  0, 13,  0, 11,  1,  1,  9,  0,\n",
      "       13, 12, 10,  8,  3,  0, 16,  0,  0]), 'Next Training set size': 392}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 392\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 147\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 00:13, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:16:16.994095Z [info     ] Start Predict                  dataset=195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 38.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9267486333847046, 'eval_accuracy': 0.675, 'eval_runtime': 1.1637, 'eval_samples_per_second': 240.614, 'eval_steps_per_second': 30.077, 'epoch': 15, 'labeled_data': array([ 2, 17,  0,  1, 11,  8,  8,  6,  1, 12,  8, 14,  9,  4,  1, 13,  1,\n",
      "        1,  2,  0,  7,  0, 17, 12,  0,  0,  0, 10,  7,  7,  0,  0, 14,  2,\n",
      "       10, 12, 15, 17,  3,  9,  9,  8, 14,  0,  9,  2,  1,  6,  7, 12,  0,\n",
      "        1,  0,  0, 10, 11,  1,  9,  1,  0,  1, 16,  3,  0, 10,  1, 17,  1,\n",
      "        0,  0,  0,  0, 10,  1, 10,  7,  1,  1, 11, 14,  6,  8, 14, 13,  0,\n",
      "       16,  1,  1,  1, 15,  7,  2,  1, 13,  0, 10,  0,  3,  8,  1, 14, 15,\n",
      "        0,  7,  2, 16, 13,  0, 15,  1, 11, 10, 11,  0,  7,  9,  0, 14,  3,\n",
      "        0,  6,  9,  9,  0,  6,  0, 10,  5,  0,  0,  1,  0, 11,  5,  0,  1,\n",
      "       13, 14, 10,  1,  1,  1, 14,  4,  3,  0,  4,  8,  6,  0, 15, 11, 17,\n",
      "        8,  2,  0,  0,  0, 13,  3,  0,  4, 11,  0,  0, 15, 15,  8,  6,  0,\n",
      "       15, 15,  0, 16, 17, 11, 14,  7,  2, 17,  0,  5,  3,  0,  0,  0,  3,\n",
      "       16,  0,  4, 17,  0, 16,  1,  0,  2, 16,  1,  1, 14,  0, 15, 16,  6,\n",
      "       15,  0,  1,  0, 16,  0,  0,  0,  0,  4,  4,  1,  2, 17,  2,  0,  0,\n",
      "        0,  1,  0, 10,  0, 13,  0, 15,  0,  8,  0,  0,  7,  5, 12,  0,  0,\n",
      "        0,  0,  6,  0,  0, 16,  8,  0, 14,  0,  7,  0,  4,  3,  0,  9, 15,\n",
      "        0,  9,  1, 15,  1,  0,  0,  1,  0, 12,  1,  8, 10,  0,  0, 16,  1,\n",
      "        0,  9,  0,  5,  0,  0, 10,  0, 17,  4,  0,  6,  3, 14,  5, 17,  0,\n",
      "        0,  0, 10,  3, 16, 10,  0,  1,  0,  2,  0, 15,  1, 11, 11,  1,  1,\n",
      "       16, 14, 12,  0,  5,  0, 11,  7,  4,  1,  0, 12,  0,  1,  5,  1, 14,\n",
      "        1,  0, 10,  7,  4,  5,  0,  8,  0,  5,  9, 13,  8, 12, 13,  4,  5,\n",
      "        1,  0,  1,  0,  0,  0, 14,  0,  0,  6,  0, 14,  5,  0,  1, 16,  0,\n",
      "        1,  6,  3,  1,  4,  0,  3,  1, 11,  7, 15, 17,  0,  0,  8,  0, 13,\n",
      "        0, 11,  0,  1,  0, 12,  0, 15,  0,  0,  0,  1, 13, 12,  6,  6,  1,\n",
      "        0, 12,  6,  3, 15, 14,  2,  0,  0,  0,  1,  0, 12,  0,  3,  0,  0,\n",
      "        0,  1,  1,  8,  1,  5, 11,  7,  2,  3,  0,  1,  4,  8,  0,  5,  1,\n",
      "        5,  0,  9,  1,  0,  0,  2, 11,  1,  1,  5,  9,  0,  1,  7,  1,  0,\n",
      "       10,  4, 17, 16, 13,  4,  0,  0,  2, 11,  0,  0,  0,  0,  0,  7, 17,\n",
      "        1,  1, 13,  2,  2,  0,  1, 12,  1,  0,  0, 16,  1,  1,  1,  0,  1,\n",
      "        5, 16,  0, 12,  1,  1, 11, 17, 11,  0,  1,  9,  8,  1,  1, 14,  4,\n",
      "        1,  0, 17,  1,  1, 12,  5,  7,  0, 12,  1,  0,  0, 12,  0,  9,  0,\n",
      "       10,  0, 13,  1,  7,  1,  3, 12,  0,  6,  0,  3,  6,  0,  9,  0, 16,\n",
      "       13,  0,  0,  1,  6,  9,  3, 13, 17,  5,  1,  2,  1,  0,  8, 13,  0,\n",
      "        4,  0,  6,  6,  0, 14,  0,  2,  1, 16,  7,  4,  4,  1,  0,  0, 10,\n",
      "       15,  1, 15,  0,  0,  9, 13,  5,  0,  0, 13,  0, 11,  1,  1,  9, 17,\n",
      "       13, 12, 10,  8,  3, 17, 16, 17,  0]), 'Next Training set size': 412}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 412\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 156\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='156' max='156' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [156/156 00:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:16:33.672797Z [info     ] Start Predict                  dataset=175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 38.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9282760620117188, 'eval_accuracy': 0.6785714285714286, 'eval_runtime': 1.1596, 'eval_samples_per_second': 241.467, 'eval_steps_per_second': 30.183, 'epoch': 16, 'labeled_data': array([ 2, 17,  0,  1, 11,  8,  8,  6,  1, 12,  8, 14,  9,  4,  1, 13,  1,\n",
      "        1,  2,  0,  7,  0, 17, 12,  0,  0,  0, 10,  7,  7,  0,  0, 14,  2,\n",
      "       10, 12, 15, 17,  3,  9,  9,  8, 14, 18,  9,  2,  1,  6,  7, 12,  0,\n",
      "        1, 18,  0, 10, 11,  1,  9,  1,  0,  1, 16,  3,  0, 10,  1, 17,  1,\n",
      "        0,  0,  0,  0, 10,  1, 10,  7,  1,  1, 11, 14,  6,  8, 14, 13,  0,\n",
      "       16,  1,  1,  1, 15,  7,  2,  1, 13,  0, 10, 18,  3,  8,  1, 14, 15,\n",
      "        0,  7,  2, 16, 13,  0, 15,  1, 11, 10, 11,  0,  7,  9,  0, 14,  3,\n",
      "        0,  6,  9,  9,  0,  6,  0, 10,  5,  0,  0,  1,  0, 11,  5,  0,  1,\n",
      "       13, 14, 10,  1,  1,  1, 14,  4,  3,  0,  4,  8,  6,  0, 15, 11, 17,\n",
      "        8,  2,  0,  0,  0, 13,  3,  0,  4, 11,  0,  0, 15, 15,  8,  6, 18,\n",
      "       15, 15,  0, 16, 17, 11, 14,  7,  2, 17,  0,  5,  3, 18,  0,  0,  3,\n",
      "       16,  0,  4, 17,  0, 16,  1,  0,  2, 16,  1,  1, 14,  0, 15, 16,  6,\n",
      "       15, 18,  1,  0, 16,  0,  0,  0,  0,  4,  4,  1,  2, 17,  2,  0,  0,\n",
      "        0,  1,  0, 10,  0, 13,  0, 15,  0,  8,  0,  0,  7,  5, 12,  0,  0,\n",
      "        0,  0,  6,  0,  0, 16,  8,  0, 14,  0,  7, 18,  4,  3, 18,  9, 15,\n",
      "        0,  9,  1, 15,  1,  0,  0,  1,  0, 12,  1,  8, 10,  0,  0, 16,  1,\n",
      "        0,  9,  0,  5,  0, 18, 10,  0, 17,  4, 18,  6,  3, 14,  5, 17,  0,\n",
      "        0,  0, 10,  3, 16, 10,  0,  1, 18,  2,  0, 15,  1, 11, 11,  1,  1,\n",
      "       16, 14, 12,  0,  5,  0, 11,  7,  4,  1, 18, 12,  0,  1,  5,  1, 14,\n",
      "        1,  0, 10,  7,  4,  5,  0,  8,  0,  5,  9, 13,  8, 12, 13,  4,  5,\n",
      "        1, 18,  1,  0,  0,  0, 14,  0,  0,  6,  0, 14,  5,  0,  1, 16,  0,\n",
      "        1,  6,  3,  1,  4,  0,  3,  1, 11,  7, 15, 17,  0,  0,  8,  0, 13,\n",
      "        0, 11,  0,  1, 18, 12,  0, 15,  0,  0,  0,  1, 13, 12,  6,  6,  1,\n",
      "       18, 12,  6,  3, 15, 14,  2,  0,  0,  0,  1,  0, 12,  0,  3,  0,  0,\n",
      "        0,  1,  1,  8,  1,  5, 11,  7,  2,  3,  0,  1,  4,  8,  0,  5,  1,\n",
      "        5,  0,  9,  1,  0,  0,  2, 11,  1,  1,  5,  9, 18,  1,  7,  1,  0,\n",
      "       10,  4, 17, 16, 13,  4,  0, 18,  2, 11,  0,  0,  0,  0,  0,  7, 17,\n",
      "        1,  1, 13,  2,  2,  0,  1, 12,  1,  0,  0, 16,  1,  1,  1,  0,  1,\n",
      "        5, 16, 18, 12,  1,  1, 11, 17, 11,  0,  1,  9,  8,  1,  1, 14,  4,\n",
      "        1,  0, 17,  1,  1, 12,  5,  7,  0, 12,  1,  0,  0, 12,  0,  9,  0,\n",
      "       10,  0, 13,  1,  7,  1,  3, 12,  0,  6, 18,  3,  6,  0,  9,  0, 16,\n",
      "       13,  0,  0,  1,  6,  9,  3, 13, 17,  5,  1,  2,  1,  0,  8, 13,  0,\n",
      "        4,  0,  6,  6,  0, 14,  0,  2,  1, 16,  7,  4,  4,  1,  0,  0, 10,\n",
      "       15,  1, 15,  0,  0,  9, 13,  5,  0,  0, 13, 18, 11,  1,  1,  9, 17,\n",
      "       13, 12, 10,  8,  3, 17, 16, 17,  0]), 'Next Training set size': 432}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 432\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 162\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='162' max='162' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [162/162 00:15, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:16:50.988985Z [info     ] Start Predict                  dataset=155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 40.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9256443381309509, 'eval_accuracy': 0.675, 'eval_runtime': 1.1791, 'eval_samples_per_second': 237.462, 'eval_steps_per_second': 29.683, 'epoch': 17, 'labeled_data': array([ 2, 17,  0,  1, 11,  8,  8,  6,  1, 12,  8, 14,  9,  4,  1, 13,  1,\n",
      "        1,  2,  0,  7,  0, 17, 12,  0,  0, 19, 10,  7,  7,  0,  0, 14,  2,\n",
      "       10, 12, 15, 17,  3,  9,  9,  8, 14, 18,  9,  2,  1,  6,  7, 12,  0,\n",
      "        1, 18,  0, 10, 11,  1,  9,  1,  0,  1, 16,  3,  0, 10,  1, 17,  1,\n",
      "       19,  0,  0,  0, 10,  1, 10,  7,  1,  1, 11, 14,  6,  8, 14, 13,  0,\n",
      "       16,  1,  1,  1, 15,  7,  2,  1, 13, 19, 10, 18,  3,  8,  1, 14, 15,\n",
      "        0,  7,  2, 16, 13,  0, 15,  1, 11, 10, 11,  0,  7,  9,  0, 14,  3,\n",
      "        0,  6,  9,  9,  0,  6,  0, 10,  5,  0,  0,  1,  0, 11,  5, 19,  1,\n",
      "       13, 14, 10,  1,  1,  1, 14,  4,  3,  0,  4,  8,  6, 19, 15, 11, 17,\n",
      "        8,  2,  0,  0,  0, 13,  3, 19,  4, 11,  0,  0, 15, 15,  8,  6, 18,\n",
      "       15, 15,  0, 16, 17, 11, 14,  7,  2, 17,  0,  5,  3, 18,  0,  0,  3,\n",
      "       16,  0,  4, 17,  0, 16,  1,  0,  2, 16,  1,  1, 14, 19, 15, 16,  6,\n",
      "       15, 18,  1,  0, 16,  0,  0,  0,  0,  4,  4,  1,  2, 17,  2,  0,  0,\n",
      "        0,  1,  0, 10,  0, 13,  0, 15,  0,  8,  0,  0,  7,  5, 12,  0,  0,\n",
      "        0,  0,  6,  0,  0, 16,  8, 19, 14,  0,  7, 18,  4,  3, 18,  9, 15,\n",
      "       19,  9,  1, 15,  1, 19,  0,  1,  0, 12,  1,  8, 10,  0,  0, 16,  1,\n",
      "        0,  9,  0,  5,  0, 18, 10,  0, 17,  4, 18,  6,  3, 14,  5, 17,  0,\n",
      "        0,  0, 10,  3, 16, 10,  0,  1, 18,  2,  0, 15,  1, 11, 11,  1,  1,\n",
      "       16, 14, 12,  0,  5, 19, 11,  7,  4,  1, 18, 12, 19,  1,  5,  1, 14,\n",
      "        1,  0, 10,  7,  4,  5, 19,  8,  0,  5,  9, 13,  8, 12, 13,  4,  5,\n",
      "        1, 18,  1,  0,  0,  0, 14,  0,  0,  6, 19, 14,  5,  0,  1, 16,  0,\n",
      "        1,  6,  3,  1,  4,  0,  3,  1, 11,  7, 15, 17,  0,  0,  8,  0, 13,\n",
      "        0, 11,  0,  1, 18, 12,  0, 15,  0,  0,  0,  1, 13, 12,  6,  6,  1,\n",
      "       18, 12,  6,  3, 15, 14,  2,  0,  0,  0,  1,  0, 12,  0,  3,  0,  0,\n",
      "        0,  1,  1,  8,  1,  5, 11,  7,  2,  3,  0,  1,  4,  8,  0,  5,  1,\n",
      "        5,  0,  9,  1, 19, 19,  2, 11,  1,  1,  5,  9, 18,  1,  7,  1,  0,\n",
      "       10,  4, 17, 16, 13,  4,  0, 18,  2, 11,  0,  0,  0,  0,  0,  7, 17,\n",
      "        1,  1, 13,  2,  2,  0,  1, 12,  1,  0,  0, 16,  1,  1,  1, 19,  1,\n",
      "        5, 16, 18, 12,  1,  1, 11, 17, 11,  0,  1,  9,  8,  1,  1, 14,  4,\n",
      "        1,  0, 17,  1,  1, 12,  5,  7,  0, 12,  1,  0,  0, 12,  0,  9,  0,\n",
      "       10, 19, 13,  1,  7,  1,  3, 12,  0,  6, 18,  3,  6,  0,  9,  0, 16,\n",
      "       13,  0,  0,  1,  6,  9,  3, 13, 17,  5,  1,  2,  1,  0,  8, 13,  0,\n",
      "        4,  0,  6,  6,  0, 14,  0,  2,  1, 16,  7,  4,  4,  1, 19,  0, 10,\n",
      "       15,  1, 15,  0, 19,  9, 13,  5,  0,  0, 13, 18, 11,  1,  1,  9, 17,\n",
      "       13, 12, 10,  8,  3, 17, 16, 17,  0]), 'Next Training set size': 452}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 452\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 171\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='171' max='171' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [171/171 00:15, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:17:08.861045Z [info     ] Start Predict                  dataset=135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 41.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9234558343887329, 'eval_accuracy': 0.6714285714285714, 'eval_runtime': 1.1898, 'eval_samples_per_second': 235.339, 'eval_steps_per_second': 29.417, 'epoch': 18, 'labeled_data': array([ 2, 17,  0,  1, 11,  8,  8,  6,  1, 12,  8, 14,  9,  4,  1, 13,  1,\n",
      "        1,  2, 20,  7,  0, 17, 12,  0,  0, 19, 10,  7,  7,  0,  0, 14,  2,\n",
      "       10, 12, 15, 17,  3,  9,  9,  8, 14, 18,  9,  2,  1,  6,  7, 12, 20,\n",
      "        1, 18,  0, 10, 11,  1,  9,  1, 20,  1, 16,  3,  0, 10,  1, 17,  1,\n",
      "       19,  0,  0,  0, 10,  1, 10,  7,  1,  1, 11, 14,  6,  8, 14, 13,  0,\n",
      "       16,  1,  1,  1, 15,  7,  2,  1, 13, 19, 10, 18,  3,  8,  1, 14, 15,\n",
      "        0,  7,  2, 16, 13,  0, 15,  1, 11, 10, 11,  0,  7,  9, 20, 14,  3,\n",
      "        0,  6,  9,  9,  0,  6, 20, 10,  5, 20,  0,  1,  0, 11,  5, 19,  1,\n",
      "       13, 14, 10,  1,  1,  1, 14,  4,  3,  0,  4,  8,  6, 19, 15, 11, 17,\n",
      "        8,  2,  0,  0,  0, 13,  3, 19,  4, 11,  0,  0, 15, 15,  8,  6, 18,\n",
      "       15, 15,  0, 16, 17, 11, 14,  7,  2, 17,  0,  5,  3, 18,  0,  0,  3,\n",
      "       16,  0,  4, 17,  0, 16,  1, 20,  2, 16,  1,  1, 14, 19, 15, 16,  6,\n",
      "       15, 18,  1,  0, 16,  0,  0,  0,  0,  4,  4,  1,  2, 17,  2,  0,  0,\n",
      "        0,  1,  0, 10,  0, 13,  0, 15,  0,  8,  0,  0,  7,  5, 12,  0, 20,\n",
      "        0,  0,  6,  0, 20, 16,  8, 19, 14,  0,  7, 18,  4,  3, 18,  9, 15,\n",
      "       19,  9,  1, 15,  1, 19,  0,  1,  0, 12,  1,  8, 10, 20,  0, 16,  1,\n",
      "        0,  9,  0,  5,  0, 18, 10, 20, 17,  4, 18,  6,  3, 14,  5, 17,  0,\n",
      "        0,  0, 10,  3, 16, 10, 20,  1, 18,  2,  0, 15,  1, 11, 11,  1,  1,\n",
      "       16, 14, 12, 20,  5, 19, 11,  7,  4,  1, 18, 12, 19,  1,  5,  1, 14,\n",
      "        1,  0, 10,  7,  4,  5, 19,  8,  0,  5,  9, 13,  8, 12, 13,  4,  5,\n",
      "        1, 18,  1,  0,  0, 20, 14,  0,  0,  6, 19, 14,  5, 20,  1, 16,  0,\n",
      "        1,  6,  3,  1,  4,  0,  3,  1, 11,  7, 15, 17,  0,  0,  8,  0, 13,\n",
      "        0, 11,  0,  1, 18, 12,  0, 15, 20,  0,  0,  1, 13, 12,  6,  6,  1,\n",
      "       18, 12,  6,  3, 15, 14,  2,  0,  0,  0,  1,  0, 12,  0,  3,  0,  0,\n",
      "        0,  1,  1,  8,  1,  5, 11,  7,  2,  3,  0,  1,  4,  8,  0,  5,  1,\n",
      "        5,  0,  9,  1, 19, 19,  2, 11,  1,  1,  5,  9, 18,  1,  7,  1,  0,\n",
      "       10,  4, 17, 16, 13,  4,  0, 18,  2, 11,  0,  0,  0,  0,  0,  7, 17,\n",
      "        1,  1, 13,  2,  2,  0,  1, 12,  1,  0,  0, 16,  1,  1,  1, 19,  1,\n",
      "        5, 16, 18, 12,  1,  1, 11, 17, 11,  0,  1,  9,  8,  1,  1, 14,  4,\n",
      "        1,  0, 17,  1,  1, 12,  5,  7,  0, 12,  1,  0,  0, 12,  0,  9,  0,\n",
      "       10, 19, 13,  1,  7,  1,  3, 12, 20,  6, 18,  3,  6,  0,  9,  0, 16,\n",
      "       13,  0,  0,  1,  6,  9,  3, 13, 17,  5,  1,  2,  1,  0,  8, 13,  0,\n",
      "        4, 20,  6,  6, 20, 14,  0,  2,  1, 16,  7,  4,  4,  1, 19,  0, 10,\n",
      "       15,  1, 15,  0, 19,  9, 13,  5,  0,  0, 13, 18, 11,  1,  1,  9, 17,\n",
      "       13, 12, 10,  8,  3, 17, 16, 17, 20]), 'Next Training set size': 472}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 472\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 177\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='177' max='177' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [177/177 00:16, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:17:27.252620Z [info     ] Start Predict                  dataset=115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 39.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9253950119018555, 'eval_accuracy': 0.675, 'eval_runtime': 1.163, 'eval_samples_per_second': 240.748, 'eval_steps_per_second': 30.094, 'epoch': 19, 'labeled_data': array([ 2, 17,  0,  1, 11,  8,  8,  6,  1, 12,  8, 14,  9,  4,  1, 13,  1,\n",
      "        1,  2, 20,  7, 21, 17, 12,  0,  0, 19, 10,  7,  7,  0,  0, 14,  2,\n",
      "       10, 12, 15, 17,  3,  9,  9,  8, 14, 18,  9,  2,  1,  6,  7, 12, 20,\n",
      "        1, 18,  0, 10, 11,  1,  9,  1, 20,  1, 16,  3, 21, 10,  1, 17,  1,\n",
      "       19,  0, 21,  0, 10,  1, 10,  7,  1,  1, 11, 14,  6,  8, 14, 13,  0,\n",
      "       16,  1,  1,  1, 15,  7,  2,  1, 13, 19, 10, 18,  3,  8,  1, 14, 15,\n",
      "        0,  7,  2, 16, 13,  0, 15,  1, 11, 10, 11,  0,  7,  9, 20, 14,  3,\n",
      "        0,  6,  9,  9,  0,  6, 20, 10,  5, 20,  0,  1,  0, 11,  5, 19,  1,\n",
      "       13, 14, 10,  1,  1,  1, 14,  4,  3,  0,  4,  8,  6, 19, 15, 11, 17,\n",
      "        8,  2,  0, 21,  0, 13,  3, 19,  4, 11,  0,  0, 15, 15,  8,  6, 18,\n",
      "       15, 15,  0, 16, 17, 11, 14,  7,  2, 17,  0,  5,  3, 18,  0, 21,  3,\n",
      "       16,  0,  4, 17,  0, 16,  1, 20,  2, 16,  1,  1, 14, 19, 15, 16,  6,\n",
      "       15, 18,  1,  0, 16,  0,  0,  0,  0,  4,  4,  1,  2, 17,  2,  0,  0,\n",
      "        0,  1, 21, 10,  0, 13,  0, 15, 21,  8,  0,  0,  7,  5, 12, 21, 20,\n",
      "        0, 21,  6,  0, 20, 16,  8, 19, 14,  0,  7, 18,  4,  3, 18,  9, 15,\n",
      "       19,  9,  1, 15,  1, 19,  0,  1,  0, 12,  1,  8, 10, 20,  0, 16,  1,\n",
      "        0,  9, 21,  5,  0, 18, 10, 20, 17,  4, 18,  6,  3, 14,  5, 17,  0,\n",
      "        0,  0, 10,  3, 16, 10, 20,  1, 18,  2,  0, 15,  1, 11, 11,  1,  1,\n",
      "       16, 14, 12, 20,  5, 19, 11,  7,  4,  1, 18, 12, 19,  1,  5,  1, 14,\n",
      "        1,  0, 10,  7,  4,  5, 19,  8,  0,  5,  9, 13,  8, 12, 13,  4,  5,\n",
      "        1, 18,  1, 21,  0, 20, 14,  0,  0,  6, 19, 14,  5, 20,  1, 16,  0,\n",
      "        1,  6,  3,  1,  4,  0,  3,  1, 11,  7, 15, 17,  0,  0,  8,  0, 13,\n",
      "       21, 11,  0,  1, 18, 12,  0, 15, 20,  0,  0,  1, 13, 12,  6,  6,  1,\n",
      "       18, 12,  6,  3, 15, 14,  2,  0, 21,  0,  1,  0, 12,  0,  3, 21,  0,\n",
      "        0,  1,  1,  8,  1,  5, 11,  7,  2,  3,  0,  1,  4,  8,  0,  5,  1,\n",
      "        5,  0,  9,  1, 19, 19,  2, 11,  1,  1,  5,  9, 18,  1,  7,  1,  0,\n",
      "       10,  4, 17, 16, 13,  4,  0, 18,  2, 11,  0,  0, 21,  0,  0,  7, 17,\n",
      "        1,  1, 13,  2,  2,  0,  1, 12,  1,  0, 21, 16,  1,  1,  1, 19,  1,\n",
      "        5, 16, 18, 12,  1,  1, 11, 17, 11,  0,  1,  9,  8,  1,  1, 14,  4,\n",
      "        1,  0, 17,  1,  1, 12,  5,  7,  0, 12,  1,  0, 21, 12, 21,  9,  0,\n",
      "       10, 19, 13,  1,  7,  1,  3, 12, 20,  6, 18,  3,  6,  0,  9,  0, 16,\n",
      "       13,  0,  0,  1,  6,  9,  3, 13, 17,  5,  1,  2,  1,  0,  8, 13,  0,\n",
      "        4, 20,  6,  6, 20, 14, 21,  2,  1, 16,  7,  4,  4,  1, 19,  0, 10,\n",
      "       15,  1, 15,  0, 19,  9, 13,  5,  0, 21, 13, 18, 11,  1,  1,  9, 17,\n",
      "       13, 12, 10,  8,  3, 17, 16, 17, 20]), 'Next Training set size': 492}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 492\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 186\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='186' max='186' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [186/186 00:17, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:17:46.397233Z [info     ] Start Predict                  dataset=95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 39.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.90831458568573, 'eval_accuracy': 0.675, 'eval_runtime': 1.1852, 'eval_samples_per_second': 236.243, 'eval_steps_per_second': 29.53, 'epoch': 20, 'labeled_data': array([ 2, 17,  0,  1, 11,  8,  8,  6,  1, 12,  8, 14,  9,  4,  1, 13,  1,\n",
      "        1,  2, 20,  7, 21, 17, 12,  0,  0, 19, 10,  7,  7,  0,  0, 14,  2,\n",
      "       10, 12, 15, 17,  3,  9,  9,  8, 14, 18,  9,  2,  1,  6,  7, 12, 20,\n",
      "        1, 18,  0, 10, 11,  1,  9,  1, 20,  1, 16,  3, 21, 10,  1, 17,  1,\n",
      "       19,  0, 21,  0, 10,  1, 10,  7,  1,  1, 11, 14,  6,  8, 14, 13,  0,\n",
      "       16,  1,  1,  1, 15,  7,  2,  1, 13, 19, 10, 18,  3,  8,  1, 14, 15,\n",
      "        0,  7,  2, 16, 13,  0, 15,  1, 11, 10, 11, 22,  7,  9, 20, 14,  3,\n",
      "       22,  6,  9,  9,  0,  6, 20, 10,  5, 20,  0,  1,  0, 11,  5, 19,  1,\n",
      "       13, 14, 10,  1,  1,  1, 14,  4,  3,  0,  4,  8,  6, 19, 15, 11, 17,\n",
      "        8,  2,  0, 21,  0, 13,  3, 19,  4, 11,  0,  0, 15, 15,  8,  6, 18,\n",
      "       15, 15,  0, 16, 17, 11, 14,  7,  2, 17,  0,  5,  3, 18,  0, 21,  3,\n",
      "       16, 22,  4, 17,  0, 16,  1, 20,  2, 16,  1,  1, 14, 19, 15, 16,  6,\n",
      "       15, 18,  1, 22, 16,  0, 22,  0,  0,  4,  4,  1,  2, 17,  2, 22,  0,\n",
      "       22,  1, 21, 10,  0, 13, 22, 15, 21,  8,  0,  0,  7,  5, 12, 21, 20,\n",
      "        0, 21,  6,  0, 20, 16,  8, 19, 14,  0,  7, 18,  4,  3, 18,  9, 15,\n",
      "       19,  9,  1, 15,  1, 19, 22,  1,  0, 12,  1,  8, 10, 20,  0, 16,  1,\n",
      "        0,  9, 21,  5, 22, 18, 10, 20, 17,  4, 18,  6,  3, 14,  5, 17,  0,\n",
      "       22, 22, 10,  3, 16, 10, 20,  1, 18,  2,  0, 15,  1, 11, 11,  1,  1,\n",
      "       16, 14, 12, 20,  5, 19, 11,  7,  4,  1, 18, 12, 19,  1,  5,  1, 14,\n",
      "        1,  0, 10,  7,  4,  5, 19,  8,  0,  5,  9, 13,  8, 12, 13,  4,  5,\n",
      "        1, 18,  1, 21,  0, 20, 14, 22,  0,  6, 19, 14,  5, 20,  1, 16, 22,\n",
      "        1,  6,  3,  1,  4,  0,  3,  1, 11,  7, 15, 17,  0,  0,  8,  0, 13,\n",
      "       21, 11,  0,  1, 18, 12,  0, 15, 20,  0,  0,  1, 13, 12,  6,  6,  1,\n",
      "       18, 12,  6,  3, 15, 14,  2,  0, 21,  0,  1,  0, 12, 22,  3, 21,  0,\n",
      "        0,  1,  1,  8,  1,  5, 11,  7,  2,  3,  0,  1,  4,  8,  0,  5,  1,\n",
      "        5,  0,  9,  1, 19, 19,  2, 11,  1,  1,  5,  9, 18,  1,  7,  1, 22,\n",
      "       10,  4, 17, 16, 13,  4,  0, 18,  2, 11,  0,  0, 21, 22, 22,  7, 17,\n",
      "        1,  1, 13,  2,  2,  0,  1, 12,  1,  0, 21, 16,  1,  1,  1, 19,  1,\n",
      "        5, 16, 18, 12,  1,  1, 11, 17, 11,  0,  1,  9,  8,  1,  1, 14,  4,\n",
      "        1,  0, 17,  1,  1, 12,  5,  7,  0, 12,  1, 22, 21, 12, 21,  9,  0,\n",
      "       10, 19, 13,  1,  7,  1,  3, 12, 20,  6, 18,  3,  6,  0,  9,  0, 16,\n",
      "       13,  0, 22,  1,  6,  9,  3, 13, 17,  5,  1,  2,  1,  0,  8, 13,  0,\n",
      "        4, 20,  6,  6, 20, 14, 21,  2,  1, 16,  7,  4,  4,  1, 19,  0, 10,\n",
      "       15,  1, 15,  0, 19,  9, 13,  5,  0, 21, 13, 18, 11,  1,  1,  9, 17,\n",
      "       13, 12, 10,  8,  3, 17, 16, 17, 20]), 'Next Training set size': 512}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 512\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [192/192 00:17, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:18:06.237522Z [info     ] Start Predict                  dataset=75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 38.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9099541306495667, 'eval_accuracy': 0.675, 'eval_runtime': 1.1767, 'eval_samples_per_second': 237.948, 'eval_steps_per_second': 29.743, 'epoch': 21, 'labeled_data': array([ 2, 17,  0,  1, 11,  8,  8,  6,  1, 12,  8, 14,  9,  4,  1, 13,  1,\n",
      "        1,  2, 20,  7, 21, 17, 12, 23,  0, 19, 10,  7,  7, 23,  0, 14,  2,\n",
      "       10, 12, 15, 17,  3,  9,  9,  8, 14, 18,  9,  2,  1,  6,  7, 12, 20,\n",
      "        1, 18,  0, 10, 11,  1,  9,  1, 20,  1, 16,  3, 21, 10,  1, 17,  1,\n",
      "       19,  0, 21,  0, 10,  1, 10,  7,  1,  1, 11, 14,  6,  8, 14, 13,  0,\n",
      "       16,  1,  1,  1, 15,  7,  2,  1, 13, 19, 10, 18,  3,  8,  1, 14, 15,\n",
      "       23,  7,  2, 16, 13,  0, 15,  1, 11, 10, 11, 22,  7,  9, 20, 14,  3,\n",
      "       22,  6,  9,  9, 23,  6, 20, 10,  5, 20,  0,  1,  0, 11,  5, 19,  1,\n",
      "       13, 14, 10,  1,  1,  1, 14,  4,  3, 23,  4,  8,  6, 19, 15, 11, 17,\n",
      "        8,  2,  0, 21,  0, 13,  3, 19,  4, 11,  0,  0, 15, 15,  8,  6, 18,\n",
      "       15, 15,  0, 16, 17, 11, 14,  7,  2, 17,  0,  5,  3, 18,  0, 21,  3,\n",
      "       16, 22,  4, 17,  0, 16,  1, 20,  2, 16,  1,  1, 14, 19, 15, 16,  6,\n",
      "       15, 18,  1, 22, 16,  0, 22,  0, 23,  4,  4,  1,  2, 17,  2, 22,  0,\n",
      "       22,  1, 21, 10,  0, 13, 22, 15, 21,  8, 23,  0,  7,  5, 12, 21, 20,\n",
      "       23, 21,  6,  0, 20, 16,  8, 19, 14,  0,  7, 18,  4,  3, 18,  9, 15,\n",
      "       19,  9,  1, 15,  1, 19, 22,  1,  0, 12,  1,  8, 10, 20,  0, 16,  1,\n",
      "        0,  9, 21,  5, 22, 18, 10, 20, 17,  4, 18,  6,  3, 14,  5, 17,  0,\n",
      "       22, 22, 10,  3, 16, 10, 20,  1, 18,  2,  0, 15,  1, 11, 11,  1,  1,\n",
      "       16, 14, 12, 20,  5, 19, 11,  7,  4,  1, 18, 12, 19,  1,  5,  1, 14,\n",
      "        1, 23, 10,  7,  4,  5, 19,  8, 23,  5,  9, 13,  8, 12, 13,  4,  5,\n",
      "        1, 18,  1, 21, 23, 20, 14, 22,  0,  6, 19, 14,  5, 20,  1, 16, 22,\n",
      "        1,  6,  3,  1,  4,  0,  3,  1, 11,  7, 15, 17,  0,  0,  8,  0, 13,\n",
      "       21, 11,  0,  1, 18, 12,  0, 15, 20,  0, 23,  1, 13, 12,  6,  6,  1,\n",
      "       18, 12,  6,  3, 15, 14,  2, 23, 21,  0,  1, 23, 12, 22,  3, 21,  0,\n",
      "        0,  1,  1,  8,  1,  5, 11,  7,  2,  3,  0,  1,  4,  8, 23,  5,  1,\n",
      "        5, 23,  9,  1, 19, 19,  2, 11,  1,  1,  5,  9, 18,  1,  7,  1, 22,\n",
      "       10,  4, 17, 16, 13,  4, 23, 18,  2, 11,  0,  0, 21, 22, 22,  7, 17,\n",
      "        1,  1, 13,  2,  2,  0,  1, 12,  1,  0, 21, 16,  1,  1,  1, 19,  1,\n",
      "        5, 16, 18, 12,  1,  1, 11, 17, 11,  0,  1,  9,  8,  1,  1, 14,  4,\n",
      "        1, 23, 17,  1,  1, 12,  5,  7,  0, 12,  1, 22, 21, 12, 21,  9,  0,\n",
      "       10, 19, 13,  1,  7,  1,  3, 12, 20,  6, 18,  3,  6,  0,  9,  0, 16,\n",
      "       13,  0, 22,  1,  6,  9,  3, 13, 17,  5,  1,  2,  1,  0,  8, 13, 23,\n",
      "        4, 20,  6,  6, 20, 14, 21,  2,  1, 16,  7,  4,  4,  1, 19, 23, 10,\n",
      "       15,  1, 15,  0, 19,  9, 13,  5,  0, 21, 13, 18, 11,  1,  1,  9, 17,\n",
      "       13, 12, 10,  8,  3, 17, 16, 17, 20]), 'Next Training set size': 532}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 532\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 201\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='201' max='201' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [201/201 00:18, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:18:26.367023Z [info     ] Start Predict                  dataset=55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 38.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9058663249015808, 'eval_accuracy': 0.675, 'eval_runtime': 1.1502, 'eval_samples_per_second': 243.436, 'eval_steps_per_second': 30.43, 'epoch': 22, 'labeled_data': array([ 2, 17,  0,  1, 11,  8,  8,  6,  1, 12,  8, 14,  9,  4,  1, 13,  1,\n",
      "        1,  2, 20,  7, 21, 17, 12, 23, 24, 19, 10,  7,  7, 23, 24, 14,  2,\n",
      "       10, 12, 15, 17,  3,  9,  9,  8, 14, 18,  9,  2,  1,  6,  7, 12, 20,\n",
      "        1, 18, 24, 10, 11,  1,  9,  1, 20,  1, 16,  3, 21, 10,  1, 17,  1,\n",
      "       19, 24, 21,  0, 10,  1, 10,  7,  1,  1, 11, 14,  6,  8, 14, 13, 24,\n",
      "       16,  1,  1,  1, 15,  7,  2,  1, 13, 19, 10, 18,  3,  8,  1, 14, 15,\n",
      "       23,  7,  2, 16, 13,  0, 15,  1, 11, 10, 11, 22,  7,  9, 20, 14,  3,\n",
      "       22,  6,  9,  9, 23,  6, 20, 10,  5, 20,  0,  1,  0, 11,  5, 19,  1,\n",
      "       13, 14, 10,  1,  1,  1, 14,  4,  3, 23,  4,  8,  6, 19, 15, 11, 17,\n",
      "        8,  2,  0, 21, 24, 13,  3, 19,  4, 11, 24,  0, 15, 15,  8,  6, 18,\n",
      "       15, 15,  0, 16, 17, 11, 14,  7,  2, 17, 24,  5,  3, 18, 24, 21,  3,\n",
      "       16, 22,  4, 17, 24, 16,  1, 20,  2, 16,  1,  1, 14, 19, 15, 16,  6,\n",
      "       15, 18,  1, 22, 16,  0, 22,  0, 23,  4,  4,  1,  2, 17,  2, 22,  0,\n",
      "       22,  1, 21, 10, 24, 13, 22, 15, 21,  8, 23, 24,  7,  5, 12, 21, 20,\n",
      "       23, 21,  6,  0, 20, 16,  8, 19, 14,  0,  7, 18,  4,  3, 18,  9, 15,\n",
      "       19,  9,  1, 15,  1, 19, 22,  1,  0, 12,  1,  8, 10, 20, 24, 16,  1,\n",
      "        0,  9, 21,  5, 22, 18, 10, 20, 17,  4, 18,  6,  3, 14,  5, 17, 24,\n",
      "       22, 22, 10,  3, 16, 10, 20,  1, 18,  2,  0, 15,  1, 11, 11,  1,  1,\n",
      "       16, 14, 12, 20,  5, 19, 11,  7,  4,  1, 18, 12, 19,  1,  5,  1, 14,\n",
      "        1, 23, 10,  7,  4,  5, 19,  8, 23,  5,  9, 13,  8, 12, 13,  4,  5,\n",
      "        1, 18,  1, 21, 23, 20, 14, 22,  0,  6, 19, 14,  5, 20,  1, 16, 22,\n",
      "        1,  6,  3,  1,  4,  0,  3,  1, 11,  7, 15, 17,  0,  0,  8, 24, 13,\n",
      "       21, 11, 24,  1, 18, 12,  0, 15, 20, 24, 23,  1, 13, 12,  6,  6,  1,\n",
      "       18, 12,  6,  3, 15, 14,  2, 23, 21,  0,  1, 23, 12, 22,  3, 21,  0,\n",
      "        0,  1,  1,  8,  1,  5, 11,  7,  2,  3, 24,  1,  4,  8, 23,  5,  1,\n",
      "        5, 23,  9,  1, 19, 19,  2, 11,  1,  1,  5,  9, 18,  1,  7,  1, 22,\n",
      "       10,  4, 17, 16, 13,  4, 23, 18,  2, 11,  0,  0, 21, 22, 22,  7, 17,\n",
      "        1,  1, 13,  2,  2,  0,  1, 12,  1,  0, 21, 16,  1,  1,  1, 19,  1,\n",
      "        5, 16, 18, 12,  1,  1, 11, 17, 11,  0,  1,  9,  8,  1,  1, 14,  4,\n",
      "        1, 23, 17,  1,  1, 12,  5,  7, 24, 12,  1, 22, 21, 12, 21,  9,  0,\n",
      "       10, 19, 13,  1,  7,  1,  3, 12, 20,  6, 18,  3,  6, 24,  9,  0, 16,\n",
      "       13,  0, 22,  1,  6,  9,  3, 13, 17,  5,  1,  2,  1,  0,  8, 13, 23,\n",
      "        4, 20,  6,  6, 20, 14, 21,  2,  1, 16,  7,  4,  4,  1, 19, 23, 10,\n",
      "       15,  1, 15,  0, 19,  9, 13,  5,  0, 21, 13, 18, 11,  1,  1,  9, 17,\n",
      "       13, 12, 10,  8,  3, 17, 16, 17, 20]), 'Next Training set size': 552}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 552\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 207\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='207' max='207' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [207/207 00:19, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:18:47.410033Z [info     ] Start Predict                  dataset=35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 44.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8891464471817017, 'eval_accuracy': 0.675, 'eval_runtime': 1.2035, 'eval_samples_per_second': 232.657, 'eval_steps_per_second': 29.082, 'epoch': 23, 'labeled_data': array([ 2, 17, 25,  1, 11,  8,  8,  6,  1, 12,  8, 14,  9,  4,  1, 13,  1,\n",
      "        1,  2, 20,  7, 21, 17, 12, 23, 24, 19, 10,  7,  7, 23, 24, 14,  2,\n",
      "       10, 12, 15, 17,  3,  9,  9,  8, 14, 18,  9,  2,  1,  6,  7, 12, 20,\n",
      "        1, 18, 24, 10, 11,  1,  9,  1, 20,  1, 16,  3, 21, 10,  1, 17,  1,\n",
      "       19, 24, 21,  0, 10,  1, 10,  7,  1,  1, 11, 14,  6,  8, 14, 13, 24,\n",
      "       16,  1,  1,  1, 15,  7,  2,  1, 13, 19, 10, 18,  3,  8,  1, 14, 15,\n",
      "       23,  7,  2, 16, 13,  0, 15,  1, 11, 10, 11, 22,  7,  9, 20, 14,  3,\n",
      "       22,  6,  9,  9, 23,  6, 20, 10,  5, 20, 25,  1,  0, 11,  5, 19,  1,\n",
      "       13, 14, 10,  1,  1,  1, 14,  4,  3, 23,  4,  8,  6, 19, 15, 11, 17,\n",
      "        8,  2, 25, 21, 24, 13,  3, 19,  4, 11, 24, 25, 15, 15,  8,  6, 18,\n",
      "       15, 15,  0, 16, 17, 11, 14,  7,  2, 17, 24,  5,  3, 18, 24, 21,  3,\n",
      "       16, 22,  4, 17, 24, 16,  1, 20,  2, 16,  1,  1, 14, 19, 15, 16,  6,\n",
      "       15, 18,  1, 22, 16,  0, 22, 25, 23,  4,  4,  1,  2, 17,  2, 22, 25,\n",
      "       22,  1, 21, 10, 24, 13, 22, 15, 21,  8, 23, 24,  7,  5, 12, 21, 20,\n",
      "       23, 21,  6, 25, 20, 16,  8, 19, 14, 25,  7, 18,  4,  3, 18,  9, 15,\n",
      "       19,  9,  1, 15,  1, 19, 22,  1, 25, 12,  1,  8, 10, 20, 24, 16,  1,\n",
      "        0,  9, 21,  5, 22, 18, 10, 20, 17,  4, 18,  6,  3, 14,  5, 17, 24,\n",
      "       22, 22, 10,  3, 16, 10, 20,  1, 18,  2,  0, 15,  1, 11, 11,  1,  1,\n",
      "       16, 14, 12, 20,  5, 19, 11,  7,  4,  1, 18, 12, 19,  1,  5,  1, 14,\n",
      "        1, 23, 10,  7,  4,  5, 19,  8, 23,  5,  9, 13,  8, 12, 13,  4,  5,\n",
      "        1, 18,  1, 21, 23, 20, 14, 22,  0,  6, 19, 14,  5, 20,  1, 16, 22,\n",
      "        1,  6,  3,  1,  4,  0,  3,  1, 11,  7, 15, 17,  0, 25,  8, 24, 13,\n",
      "       21, 11, 24,  1, 18, 12, 25, 15, 20, 24, 23,  1, 13, 12,  6,  6,  1,\n",
      "       18, 12,  6,  3, 15, 14,  2, 23, 21, 25,  1, 23, 12, 22,  3, 21, 25,\n",
      "       25,  1,  1,  8,  1,  5, 11,  7,  2,  3, 24,  1,  4,  8, 23,  5,  1,\n",
      "        5, 23,  9,  1, 19, 19,  2, 11,  1,  1,  5,  9, 18,  1,  7,  1, 22,\n",
      "       10,  4, 17, 16, 13,  4, 23, 18,  2, 11, 25, 25, 21, 22, 22,  7, 17,\n",
      "        1,  1, 13,  2,  2, 25,  1, 12,  1, 25, 21, 16,  1,  1,  1, 19,  1,\n",
      "        5, 16, 18, 12,  1,  1, 11, 17, 11,  0,  1,  9,  8,  1,  1, 14,  4,\n",
      "        1, 23, 17,  1,  1, 12,  5,  7, 24, 12,  1, 22, 21, 12, 21,  9, 25,\n",
      "       10, 19, 13,  1,  7,  1,  3, 12, 20,  6, 18,  3,  6, 24,  9,  0, 16,\n",
      "       13,  0, 22,  1,  6,  9,  3, 13, 17,  5,  1,  2,  1, 25,  8, 13, 23,\n",
      "        4, 20,  6,  6, 20, 14, 21,  2,  1, 16,  7,  4,  4,  1, 19, 23, 10,\n",
      "       15,  1, 15,  0, 19,  9, 13,  5,  0, 21, 13, 18, 11,  1,  1,  9, 17,\n",
      "       13, 12, 10,  8,  3, 17, 16, 17, 20]), 'Next Training set size': 572}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 572\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 216\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:19, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10672-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-21T22:19:08.976150Z [info     ] Start Predict                  dataset=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 33.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9069562554359436, 'eval_accuracy': 0.675, 'eval_runtime': 1.1947, 'eval_samples_per_second': 234.362, 'eval_steps_per_second': 29.295, 'epoch': 24, 'labeled_data': array([ 2, 17, 25,  1, 11,  8,  8,  6,  1, 12,  8, 14,  9,  4,  1, 13,  1,\n",
      "        1,  2, 20,  7, 21, 17, 12, 23, 24, 19, 10,  7,  7, 23, 24, 14,  2,\n",
      "       10, 12, 15, 17,  3,  9,  9,  8, 14, 18,  9,  2,  1,  6,  7, 12, 20,\n",
      "        1, 18, 24, 10, 11,  1,  9,  1, 20,  1, 16,  3, 21, 10,  1, 17,  1,\n",
      "       19, 24, 21, 26, 10,  1, 10,  7,  1,  1, 11, 14,  6,  8, 14, 13, 24,\n",
      "       16,  1,  1,  1, 15,  7,  2,  1, 13, 19, 10, 18,  3,  8,  1, 14, 15,\n",
      "       23,  7,  2, 16, 13, 26, 15,  1, 11, 10, 11, 22,  7,  9, 20, 14,  3,\n",
      "       22,  6,  9,  9, 23,  6, 20, 10,  5, 20, 25,  1, 26, 11,  5, 19,  1,\n",
      "       13, 14, 10,  1,  1,  1, 14,  4,  3, 23,  4,  8,  6, 19, 15, 11, 17,\n",
      "        8,  2, 25, 21, 24, 13,  3, 19,  4, 11, 24, 25, 15, 15,  8,  6, 18,\n",
      "       15, 15, 26, 16, 17, 11, 14,  7,  2, 17, 24,  5,  3, 18, 24, 21,  3,\n",
      "       16, 22,  4, 17, 24, 16,  1, 20,  2, 16,  1,  1, 14, 19, 15, 16,  6,\n",
      "       15, 18,  1, 22, 16, 26, 22, 25, 23,  4,  4,  1,  2, 17,  2, 22, 25,\n",
      "       22,  1, 21, 10, 24, 13, 22, 15, 21,  8, 23, 24,  7,  5, 12, 21, 20,\n",
      "       23, 21,  6, 25, 20, 16,  8, 19, 14, 25,  7, 18,  4,  3, 18,  9, 15,\n",
      "       19,  9,  1, 15,  1, 19, 22,  1, 25, 12,  1,  8, 10, 20, 24, 16,  1,\n",
      "       26,  9, 21,  5, 22, 18, 10, 20, 17,  4, 18,  6,  3, 14,  5, 17, 24,\n",
      "       22, 22, 10,  3, 16, 10, 20,  1, 18,  2, 26, 15,  1, 11, 11,  1,  1,\n",
      "       16, 14, 12, 20,  5, 19, 11,  7,  4,  1, 18, 12, 19,  1,  5,  1, 14,\n",
      "        1, 23, 10,  7,  4,  5, 19,  8, 23,  5,  9, 13,  8, 12, 13,  4,  5,\n",
      "        1, 18,  1, 21, 23, 20, 14, 22, 26,  6, 19, 14,  5, 20,  1, 16, 22,\n",
      "        1,  6,  3,  1,  4, 26,  3,  1, 11,  7, 15, 17, 26, 25,  8, 24, 13,\n",
      "       21, 11, 24,  1, 18, 12, 25, 15, 20, 24, 23,  1, 13, 12,  6,  6,  1,\n",
      "       18, 12,  6,  3, 15, 14,  2, 23, 21, 25,  1, 23, 12, 22,  3, 21, 25,\n",
      "       25,  1,  1,  8,  1,  5, 11,  7,  2,  3, 24,  1,  4,  8, 23,  5,  1,\n",
      "        5, 23,  9,  1, 19, 19,  2, 11,  1,  1,  5,  9, 18,  1,  7,  1, 22,\n",
      "       10,  4, 17, 16, 13,  4, 23, 18,  2, 11, 25, 25, 21, 22, 22,  7, 17,\n",
      "        1,  1, 13,  2,  2, 25,  1, 12,  1, 25, 21, 16,  1,  1,  1, 19,  1,\n",
      "        5, 16, 18, 12,  1,  1, 11, 17, 11, 26,  1,  9,  8,  1,  1, 14,  4,\n",
      "        1, 23, 17,  1,  1, 12,  5,  7, 24, 12,  1, 22, 21, 12, 21,  9, 25,\n",
      "       10, 19, 13,  1,  7,  1,  3, 12, 20,  6, 18,  3,  6, 24,  9, 26, 16,\n",
      "       13, 26, 22,  1,  6,  9,  3, 13, 17,  5,  1,  2,  1, 25,  8, 13, 23,\n",
      "        4, 20,  6,  6, 20, 14, 21,  2,  1, 16,  7,  4,  4,  1, 19, 23, 10,\n",
      "       15,  1, 15, 26, 19,  9, 13,  5, 26, 21, 13, 18, 11,  1,  1,  9, 17,\n",
      "       13, 12, 10,  8,  3, 17, 16, 17, 20]), 'Next Training set size': 587}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 222\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='222' max='222' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [222/222 00:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    }
   ],
   "source": [
    "al_epochs=30\n",
    "performance_history_abortion2=[unqueried_score]\n",
    "for epoch in range(al_epochs):\n",
    "    model_abortion.train()\n",
    "    eval_metrics = model_abortion.evaluate()\n",
    "    should_continue = active_loop_abortion.step()\n",
    "    model_abortion.load_state_dict(init_weights)\n",
    "    model_abortion.lr_scheduler = None\n",
    "    if not should_continue:\n",
    "            break\n",
    "    active_logs = {\n",
    "        \"epoch\": epoch,\n",
    "        \"labeled_data\": active_set_abortion.labelled_map,\n",
    "        \"Next Training set size\": len(active_set_abortion),\n",
    "    }\n",
    "\n",
    "    logs = {**eval_metrics, **active_logs}\n",
    "    performance_history_abortion2.append(eval_metrics['eval_accuracy'])\n",
    "    print(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ac9d245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8sAAAK5CAYAAACIbLzRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAABP+AAAT/gEHlDmEAADk2ElEQVR4nOzdeVxU9f748ddnBhlWBYLEwBS3tEwtc8EtpaysNPVqLqmZmWWLWV/rmmnizaW6pXZvmWtilpo/TU3zmi1arplb1u26JZj7AiIiIMt8fn+cmWkGBhg2QXw/Hw8eA5/zOee8z5kzwPt8lqO01gghhBBCCCGEEOIvpvIOQAghhBBCCCGEqGgkWRZCCCGEEEIIIXKRZFkIIYQQQgghhMhFkmUhhBBCCCGEECIXSZaFEEIIIYQQQohcJFkWQgghhBBCCCFykWRZCCGEEEIIIYTIRZJlIYQQQgghhBAiF0mWhRBCCCGEEEKIXCRZFkIIIYQQQgghcpFkWQghhBBCCCGEyEWSZSGEEEIIIYQQIhdJloUQohQppRKUUlop1bG8YxFlTym1sazfb6drqnZZ7aOklFK1bTEm5LP8KaXUXqVUmq1esq081vZz7FUM12NX4/0VQghRcUmyLIQQotKr6ElZZaaUehiYDTQAvgEWAIvKNShAKdXRdk1sLO9YhBBCVExe5R2AEEIIIa55J4BGQJabZb1try9oreflWvYBsAQ4X4axlcQgwA/4s7wDEUIIcfVJsiyEEEKIEtFaZwH781lc0/b6h5v1zlNxE2W01pIkCyHEdUy6YQshxFWglIqzdfkcrJSqr5RaopQ6p5TKUEr9ppR6poB1TUqpx5RS3yilziulriiljiml1iqlHstV1zHGUil1r1JqvVIqyVbWzKleLaXUh0qpw7YYkpVSG5RSPfOJwTFuVinVQym1VSmVqpQ6q5T6RClV3VbPVyn1ptN2jyilXlVKqQKObYBS6ntbnFds67xv32au+oNtccQppQKVUu8ppY7a1vtTKfWuUsovd+zAeNuP423r279inerdq5SaoZTaZ4vFHv9MpVSt/N6f4lBKeSulnlNKbVJKXbDtK14ptVwp9aCH22hlO/5dtvfBfl18qpRqnM86fkqpF5VSO52uv2O29/41N/V7KqW+VUodt23/tG3dd5VSYU718oxZtl/zQCdb0Qan8z7YVqfA7vFKqbZKqc+d9n/Gdu2NVkr5OtW7USk10na9J9iO64JS6kel1CA3240DNth+vDvXNbHRqV6+Y5Zt1994pdSvyhiLfUkp9bPt/Hq7qe84VqVUuFJqjlLqpO24DimlXldKmd2dh/wopW6zfd62KaVOKaUybe/RCqVU20LW9ejcFrW+cvpdl89+3S5Xrr8jmyulVtqua6tSqrutTi2l1Bil1A9OcZxXSn2tjO7+BR3v7Uqpj5XxOctQSiXaPjtvKqVusNV53RbDvwvYzgu2Op8UtD8hROUgLctCCHF13QH8C0gENgFhQFvgI6VUNa31286VlVIW4AvgQYwurluBk8BNQGvgVuAzN/vpCwwDfgHWYbTuWW3bvNe2zUDgAPAVcINtex2VUlO01mPyif95YCTwo2270cBA4E6lVDTwNdAQ2A7EA3cDbwM+wD9yHVsV4P8BjwCpwE4gCWgGjAD+ppTqoLU+4iaOasA2oAbwM/BfoAPwf7Zz4pxwLgPuBZrazsdep2XO38/EOK+/At8D3rZ1ngZ6K6XaaK0P5HNePKaUCsE4dy2ANGALxvVQE7gf471Y68GmJmEc868Y14UVuA14DOiplHpAa/2j035Ntv22B5Jt+03BOIe3YryXU5zqTwLGYFx3mzHe8xCgLsZ5XgacKyC+zbbXB4DqGNfGaVvZ4cIOTik1jr+umb0Yn5dgjO7eUzC6byfYlt8HTMO45g5hXBsRQBugvVKqldb6uVyxhWOc7zMY58UuvxZy59huxEi2b8VoGV8LVAFigOlAd6VUF611hpvVbwZ2AQrjmvfHeE8mApHA8ML27+QlYAjGNbATyMAYG94d6KqUGqC1XuIm/qKc2yLXL6H2GGPc44HvgFD+6t4/EHgT4z36FeP6rQ10Bu5TSr2qtf5n7g0qpZ4AZmG8RweAVRjnvQEw1rafjcAc4A1gkFJqtNb6spv4nra9flTC4xRCXAu01vIlX/IlX/JVSl8Y/zBqoGOu8jhbucb4p9PktKyvrTwF8Mu13r9ty/YBUbmWWYAuuco2Ou1nsJv4IoALGP989su1rKFT/DH5HNdlINqpvBpGoqqB3zASqlCn5ffblqUC/rm2+U/bsm+AcKdyE0YiqIEfc60z2On4vgKCnJY1sJ1DDbTPtV6srTy2gPfuEaBqrjKz07rr3KxjP98d89uum3VW29b5HgjLtSwQuCefc187V/n9ude3lQ+11f8foJzK77aV73TzXpid33OMmxvpwCWgnpt9NAVudPq5tm3bCUU5R/m9L8DfbOUXcp8P2/JOQDWnnxsBd7mpVxc4attW61zLOtrKNxbwXrmNHeNGgca4ARDoVF4D43OggbfzOVYNzAN8nJa1BXIwbnjUKsK1dDdQ0035g0Amxs2n3L9Tinpui1o/jnx+/xS0HNffkeOdr12nOi2AW9yU34VxAygr9/kAWgHZwBWgfz7rRjr9/Kkthqfc1O1gW7bX0/dIvuRLvq7tL+mGLYQQV9dPWus3tNZWe4E2Wn5+x0iUWtjLldEN+WmMf/S6a63jnTektb6itf5PPvv5Wmsd56Z8JBAETNZaL861vf3Ay7Yfn89nu9O01tuc1rmI0QoERsIyVBvjUO3Lv8ZoifLH+KfUfmw32PZxAeirtT7ttI4VGIfRCtxeKdXETRyXgCe01slO6x0EFtp+jMkn/nxprVdprVNyleVorWMxJrDqrJQKLOp2nSml7gQexkhiemqtXVpmtdaXtNbfeRjv17nXt5XPxWhpbojR8ml3o+11s87VYmY7zu+digIxEuY/tNZ5WoG11r9orc96Emcx2bvNv+jufGitN9iuPfvP/9Na73RT7w+MFlswkr4SU0aX/J4YidnTWutLTvs7xV+fnWeVUj5uNvEn8Kx2anXWWm/BaN1WGEm8R7TWP2itj7kpX4vRayOYv7rB2xXp3Bajfkn9D3hTa63d7Otn7aZ3h+29/xCjx2S3XItfx7gZNElrnWcWdq31Tq31caeiD2yv7obG2MukVVmI64R0wxZCiKsrv+R2P0Zic5NTWQxGt8FvtfuuyAVZkU95F9vr/8tnub3bbut8lq93U2ZPpo7aElZ3y5vhemydMJKxr7TWiblX0FpblVKbMVowW2O0rDvblU+yZu9Ce5ObZYWyJUIPYbRSB2L8kw3G+2AC6gF7irNtm/ttr184J/rFZesO3BXj2qnGX3/Xw22vDTBa/sGIOwcYopQ6YIvhjLvtaq3PKaWOAk2VUv8E5rpLUsqCUqoGcDtGF/XFhVR3Xq8KRnf71hjdvi0YyWcNW5UGpRRie9t2f9RaJ+ReqLXeqJSKB6KA5hjd3Z19r7W+4ma7+zFahIt07SqlqmHcgGmKkRxXsS2yj1tvgNELo8jntrjvRQmtcr6Z6CYmX4zfY3dhdNG2jw+vb3tt4FTXDNxj+zH3TOxuaa23K6V2Ac2VUi211jts2wrDuOFyCfdDX4QQlZAky0IIcXXlaQWysbdOWZzKbra9FidJyW8W3yjb66/K/ZxbdmH5lB93U3a5gGXOy52PzR7H35QxCVRRYynKefSIUmoiMJq/EmR3qhZ1u7mU5D11oZR6FngP46ZDfhzxaq0PK6VeBN4FZgAzlFKHMMbvLgfW5mrNG4gxFnUUMEopdQajxXotsEhrnVbSY8iH/RzFa2OW7UIppRpijEMtKCEu6XtnF2F7jS+gzhGMazzCzbJSu3aVUj2AjzF6i+TH+biLem6L/F6UgnxnILdNWraUgm8oOB9vKMajvy5rrU8UIYYPMc7rcGCHrexJjMR8rtY6tQjbEkJcwyRZFkKIqyvfFpMCFJZMupOeT7l9+M0i3D8TtzAFxV+UY7PH8TvGBF0F+a+bsuKcx3wppXphdNdMweiqvgE4ZW8BVEptxZgAq8A7DEVQnPfUQSnVAqO7aDZG1/k1wHGtdbpt+SKgH7ni1Vp/qJRajtESeQ9GK+kTtq/vbJNSZdnqblJK1cdoDb/fVreH7WucbfK1oyU5jkIU5Rwtw0iUV2JMKHcASNFa5yil7sMYW1xa750n2ymoTqlcu0qpmhifYx+MMf6LMca3p2mttVJqMvBaPrEU9for0fWaS2FDAN3+7lJK+WNMTHgjxkRcH2E8jizV1hNlGMYkXqVxvIsxbir1UUq9DFzEmDARpAu2ENcVSZaFEKLisicit5TiNo9hdFd8wzaes7zYW9d2a60Hl2Mcdr1sr69rree7WV6vlPZTWu/p3zCSgn9prae5WZ5vvLbx4XNtXyilWmEkB/dgzKw8y6luGkaX/hW2urUwZg1/AHgLIyEvbfZzVEcpVaWwFk1bq/JtGLNa99Ja5+SqUlrvnZ29B0WdAurYe04UpTWzqB7CSJSXa63Hulnu7riLdG6LUR+MicXAGMbgTi0PtuFOe4xEeZfWepib5e6O9zxGF/IApVSEp63LWusMpdQ84BXgcYybL1EY4/1/K1b0QohrkkzwJYQQFdcGjNbfTkqpqMIqe8j+iJxeBdYqe99jHNsDSqmAq7A/+z/w+d0kDrG95ukiq5S6h/y7pReVfcx3T9tY0+IqKN6GGGPEPaK1/om/xnO6m0zNue5R/powq8C6xWVL5n/F6D7bx4NV7OfilJtEGYzZ5t0p7JrIzyaMlsoOSqnauRcqpTpgJFapGI+IKisFXQOhGI9TclHUc1uM9wL+ukGQ54aQbYz9HR5uJ7eCjtcbY9I1F7brwT4p2RNF3N9HGL0Anuavx3lJq7IQ1xlJloUQooKyTb40G+Of+S9srXoOSimLUqqL25Xz9x7G2MhYpdSTtglwnLdpUkp1Ukrd73710mH7J/wjjDGFK5RSeVrplFLhSqkXlVKl0QvK/g98o3yW2ycGe8r2j7c9htqU4j/IWuvd/PVc62W2pMZBKRVoS84LY493kPPNBtss4/P5a5In523HKKW65D6ftuO91/bjn7ayWrbrw13r4EPOdcuI/Zm+/1JK5Z7NGaVUR6ebDYcwkprGSqn2TnWUUuo1jBZJd+zXRL2iXGO2GwYrMD6XM3Od/+r8NZvyDO3+OculxX4N/M22X3sM/hi9BoLyWa8o57Y49e2zqg9USjlPthWEcW0Wd0Z5+/HG2G4I2bdbBePZ1nXzWW8yxsR2Y5VSj7qJv7lSKjJ3ue3pA2sxZpXvivFM8WXFjF0IcY2SbthCCFGxjcLoNn0fcFAptQU4jTHDb1OMMba1Pd2Y1vqoUqonxmzYczGS5v9ijMmLwBj3GYYx7vPr0jsMt14BIjFahPYrpfZgjLkMBGpiJLZmjG7B2SXc19cY3TF7KqV+xBjrmAN8qbX+EvgXRnfLh4BDSqmfbHF0xJjg5xzQpoQx2A22xXMvcFQptQnjEVqRGK1uO/mrNSw/84GXgDuBP2wzh3thzDJ+EmPsbvdc6zQBpgHJttl+zwABGGOxw4CD/NUFOxjj+vjQ6X3xsm2jAUar6XjKiNZ6mVLqTYxHiH1vi2G/La5bMSaeigIu2mbungk8C2xQSm3EeL/uxEig3sX4HOXex1Hbdu8A9tnOyRXggNb6n4WEOBzj+rwfOKKU+gHjBkUMxnXzA2V4fmxWYzxerSnG74aNGJ+TDhg3D+bjpjW1KOe2mPU3KaX+gzFj9W7b5w2gJcY1t5K812ahtNa7lVJrMWYM36uU+h7jxl80xs2nfwMvuFlvu1JqOMZNr8+VUhNs580fo/W7Psbnxt0EhR9ijO8HmKe1znRTRwhRiUnLshBCVGC2lqkHMcaSbsP4x/5vGEnAVozZm4u6zW8xxni+g5GktcNoObkJ45nIIzGSxzKltc7UWv8NI1n+GmMsYw+MZ01bMSbxeaA0WudsLdkPAxsxEr7HMWa3vdO2/DDGY36WYSSFXTESgLcxblSU2kzA2ngOdVuMZPc32/fdMZLl/2CMBS5sGxcwztPHGBMiPWQ7rnkYj05y99zbNRithHsxkoS/YSQaRzFuXLRwepzVHxgTh32NMU60K8Z5yMZoxbvd/kidsqK1fgMjiVmBcW32wni/jgN/x7hpZPcC8BzGZHDRtlgPYbQqf1XAbnpizK4cgjH++kn+ajkvKLazQCtgAnAW49q6F+OGw0vAfWXcqoxt/PDdGDdAzmIk7q2ALzHOU74t/0U8t0Wub1v+LpCIcV5ux3jcUhvcX5ue6gm8gTHbeCeMm1nbMB4jtTu/lbTWczA+L59h3MzoiXGdpGC8h7kfTWe3EeOzb+Wv58kLIa4jys0z34UQQgghhLiuKaX6YyTYa7XWhd5EEUJUPtKyLIQQQgghhBPbWP7XbD9OL8dQhBDlSMYsCyGEEEIIASilnsAY990aY3Kvb7TW35RvVEKI8iIty0IIIYQQQhjuxpiE70ZgEdC/XKMRQpQrGbMshBBCCCGEEELkUuFblpVSryml/p9S6ohSSiulEgqpX10p9bFS6oxSKkMptU8p9VQB9fsppXYppdKVUueVUotzP8vUVu9updTPSqlUpdRvSqkebuqYbduSh9YLIYQQQgghxDWswifLGA+Tj8F4jMWFgiraHni/GeiL8fiMFzAenTBbKZXneYdKqecxutikYzzqYTrQGdiqlLrJqV5NjEdPpAD/B/wP+H9KqTtzbXIkxiMVivwoFyGEEEIIIYQQFUeF74atlKqjtT5i+/43IEBrXTufulMwEtW/aa2/cCr/EngAuEVrHW8ruwFIwHgmYiutdbat/C5gB/Cx1nqorWwY8D4QqrW+rJQyYTzj7zOt9eu2OrUwnu/4hNb6/5XuWRBCCCGEEEIIcTVV+JZle6LsoceAeOdE2WYqUAXo41T2CBAA/MueKNv2txP4EXjU9tgAAH8gXWt92VbHitHK7e+0vY+AjZIoCyGEEEIIIcS1r9I8OkopFQ7UxOhWnds2QAMtncrs3291U38rxmyIDYF9wBYgWCk1BvgUo6t2U4wu4iil+mE8ZuC2YsRdE4jMVXwDcCuwC0gr6jaFEEIIIYQQQrjwA+oAa7TWpzxZodIky0CE7fV47gVa6ytKqfO4JqX51ncqiwT2aa13KKVigX8Ak2zL5mqt/59SKhiYBryhtT5ajLifBPKMpxZCCCGEEEIIUeqGAXM8qViZkmU/2+uVfJZnONUprH5GrjporScopWYA9YA/tdYnbIv+CZwE3ldK3Qz8C6PV+k/g71rrHwqJex7wda6y5sC/p06dyq233lrI6lfX5cuXOXToEPXr18ff37/wFYQQHpHPlhBlQz5bQpQN+WyJa83vv//Oyy+/DMbcUx6pTMmyvbuyJZ/lvsDpfOqnu6nrXAcArfU54Jz9Z6VUB+BxINpW9BVwFOgK9ADWKaVu0Vr/mV/QWutjwDHnMqUUAK1btyY6OtrdauUmKSkJs9lM+/btCQkJKe9whKg05LMlRNmQz5YQZUM+W+JaU7VqVfu3Hg9zrfATfBWBvaU39/hflFI+GOOAj3tSn4K7aNu3aQFmAx/YJgVrBTQGRmqtdwHjgPMYk44JIYQQQgghhLiGVJpkWWt9GiO5ddcU2xpQwM9OZfbv27ip3wZIBfYXsMvXMbppj7P9bE+6j9ni0bZ4anoQvhBCCCGEEEKICqTSJMs2i4AopVTPXOUvA9nA505lqzCa4EcopRzd0W3PWe4ALNVaZ7rbiVKqEfB34Hmtdaqt+KTt9XZbHQtQ36lcCCGEEEIIIcQ1osKPWVZKDQRq2X4MA7yVUmNtPydrrT9wqv4W0AtYqJRqDsRjPE/5YeBN52c2a63P2x4FNR3YqJRaCIQCLwFngDfyiUdhzJ62Wmv9pdOin4BDwCdKqQ+ALkBVXBN0IYQQQgghhBDXgAqfLGM8WunuXGVv2l6PAo5kWWt9QSnVDuP5x09hJKuHgeFa65m5N6y1ft/2SKn/w0ia04BvgNecZrvObRhG6/GjubaVpZTqCnwEvG2LrafW+pDnhyqEEEIIIYQQoiKo8Mmy1rpjEeufAp4oQv3PgM+KUH8WMCufZQeAGE+3JYQQQgghPKO15uLFi1y6dIkrV65gTA8jyktWVhahoaGcPn2axMTE8g5HXIeUUlgsFgIDA6lWrZrjiUKlqcIny0IIIYQQ4vqmtebkyZOkpKQAYDKZMJkq29Q71xaz2UxwcDBms7m8QxHXqZycHFJTU0lNTeXy5cvcdNNNpZ4wS7IshBBCCCEqtIsXL5KSkoLFYqFGjRr4+PiUSSuS8Fx2djapqakEBATg5SUphbj6tNZkZGRw6tQpUlJSCAgIoFq1aqW6D7klJ4QQQgghKrRLly4BUKNGDXx9fSVRFkKglMLX15caNWoAOHqelCZJloUQQgghRIV25coVTCYTPj4+5R2KEKKC8fHxwWQyceXKlVLftiTLQgghhBCiQtNaYzKZpEVZCJGHUgqlVJlM+ifJshBCCCGEEEKIa1ZZ3UiTZFkIIYQQQgghhMhFkmUhhBBCCCGEECIXSZaFEEIIIYQQJVa7dm06duzocf2OHTtSu3btYu8vNjYWpRQJCQnF3kZpU0oxePDgYq9fEY/peibJshBCCCGEEBXMlClT6N27N3Xq1EEpVWhSeebMGYYMGUL16tXx8fGhSZMmzJkzx+P92ZO07du3lzByV3FxcUyfPr1Ut1kcK1euJDY2trzDuG4lJCQQGxvL3r17yzuUIpEniAshhBBCCFHBjBkzhpCQEO68806Sk5MLrJucnEy7du04ceIEI0eOJCoqilWrVjFs2DBOnjzJ+PHjr0rMBw4cyDPRUlxcHAkJCYwcOTJP/fXr15fJDMburFy5kgULFpR5wpyeno7ZbC72+mPHjmX06NFYLJZSjKr8JSQkMGHCBGrXrk2zZs3KOxyPSbIshBBCCCFEBfPHH39Qp04dABo3bkxqamq+dd9++20OHz7M8uXL6dmzJwBPPfUU3bp1Y9KkSQwaNIioqKgyj7moCZ63t3cZRVJyqampBAQEFHm9kj4L3MvLCy8vSdEqCumGLYQQQgghRAVjT5Q98dlnnxEVFeVIlO1efvllsrKy+Pzzz4sVQ1xcHEopvv/+e95++23q1KmDxWKhQYMGfPLJJ3nq5x6zrJTihx9+4OjRo45n4TqPx3U3ZnnHjh0MHjyYBg0a4OfnR2BgIG3btmXFihXFOgZ7XAsWLHDEZP/auHGjSxxHjhyhV69ehISEEBgYCIDVamXSpEl06NCB8PBwvL29ufnmmxk+fDiJiYl59uVuzLK9bPPmzbRv3x4/Pz9CQ0MZOnRonpsg7sYs28v279/Pq6++SkREBBaLhaZNm7J27do8MWRkZDjq+fj40LRpUxYvXlyk8dBbt27lwQcfJDw8HIvFQnh4OJ07d2bTpk0u9S5evMjf//536tWrh8ViISwsjH79+nHkyBGX+Dt16gTAE0884Tj/JRnbfbXIbQshhBBCCCGuUadPn+bYsWP0798/z7Lo6GiUUuzYsaNE+3jttdfIyMjgmWeewdvbm5kzZ/Lkk09y0003ce+99+a73sKFC5k0aRLnz59n2rRpjvKwsLB811mxYgUHDx6kX79+REZGkpiYyIIFC+jZsyefffaZ2+MszPTp05k6dSqbNm1i4cKFjvJGjRo5vk9NTeXuu++mXbt2TJo0ibNnzwKQmZnJu+++S+/evenRowd+fn7s2LGDefPmsXnzZnbt2uVRC/nevXt55JFHGDJkCAMGDGDjxo3MmzcPk8nE7NmzPTqOxx9/HIvFwiuvvEJmZibTp0+ne/fuHDx40OWmw6OPPsrq1at56KGH6NKlCydPnmT48OHUrVvXo/0cOHCAzp07Ex4ezogRIwgPD+fs2bNs27aNPXv20L59e8BIlNu0acOff/7JkCFDuO222zh16hQfffQRrVq1YufOndSqVYuePXuSlZXF5MmTGTZsmGN9T+MpT5IsCyGEEEKIa9pjc7dz4kJ6eYeRR0SwL58NbV2m+zhx4gQAkZGReZZZLBZCQ0M5fvx4ifaRmZnJzz//7EgK7ROPzZkzp8BkecCAAcydO5f09HQGDBjg0b7Gjh3LlClTXMpGjBjBHXfcwcSJE4uVLHfv3p2VK1eyadOmfONITEzkjTfeYMKECS7lFouFkydP4uvr6yh7+umnadOmDUOHDmXlypU8+uijhcawb98+tm7dSuvWrR3bSElJYf78+UydOtWjLt9hYWGsXr3aMS68U6dOtGzZklmzZjnO2bp161i9ejWDBg1ytKaD8Z41b9680H0AfP3116SlpbFkyRJatGiRb71x48Zx5MgRtm/fTtOmTR3lgwcP5vbbb2f8+PHExcXRpEkTkpKSmDx5MtHR0R5fCxWBJMtCCCGEEOKaduJCOgmJaeUdRrlISzOOO7/xwj4+Po46xfXss8+6tJ5GRERQv359l662pcXf39/xfVpaGunp6WitiYmJYebMmaSkpFC1atVS3y8Y3dZzU0o5EuWcnBwuXbpEdnY2MTExAPz0008eJcvR0dGORNkuJiaGtWvXkpCQQOPGjQvdxosvvugygVqLFi0IDAzk0KFDjrJVq1YBMGrUKJd1mzVrxn333ce6desK3U9QUBBgTIp2++23ux2HrbVm0aJFtG3bloiICM6fP+9Y5u/vT+vWrVm/fn2h+6roJFkWQgghhBDXtIhg38IrlYOrEZefnx8AV65ccbs8PT2d8PDwEu3D3fjpG264oUyeBXz27FnGjh3LqlWrHF2hnSUnJ5dJshwWFka1atXcLlu6dCnvvfcee/bsISsry2XZhQsXPNp+fucQcDv22dNthISEuKwfHx+PUooGDRrkqduwYUOPkuW+ffuyaNEiJk+ezNSpU2ndujX33Xcfffv2dUwUd+7cORITE/nuu+/y7VZvMl3702NJsiyEEEIIIa5pZd3VuSKLiIgAcNvVOiMjg8TERMcY0eLK71FIpf3YJ6vVSufOndm/fz8jRoygRYsWVKtWDbPZzPz581m0aBFWq7VU92lnv+mQ2/Lly+nTpw8tW7bk/fffp2bNmvj4+JCTk8MDDzzgcTwFPU7K0/PoyftQ0LY83Y+3tzfr1q1j586dfP311/z4449MmDCBCRMmMH/+fPr16+fYVqdOnRgzZoxH270WSbIshBBCCCHENSo8PJzIyEi2bduWZ9n27dvRWhc47rSs5X7uckF+/fVX9u3b53bs8Ny5c69aHM4+/fRTfHx82LBhg0tCvX///hLFU1bq1KmD1poDBw7QpEkTl2UHDhwo0rbuuusu7rrrLl5//XVOnTpF8+bNGT16NP369SMsLIygoCAuXrxY4Lh1u+Ke//J27beNCyGEEEIIcR3r378/8fHxfPHFFy7lU6dOxcvLiz59+pRTZBAQEEBycrJHrZr2ltPcdX/77bcSPTrKHgd43m3aOSallEsLstaaiRMnliiestKtWzcA3n33XZfyvXv3ejyG2Hn8sV2NGjWoUaMGSUlJgNHF+rHHHmP37t0sWbLE7Xacu9EX9/yXN2lZFkIIIYQQooJZuHAhR48eBYzxoZmZmY4ELSgoiOeff95Rd/To0SxbtoyBAweya9cuoqKiWLVqFWvWrGHcuHFFemZzaWvVqhVr1qxhxIgRtG7dGrPZTNeuXV0m8rJr1KgRt912G++88w5paWnccsstHDx4kFmzZtG4cWN2795dojg++OADnnvuObp06UKVKlWIiYnhxhtvLHC9Xr16sXz5cmJiYhg0aBBZWVmsXLmyxJOmlZUuXbrw4IMPsnDhQpKSkhyPjpoxYwZ33HEHu3btKrSVd+LEiaxfv56HH37YMUb5P//5D7t37+a5555z1Js0aRJbtmyhf//+rFixgujoaLy9vTl69Chr166lefPmxMXFAXDrrbcSEBDAjBkz8Pf3p2rVqkRFRdGqVasyOxelQZJlIYQQQgghKph58+bxww8/uJSNGzcOgFq1arkky8HBwWzevJkxY8YwZ84cUlJSqFevHh999BHPPPPMVY07t5EjR3Lo0CEWL17Mhx9+iNaa+Ph4t8my2Wzmq6++YtSoUSxYsIDLly/TuHFjFixYwC+//FKiZLlfv37s2rWLJUuW8Pnnn2O1WtmwYUOhyXLfvn25dOkS06ZNY9SoUQQHB9O1a1feeustxwRdFc2yZcsYN24cixYt4ttvv6Vhw4bMnj2b7du3s2vXLpfHYLnTvXt3Tp06xdKlSzlz5gw+Pj7Uq1ePGTNmMGzYMEe9atWqsWXLFt577z2WLl3Kl19+iZeXF5GRkbRr146hQ4c66vr6+rJo0SLGjh3LCy+8QGZmJo8//niFT5ZVaQ/MFyWnlIoGtm7dupXo6OjyDsdFUlISmzZton379oSEhJR3OEJUGvLZEqJsyGercrA/Gqd+/frlHImwy87OJjU1lYCAALy8pP3tWvDwww+zYcMGUlJSCpxw7Frkye+Ibdu20aZNG4A2Wuu8g/zdkDHLQgghhBBCCFFJpKen5ynbs2cP69at45577ql0iXJZkttAQgghhBBCCFFJ/OMf/2DPnj3ExMQQFBTE77//zpw5c7BYLLz55pvlHd41RZJlIYQQQgghhKgkOnTowNatW/nnP/9JcnIyQUFB3H///YwfP56mTZuWd3jXFEmWhRBCCCGEEKKS6NKlC126dCnvMCoFGbMshBBCCCGEEELkIsmyEEIIIYQQQgiRiyTLQgghhBBCCCFELpIsCyGEEEIIIYQQuUiyLIQQQgghhBBC5CLJshBCCCGEEEIIkYsky0IIIYQQQgghRC6SLAshhBBCCCGEELlIsiyEEEIIIYQosdq1a9OxY0eP63fs2JHatWsXe3+xsbEopUhISCj2NkqbUorBgwcXe/2KeEzXM0mWhRBCCCGEqGCmTJlC7969qVOnDkqpQpPKM2fOMGTIEKpXr46Pjw9NmjRhzpw5Hu/PnqRt3769hJG7iouLY/r06aW6zeJYuXIlsbGx5R3GdSshIYHY2Fj27t1b3qEUiVd5ByCEEEIIIYRwNWbMGEJCQrjzzjtJTk4usG5ycjLt2rXjxIkTjBw5kqioKFatWsWwYcM4efIk48ePvyoxHzhwAKWUS1lcXBwJCQmMHDkyT/3169ejtb4qsa1cuZIFCxaUecKcnp6O2Wwu9vpjx45l9OjRWCyWUoyq/CUkJDBhwgRq165Ns2bNyjscj0myLIQQQgghRAXzxx9/UKdOHQAaN25MampqvnXffvttDh8+zPLly+nZsycATz31FN26dWPSpEkMGjSIqKioMo+5qAmet7d3GUVScqmpqQQEBBR5PR8fnxLt18vLCy8vSdEqCumGLYQQQgghRAVjT5Q98dlnnxEVFeVIlO1efvllsrKy+Pzzz4sVQ1xcHEopvv/+e95++23q1KmDxWKhQYMGfPLJJ3nq5x6zrJTihx9+4OjRoyilHF/28bjuxizv2LGDwYMH06BBA/z8/AgMDKRt27asWLGiWMdgj2vBggWOmOxfGzdudInjyJEj9OrVi5CQEAIDAwGwWq1MmjSJDh06EB4ejre3NzfffDPDhw8nMTExz77cjVm2l23evJn27dvj5+dHaGgoQ4cOzXMTxN2YZXvZ/v37efXVV4mIiMBisdC0aVPWrl2bJ4aMjAxHPR8fH5o2bcrixYuLNB5669atPPjgg4SHh2OxWAgPD6dz585s2rTJpd7Fixf5+9//Tr169bBYLISFhdGvXz+OHDniEn+nTp0AeOKJJxznvyRju68WuW0hhBBCCCGue0cTL7N05zGOX0gnMtiXR++qSa0b/Ms7rEKdPn2aY8eO0b9//zzLoqOjUUqxY8eOEu3jtddeIyMjg2eeeQZvb29mzpzJk08+yU033cS9996b73oLFy5k0qRJnD9/nmnTpjnKw8LC8l1nxYoVHDx4kH79+hEZGUliYiILFiygZ8+efPbZZ26PszDTp09n6tSpbNq0iYULFzrKGzVq5Pg+NTWVu+++m3bt2jFp0iTOnj0LQGZmJu+++y69e/emR48e+Pn5sWPHDubNm8fmzZvZtWuXRy3ke/fu5ZFHHmHIkCEMGDCAjRs3Mm/ePEwmE7Nnz/boOB5//HEsFguvvPIKmZmZTJ8+ne7du3Pw4EGXmw6PPvooq1ev5qGHHqJLly6cPHmS4cOHU7duXY/2c+DAATp37kx4eDgjRowgPDycs2fPsm3bNvbs2UP79u0BI1Fu06YNf/75J0OGDOG2227j1KlTfPTRR7Rq1YqdO3dSq1YtevbsSVZWFpMnT2bYsGGO9T2NpzxJsiyEEEIIIa5ry3cd59Vl+8hxGj87c+MR3unVhL81jyzHyAp34sQJACIj88ZpsVgIDQ3l+PHjJdpHZmYmP//8syMptE88NmfOnAKT5QEDBjB37lzS09MZMGCAR/saO3YsU6ZMcSkbMWIEd9xxBxMnTixWsty9e3dWrlzJpk2b8o0jMTGRN954gwkTJriUWywWTp48ia+vr6Ps6aefpk2bNgwdOpSVK1fy6KOPFhrDvn372Lp1K61bt3ZsIyUlhfnz5zN16lSPunyHhYWxevVqx7jwTp060bJlS2bNmuU4Z+vWrWP16tUMGjTI0ZoOxnvWvHnzQvcB8PXXX5OWlsaSJUto0aJFvvXGjRvHkSNH2L59O02bNnWUDx48mNtvv53x48cTFxdHkyZNSEpKYvLkyURHR3t8LVQE0g1bCCGEEEJct44mXs6TKAPkaM2ry/bxZ2JaOUXmmbQ0I778xgv7+Pg46hTXs88+69J6GhERQf369V262pYWf/+/WvPT0tJITEwkLS2NmJgY/ve//5GSklLq+7R7+eWX85QppRyJck5ODsnJyZw/f56YmBgAfvrpJ4+2HR0d7UiU7WJiYsjOzvb4MVEvvviiywRqLVq0IDAwkEOHDjnKVq1aBcCoUaNc1m3WrBn33XefR/sJCgoCjEnRMjIy3NbRWrNo0SLatm1LREQE58+fd3z5+/vTunVr1q9f79H+KjJJloUQQgghxHVr6c5jeRJluxyt+Xznn1c5oqLx8/MD4MqVK26Xp6enO+oUl7vx0zfccANJSUkl2q47Z8+eZdiwYVSvXh1/f39CQ0MJCwtj5syZAIXODF5cYWFhVKtWze2ypUuX0qpVK3x9fQkODiYsLMxxTi5cuODR9vM7h4Dbsc+ebiMkJMRl/fj4eJRSNGjQIE/dhg0berSfvn37cv/99zN58mSCg4Pp1KkTU6ZMIT4+3lHn3LlzJCYm8t133xEWFpbn65tvvuHMmTMe7a8ik27YQgghhBDiunX8QnqJlpe3iIgIALddrTMyMkhMTHSMES2u/B6FVNqPfbJarXTu3Jn9+/czYsQIWrRoQbVq1TCbzcyfP59FixZhtVpLdZ92+d1QWL58OX369KFly5a8//771KxZEx8fH3JycnjggQc8jqegx0l5eh49eR8K2pan+/H29mbdunXs3LmTr7/+mh9//JEJEyYwYcIE5s+fT79+/Rzb6tSpE2PGjPFou9eiSpcsK6WqAxOAh4DqwGlgBTBea53spu4UW91qwEHg31rrObnq+QFvA72AKsBaYKTWOilXve7AZ0BjrXU8QgghhBCiQosM9i3R8vIWHh5OZGQk27Zty7Ns+/btaK0LHHda1nI/d7kgv/76K/v27XM7dnju3LlXLQ5nn376KT4+PmzYsMElod6/f3+J4ikrderUQWvNgQMHaNKkicuyAwcOFGlbd911F3fddRevv/46p06donnz5owePZp+/foRFhZGUFAQFy9eLHDcul1xz395q1TdsJVSNwI/AUOAlcALwCpgOLDBlvTa6wYBm4G+wDxb3T+B2Uqp3E9unwI8Acywff8A4PKJVUpVBT4AJkiiLIQQQghxbXj0rpqY8/lH3qwUfe66+SpHVHT9+/cnPj6eL774wqV86tSpeHl50adPn3KKDAICAkhOTvaoVdPecpq77m+//VaiR0fZ4wDPu007x6SUcmlB1lozceLEEsVTVrp16wbAu+++61K+d+9ej8cQnz9/Pk9ZjRo1qFGjhqPrvclk4rHHHmP37t0sWbLE7XbsM4pD8c9/eatsLcuvAbWA/lrrxfZCpdRWYBHwMmC/sv8O1AP+prW2/2aZo5T6EnhdKfWJU9LbG5iqtX7Ttr0LGEm1j9baPup9CpAITC27wxNCCCGEEKWp1g3+vNOrSZ5JvsxK8c/eTbj5hpKN9y2uhQsXcvToUcAYH5qZmelI0IKCgnj++ecddUePHs2yZcsYOHAgu3btIioqilWrVrFmzRrGjRtXpGc2l7ZWrVqxZs0aRowYQevWrTGbzXTt2tVlIi+7Ro0acdttt/HOO++QlpbGLbfcwsGDB5k1axaNGzdm9+7dJYrjgw8+4LnnnqNLly5UqVKFmJgYbrzxxgLX69WrF8uXLycmJoZBgwaRlZXFypUrSzxpWlnp0qULDz74IAsXLiQpKcnx6KgZM2Zwxx13sGvXrkJbeSdOnMj69et5+OGHiYqKAuA///kPu3fv5rnnnnPUmzRpElu2bKF///6sWLGC6OhovL29OXr0KGvXrqV58+bExcUBcOuttxIQEMCMGTPw9/enatWqREVF0apVqzI7F6WhsiXLnYB0IPftjc+BjzFah+3J8mNAvFOibDcV6Ar0Ad6ylfkDzrdYEgEz4ANkKKVaA8OAdlrr7NI5FCGEEEIIcTX8rXkkLWqH8PnOPx3PWe5z183lligDzJs3jx9++MGlbNy4cQDUqlXLJVkODg5m8+bNjBkzhjlz5pCSkkK9evX46KOPeOaZZ65q3LmNHDmSQ4cOsXjxYj788EO01sTHx7tNls1mM1999RWjRo1iwYIFXL58mcaNG7NgwQJ++eWXEiXL/fr1Y9euXSxZsoTPP/8cq9XKhg0bCk2W+/bty6VLl5g2bRqjRo0iODiYrl278tZbbzkm6Kpoli1bxrhx41i0aBHffvstDRs2ZPbs2Wzfvp1du3a5PAbLne7du3Pq1CmWLl3KmTNn8PHxoV69esyYMYNhw4Y56lWrVo0tW7bw3nvvsXTpUr788ku8vLyIjIykXbt2DB061FHX19eXRYsWMXbsWF544QUyMzN5/PHHK3yyrEp7YH55UkrtB27UWoe4WZYEBANhGDcJTgGLtNaP5apnwUi4V2qte9rK1gJRwADbsrlANa31bUqpKsBuYKPW+oVixFwTyP1gvMbA7HXr1pXrGBN3UlJS+OWXX2jatClVq1Yt73CEqDTksyVE2ZDPVuVw+vRpzGYzdevWLe9QhE1OTg7p6en4+voWOHmVqDgeeeQRNm7cSFJSUqV7z/744w9ycnIIDw/Pt87PP//MAw88ANBGa513kL8bla1l+XfgFqVUM631XnuhUqoZRqIMcDNg73uQZ9pArfUVpdR5XBPYF4EvgZ22n08Af7N9/6pt268XM+YngdxjpAFjbEF+zzYrb7/88kt5hyBEpSSfLSHKhny2rm2hoaEEBweTmppa3qGIXNLTK/Zs4dcj+00MZ/v27ePrr7+mc+fOlfI9y8nJ4cKFCy7PnM6tOJOyVbZk+X3gEWCpUmok8BtwGzAdyMKYydqPv5Jl9w+kgwxbPQC01oeUUrcDDW3b+N2WVNcDxmKMkU5RSj0LPAsEYiTXr2qtC7sa5wFf5yprDMxu1qyZtCwLcZ2Qz5YQZUM+W5WDvWXZPkmQKH/SslxxTZkyhb1799KpUyeqVavG//73P+bNm4fFYmHixImV8nNkNpsJDg6mUaNG+dbx8fEp8nYrVbKstf5BKfUYRnL8la3YijFe+b9ADyAFI+EFsOSzKV+MR045bzsbI/l2Ngv4Wmu9QinVB3gPo6X4GBCHMa752UJiPmar72AfdF+1alVCQvL0KK8QKnJsQlzL5LMlRNmQz9a1LTExEQAvr0r1r2ulYDab5X2pYDp27Mj27dt57733SE5OJigoiPvvv5/x48fTtGnT8g6vTJhMJkwmU4G/54tzw7TSXdla6yVKqWUYrbOBwEGt9Rml1A4gGzgM2M9U7rHCKKV8gBuATQXtRyk1GGgJ2G9fPAks11ovsi2fAvxbKfW81rpsnp4uhBBCCCGEEE66dOlCly5dyjuMSqHSJcvgaAXea/9ZKRUO3AH8oLVOA9KUUseBaDert8bopv1zfttXSoUB7wKva63t454jgV1O1Y5hzJYdCpxFCCGEEEIIIcQ1w1TeAZQ1pZQJ+BdGl+hJTosWAVFKqZ65VnkZowX68wI2Ow2IBz5wKjsJ3O708+1AJq6PnBJCCCGEEEIIcQ2oVC3LSqkAYAewAiOZrQb0A5pjtAJvcKr+FtALWKiUam6r/wjwMPCm1vpIPvvojPEM5pa5uld/CnyslJqOMcv2OIxHU0kXbCGEEEIIIYS4xlSqZBmjJXcf0B+oAaRhdKd+QGvtMuO01vqCUqodMBl4CmMc82FguNZ6pruNK6V8gZnA+1rrPbkWL7DtczjgD6zEeOSUEEIIIYQQQohrTKVKlrXWmUDfItQ/BTxRhPrpQN18lmlgiu1LCCGEEEIIIcQ1rNKPWRZCCCGEEEIIIYpKkmUhhBBCCCGEECIXSZaFEEIIIYQQQohcJFkWQgghhBBClFjt2rXp2LGjx/U7duxI7dq1i72/2NhYlFIkJCQUexulTSnF4MGDi71+RTym65kky0IIIYQQQlQwSql8v5KTk/PUP3PmDEOGDKF69er4+PjQpEkT5syZ4/H+7Ena9u3bS/EoIC4ujunTp5fqNotj5cqVxMbGlncY162EhARiY2PZu3dveYdSJJVqNmwhhBBCCCEqi/bt2zNs2LA85f7+/i4/Jycn065dO06cOMHIkSOJiopi1apVDBs2jJMnTzJ+/PirEu+BAwdQSrmUxcXFkZCQwMiRI/PUX79+PcYDZcreypUrWbBgQZknzOnp6ZjN5mKvP3bsWEaPHo3FYinFqMpfQkICEyZMoHbt2jRr1qy8w/GYJMtCCCGEEEJUQHXq1GHAgAGF1nv77bc5fPgwy5cvp2fPngA89dRTdOvWjUmTJjFo0CCioqLKOtwiJ3je3t5lFEnJpaamEhAQUOT1fHx8SrRfLy8vvLwkRasopBu2EEIIIYQQFVRmZiaXLl0qsM5nn31GVFSUI1G2e/nll8nKyuLzzz8v1r7j4uJQSvH999/z9ttvU6dOHSwWCw0aNOCTTz7JUz/3mGWlFD/88ANHjx516UZuH4/rbszyjh07GDx4MA0aNMDPz4/AwEDatm3LihUrinUM9rgWLFjgiMn+tXHjRpc4jhw5Qq9evQgJCSEwMBAAq9XKpEmT6NChA+Hh4Xh7e3PzzTczfPhwEhMT8+zL3Zhle9nmzZtp3749fn5+hIaGMnToUFJTU13quhuzbC/bv38/r776KhEREVgsFpo2bcratWvzxJCRkeGo5+PjQ9OmTVm8eHGRxkNv3bqVBx98kPDwcCwWC+Hh4XTu3JlNmza51Lt48SJ///vfqVevHhaLhbCwMPr168eRI0dc4u/UqRMATzzxhOP8l2Rs99Uity2EEEIIIYSogJYtW8ann35KTk4OISEh9OjRg4kTJxIeHu6oc/r0aY4dO0b//v3zrB8dHY1Sih07dpQojtdee42MjAyeeeYZvL29mTlzJk8++SQ33XQT9957b77rLVy4kEmTJnH+/HmmTZvmKA8LC8t3nRUrVnDw4EH69etHZGQkiYmJLFiwgJ49e/LZZ5+5Pc7CTJ8+nalTp7Jp0yYWLlzoKG/UqJHj+9TUVO6++27atWvHpEmTOHv2LGDcrHj33Xfp3bs3PXr0wM/Pjx07djBv3jw2b97Mrl27PGoh37t3L4888ghDhgxhwIABbNy4kXnz5mEymZg9e7ZHx/H4449jsVh45ZVXyMzMZPr06XTv3p2DBw+63HR49NFHWb16NQ899BBdunTh5MmTDB8+nLp163q0nwMHDtC5c2fCw8MZMWIE4eHhnD17lm3btrFnzx7at28PGIlymzZt+PPPPxkyZAi33XYbp06d4qOPPqJVq1bs3LmTWrVq0bNnT7Kyspg8eTLDhg1zrO9pPOVJkmUhhBBCCHFtW9ANLh4r7yjyqlYTHv+yWKu2aNGCXr16Ub9+fdLS0tiwYQPz589n/fr1/PTTT9SoUQOAEydOABAZGZlnGxaLhdDQUI4fP178Y8BIGH/++WdHUti7d2/q1KnDnDlzCkyWBwwYwNy5c0lPT/eoOzkYY3anTJniUjZixAjuuOMOJk6cWKxkuXv37qxcuZJNmzblG0diYiJvvPEGEyZMcCm3WCycPHkSX19fR9nTTz9NmzZtGDp0KCtXruTRRx8tNIZ9+/axdetWWrdu7dhGSkoK8+fPZ+rUqR51+Q4LC2P16tWOceGdOnWiZcuWzJo1y3HO1q1bx+rVqxk0aJCjNR2M96x58+aF7gPg66+/Ji0tjSVLltCiRYt8640bN44jR46wfft2mjZt6igfPHgwt99+O+PHjycuLo4mTZqQlJTE5MmTiY6O9vhaqAgkWRZCCCGEENe2i8cg6Ujh9a4huVuDH3vsMe6++24GDRrE+PHjHa2RaWlpQP7jhX18fBx1iuvZZ591aT2NiIigfv36Ll1tS4vz5GVpaWmkp6ejtSYmJoaZM2eSkpJC1apVS32/YHRbz00p5UiUc3JyuHTpEtnZ2cTExADw008/eZQsR0dHOxJlu5iYGNauXUtCQgKNGzcudBsvvviiywRqLVq0IDAwkEOHDjnKVq1aBcCoUaNc1m3WrBn33Xcf69atK3Q/QUFBgDEp2u233+52HLbWmkWLFtG2bVsiIiI4f/68Y5m/vz+tW7dm/fr1he6ropNkWQghhBBCXNuq1SzvCNwr5bgGDhzIG2+8wVdffeUo8/PzA+DKlStu10lPT3fptl0cderUyVN2ww03lMmzgM+ePcvYsWNZtWqVoyu0s+Tk5DJJlsPCwqhWrZrbZUuXLuW9995jz549ZGVluSy7cOGCR9vP7xwCbsc+e7qNkJAQl/Xj4+NRStGgQYM8dRs2bOhRsty3b18WLVrE5MmTmTp1Kq1bt+a+++6jb9++jonizp07R2JiIt99912+3epNpmt/eixJloUQQgghxLWtmF2dr0W1a9dmy5Ytjp8jIiIA3Ha1zsjIIDEx0TFGtLjyexRSaT/2yWq10rlzZ/bv38+IESNo0aIF1apVw2w2M3/+fBYtWoTVai3VfdrZbzrktnz5cvr06UPLli15//33qVmzJj4+PuTk5PDAAw94HE9Bj5Py9Dx68j4UtC1P9+Pt7c26devYuXMnX3/9NT/++CMTJkxgwoQJzJ8/n379+jm21alTJ8aMGePRdq9FkiwLIYQQQghxDdBac/jwYZeW4vDwcCIjI9m2bVue+tu3b0drXeC407KW+7nLBfn111/Zt2+f27HDc+fOvWpxOPv000/x8fFhw4YNLgn1/v37SxRPWalTpw5aaw4cOECTJk1clh04cKBI27rrrru46667eP311zl16hTNmzdn9OjR9OvXj7CwMIKCgrh48WKB49btinv+y9u13zYuhBBCCCFEJXLmzBm35f/+9785fvw43bp1cynv378/8fHxfPHFFy7lU6dOxcvLiz59+pRZrIUJCAggOTnZo1ZNe8tp7rq//fZbiR4dZY8DPO827RyTUsqlBVlrzcSJE0sUT1mxXxvvvvuuS/nevXs9HkPsPP7YrkaNGtSoUYOkpCTA6GL92GOPsXv3bpYsWeJ2O87d6It7/subtCwLIYQQQghRgUyZMoVvv/2Whx9+mFq1apGens7GjRtZvXo19evXJzY21qX+6NGjWbZsGQMHDmTXrl1ERUWxatUq1qxZw7hx49yOdb1aWrVqxZo1axgxYgStW7fGbDbTtWtXl4m87Bo1asRtt93GO++8Q1paGrfccgsHDx5k1qxZNG7cmN27d5cojg8++IDnnnuOLl26UKVKFWJiYrjxxhsLXK9Xr14sX76cmJgYBg0aRFZWFitXrizxpGllpUuXLjz44IMsXLiQpKQkx6OjZsyYwR133MGuXbsKbeWdOHEi69ev5+GHH3aMUf7Pf/7D7t27ee655xz1Jk2axJYtW+jfvz8rVqwgOjoab29vjh49ytq1a2nevDlxcXEA3HrrrQQEBDBjxgz8/f2pWrUqUVFRtGrVqszORWmQZFkIIYQQQogKJCYmhv379/Ppp59y/vx5lFLUrVuX119/nVdeeSXPRFTBwcFs3ryZMWPGMGfOHFJSUqhXrx4fffQRzzzzTDkdhWHkyJEcOnSIxYsX8+GHH6K1Jj4+3m2ybDab+eqrrxg1ahQLFizg8uXLNG7cmAULFvDLL7+UKFnu168fu3btYsmSJXz++edYrVY2bNhQaLLct29fLl26xLRp0xg1ahTBwcF07dqVt956yzFBV0WzbNkyxo0bx6JFi/j2229p2LAhs2fPZvv27ezatcvlMVjudO/enVOnTrF06VLOnDmDj48P9erVY8aMGQwbNsxRr1q1amzZsoX33nuPpUuX8uWXX+Ll5UVkZCTt2rVj6NChjrq+vr4sWrSIsWPH8sILL5CZmcnjjz9e4ZNlVdoD80XJKaWiga1bt24lOjq6vMNxkZSUxKZNm2jfvj0hISHlHY4QlYZ8toQoG/LZqhzsj8apX79+OUci7LKzs0lNTSUgIAAvL2l/uxY8/PDDbNiwgZSUlAInHLsWefI7Ytu2bbRp0wagjdY67yB/N2TMshBCCCGEEEJUEunp6XnK9uzZw7p167jnnnsqXaJcluQ2kBBCCCGEEEJUEv/4xz/Ys2cPMTExBAUF8fvvvzNnzhwsFgtvvvlmeYd3TZFkWQghhBBCCCEqiQ4dOrB161b++c9/kpycTFBQEPfffz/jx4+nadOm5R3eNUWSZSGEEEIIIYSoJLp06UKXLl3KO4xKQcYsCyGEEEIIIYQQuUiyLIQQQgghhBBC5CLJshBCCCGEEEIIkYsky0IIIYQQQgghRC6SLAshhBBCCCGEELlIsiyEEEIIIYQQQuQiybIQQgghhBBCCJGLJMtCCCGEEEIIIUQukiwLIYQQQgghSqx27dp07NjR4/odO3akdu3axd5fbGwsSikSEhKKvY3SppRi8ODBxV6/Ih7T9UySZSGEEEIIISoYpVS+X8nJyXnqnzlzhiFDhlC9enV8fHxo0qQJc+bM8Xh/9iRt+/btpXgUEBcXx/Tp00t1m8WxcuVKYmNjyzuM61ZCQgKxsbHs3bu3vEMpEq/yDkAIIYQQQgiRV/v27Rk2bFiecn9/f5efk5OTadeuHSdOnGDkyJFERUWxatUqhg0bxsmTJxk/fvxViffAgQMopVzK4uLiSEhIYOTIkXnqr1+/Hq31VYlt5cqVLFiwoMwT5vT0dMxmc7HXHzt2LKNHj8ZisZRiVOUvISGBCRMmULt2bZo1a1be4XhMkmUhhBBCCCEqoDp16jBgwIBC67399tscPnyY5cuX07NnTwCeeuopunXrxqRJkxg0aBBRUVFlHW6REzxvb+8yiqTkUlNTCQgIKPJ6Pj4+Jdqvl5cXXl6SolUU0g1bCCGEEEKICiozM5NLly4VWOezzz4jKirKkSjbvfzyy2RlZfH5558Xa99xcXEopfj+++95++23qVOnDhaLhQYNGvDJJ5/kqZ97zLJSih9++IGjR4+6dCO3j8d1N2Z5x44dDB48mAYNGuDn50dgYCBt27ZlxYoVxToGe1wLFixwxGT/2rhxo0scR44coVevXoSEhBAYGAiA1Wpl0qRJdOjQgfDwcLy9vbn55psZPnw4iYmJefblbsyyvWzz5s20b98ePz8/QkNDGTp0KKmpqS513Y1Ztpft37+fV199lYiICCwWC02bNmXt2rV5YsjIyHDU8/HxoWnTpixevLhI46G3bt3Kgw8+SHh4OBaLhfDwcDp37symTZtc6l28eJG///3v1KtXD4vFQlhYGP369ePIkSMu8Xfq1AmAJ554wnH+SzK2+2qR2xZCCCGEEEIkHYE9n0LynxB0M9wxAELqlGtIy5Yt49NPPyUnJ4eQkBB69OjBxIkTCQ8Pd9Q5ffo0x44do3///nnWj46ORinFjh07ShTHa6+9RkZGBs888wze3t7MnDmTJ598kptuuol777033/UWLlzIpEmTOH/+PNOmTXOUh4WF5bvOihUrOHjwIP369SMyMpLExEQWLFhAz549+eyzz9weZ2GmT5/O1KlT2bRpEwsXLnSUN2rUyPF9amoqd999N+3atWPSpEmcPXsWMG5WvPvuu/Tu3ZsePXrg5+fHjh07mDdvHps3b2bXrl0etZDv3buXRx55hCFDhjBgwAA2btzIvHnzMJlMzJ4926PjePzxx7FYLLzyyitkZmYyffp0unfvzsGDB11uOjz66KOsXr2ahx56iC5dunDy5EmGDx9O3bp1PdrPgQMH6Ny5M+Hh4YwYMYLw8HDOnj3Ltm3b2LNnD+3btweMRLlNmzb8+eefDBkyhNtuu41Tp07x0Ucf0apVK3bu3EmtWrXo2bMnWVlZTJ48mWHDhjnW9zSe8iTJshBCCCGEuL7tXQyrngOd81fZ5unwyIfQrF+5hNSiRQt69epF/fr1SUtLY8OGDcyfP5/169fz008/UaNGDQBOnDgBQGRkZJ5tWCwWQkNDOX78eIliyczM5Oeff3Ykhb1796ZOnTrMmTOnwGR5wIABzJ07l/T0dI+6k4MxZnfKlCkuZSNGjOCOO+5g4sSJxUqWu3fvzsqVK9m0aVO+cSQmJvLGG28wYcIEl3KLxcLJkyfx9fV1lD399NO0adOGoUOHsnLlSh599NFCY9i3bx9bt26ldevWjm2kpKQwf/58pk6d6lGX77CwMFavXu0YF96pUydatmzJrFmzHOds3bp1rF69mkGDBjla08F4z5o3b17oPgC+/vpr0tLSWLJkCS1atMi33rhx4zhy5Ajbt2+nadOmjvLBgwdz++23M378eOLi4mjSpAlJSUlMnjyZ6Ohoj6+FikC6YQshhBBCiOtX0pG8iTIYP696DpLiyyWsHTt28Oqrr9KjRw8ee+wx5s6dS1xcHMeOHXOZsCstLQ3If7ywj4+Po05xPfvssy6tpxEREdSvX9+lq21pcZ68LC0tjcTERNLS0oiJieF///sfKSkppb5Pu5dffjlPmVLKkSjn5OSQnJzM+fPniYmJAeCnn37yaNvR0dGORNkuJiaG7Oxsjx8T9eKLL7pMoNaiRQsCAwM5dOiQo2zVqlUAjBo1ymXdZs2acd9993m0n6CgIMCYFC0jI8NtHa01ixYtom3btkRERHD+/HnHl7+/P61bt2b9+vUe7a8ik2RZCCGEEEJcv/Z8mjdRttM5sGeh+2XlYODAgdSuXZuvvvrKUebn5wfAlStX3K6Tnp7uqFNcderk7Y5+ww03kJSUVKLtunP27FmGDRtG9erV8ff3JzQ0lLCwMGbOnAng9rFZpSEsLIxq1aq5XbZ06VJatWqFr68vwcHBhIWFOc7JhQsXPNp+fucQcDv22dNthISEuKwfHx+PUooGDRrkqduwYUOP9tO3b1/uv/9+Jk+eTHBwMJ06dWLKlCnEx/914+jcuXMkJiby3XffERYWlufrm2++4cyZMx7tryKTbthCCCGEEOL6lfxnyZZfZbVr12bLli2OnyMiIgDcdrXOyMggMTHRMUa0uPJ7FFJpP/bJarXSuXNn9u/fz4gRI2jRogXVqlXDbDYzf/58Fi1ahNVqLdV92uV3Q2H58uX06dOHli1b8v7771OzZk18fHzIycnhgQce8Diegh4n5el59OR9KGhbnu7H29ubdevWsXPnTr7++mt+/PFHJkyYwIQJE5g/fz79+vVzbKtTp06MGTPGo+1eiyRZFkIIIYQQ16+gm0u2/CrSWnP48GGXCb7Cw8OJjIxk27Zteepv374drXWB407LWu7nLhfk119/Zd++fW7HDs+dO/eqxeHs008/xcfHhw0bNrgk1Pv37y9RPGWlTp06aK05cOAATZo0cVl24MCBIm3rrrvu4q677uL111/n1KlTNG/enNGjR9OvXz/CwsIICgri4sWLBY5btyvu+S9v0g1bCCGEEEJcv+4YACqfVj9lhjsGXt14IN/uq//+9785fvw43bp1cynv378/8fHxfPHFFy7lU6dOxcvLiz59+pRZrIUJCAggOTnZo1ZNe8tp7rq//fZbiR4dZY8DPO827RyTUsqlBVlrzcSJE0sUT1mxXxvvvvuuS/nevXs9HkN8/vz5PGU1atSgRo0ajq73JpOJxx57jN27d7NkyRK327HPKA7FP//lTVqWhRBCCCHE9SukjjHrde5JvpQZus+AkKirHtKUKVP49ttvefjhh6lVqxbp6els3LiR1atXU79+fWJjY13qjx49mmXLljFw4EB27dpFVFQUq1atYs2aNYwbN87tWNerpVWrVqxZs4YRI0bQunVrzGYzXbt2dZnIy65Ro0bcdtttvPPOO6SlpXHLLbdw8OBBZs2aRePGjdm9e3eJ4vjggw947rnn6NKlC1WqVCEmJoYbb7yxwPV69erF8uXLiYmJYdCgQWRlZbFy5coST5pWVrp06cKDDz7IwoULSUpKcjw6asaMGdxxxx3s2rWr0FbeiRMnsn79eh5++GGioozr/z//+Q+7d+/mueeec9SbNGkSW7ZsoX///qxYsYLo6Gi8vb05evQoa9eupXnz5sTFxQFw6623EhAQwIwZM/D396dq1apERUXRqlWrMjsXpUGSZSGEEEIIcX1r1g9ubm1M5uV4zvLAckmUwZglef/+/Xz66aecP38epRR169bl9ddf55VXXskzEVVwcDCbN29mzJgxzJkzh5SUFOrVq8dHH33EM888Uy7HYDdy5EgOHTrE4sWL+fDDD9FaEx8f7zZZNpvNfPXVV4waNYoFCxZw+fJlGjduzIIFC/jll19KlCz369ePXbt2sWTJEj7//HOsVisbNmwoNFnu27cvly5dYtq0aYwaNYrg4GC6du3KW2+95Zigq6JZtmwZ48aNY9GiRXz77bc0bNiQ2bNns337dnbt2uXyGCx3unfvzqlTp1i6dClnzpzBx8eHevXqMWPGDIYNG+aoV61aNbZs2cJ7773H0qVL+fLLL/Hy8iIyMpJ27doxdOhQR11fX18WLVrE2LFjeeGFF8jMzOTxxx+v8MmyKu2B+aLklFLRwNatW7cSHR1d3uG4SEpKYtOmTbRv356QkJDyDkeISkM+W0KUDflsVQ72R+PUr1+/nCMRdtnZ2aSmphIQEICXl7S/XQsefvhhNmzYQEpKSoETjl2LPPkdsW3bNtq0aQPQRmudd5C/G5VuzLJSKkApNU4p9ZtSKlUpdU4ptVkplefp10qp6kqpj5VSZ5RSGUqpfUqpp9zU81NK/VspdUopdV4p9YlSKs9fXKVUd6XUZaVU+dyGFEIIIYQQQlzX0tPT85Tt2bOHdevWcc8991S6RLksVarbQEopE/A10BqIA/4F+AMDgYVKqQZa6zdsdYOAzUAEMB2IBx4BZiulbtJaO0/BNwV4AngbSAP+DswFejrtuyrwATBBa10+T68XQgghhBBCXNf+8Y9/sGfPHmJiYggKCuL3339nzpw5WCwW3nzzzfIO75pSqZJloBXQBpiutX7JXqiUmgkcAYYBb9iK/w7UA/6mtbZPHThHKfUl8LpS6hOnpLc3MFVr/aZtexcwkmofrXWGrc4UIBGYWnaHJ4QQQgghhBD569ChA1u3buWf//wnycnJBAUFcf/99zN+/HiaNm1a3uFdUypbsmyf7eCkc6HWOt2W4Po4FT8GxDslynZTga5AH+AtW5k/4DyHeiJgtm0vQynVGiMRb6e1zi6NAxFCCCGEEEKIourSpQtdunQp7zAqhcqWLO8AUoBXlVIJwHYgACORvQWjKzVKqXCgJrDIzTa2ARpo6VS2BRiulNoCpGO0Sv+utU5WSlUB5gAztdY/FTVgpVRNIDJXcWOAlJQUx7PMKoqUlBSXVyFE6ZDPlhBlQz5blUNWVhZms5nsbGmTqChycnJcXoUoT1arlZycnAJzp+L8HahUybLWOkkp1R0jeV3qtCgZeERrvcb2c4Tt9bibbVxRSp3HNYF9EfgS2Gn7+QTwN9v3rwLBwOvFDPtJYLy7BXv37iUjI8PdonL3yy+/lHcIQlRK8tkSomzIZ+vaFhoaSnBwMKmpqeUdisjF3WRSQlxtOTk5XLhwwTErtjv79+8v8nYrVbJscwHYA6wAtgJBwHBgqVLqb1rr/wB+trpX8tlGhlMdtNaHlFK3Aw2BKhityleUUvWAsUB/rXWKUupZ4FkgECO5flVrXdhvkHkYk5I5awzMbtasGS1atPDkmK+alJQUfvnlF5o2bUrVqlXLOxwhKg35bAlRNuSzVTmcPn0as9lMQEBAeYcibHJyckhPT8fX11dmVxblzmw2ExwcTKNGjfKt4+Pjk++y/FSqZNmW0G4DRmqtZzmVLwL2Ah8rpWpjzGgNYMlnU77AaecC21jk33LVmwV8rbVeoZTqA7yH0VJ8DGM2bjNG8pwvrfUxW33n4wCgatWqFfaZkBU5NiGuZfLZEqJsyGfr2paYmAggz/OtgMxms7wvotyZTCZMJlOBv+eLc8O0sj1n+SWMSbf+n3Oh1voKsBIIx2gdPmFblHusMEopH+AG3HTRzlVvMMa45udtRU8Cy7XWi7TWm7A9bsr2OCshhBBCCCGEENeQypbI2cciV3GzzF7mpbU+jZEMR7up1xpQwM/57UQpFQa8C7yutbYn1ZG4thAfw0jcQz2OXgghhBBCCCFEhVDZkuXfba+DnQuVUoEYz0q+DPzXVrwIiFJK9cy1jZeBbODzAvYzDYgHPnAqOwnc7vTz7UAmro+cEkIIIYQQQghxDahsAwymA4OAKbbxy5sxZqp+ErgZGKW1tk8v/RbQC1iolGqOkfw+AjwMvKm1PuJuB0qpzhjPYG6ptbY6LfoUY0z0dIxW63HAolx1hBBCCCGEEEJcAypVy7LW+ijQFPgIuAuYCowBTgF9tdbvOdW9ALTDeMTUUxitxFHAcK31G+62r5TyBWYC72ut9+RavADj8VE9gdcwxki/WFrHJoQQQgghRGURFxeHUoqNGzd6VH/jxo0opYiLiyv2PpVSDB48uNjrl7bY2FiUUiQkJBR7GxXtmCqbSpUsA2itj2utn9NaN9Ra+2mtA7XW7bXWebpVa61Paa2f0FrfqLX20Vo31lrPLGDb6VrrulrrUW6Waa31FK31zVrrG7TWj2uti/7kayGEEEIIcd2bMmUKvXv3pk6dOiilqF27doH1z5w5w5AhQ6hevTo+Pj40adKEOXPm5Ft/8eLFNG/eHF9fX0JDQ+nXrx9Hjx71OL4qVarQq1cvj+t7IiEhgdjYWPbu3Vuq2y2q5ORkYmNjPU7kRemLi4tj+vTp5R1GpeuGLYQQQgghxDVvzJgxhISEcOedd5KcnFxg3eTkZNq1a8eJEycYOXIkUVFRrFq1imHDhnHy5EnGjx/vUv+DDz7ghRdeoG3btkybNo3z588zffp0fvzxR37++WduuummMjwyw8CBA+nbty/e3t6OsoSEBCZMmEDt2rVp1qyZS/0OHTqQnp5OlSru5vEtXcnJyUyYMAGAjh07ltl+xo4dy+jRo7FY8nuabeHS09Mr5XOu4+LiSEhIYOTIkeUahyTLQgghhBBCVDB//PEHderUAaBx48akpqbmW/ftt9/m8OHDLF++nJ49jblrn3rqKbp168akSZMYNGgQUVFRgPHM6tdee40777yTjRs3Op6R/MADD9CyZUveeOMN5s6dW8ZHZzyfuShJnslkwsfHpwwjKpnLly/j7+9fpHW8vLxK/IzqinxOKoNK1w1bCCGEEEKIa509UfbEZ599RlRUlCNRtnv55ZfJysri88//Go24atUqUlNTGTFihEuidtddd9GhQweWLl1KZmZmsWKuXbs2HTt25L///S8PPPAAgYGBVKtWjV69enH69GmXurnHLMfGxtKpUycAnnjiCZRSLuNx3Y1ZtlqtTJo0iQ4dOhAeHo63tzc333wzw4cPJzExsVjHEBcX57ixMGHCBEcc9hZm5zg+/PBDbr31ViwWC//85z8B2LFjB4MHD6ZBgwb4+fkRGBhI27ZtWbFiRZ59uRuzbC/bv38/r776KhEREVgsFpo2bcratWvzbMPdmGV72ebNm2nfvj1+fn6EhoYydOhQtzdd7PXsXfIHDRrEuXPnPB4PnZGRQWxsLA0bNsTPz4+qVavSsGFDRowYkafut99+y3333UdQUJBjuMDMma6jYJVS/PDDDxw9etRx/ks6tru4pGVZCCGEEEKIa9Tp06c5duwY/fv3z7MsOjoapRQ7duxwlNm/b9OmTZ76bdq04YcffmD//v00adKkWPGcOHGCmJgYevbsSY8ePdizZw+zZ88mJSWF9evX57tez549ycrKYvLkyQwbNoz27dsDULdu3XzXyczM5N1336V379706NEDPz8/duzYwbx589i8eTO7du1y6ebtiQ4dOjBt2jReeuklevTo4bgBUb16dZd606dPJykpiaeeeorq1atTs2ZNAFasWMHBgwfp168fkZGRJCYmsmDBAnr27Mlnn33m9n1y5/HHH8disfDKK6+QmZnJ9OnT6d69OwcPHix0/DrA3r17eeSRRxgyZAgDBgxg48aNzJs3D5PJxOzZsx31tm7dyr333ktAQACvvPIKYWFhrF69mi5dunh4xuC5557j448/ZuDAgYwcORKr1coff/zBN99841Jv9uzZPPPMM7Ru3ZrXX3+dgIAAvvnmG4YPH84ff/zhuOGwcOFCJk2axPnz55k2bZpj/bCwMI9jKi2SLAshhBBCiGva0PVDOZV6qrzDyKNGQA3m3le2XZpPnDgBQGRkZJ5lFouF0NBQjh8/7lF9e9nx48eLnSwfPnyYzz//nEcffdRRZjabmTFjBvv376dhw4Zu12vSpAlJSUlMnjyZ6OhoBgwYUOi+LBYLJ0+exNfX11H29NNP06ZNG4YOHcrKlStd4vBEnTp16N69Oy+99BJNmjTJN45jx45x4MABQkNDXcrHjh3LlClTXMpGjBjBHXfcwcSJEz1Olu1Jq1IKgE6dOtGyZUtmzZqVZ/vu7Nu3j61bt9K6dWvAOC8pKSnMnz+fqVOnEhAQABi9D6xWK1u2bOGWW24B4Pnnn6dXr17s2rXLo1hXrFjBgw8+yCeffJJvnVOnTjFixAj69OnD4sWLHeXDhw/nxRdfZOrUqTzzzDPUrVuXAQMGMHfuXNLT0z26DsqSJMtCCCGEEOKadir1FH9e+rO8wygXaWlpAPlOEuXj4+OoU1h9+/hX5/pFddNNN+VJUGNiYpgxYwaHDx/ON1kuDqWUI1HOycnh0qVLZGdnExMTA8BPP/1U5GTZU4MGDcqTKAMu45bT0tJIT09Ha01MTAwzZ84kJSWFqlWrFrr9F1980ZEoA7Ro0YLAwEAOHTrkUXzR0dGORNkuJiaGtWvXkpCQQOPGjTlz5gw//fQTPXv2dCTKYJzXV199lS+++MKjfQUFBfHbb7/x66+/cvvtt7uts2zZMq5cucITTzzB+fPnXZZ17dqVf/3rX3z33XcF9iQoD5IsCyGEEEKIa1qNgBrlHYJbVyMuPz8/AK5cueJ2eXp6OuHh4W7rO7fI2us61ykOd2Otb7jhBoBijyMuyNKlS3nvvffYs2cPWVlZLssuXLhQ6vuzq1+/vtvys2fPMnbsWFatWsXZs2fzLE9OTvYoWXZ3HkNCQjw+h568D/Hx8QAuibJdUW5qvP/++wwYMIAmTZoQFRVFp06dePjhh3nkkUcwmYwpsv73v/8BcP/99+e7nTNnzni8z6tFkmUhhBBCCHFNK+uuzhVZREQEgEtXa7uMjAwSExMd439z18+d8BXURdtTBc1wrbUu9nbdWb58OX369KFly5a8//771KxZEx8fH3JycnjggQewWq2luj9n7m4oWK1WOnfuzP79+xkxYgQtWrSgWrVqmM1m5s+fz6JFizyOKb/z6Ok59OR9KK33o2vXriQkJPCf//yHjRs38v333/Pxxx/TqlUrNmzYgK+vr2Nf8+fPz/f6KsqkdleLJMtCCCGEEEJco8LDw4mMjGTbtm15lm3fvh2tNS1atHCUtWjRglmzZrF169Y8yfLWrVsJCAgo1a7SReHc7dgTn376KT4+PmzYsMEled2/f/9VjcPu119/Zd++fbzxxhuO5zTbXY3HcRWVPTl1d76Keg6Dg4Pp37+/Y0z2hAkTiI2NZcmSJTzxxBM0aNAAMFq377333kK3V9z3oLTJo6OEEEIIIYS4hvXv35/4+Pg8Y0ynTp2Kl5cXffr0cZQ98sgj+Pn58a9//Yvs7GxH+c6dO/nxxx959NFHizyDdGmxTzrlafdps9mMUsqltVZrzcSJE69qHM7x2GNw9ttvv7l9dFR5q169Oi1btmTNmjUcOHDAUa61dsxMXZicnBySk5PzlN95550AJCUlAdC7d28sFguxsbFux8RfvHjRZShBQEAAycnJpd4boaikZVkIIYQQQogKZuHChRw9ehSAc+fOkZmZ6UgCg4KCeP755x11R48ezbJlyxg4cCC7du0iKiqKVatWsWbNGsaNG+fSvTU0NJTJkyczcuRIOnbsyMCBAx2P6KlevTr/+Mc/ru6BOrn11lsJCAhgxowZ+Pv7U7VqVaKiomjVqpXb+r169WL58uXExMQwaNAgsrKyWLlyZYkmKAOj9bNu3bosWbKEevXqERYWxo033uiYOCw/jRo14rbbbuOdd94hLS2NW265hYMHDzJr1iwaN27M7t27SxRXWXjvvfe45557aNu2Lc899xxhYWF8+eWXjhsFhbXwXrp0iRo1atCtWzeaNWtG9erVOXr0KDNnziQgIMDx6K3IyEg++ugjhg4dSqNGjRg0aBC1atXi3Llz/Prrr6xcuZLff//d8VisVq1asWbNGkaMGEHr1q0xm8107drVZQK1q0GSZSGEEEIIISqYefPm8cMPP7iUjRs3DoBatWq5JMvBwcFs3ryZMWPGMGfOHFJSUqhXrx4fffQRzzzzTJ5tv/jii4SGhvLee+8xcuRI/Pz86Ny5M1OmTHGMaS4Pvr6+LFq0iLFjx/LCCy+QmZnJ448/nm+y3LdvXy5dusS0adMYNWoUwcHBdO3albfeessxmVVxLVy4kJdeeolXX32VjIwM7r777kKTZbPZzFdffcWoUaNYsGABly9fpnHjxixYsIBffvmlQibL7dq145tvvmHMmDG88847+Pv707VrV2bPnk1UVFSeSeBy8/PzY+TIkXz//fd8++23pKamEh4ezv33389rr71GVFSUo669O/a7777LrFmzSE5OJjQ0lFtuuYU333zTZSK6kSNHcujQIRYvXsyHH36I1pr4+Pirniyr8m7aFnkppaKBrVu3biU6Orq8w3GRlJTEpk2baN++PSEhIeUdjhCVhny2hCgb8tmqHOyPy8lvBmJx9WVnZ5OamkpAQABeXtL+Vtns3LmTFi1aMGXKFEaPHl3e4RTKk98R27Zto02bNgBttNZ5B/m7IWOWhRBCCCGEEOI6pLUmIyMjT9lbb70FwH333VceYVUYchtICCGEEEIIIa5DV65coVatWgwYMIAGDRqQnJzMqlWr2LZtG/3793dM1HW9kmRZCCGEEEIIIa5DVapU4aGHHmLVqlWcOnWKnJwc6tWrx1tvvcX//d//lXd45U6SZSGEEEIIIYS4DpnNZj7++OPyDqPCkjHLQgghhBBCCCFELpIsCyGEEEIIIYQQuUiyLIQQQgghhBBC5CLJshBCCCGEEEIIkYsky0IIIYQQQgghRC6SLAshhBBCCCGEELlIsiyEEEIIIYQQQuQiybIQQgghhBBCCJGLJMtCCCGEEEKIqyouLg6lFBs3bvSo/saNG1FKERcXV+x9KqUYPHhwsdcvbbGxsSilSEhIKPY2KtoxVTaSLAshhBBCCFHBTJkyhd69e1OnTh2UUtSuXbvA+mfOnGHIkCFUr14dHx8fmjRpwpw5c/Ktv3jxYpo3b46vry+hoaH069ePo0ePehxflSpV6NWrl8f1PZGQkEBsbCx79+4t1e0WVXJyMrGxsR4n8qL0xcXFMX369PIOA6/yDkAIIYQQQgjhasyYMYSEhHDnnXeSnJxcYN3k5GTatWvHiRMnGDlyJFFRUaxatYphw4Zx8uRJxo8f71L/gw8+4IUXXqBt27ZMmzaN8+fPM336dH788Ud+/vlnbrrppjI8MsPAgQPp27cv3t7ejrKEhAQmTJhA7dq1adasmUv9Dh06kJ6eTpUqVco8tuTkZCZMmABAx44dy2w/Y8eOZfTo0VgslmJvIz09HbPZXIpRVQxxcXEkJCQwcuTIco1DkmUhhBBCCCEqmD/++IM6deoA0LhxY1JTU/Ot+/bbb3P48GGWL19Oz549AXjqqafo1q0bkyZNYtCgQURFRQGQmJjIa6+9xp133snGjRvx8jLSgQceeICWLVvyxhtvMHfu3DI+OjCbzUVK8kwmEz4+PmUYUclcvnwZf3//Iq3j5eXlOP/FVZHPSWUg3bCFEEIIIYSoYOyJsic+++wzoqKiHImy3csvv0xWVhaff/65o2zVqlWkpqYyYsQIl0TtrrvuokOHDixdupTMzMxixVy7dm06duzIf//7Xx544AECAwOpVq0avXr14vTp0y51c49Zjo2NpVOnTgA88cQTKKVcxuO6G7NstVqZNGkSHTp0IDw8HG9vb26++WaGDx9OYmJisY4hLi7OcWNhwoQJjjjsLczOcXz44YfceuutWCwW/vnPfwKwY8cOBg8eTIMGDfDz8yMwMJC2bduyYsWKPPtyN2bZXrZ//35effVVIiIisFgsNG3alLVr1+bZhrsxy/ayzZs30759e/z8/AgNDWXo0KFub7rY69m75A8aNIhz5855PB46IyOD2NhYGjZsiJ+fH1WrVqVhw4aMGDEiT91vv/2W++67j6CgIMdwgZkzZ+aJ/4cffuDo0aOO81/Ssd3FJS3LQgghhBDiuncs5RgrDq/gROoJIgIi6FGvBzWr1izvsAp1+vRpjh07Rv/+/fMsi46ORinFjh07HGX279u0aZOnfps2bfjhhx/Yv38/TZo0KVY8J06cICYmhp49e9KjRw/27NnD7NmzSUlJYf369fmu17NnT7Kyspg8eTLDhg2jffv2ANStWzffdTIzM3n33Xfp3bs3PXr0wM/Pjx07djBv3jw2b97Mrl27XLp5e6JDhw5MmzaNl156iR49ejhuQFSvXt2l3vTp00lKSuKpp56ievXq1KxpXCsrVqzg4MGD9OvXj8jISBITE1mwYAE9e/bks88+c/s+ufP4449jsVh45ZVXyMzMZPr06XTv3p2DBw8WOn4dYO/evTzyyCMMGTKEAQMGsHHjRubNm4fJZGL27NmOelu3buXee+8lICCAV155hbCwMFavXk2XLl08PGPw3HPP8fHHHzNw4EBGjhyJ1Wrljz/+4JtvvnGpN3v2bJ555hlat27N66+/TkBAAN988w3Dhw/njz/+cNxwWLhwIZMmTeL8+fNMmzbNsX5YWJjHMZUWSZaFEEIIIcR17cs/vmTclnFYtdVRNu+3ebzZ9k261e1WjpEV7sSJEwBERkbmWWaxWAgNDeX48eMe1beXHT9+vNjJ8uHDh/n888959NFHHWVms5kZM2awf/9+GjZs6Ha9Jk2akJSUxOTJk4mOjmbAgAGF7stisXDy5El8fX0dZU8//TRt2rRh6NChrFy50iUOT9SpU4fu3bvz0ksv0aRJk3zjOHbsGAcOHCA0NNSlfOzYsUyZMsWlbMSIEdxxxx1MnDjR42TZnrQqpQDo1KkTLVu2ZNasWXm2786+ffvYunUrrVu3BozzkpKSwvz585k6dSoBAQGA0fvAarWyZcsWbrnlFgCef/55evXqxa5duzyKdcWKFTz44IN88skn+dY5deoUI0aMoE+fPixevNhRPnz4cF588UWmTp3KM888Q926dRkwYABz584lPT3do+ugLEk3bCGEEEIIcd06lnIsT6IMYNVWxm0Zx7FLx8opMs+kpaUB5DtJlI+Pj6NOYfXt41+d6xfVTTfdlCdBjYmJAYxEujQppRyJck5ODsnJyZw/f96xv59++qlU9+ds0KBBeRJlwGXcclpaGomJiaSlpRETE8P//vc/UlJSPNr+iy++6EiUAVq0aEFgYCCHDh3yaP3o6GhHomwXExNDdna2ozvzmTNn+Omnn+jatasjUQbjvL766qse7QcgKCiI3377jV9//TXfOsuWLePKlSs88cQTnD9/3uWra9euWK1WvvvuO4/3ebVIsiyEEEIIIa5bKw6vyJMo21m1lRWH8o41rUj8/PwAuHLlitvl6enpjjqF1U9PT3epUxzuxlrfcMMNAMUeR1yQpUuX0qpVK3x9fQkODiYsLMwRw4ULF0p9f3b169d3W3727FmGDRtG9erV8ff3JzQ0lLCwMMe43MJmNrdzdx5DQkI8PoeevA/x8fEALomyXX49ANx5//33SU5OpkmTJtSpU4cnn3ySFStWYLX+9bn63//+B8D9999PWFiYy1fnzp0BI3mvaKQbthBCCCGEuG6dSD1RouXlLSIiAsClq7VdRkYGiYmJjvG/uevnTvgK6qLtqYJmuNZaF3u77ixfvpw+ffrQsmVL3n//fWrWrImPjw85OTk88MADLslaaXN3Q8FqtdK5c2f279/PiBEjaNGiBdWqVcNsNjN//nwWLVrkcUz5nUdPz6En70NpvR9du3YlISGB//znP2zcuJHvv/+ejz/+mFatWrFhwwZ8fX0d+5o/f36+11dRJrW7WiRZFkIIIYQQ162IgIgSLS9v4eHhREZGsm3btjzLtm/fjtaaFi1aOMpatGjBrFmz2Lp1a55keevWrQQEBBSpVbE0OXc79sSnn36Kj48PGzZscEle9+/ff1XjsPv111/Zt28fb7zxhuM5zXZX43FcRWVPTt2dr6Kew+DgYPr37+8Ykz1hwgRiY2NZsmQJTzzxBA0aNACM1u1777230O0V9z0obdINWwghhBBCXLd61OuBSbn/l9ikTPSo3+MqR1R0/fv3Jz4+ni+++MKlfOrUqXh5edGnTx9H2SOPPIKfnx//+te/yM7OdpTv3LmTH3/8kUcffbTIM0iXFvukU552nzabzSilXFprtdZMnDjxqsbhHI89Bme//fab20dHlbfq1avTsmVL1qxZw4EDBxzlWmvHzNSFsY8Vz+3OO+8EICkpCYDevXtjsViIjY11Oyb+4sWLLkMDAgICSE5OLvXeCEUlLctCCCGEEOK6VbNqTd5s+2aeSb5MysTEthOpGVg+j49auHAhR48eBeDcuXNkZmY6ksCgoCCef/55R93Ro0ezbNkyBg4cyK5du4iKimLVqlWsWbOGcePGuXRvDQ0NZfLkyYwcOZKOHTsycOBAxyN6qlevzj/+8Y+re6BObr31VgICApgxYwb+/v5UrVqVqKgoWrVq5bZ+r169WL58OTExMQwaNIisrCxWrlxZognKwGj9rFu3LkuWLKFevXqEhYVx4403OiYOy0+jRo247bbbeOedd0hLS+OWW27h4MGDzJo1i8aNG7N79+4SxVUW3nvvPe655x7atm3Lc889R1hYGF9++aXjRkFhLbyXLl2iRo0adOvWjWbNmlG9enWOHj3KzJkzCQgIcDx6KzIyko8++oihQ4fSqFEjBg0aRK1atTh37hy//vorK1eu5Pfff3c8FqtVq1asWbOGESNG0Lp1a8xmM127dnWZQO1qkGRZCCGEEEJc17rV7cYdN97BikNOz1mu36PcEmWAefPm8cMPP7iUjRs3DoBatWq5JMvBwcFs3ryZMWPGMGfOHFJSUqhXrx4fffQRzzzzTJ5tv/jii4SGhvLee+8xcuRI/Pz86Ny5M1OmTHGMaS4Pvr6+LFq0iLFjx/LCCy+QmZnJ448/nm+y3LdvXy5dusS0adMYNWoUwcHBdO3albfeessxmVVxLVy4kJdeeolXX32VjIwM7r777kKTZbPZzFdffcWoUaNYsGABly9fpnHjxixYsIBffvmlQibL7dq145tvvmHMmDG88847+Pv707VrV2bPnk1UVJTLY7nc8fPzY+TIkXz//fd8++23pKamEh4ezv33389rr71GVFSUo669O/a7777LrFmzSE5OJjQ0lFtuuYU333yT8PBwR92RI0dy6NAhFi9ezIcffojWmvj4+KueLKvybtoWeSmlooGtW7duJTo6urzDcZGUlMSmTZto3749ISEh5R2OEJWGfLaEKBvy2aoc7I/LyW8GYnH1ZWdnk5qaSkBAAF5e0v5W2ezcuZMWLVowZcoURo8eXd7hFMqT3xHbtm2jTZs2AG201nkH+bshY5aFEEIIIYQQ4jqktSYjIyNP2VtvvQXAfffdVx5hVRhyG0gIIYQQQgghrkNXrlyhVq1aDBgwgAYNGpCcnMyqVavYtm0b/fv3d0zUdb2SZFkIIYQQQgghrkNVqlThoYceYtWqVZw6dYqcnBzq1avHW2+9xf/93/+Vd3jlTpJlIYQQQgghhLgOmc1mPv744/IOo8KSMctCCCGEEEIIIUQulSpZVkrFKqV0AV9ZuepXV0p9rJQ6o5TKUErtU0o95Wa7fkqpfyulTimlziulPlFK5ZlSUynVXSl1WSkVlXuZEEIIIYQQQojSV1ZPeKps3bC/AA67KW8CvAKsthcopYKAzUAEMB2IBx4BZiulbtJaT3BafwrwBPA2kAb8HZgL9HTaXlXgA2CC1jq+1I5ICCGEEOI6p5QiJycHrTVKqfIORwhRgWit0VpjMpV+O3ClSpa11vuAfbnLlVKzbN/Ocyr+O1AP+JvW+gtb2Ryl1JfA60qpT5yS3t7AVK31m7btXcBIqn201va51qcAicDUUj0oIYQQQojrnMViITU1lYyMDHx9fcs7HCFEBZKRkYHVasXPz6/Ut12pumG7o5TyA/oCJ4B1ToseA+KdEmW7qUAVoI9TmT9w3unnRMAM+Nj20RoYBgzTWmeX6gEIIYQQQlznAgMDATh16hTp6ell1uVSCHHt0FqTnp7OqVOnAKhatWqp76NStSzn41GgKvAvrXUOgFIqHKgJLHJTfxuggZZOZVuA4UqpLUA6Rqv071rrZKVUFWAOMFNr/VNRg1NK1QQicxU3BkhJSSEpKamomyxTKSkpLq9CiNIhny0hyoZ8tioHrTVVqlQhLS2NI0eOYDabpTt2BZCTk4PZbC7vMMR1SmvtGJ7h4+NDdnZ2gblTcf4OXA/J8pMYya/znOgRttfjuStrra8opc7jmsC+CHwJ7LT9fAL4m+37V4Fg4PUSxDfe3YK9e/eSkZHhblG5++WXX8o7BCEqJflsCVE25LNVOfj4+GCxWPDy8pJkWYjrnNaa7Oxsrly54lHOtH///iLvo1Iny0qpW4B2wHe5Jt2yd2i/ks+qGU510FofUkrdDjTE6KL9uy2prgeMBfprrVOUUs8CzwKBGMn1q1rr9ELCnAd8nausMTC7WbNmtGjRotDjvJpSUlL45ZdfaNq0aZl0dRDieiWfLSHKhny2hCgb8tkS1xofH58ir1Opk2WMVlswZq52lmZ7teSzni9w2rnANhb5t1z1ZgFfa61XKKX6AO/Z9nkMiMMY1/xsQQFqrY/Z6jvY75RWrVqVkJA8T6iqECpybEJcy+SzJUTZkM+WEGVDPlviWlGcmzqVdoIvpZQXMAhIAlbkWnzC9pp7rDBKKR/gBtx00c5VbzDGuObnbUVPAsu11ou01puwPW5KKVVpz7EQQgghhBBCVFaVOZHrClQHFmqtXbpba61PYyTD0W7Waw0o4Of8NqyUCgPeBV7XWtuT6khcW4iPYcyWHVrcAxBCCCGEEEIIUT4qc7Js74I9L5/li4AopVTPXOUvA9nA5wVsexoQD3zgVHYSuN3p59uBTFwfOSWEEEIIIYQQ4hpQKccsK6VuAh4Admitf82n2ltAL2ChUqo5RvL7CPAw8KbW+kg+2+6M8Qzmllprq9OiT4GPlVLTMVqtxwGLctURQgghhBBCCHENqJTJMjAYY3Kt3BN7OWitLyil2gGTgacwnsV8GBiutZ7pbh2llC8wE3hfa70n1+IFQA1gOOAPrMR45JQQQgghhBBCiGtMpUyWtdaTMZLgwuqdAp4ownbTgbr5LNMYk3pN8XR7QgghhBBCCCEqpkqZLAshREkdSznGisMrOJF6goiACHrU60HNqjXLbF9fHfiKGtRg6YGlPHTbQ2W2r8pq+58H+NeOzzibfpobfcMZ0fIxWt98S3mHVSJX+xq8WvuqrOQcCiFE5SPJshBC5PLlH18ybss4rE5TDsz7bR5vtn2TbnW7lcm+IkwRPB34NF/+8SUfHfqoTPZVWY37No4Vx6eilAbgzGUY+v1KekS+zJv3Di7f4IqpPK7Bq7GvykrOoRBCVE7K6D0sKhKlVDSwdevWrURHu3u6VTlJOkLSzi/YlF6f9r6HCLmrJ4TUKbN9sedTSP4Tgm6GOwbIvoro2LEtrPh5OifSzxHhG0aPFiOpWbPttb2vMjx/WmuSMpL46dRPjN40Go373421qtaiiqlKqewzy5rF0ZSjAFShCqHmUJJykriC8bS7AY0GUKtqLYJ8ggi2BBNkCSLYx3j1NnsXa58///c7/t9P07iQnUSwVwi9W71Ei9vuKZXjye3Ekf/y53ezqXLpOFmBkdx8zzAi6txW5O1kZOVwIS2TpMuZXLicRVJaJmcvXSIh5Si/n/+d35N/QnmlocypgAJdBW31AhRNbmhO3ZBIbvS/gRoBNxBZLYxaQTdyU2AQJlPxHghRGudQa83lrMtcuHKB5Ixk4/VKMhcyLvBnyp8sPbg033XL6hp057FGj1Grai3j+nO6DoN8grCYLcXa59W8Bn/+73es2/UZTao9wr6Lq3ig+WPF2ldmTiYXMmzvkfN7lpHMsUvHWH1kdb7rPtH4CaKqRrl8foN9ggn0DsSkincNVobfublVyr9ZlXhfpfXZ8kRlvN5L6++jJ44mXmbpzmMcv5BOZLAvj95Vk1o3+F/z+yqObdu20aZNG4A2WuttnqwjyXIFVCGT5b2LYdVzJPlGsemWN2h/4B+EpMfDIx9Cs35lsi90zl9lyiz7KoIvvx/DuD+/xKqUo8ykNW/e3I1uMYUO56+Y+yql85dtzeb4pePEX4wnPiXeeLV9pWSmlF68Zcy/ir/xT7dTEhPsE/zXP+POyY1PENW8q/HvZS8xP+37PO/VE34xjHz0X6Ua388rP+SOPWPxUn+1tGVrEz83nUi9zkNJumxLfh1JcCZJafbXLC5cziTx8hWSr1zgijqFyfscJu+zmCznMHmfQ1VJdrQkF4fWJpTVHy8dgLcpEF9TVQKqVKOqdxDBPkGE+YVwo38INwWGElk1lFpBN3KDXwD/WjbS7Tkc6Hs3jz001m3y6/LqtDzbml2ic1ze/Lz8HNebuxs6ua/FIEsQHyx7+apdg9OXjmB+2vdEeN3M04FPM+vSLE5k/8njvh15vNuEfN+XPK9XkrmcdblUYwMwKZNx7mxfec6b0/mzf7b9vPxYveH1a+p3ricq5d+sSryv/D5bZfE5vtb+x/BEfn8f99wxkRbdnyvVfS3fdZxXl+0jxynfMyvFO72a8LfmkdfsvopLkuVKosIly0lH4N93gc4hya/eX8ly2mHjF8kLuyAkqtT3lYfsyyNHjv5A9w3PGe2iTn9csH3W77zhNnx8gkplXxkZyexO/K/xQ659KeCV256ibkQLxz97QZYgfLx8ir4j2/n706xYGejPCS8vIrKz6X7pMjfnaLfnLzUzlYSUBEcifOTiEeIvxvPnpT89TlK0Bp3ji/Mj6U3KVKqtevZumwqFWWlyTGklSgLzpRXa6o22WtBWH3SOD9i+J8eHmyxRBFhuxEsH4kUAZgIw44ui6C1fV9JT8T6xgysmxVmzmVR8ycnxJzvHn1Tc3WHOQXknYfI+h9n7HCbLWSM5tpxDmdM9P8QcC6BR5swix+zR9q1e6BxftNUC2gtlygJTBsp0BWUqm8RXW73QVm/A6R/FMroGAZTKAdOVsrkGwbgGc3yMc2itgvNxBXj542UunePKzskiNdtIcE1K4Ws2ccWUhFWlo0xufg9fI7yUF9nWLOOHCvY71xPp2el5bkbEn97NrIOfuz0muHp/s2RfhdCQlWPlXMoFjlw6hbZ6Y9Y+VDX7km4+Q6ZKQaG5rVojqgWElGxfNgUdlwlYc88catYshf+Tr9L/aFk5Vn7+5RcufvEK8TqcP/RNnCXYWKhBA5kRrbD4lk5LbEZWDj8nXMh3eYvawfhUMZf5vsxKsWFUR26+wa9U9lUSkixXEhUuWf7uH7DpPQCyTL5cqVIV38wkzNr2B9snCPxK5xcjaUmQkZz/ctlXHilofvHS7DFrdntpfjVrMp3/qFQwvhqCbF/BVmW8agjSyni1QojTz9U0VEm7QOqViySaXX+payAHOONXjXjfQI6YNPFmTYIJzhXh97+3VRORpYnM1EQ6vd6UpbFc5V+RViDNBClmRYr91Vzwz6nmsnm/TVoTmANVrZpqOVA1R1PV9nOg42dNVetfy3y0c/rjKk3BCW/F8SqK496KY1UUJ7wVp6oosj28ZpXWhFsVtXOgdg5UT08lPPsKkVlZVLNaUUAWkGLyIsVkJt1UhSs+Vbmg4ILSJCtINmkumuCiSdleIctU9p8ZL207f07nsarTeQx0Oo/283q1rz8wPleXTTiur0v2a87kdO3l+jnVBLoC/94pjmpW++8mp99PTr+37L+nzKnnUNlX8LP9Aw/GNXjJZCLFbCLHbCHLL5hkE1xQkKy07RUumGzXpIL0Mjp9hf3ODba6/lzQ71yAG3JyCLBUM45J5TqmXMd4wfZ5sx9vRuW6RMRVFpSTw6cnzzh+rmbyJiggvOQbLuX/0XK0JitHk5VjNb6yje+zrRp3edcJHcqArNeLHvc15LlOdXnl/oblHUaxkuUST/CllKqntT5c0u2ICiz5T8e3Jp1NwJUzrsszkgv+JVOaZF+cNpvZ42Nht4+FPRYLB72r5Pon1fW/EfNVuiFmxbN/ltNt/xSeAjA7x5Z/nIEBAQRZfQnOsRJkteJjtXK8ihfxVaqQ7hh3as13fbuQnBzqZGYRlZVFVFa27TWLGtk57ttPFflnfmUtx/aVVXjVbOCiyUSy2cQFs5lkk4kLZhPJJrPrq9nEBdv3aR6M17UqxUUvuIjimIdhe1s1QdYcx3sVlJNDstlMfBUvznp5/ifHYrVS2/Ye1XF6v27OysbXo2vaqaU3LbnAmhpIV8p2fkwkm825XvOe1xSTiQBtJSjH+tfx5lgJtn0fbM0xfnZa7mdr/fNYeV5/YHykrHh0DeYAKXmuO9t5s51Xl3NoNpN+FZNrX60JyvnrugzOybG95n3/gnKsVLVaS3EG1AxIvVhorXSlXM6P49ozmV2vTadz68lNptL4netvtZJqMrnEl1pGLfTK6aaDEM68taZWtnMvnmyjVbisFfH/QbPtK0+fjnx+pysrmDE+TxqFMpVOa6/Vmt/sK3+FYyqlG8WF7ev4Bc97iVU0pfG34KBSaiMwF1iutb5SCtsUFUnQzY5vrcqLdO8QaVm+Svuyojligt1OLccnC/gvwqyhflYWt1y5wq1XMrn1SibBVtckstTuxALJqae5aDW6vNoTjhSTiYtmEykmE9lmb674ViNJaS5gtKLYWxgumjQXlWcJ9iWziUtmE8c86KFp0poaWXlbiiOyjJY6k8mEyeSDWSlMJoXZpLjoY3TVNJsU2ekpoNO4aAKUxvkfyhtycjCbAvCtFlas85Vb+sVz5FhTSTSb8VJeVDNV46L1Itk6u0j78gJusH25ZYXzySe57JRAGq2vRsvXRZOJK6Yq5PjbW4r0Xy1Gpr9aiDI9+JuaaVKcNXlx1sO/LiFWiLJCnRxFlFURZYWoHEUNbcaEbRIzE2CxfeWWllRoC1hhn2MF+Nm+bnJXQQPZcD7F9Rzm5o8XoVVvKvFfVufrIreyvAZLsi8zEGz7csvNNZib4/yVAuf3ykt5EaiqkZJzmWwNaDNm7QXKl+ycvDfZLtq+clNKUcWsqGI2Ob2aqJKZTFoh16D2C0FryLFqrFq7eQWr1mDVVMvWBGRqbtK4bYWy96nR5JCucGrt/6u3yUUzRo+AXL1RLnnYA6Aov3MLYtJ/9ZgIdOox4dyDoppjuVHmW0DvlKtNKYVZGQmF42+G4xXH3xD73w+TUthzD+e/j+6U1d/ivEz4YcHiHezS0pltLfwGs53ztZ+VfZkslYVSOXgphS9VSc3JJMdaBXTed04phU8VE37eXvh5m/EqQnLm7riOOt10vRoty1YN2ZZgsqoEkpWjybSdw+wc47PrKbPJOH+mnCv46nSqkE0VsjFjpbbpDH/4DARgW8Rgop96v+THBPzz6/18uOGPfJc/W4qtvYXtKzLYt1T2Ux5KI1n+AOgPfAp8oJT6FJintf6lFLYtKoI7BsDm6aBzuOQTkXfM8rCNV29sbxns65hZscJpTFaPS5epmaPLZV+ZOZn8nvg7u87sYs/ZPew5u6fASad8vXxpEtaEO2+8kztuvIOmYU1JPL2Hh797mlUB/vmO8QkqjTE+wKH/fsfQn18kJ8eHrIstsWbegM7xQ2f5o3P8qGq6idRzkG3N7w+KFczpKHMaJvNllPkyypyG8rK9mlNz/XwZZc4wDifHgjXzBqxZQZhyQrglqCnVfW8mIqAmof5+hPhXIdjPmxsCvAn28ybE35uqPlUKvYt64sh/qb6gHZdMihWBAX+9Vymp+FgVZwZ+Q0SdRqVy/pJs+zKZNKtDb6FGjf/j1Kn3eOjcb6W+r3jbe2UFt9fFvBYfcNdtHfNdX2ttjDe0TYZ0IeNCnsmr7N//7/zvXM5Jy3dbDQPr83q7N4iqFkU1S7WSHVjSEQL+fRcX0K7v16VUAjCV6ufYk3MYWsA59JTzdbGi6tW7Bst6X1fr/OXeV02nSYiOZf/pcr2nZ+YQf/4yf5xL5Y9zqRw+m8of5y5z5FwqV7I9Tyaqk0Sk6STZPolcNinM2X4EZPqQpgM5b6rDxbOazCJsr+wU9DvX3e/gv37nAsZ48xx/dLbxO17n+Nu+/Pj/7d13mJxlufjx753eQxJKSKMFpQUCoaqIoOhRQTocCwpiAzkW/B1QERXxiBVQUREEFREVQSCKiqKAiAgESOhICaTR0tiQnuz9++OdDZNhd7PZnd3Z8v1c114z8z7P+z73bPbd7D1PyzWDqa94Tf0AXuph/cSD+vVmxKB+9O+zglkrH4WG72mvhqSvGGFyyJb/xZabbVWVNue9OJMbnv1L6aPdXtSvHk79qs2oX7U51Ld81fpRg/ux3WZD2G7zwcXjZkOYuPkQxmwykN6l/zvvbuLemrV6Nrl8Kw4a/D9Mf74vsxeW9SSWdaNNHr8Jb915C96282i222xIs/EsmX077/rbR5v8nVGtv2fmPPkgfX/+Dp7O0TyVY3iy4at+DLPZjFzZsp/hPr2CrUYNKn0PX/n+bbvZYIYNKD55mvvUQwz6+RvoTf2rppevpRcT3vyxNr+fBsfuOZ6LbnlqvQW3GvSO4Lg9JzRyVudvq6O1OVnOzE9ExP8DjgBOAk4BPh4R9wKXAL/KzCVtbUc1NHLbYjXA6ytW6IvecPgPq5dQVrZVuSJhO7Q1df+PvWqVxUuHD+Ocrd7FuzqgrZ8MH8bxm+9Dv6encu+d9/Lg/AdZ1cwn0SMHjGTKFlPYffPd2WPzPXjNyNe8aqGfQeNfzzkT3lW0VXa8F/DVrQ6rzmIYJbfMGcv28/bk3pVvoH7llq8qX9zsoJxSVKU/rvr3G82I/kVSO2JwP0YO6svIwf0ZObgvv3vsRuatuL34w61PKYHuvYzeA+fRe+A8Jg0+giuPrs5/MGO33Zm7d/8qu9/3BT6x6JX+pTXZi/v2+D/2qlLiUNnWsXVLuW1LOLZuKcPWZNXb2mvnN3PiQwcVKxGXHe8FfHDwm5tNlKHoHRjUdxCD+g5izJDme/++d+/3uOSBS5os33/rNzF588ktjr1Zpd8Z46//+Hr/Xu3xO6Ot38OWqtXPYHu31VHfv8q2ylW2NbBfb3YaM4ydxgxbr159fTJ38fJSEl1Kpl8oEur5L7/6d/TzjOT5+pHQ2GdES1s+XLlfn16MGvzKB3wjBvcre92X256Yz+ynr2T2ZveTfZYX4zcpenC3f2EXdpv0KU550/Ytbq8pJ//hGzyy7E9k9imS3nUCeq1kp00O4keHnNHmdgB+eMvjzHjgfB7f/KFXrXhczffUaFvZh1wzCNYOYsyCnRg99lD2GD+itDL/ahYsXbluu7pFS1c188HvK5atWsuyVQ2J4mubrHfNgtVANWcxtmzbpl4BW40azHabvZIQb7f5YLbddAgjBm94S8Km7q3ekXxws+345DFvIzN59Lkl/OWh5/nLw8/x0LxXPvSfPnsx02cv5pt/foztNhvMW3cezVt32oLdxm3yqg+zx1f575k1a+uZs2j5qz4ce3DuS6xc86MWX2fogD7rfZiw3WaD2W7zIUwYOYi+vZtPrMt/5/Ype1drqf7v3K1GDeabR+/a6ArV3zpm16ouuNWRbXW0qi/wFRETgA8CHwC2oviv4yrgJ5n5r6o21k11ugW+GiycycJp15Tts3xUdZPXira47xdle90dX/W2ZtfN5pDrDllvJdgGQXDybiczYkCTgwo3yqIVi/jRjB81uXdvU7YetjW7b757kRxvsQcThk4gWjjPb/bsO7j27vPK9iU8raqJMsDHr7yHG+5/rpGSeqAXwwb0YdK44a/84TeoPBnux4jBfdcdb25Fxn/PeowP/f0YgorxeVl8Rn/pQdewz4Tq/DHVYO5TjzDrbxeV7YH4sar1sDXW1pO3XsmikXsyYuE0tjvgPe3W1rSHbuGqO7+9bo/bY/f5f1VNUqD5e6tX9OIPR/yB8UPHV7XNjvid0aAjvofQ8T+DHdVWR33/Gtr60z2Xr9sL9u1T3t/mthYvW/VKAv3iy1x/3zyeq1tBMTy64hcUwdABfdh5zLD1fwc28btwYN/ezf6Of2bBUg769q1s0fdRJo74I2v71tF79TCeWPQOnl+9Q9VWnO3I37kd9Z7a2lZmsmTlmmJ7u3Xb3q1ef9u7su3wZi9czqpGhvl3lN6xil6sZXUOZIfRQ/nkm7dnu82HsNWoQfTv0/Y5sRtzb81ZtGxd4nzXzIU09pnDFsP6c/BOW/DWnUaz77aj6NfnlaRz2kM3c9Wd3yn7nfEZ9tz5wCZje3nlGp4q3Z9PvvDKvfr0/GUb9W/Sm7WspTfbbjqYD75hm3UfLGw2pH+L/xZrSkf+zp21YBm/mTZr3d7Hx+05od2S145sqzU61WrYETEIuAh4X+lQAg8BX83Mq9ql0W6i0ybLwMKFC7ntttvYf//9GTmySvN5a2RDvV8drXf0ZseRO7L7FkWv8eTNJ7PpwE1rHVaT1qyt5y3n3crTC5oeblvN1Q/PuulnXDvnvPW2tMkMjhr/Gc5+8weq0kYtdad7C2Dqk1M56/az1kuYe0Uvvvr6r3LodofWMDL1NO19b21orl61V4Ftai/Tbx2zK0fuUb29TDvyd25HvaeObGtDPxfH7jmO9++3dVXauvyOp7lq2pwmy9trJeLW3FsLl67i74++wF8eeo5/PP4iK1a/Onkd2r8PB+6wOW/deQteWraaL17/0Kv+vb5x1CTesP1m6xLhJ194ZRTIsy+teNU1m9KvTy+G9u/DgqVNj+rrLCs5q+1qshp2pYiYDHyIYh7zJsBTFIt/rQFOBn4VETtk5leq3ba0MZ56qQNWUGyhvUfvzfcP+j6D+naeT9+ak5l87ncPNJsoV3uOyjlvOYFDZr2e7971C15Y/hybDxzNJ/c+vuo9yqqOd233LnbffHeuffxa5r48l7FDxnLE9kdUv0dZqrGOnqt31JRx7LX1yHbvvenI37kd9Z46sq0N/VyceuD2VWvz4wdO5Jp75naJ+aIjB/fj6CnjOHrKOJavWss/Hn+Rvzz0PH979HkWLysWjl2ycg1TZ8xj6ox5jV5jbSb/7+r7N6rdxuZjb7fZEMaOGMicRcs46Nu3donvnzpeVZLliBgOvJdizvJkisR4KnBxZv61rN75wJXAxwGTZdXMg/Mf5N/P/rvZOm/d6q28a7t3VaW9qU9O5S/P/KXJ8t02263LJMoA3/jzY/z2nuJT7P59erF6Tf1684naa47KPhO258oJ/uroKsYPHc8n9vhErcOQ2lUt5upNGDWoQ3q6OvJ3bke9p45qy/miGzawX2/etvNo3rbzaNasrefupxdx40PP8deHn2fu4o3faqhXwISRryywNbGF87G76vdPHaMa+yz/AjgSGEjRi/x54KeZ+UJl3cxcGxHXA8e0tV11vNl1s7nhsRvYki256rGreOfO72T8sK7XS3T1f67ma3d+jdX1TW8e2it68akpn6paL9i2w7flplk3NTmH84jtj6hKOx3hJ7c9xUW3FkPL+vXuxU9P3Itxmwzq1HNUJKk9dWTPqLqO7thj3l769O7FftuNYr/tRvGlQ3fioXl1fOaq6Tz2/MtNnjNuxED+e6/x65LjtszH7urfP7WfavQsHwtcT9GLfFML6v8LOLEK7aoDNcw/HNtrLB8d+lGmPjmVHz3+I855/TlV631tbyvXruRrd36N3z3+u3XHdhi5A48tfGy9hbca5lVWc7jo+GHjOef15zQ5h7OrDE393b1z+OoNjwDFJ7jfe/dkXrddMa/a+TySerKO7BlV19Hdesw7QkSwy9jhvGWnLZpNlg+bPIZTD6retIDu8v1TdVUjWR7fWC9yUzLzaeDpKrSrDjK7bva6JG91rmbmmpkA1Gc9Z91+FrtvvnunT/bmvTyPT9/yaR5e8DBQrHZ96u6n8qFJH2Luy3M7ZF5lV5/DefOjL/C/ZXOEvnr4JP5rl1dvFyVJktRW3XnvXnUd1UiW10TErpnZ6Ez7iNgVmJ2Zi6rQlmrg2ieuXdcburh+MZe+fCkDGAAUCfO1j1/bqecl/mvevzjjH2eweOViAIb3H8439v8Grx/7eqBj51V21Tmc9zyziJN/eQ9rS/s9nHbwa3jPPv4nJUmS2odzidUZVCNZ/iawR+mrMT8F7gY+VoW2VANzX5677vkKVqz3CPDk4qa3Rqil+qzn0gcu5fv3fX/dMOsdR+7IeW86j3FDq7sVRXf2n+eX8MGf3b1ue4cP7LcV/3PQxBpHJUmSujvnEqvWqpEsHwhc0Uz5VOD4KrSjGhk7ZOy655v22pRe9OKF+ldG3v9jzj/4wfQfcMLOJzC47+BahPgqS1Yt4cx/nsnNs29ed+zwiYdz5j5nMqDPgBpG1rXMXbyc9196Fy8tLxZDO2TXLfnSoTsTETWOTJIk9QTOJVYt9arCNcYAs5opn1Oqoy7qiIlH0CuKH5WBMZCPD/04I2LEuvI1uYaLZlzEO3/3Tq567KpmV5nuCI8vepx33/DudYly3159+eJ+X+Qrr/uKifJGWLh0Fe+/9E6eqytGEey//aacd+xkevUyUZYkSVL3V41keSnQ3OTFrYCVVWhHNdKwknNDwtw7ejOk1xCC4C0T3sKgPsVQmAUrFnDOv8/hyOuP5G+z/kY2siBDe/vTzD/x3j++l2fqngFgi0Fb8PP/+jnHvOYYe0M3wtKVazjxZ3fz5ItLAdh13HB+9L4p9OtTjV8ZkiRJUudXjWHYdwLvj4hvZubS8oKIGAq8H7irCu2ohhpWcr7hwRvgheL1O3d5J+OHjmf+8vlcNOMirv7P1azNtTxd9zSfuvlT7LH5Hpy252nsttlu7R7f6vrVnDftPK545JUZAXuP3ptvvvGbjBo4qt3b705Wrann5F/ey4zZiwHYdtPB/PSEvRjSvxq/LiRJkqSuoRrdRN+m6Fm+IyKOiYjXlr6Oo9hTeRzwrSq0oxobP3Q8x772WACOfe2x67Y82nTgpnxh3y9w7WHXctD4g9bVv/eFe3nfH9/HZ275DLPqmhup3zbzl8/nQzd+aL1E+cRdTuTHB//YRHkj1dcn/3v1DP7xnxcB2GJYf37+wb0ZNaR/jSOTJEmSOlabu4oy8+aIOAX4LvDriuLVwKmZeVNb21Hnt83wbfjuQd/l3ufv5Tv3fIf7Xyx2E/vLM3/h77P/znGvPY6P7vpRRgwYsYErtdx9L9zHZ275DC8uL5K7QX0G8dU3fJWDtzq4am30FJnJOTc8zPXT5wEwbEAfLv/gPowf6YqTkiRJ6nmqMq4yM38cEX8AjgUmAgE8BlydmXObPVndzh5b7MEVb7+Cvz7zV75773eZtWQWa+rX8MtHfsn1T1zPSZNO4n07vq9Ni21lJlc+eiXfvvvbrMk1AGw7fFvOP/B8th2+bbXeSo/yw1ue5Ke3Pw1A/z69uOyEvXjt6KG1DUqSJEmqkapNQiwlxedX63rq2iKCt279Vg4cfyC//c9vuWjGRSxauYiXV7/Md+/9Lr9+9NecuvupHLrtofTu1Xujrr1s9TK+8u+vcMNTN6w7dvBWB3PO68/pNFtXdTW/vmsW37rxMQB69wp++N492HPrkTWOSpIkSaodl7ZVu+rbuy/v2fE93HDkDXx40ofp37uY+/r8suc56/azOPYPx3L73NtbvHL2rLpZvO9P71uXKPeKXnxmymf4zgHfMVFupRsfeo7PX/vAutdfP3ISb95xixpGJEmSJNVeVXqWI2IEcBKwDzCCVyfhmZlvrkZb6pqG9hvKJ/b4BMe+9lh+MP0HXP/E9STJfxb9h4/d9DH23XJfTptyGjuO2rHJa9wy+xY+f9vnWbJ6CQAjB4zkW2/8FntvuXcHvYvu586nFvA/v7qP+tJnFZ97+w4cs+f42gYlSZIkdQJtTpYjYivgdmAM8BIwDFjIK0nzfIq9mCVGDx7NOa8/h/ft+D7Ov/d8bp97OwD/fvbfHPeH4zhk20M4dfdTWVu/lmufuJa5L89ly8FbsnT1Un792Cvrx+262a5854DvMHrw6Fq9lS7v4Xl1fOjn01i1ph6AD++/DR89YLsaRyVJkiR1DtXoWf4qsAnwZuAB4AXgOODfwJnAfwMHVKEddSOvHflaLnrLRdwx7w7Ov+d8Hln4CEny+6d+z59m/mndol2NOe61x3H6XqfTr3e/Doy4e5m1YBkf+OldLFlZfJ+P3H0sn3t70736kiRJUk9TjTnLbwYuycybgYaJp5GZyzLzTIoE+htVaEfd0H5j9uPXh/yar73ha2w5eEuAZhPl06acxhf2/YKJchu8uGQlx192Jy8uWQnAga/djG8cvSu9ekWNI5MkSZI6j2oky6OAB0vPV5ceB5aV/xVw01s1qVf04tDtDuX3R/yevUc3P/94yaolHRRV97RkxWpO+OldPLNgGQB7TNiEH753Cn17u9afJEmSVK4afyG/SDEMG2AJsALYuqy8H+snz1Kj+vfuz6YDN222ztyX3ba7tVasXstHLr+Hh+bVAbD95kO47IS9GNhv47bukiRJknqCaiTLDwG7QrHkNXAXcEpETIiIrYGPAI9WoR31AGOHjG1TuRq3tj759G+mc8dTCwAYM3wAl5+0N5sMcji7JEmS1JhqLPB1PXBaRAzMzOXAV4AbgZml8gSOrEI76gGOmHgElz54KfVZ/6qyXtGLI7Y/ogZRdU3PLFjKVdNmM3vhMp58cem6HuURg/py+Un7sOVwB3xIkiRJTWlzspyZPwR+WPb67xHxOuDdwFrg2sz8V1vbUc8wfth4znn9OZx1+1nrJcy9ohdfff1XGT/UPYBb4pp75nD61fezNnO94/169+KnJ+7NxM2H1CgySZIkqWtoU7IcEb2BscDLmbmw4Xhm3g3c3cbY1EO9a7t3sfvmu3Pt48U+y2OHjOWI7Y8wUW6hZxYsbTRRBliztp6RDr2WJEmSNqitPcu9gaeAzwHfans4UmH80PF8Yo9P1DqMLumqabMbTZQB6oHfTJvF/75th44NSpIkSepi2rTAV2auAuYDS6sTjqS2eGDOS1x7b/Mrhs9ZtLyDopEkSZK6rmos8PVH4B2UzVuW1HEykzueXMCPbn2S2x6fv8H640a4sJckSZK0IdVIlk8H/hoRlwHnA49n5ooqXFdSM+rrk788/Dw/uvVJZsxe3KJzekdw3J4T2jcwSZIkqRuoRrL8AsX2ULsBHwCIiMo6mZnVaEvq8Vatqee66XO56NYneerF9WdATBo7nFPetB0vr1zDZ695YL25y70j+NYxuzJh1KCODlmSJEnqcqqRwF5OkSxLakdLV67h13fP5ie3PcWzL60/eOP1E0dx8gETef3EUes+rNpnm1H8Ztos5ixazrgRAzluzwkmypIkSVILVWOf5ROqEEdVRcRw4LPAkcBWwDLgUeBbmXltWb0tgHOBdwLDgf8A38/MSyquNwj4BnA00JdinvanyrfLKtU7HPglsEtmzmyXN6ceZ9HSVfz8jqf52b+eZvGy1euOR8DbdhrNx960HZPHb/Kq8yaMGuSq15IkSVIrdbuh0RExHrgZGAn8FHgYGATsAEwoq7cJ8E+KfaIvAGYChwEXR8SYzDy77LLnAidSJMzLgDOAn1Ak4w3XGwZcCJxtoqxqmLd4OT+5bSa/umsWy1evXXe8b+/giN3H8pE3bsfEzYfUMEJJkiSp+2pzshwRLVotKDNntbWtFvoFMBjYLTNnN1PvDGAicFRm/q507JKImAqcGRGXlyW9xwDnZeY5ABGxiCKpHlC2mNm5wALgvCq/H/UwT7zwMj++9Umumz6X1WtfmeEwsG9v3rPPBE56wzaM2cQVrSVJkqT2VI2e5adp2Zzl3lVoq1kRsT9wAPDpzJwdEX2A/pnZ2D7Q7wVmliXKDc4DDgWOA75eOjaYYj/pBgso3s8AYEVE7At8BHhDZq6p2htSjzJj9mJ+dMuT3Pjwc5Sty8Umg/pywuu25gP7bc2Iwf1qF6AkSZLUg1QjWf4Kr06W+wDbUQxrfgD4UxXaaYl3lB6fiojfUSS9fSLiGeDbmXkhQESMBsYDVzZyjTso3s/eZcduB06OiNuB5RS90g9n5uKI6AtcAlyUmXe2x5tS9/HMgqVcNW32ukW3jpkyjtmLlvOjW57kX08uWK/ulsMH8OH9t+W/9x7PoH7dbsaEJEmS1KlVY4GvLzdVFhHbUiSf09raTgs1rGb0E4o5yCdRJL6nAN+PiBGlodRjS/XmVF4gM1dGxHxgXNnhTwJTeeV9zAWOKj0/HRgBnNmagEtzrMdVHN4FoK6ujoULF776pBqqq6tb71Etd/OjL/CDm5+gPiET/rUWLrn1CVbVr7/V2tYjB3LCPmN4+06b0rd3L1a8XIcbl3d/3ltS+/DektqH95a6mtb8rEZm++76FBFfAd6RmXu2a0NFWzcBb6YYGr5DZq4sHe9HsdDXGIpEeRfgH8A5mfnFRq4zC6jLzF3KjvWhSMb7UvQqr4yIiRQ95+/JzGsj4hSKxHwoRXJ9emYu30DMXwa+1FjZ17/+dXbYwdWMu5t75gd/nt2LF1asnyRPGJy8ZWw9k0YmvV61VbkkSZKk1nr00Uf57Gc/C/C6zLyjJed0xNjOucBOHdAOFEOkAa5sSJQBMnNVRPwS+CKwD/Biqah/E9cZCDxXfqA0F/nBino/Bm4sJcrHAd+h6M2eDfyMYl7zKRuI+VLgxopjuwAXT548mb322msDp3esuro6ZsyYwW677cawYcNqHU6X8cs7n+Gae+aybA2vSpIH9E4O3XlTPvu27dftkayex3tLah/eW1L78N5SVzNgwICNPqcjkuXDgUUd0A68Mqz62UbKGo6NBKaXnlcOfyYiBgCjgNuaaygiTqCY17xj6dBJwDWZeWWp/FyKod+nZmZ9U9cprdi93qrdDQnTsGHDGDlyZHNh1Exnjq0zeuKlZ3j65cYT4RVrg1W9+jNq1KgOjkqdkfeW1D68t6T24b2lrqI1H+pUY+uoVw1jLhkJHETRS/rNtrbTQv8GPkaxeFelhi2uns/M5yJiDrBfI/X2BQK4u6lGImIz4NvAmZnZkKCPA+4pqzabYrXsTYEXNuZNqPsZN6L5rZ42VC5JkiSpY1WjZ/nLzZQ9B3wB+EYV2mmJ64E64P0R8bXMfAkgIoYCH6Do4W4Yn34lcHpEHFmxfdRpwBrgN820cz7FAmIXlh2bB0wqez0JWMX6W06phzp2z/H88OYnG91jrXcEx+3Zou3KJUmSJHWQaiTL2zRyLIGFmflyFa7fYqWtnD5NMQ/4roj4SSmWk4AtgRMyc1mp+teBo4FfRMQUiuT3MOAQioW/nmqsjYg4mGIP5r0rhldfAVwWERdQDAc/i2LudJNDsNVzbDVqMFuNGsTTC5atd7x3BN86ZlcmjBpUo8gkSZIkNaYaW0c9U41AqiUzL4uIFyn2Qv4SxZDqe4DTMvNPZfUWRcQbgK8BHwaGAU8AJ2fmRY1dOyIGAhcB383M+yqKf06RkJ8MDAauo9hySmL2wmXrEuUxwwew1zYjGTdiIMftOcFEWZIkSeqEqjFneRtgl8z8fRPlhwIPZObTbW2rpUqxNBpPRb1ngRM34rrLge2aKEvg3NKXtJ6pM+ate37qQdvznn0cdi1JkiR1ZtUYhv1/FAtqNZWcfoZisavjq9CW1OVkJtfdNxeAvr2Dd0waXeOIJEmSJG1Irypc4w28ep/gcn8B9q9CO1KX9PCzdTz+QjF9/4DXbM4mg/rVOCJJkiRJG1KNZHlzilWvm/ICsEUV2pG6pKnTXxmCffjuY2oYiSRJkqSWqkayvJgm5vGWTASWVKEdqcupr89185WH9O/DW3b0cyNJkiSpK6hGsnwb8KGI2LyyICJGAx8C/lmFdqQu586ZC3n2pRUAvG3n0Qzo27vGEUmSJElqiWot8HUoMCMizgPuLx2fDHwaGEKxPZPU41w/fe6654dNdgi2JEmS1FVUY5/l6RFxNPBT4BtAlooCmA8ck5nT2tqO1NWsXLOWPz7wLACbDunP67YbVeOIJEmSJLVUNXqWycw/RMQE4G3A9hSJ8mPAX0p7E0s9zi2PvUjdijUAHLrblvTpXY1ZD5IkSZI6QlWSZYBSUnxdta4ndXXlQ7APnzy2hpFIkiRJ2lht7uqKiN0j4uPNlH88Iia3tR2pK6lbsZqbHnkBgK1HDWLXccNrHJEkSZKkjVGNcaFfAt7ZTPnbgS9WoR2py/jzg8+xak09AIdNHktE1DgiSZIkSRujGsnyXsCtzZTfCuxdhXakLmPq9Hnrnh++u0OwJUmSpK6mGsnypsDCZsoXl+pIPcILdSv415PzAdht3HC22XRwjSOSJEmStLGqkSy/AOzUTPkuNJ9MS93K1BnzqC9toPYuF/aSJEmSuqRqJMs3AR+OiB0qCyJiJ+CkUh2pR7i+NAS7VxRbRkmSJEnqeqqxddRXgSOBeyPip8D9peOTgQ8Aq4BzqtCO1Ok9+eLLPDD3JQBeP3FTNh86oMYRSZIkSWqNNifLmflkRLwZ+BlwckXxQ8CJmfl4W9uRuoLryxb2Oswh2JIkSVKXVY2eZTJzGrBLaT/l7YEAHsvMGdW4vtQVZCbXT58LQP8+vXjbzlvUOCJJkiRJrVWVZLlBZk4Hppcfi4j9gZMy84RqtiV1NtNnL+aZBcsAeMuOWzB0QN8aRyRJkiSptaqxwNerRMToiDgjIh6j2Gf5+PZoR+pM1h+CPaaGkUiSJElqq6olyxHROyIOi4ipwCzgXGAt8H/AlGq1I3VGa9bW84f7i2R5+MC+vOm1m9c4IkmSJElt0eZh2BHxWortoY4HNgdeAnoDH83MS9p6fakruP3JBcx/eRUA75g0mn592mXQhiRJkqQO0qpkOSIGAcdRJMn7UWwPNZViReyngEeABdUJUer8rr9v7rrnroItSZIkdX2t7Vl+DhgM3A18HPh1Zi4GiIjtqhOa1DUsX7WWGx96DoAxwwew99YjaxyRJEmSpLZqbbI8BPgP8EPg6sxcVr2QpK7lpkeeZ+mqtQAcOnkMvXpFjSOSJEmS1FatnVj5MWAxxbDr5yLi0oh4Y7WCkrqShr2VAQ7bzSHYkiRJUnfQqmQ5My/OzH2BXYFLgUOBmyPiKeD/AVm9EKXOa9HSVdzy2IsAvGaLIey45dAaRyRJkiSpGtq0ZG9mPpiZnwbGAv9NMTT7w0AAZ0XEaRGxVdvDlDqnGx54ljX1xWdDh00eS4RDsCVJkqTuoCr722Tm6sz8bWb+F7A18GVgOPBt4KmIuKsa7UidzdTp89Y9f9duY2oYiSRJkqRqqvpmsJk5JzO/kpnbAm8FrgImVbsdqdbmLFrGXU8vBGDPrUYwfuSgGkckSZIkqVpauxp2i2TmTcBNETGiPduRamHqjFd6lQ/b3YW9JEmSpO6k6j3LjcnMRR3RjtSRrr+vSJb79AreOWnLGkcjSZIkqZo6JFmWuptHn6vjseeXAHDAazZj5OB+NY5IkiRJUjWZLEutcN19ZQt7TXZhL0mSJKm7MVmWNlJ9fTJ1+lwABvXrzcE7bVHjiCRJkiRVm8mytJHufnoh815aAcDbdh7NoH7tuk6eJEmSpBowWZY20vXlq2A7BFuSJEnqlqrWJRYRrwEmAqOAqCzPzMur1ZZUK6vW1PPHB54FYNTgfrxh4qY1jkiSJElSe2hzshwRWwA/Bw5uONRItQRMltXl3fqfF1m8bDUAh+y6JX16OzhDkiRJ6o6q0bN8IUWi/CPg78CCKlxT6pSuKy3sBXDY7mNrGIkkSZKk9lSNZPlg4MeZeWoVriV1WktWrOamh58HYMLIQew+fpPaBiRJkiSp3VRjDGkv4L4qXEfq1P7y0POsXFMPFAt7RTQ240CSJElSd1CNZPlfwOQqXEfq1NYbgj3ZIdiSJElSd1aNZPk04MiIOKoK15I6pReWrOD2J+YDsMvYYUzcfEiNI5IkSZLUnqq1wNcS4KqImAc8BaytqJOZ+eYqtCXVxB9mPEt9Fs8Pt1dZkiRJ6vaq0bO8LdAXmAWsASYA21R8bVuFdlokIrKZr00q6m4REZdFxPMRsSIi7o+IDzdyzUER8f2IeDYi5kfE5RExspF6h0fE0ojYph3fomrg+hnzAIiAQ3YdU+NoJEmSJLW3NvcsZ+bWVYij2m4DLm7k+NKGJ6XE+Z/AWOACYCZwGHBxRIzJzLPLzjsXOBH4BrAMOAP4CXBk2fWGUfSyn52ZM6v4XlRjM+cvZcbsxQDst+0oRg8fUNuAJEmSJLW7agzD7oyeyswrNlDnDGAicFRm/q507JKImAqcGRGXlyW9xwDnZeY5ABGxiCKpHpCZK0p1zqXYY/q8qr4T1dz1ZQt7OQRbkiRJ6hmqlixHxEDgQF4Zcv0kcEtmLq9WGxsZTz+gf2YuaaLKe4GZZYlyg/OAQ4HjgK+Xjg0G5pfVWQD0BgYAKyJiX+AjwBsyc02V3oI6gczk+unFEOx+fXrxX5NG1zgiSZIkSR2hGnOWiYh3A7OB3wPfK339AZhdKutoR1MMl66LiAUR8ZOIWJfllJ6PB+5o5Nw7gAT2Ljt2O3ByREyJiJ0oeqUfzszFEdEXuAS4KDPvbKf3oxp5YO5LzJxfjN5/8w6bM2xA3xpHJEmSJKkjtLlnOSIOBq4Ange+BDwABLALcArwi4h4MTNvamtbLXQ3cDXwODCIorf7ROCtEbFPZj5LMU8ZYE7lyZm5MiLmA+PKDn8SmApMK72eCzRslXU6MAI4szXBRsT4irag+N5RV1fHwoULW3PZdlNXV7feY3f36zueXvf8oInDOt2/h7qPnnZvSR3Fe0tqH95b6mpa87NajWHYn6NYHGuvzFxUdvy6iPghcFepTocky5m5d8WhX0bErcDlwNkUw6UHlcpWNnGZFWV1yMzHI2ISsAPFyt8Pl5LqicAXgPdkZl1EnELxAcFQiuT69BYMQz+J4kOGV5k+fTorVqxorKjmZsyYUesQ2l19wh/u7w0EA3sn8ezD3PZ8raNSd9cT7i2pFry3pPbhvaWu4tFHH93oc6qRLO8JnFuRKAOQmQsj4jLgs1Vop9Uy8xcR8RXgnaVDy0qP/Zs4ZSDwXMU11gAPVtT7MXBjZl4bEccB36FIfmcDP6OY13zKBsK7FLix4tguwMWTJ09mr7322sDpHauuro4ZM2aw2267MWzYsFqH067+/fRi6v79CABv22kLDjpguxpHpO6sJ91bUkfy3pLah/eWupoBAzZ+R5tqJMu9KXpim7K8VKfWngZeX3resLxx5fBnImIAMIpi+6kmRcQJFPOadywdOgm4JjOvLJWfC3w/Ik7NzPqmrpOZsymS6/JrAzBs2DBGjnzVds6dQmeOrVr+dtMr/yzH7rtNt3+/6hx6wr0l1YL3ltQ+vLfUVbTmQ51qLPD1MPDu0kJX6ykde3epTs1EkX1OpNRbnJnPUcxX3q+R6vtSzLm+u5nrbQZ8GzgzMxvmPY9j/aR3NsVq2Zu2NX51vBWr13LjQ8Xggi2G9WefbUbVOCJJkiRJHakayfIPKYZi3xIRh0XE9qWvw4GbgSnAD6rQzgZFxBZNFP0PRTI7tezYlcA2EXFkRd3TgDXAb5pp6nyKedoXlh2bB0wqez0JWMX6W06pi/jbIy/w8spiF7B37TaG3r2ixhFJkiRJ6khtHoadmT+NiO0ptlOq3LMY4OuZ+bO2ttNCn4uIt1BsW/UMxdzjN1Hsm/w48OXyuCi2mPpFREyhSH4PAw4BzsnMpxproLT693HA3hXDq68ALouICyh6rc8CrmxuCLY6r+umz133/LDJY5upKUmSJKk7qsacZTLz8xHxU4pkc1uKYcxPAtdl5hPVaKOF/k6xYvX7KIY/ZymO/wO+lZkvlcW8KCLeAHwN+DAwDHgCODkzL2rs4hExELgI+G5m3ldR/HNgS+BkYDBwHcWWU+piFi9bxS2PvQDAxM2HsPMYF62QJEmSepqqJMtQbK9EMY+3ZjJzKusPtd5Q/Wcp9mBuaf3lQKNLImdmAueWvtSF/enB51i9NgE4bLcx6xZckyRJktRzVGPOstStXHefQ7AlSZKknm6je5ZL+yYn8JHMXFt6vSGZmSdtdHRSB5u3eDl3zlwIwB4TNmHCqEE1jkiSJElSLbRmGPYJFMnyycDa0usNSYp9iKVObeqMeeueH767vcqSJElST7XRyXJm9mrutdSVXT+9SJZ79wreMWnLGkcjSZIkqVZMdKWS/zy/hEeerQNg/+03ZdMh/WsckSRJkqRaaXOyHBFPRcS7mik/JCIa3bNY6kzKF/Y63IW9JEmSpB6tGj3LWwNDmikfDGxVhXakdlNfn+uGYA/s25uDd9qixhFJkiRJqqWq7bPcjPHAyx3QjtQqzyxYyndv+g9zFy8H4HUTRzG4f0fcGpIkSZI6q1ZlBBFxGHBY2aGPRMRbGqk6AngL8O/WtCO1t2vumcPpV9/P2sx1x25+5AWuuWcOR00ZV8PIJEmSJNVSa7vPJvPKllEJvLH0VellikT5461sR2o3zyxY+qpEGaAeOP3q+9lr65HusyxJkiT1UK2as5yZZ2dmr9K2UQG8r+F1xdewzDw4M/9T3bCltrtq2uxXJcoN1mbym2mzOjgiSZIkSZ1FNSZmHgg8XIXrSB1qzqLlbSqXJEmS1H21OVnOzFurEYjU0caNGNimckmSJEndV1WW/I2IPsDhwD4Ui3pVDu/OzDypGm1J1XLsnuP54c1P0thA7N4RHLfnhA6PSZIkSVLn0OZkOSJGAjcDu1DMX87SI2XPEzBZVqcyYeQgRg3px/yXV613vHcE3zpmVxf3kiRJknqwavQsfxXYAfgQcAvwJPA2YBZwFrB96bXUqdw1c+G6RHm7zQazy9jhjBsxkOP2nGCiLEmSJPVw1UiW3wlcnpk/jYhRpWNrM/Mx4H0RcQtwLnByFdqSquY302ave37WITvxptduXsNoJEmSJHUmrdo6qsJo4K7S8zWlxwFl5dcB76pCO1LV1K1YzR8feBaAMcMHsP/2m9U4IkmSJEmdSTWS5YVAw5jVJcBqYHxZ+WqKRb+kTuP3M+axYnU9AEdPGUfvXrGBMyRJkiT1JNVIlv8D7AiQmfXAfcAJEdE/IgYB7weeqkI7UtVcdfcrQ7CP2XN8MzUlSZIk9UTVSJb/AhwbEf1Lr8+j2EJqIfACsCdwfhXakari0efqmDHnJQBeP3EU40e6mJckSZKk9VVjga+vAd/OzJUAmXlVRKwF3gusBa7OzN9UoR2pKn5T1qt8rL3KkiRJkhrR5mQ5MxNYWXHsGuCatl5bqraVa9Zy7X1zARg+sC9v23l0jSOSJEmS1Bm1eRh2RPSJiGHNlA+LiGr0YEtt9teHn2fxstUAHD55DAP69q5xRJIkSZI6o2rMWf4OMK2Z8ruBb1ShHanN1huCvZdDsCVJkiQ1rhrJ8ttofsj1NcDbq9CO1CZzFi3jn0/MB2CXscPYeczwGkckSZIkqbOqRrI8HniymfKnWH/fZakmrr5nDpnF8+Nc2EuSJElSM6qRLK8CmlslaTRQX4V2pFarr09+O20OAP379OJdk8fWOCJJkiRJnVk1kuX7KPZZ7ltZEBH9gOOA+6vQjtRqtz85n7mLlwPw9l1GM3zgq35cJUmSJGmdaiTLPwB2AW6IiL0iYkDpax/gBmAn4MIqtCO1mgt7SZIkSdoY1dhn+ZqIOBf4HPDmhsNAlL6+kZm/aWs7UmstWrqKvzz0PAATRg5i321G1TgiSZIkSZ1dVfY/zswzI+I64H3ARIok+THgysy8uxptSK113fS5rFpbTJs/ds9x9OoVNY5IkiRJUmdXlWQZoJQUmxirU8nMdUOwewUcPcUh2JIkSZI2rBpzlqVO64G5L/Hoc0sAOOA1mzF6+IAaRyRJkiSpK9jonuWI+CLFnOT/y8z60usNycw8Z6Ojk9qofGGv41zYS5IkSVILtWYY9pcpkuVvUOyx/OUWnJOAybI61PJVa5k6fR4Aowb346AdtqhxRJIkSZK6itYky9sAZOaq8tdSZ/OnB59lyco1ABy5x1j69XHWgSRJkqSWaU2yfBjw54YXmflM9cKRqsch2JIkSZJaqzVdbecDeza8iIi1EfGe6oUktd3T85dy58yFAEzZagQTNx9a44gkSZIkdSWtSZZfBgaXvXbTWnU6V00r61Xe015lSZIkSRunNcOwHwBOjYjngcWlYztExBubOykz/9GKtqSNtmZtPVffMweAwf16885dt6xxRJIkSZK6mtYky58FrgOuLb1O4MzSV2OiVKd3K9qSNtqt/3mRF5asBOCQXccwuH9rfswlSZIk9WQbnUVk5j8jYjtgb2BL4GfAxcAd1Q1Nnc0zC5Yy9a5nmAD88s5neNfe/dlq1OANntfRyhf2OtaFvSRJkiS1Qqu63DLzJeCvABFxNvDHzJxazcDUuVxzzxxOv/p+xg+u59OT4Jp75nLBP57lm0fvylFTxtU6vHVeWLKCvz36AgATNx/CHhM2qW1AkiRJkrqkNm88m5nbmCh3b88sWMrpV9/P2kwy4aFFQSaszeT0q+9n1oJltQ5xnd/dO5e19QkUC3tFuP6cJEmSpI3X5mS5s4uIQRHxVERkRFzUSPkWEXFZRDwfESsi4v6I+HAT1/l+RDwbEfMj4vKIGNlIvcMjYmlEbNNe76mjXTVtNmuzSEDnr4SLH+1N3eqibG0mv5k2q4bRvSIzuao0BLtPr+CIPcbWOCJJkiRJXdVGD8OOiHqgHhiUmatKr3MDp2Vm1mqVpa8AmzVWEBGbAP8ExgIXADOBw4CLI2JMZp5dVv1c4ETgG8Ay4AzgJ8CRZdcbBlwInJ2ZM6v9RmplzqLl654vXVM8LlrVeHktTXtmEU/NXwrAW3bcgk2H9K9xRJIkSZK6qtYksJdTJMdrK153OhGxO/ApisT2241UOQOYCByVmb8rHbskIqYCZ0bE5WVJ7zHAeZl5TunaiyiS6gGZuaJU51xgAXBeu7yhGhk3YuC65yP7wcJVUL69dnl5LZUv7HWcC3tJkiRJaoPWrIZ9QnOvO4uI6A1cAtwIXEPjyfJ7gZlliXKD84BDgeOAr5eODQbml9VZQLEd1gBgRUTsC3wEeENmrqnW++gMjt1zPBfd8hRrMxnaF7YbXs/dL74ygv+w3Wo/3HnJitXccP+zAIweNoA3vqbRwQSSJEmS1CLdec7yp4CdgFMbK4yI0cB4Gt/y6g6K3vK9y47dDpwcEVMiYieKXumHM3NxRPSlSMwvysw7q/cWOoetRg3mm0fvSu8IIuDYberp1+uVwQQ/vOUJMms7uOAP9z/L8tXFYIejp4yjdy8X9pIkSZLUem2eRxwRWwBjMvO+smM7UCSTI4GfN9Jz264iYivgbOCczJwZEVs3Uq2hO3ROZUFmroyI+UD5nkifBKYC00qv5wJHlZ6fDowAzmxFrOMr2gHYBaCuro6FCxdu7CXbxYHbDOIPH5nMPx6eRb81z/OhKSO44oGXqVuxhuumz2PiyH68Z88taxbfL+94ZYr4W7cf2mm+b1JL1dXVrfcoqTq8t6T24b2lrqY1P6vVWHTru8AE4HUAETEU+DswmmIhsEMi4m2ZeVMV2mqpHwHP0PjQ6waDSo8rmyhfUVaHzHw8IiYBOwB9KXqVV0bEROALwHsysy4iTgFOAYZSJNenZ2ZzK2CdBHypsYLp06ezYsWKxopqZnTp8bV95vP+bYMfPtyLeoLz/j6TFc89yfbDO76H+dll8OCzxY/y9sPqmfnA3XSb1dXU48yYMaPWIUjdkveW1D68t9RVPProoxt9TjWS5f2Ay8pe/zdFTvUmYAZwK/AZoEOS5Yh4D/B24IDMXN1M1YbNgZtaMnkg8Fz5gdJc5Acr6v0YuDEzr42I44DvUCTAs4GfUcxrPqWZOC6lmFddbhfg4smTJ7PXXns1c2rHq6urY8aMGey2227sP2wY/Uc/y3f+/jT1BFfM7M8vP7ArWw7r2FWov/P3p4FivvIH9n8N++/sfGV1PeX31rBhw2odjtRteG9J7cN7S13NgAEDNvqcaiTLm1Ikhg3eDtyVmf8AiIjLgf9XhXY2KCL6AecDfwBmlQ2/bhjmPLR0bBHFMOrysvLrDABGAbdtoL0TKOY171g6dBJwTWZeWSo/F/h+RJyamfWNXSMzZ7P+94+IYr7tsGHDGDnyVVs5dwoNsZ168AieWrSaa++by+Lla/js75/ktx/bjwF9e3dIHKvW1POnRxYAMHRAH47ed2KHtS21h85830tdmfeW1D68t9RVtOZDnWos8LWSsuHKwP4UvckNXqKYz9sRBgGbA4dQ7Jnc8NWQ9L6n9PrkzHyOYr7yfo1cZ1+KvZHubqqhiNiMYpj3mZnZMO95HOsnvrMpVsvetJXvp9OLCL52xCR2HlP88D0w9yU+f+0DHbbg102PPM/CpcWmz4dPHmuiLEmSJKkqqpEsPw4cFYXDKBb1Kh9yPR7oqNWWlgJHNPL10VL5jaXX15ReXwlsExFHVlznNGAN8Jtm2jqfIvG+sOzYPGBS2etJwCrW33Kq2xnYrzcXvW8KIwb1BeB3987l8jue6ZC23VtZkiRJUnuoxjDsC4GfUyTEg4EngJvLyt8IPFCFdjaoNEf5usrjZcOxn87M8vKvA0cDv4iIKRTJ72EUPdPnZOZTjbUTEQdT7MG8d8Xw6iuAyyLiAope67OAK5sagt2djB85iAvfswfHX3on9Qnn/OFhdhg9lH22HdVubc5bvJx/PP4iADttOYxdxg5vt7YkSZIk9Sxt7lnOzF8A76dYAfsXwNtLC2EREaOA4cBVbW2nPWTmIuANFPF9mCLx34ZimPYXGzsnIgYCFwHfLd8uq+TnFNtHHQl8jiJx/2S7BN8JvX7ipnz+HcX07TX1ySm/vJd5i5tbCLxtrr5nDg2jve1VliRJklRN1ehZJjOvoOhVrTy+AJhSjTbaIjOfppiD3FjZs8CJG3Gt5cB2TZQlcG7pq0c66Q3bcP+cl5g6Yx4Llq7i5Cvu4Tcfrf6CX/X1yVXTiiHY/fr04vDJYzdwhiRJkiS1XDXmLDcqIg6IiCNK+y6rh4gIvnHUruy4ZbHg14w5L3HWdQ9WfcGvO55awJxFRa/1f+08muGl+dKSJEmSVA1tTpYj4vMRcWPFsWsohmVfDTwUEXb79SAD+/Xm4uOnsEkpgf3tPXO44s5ZVW3Dhb0kSZIktadq9CwfBzzW8CIi3kKx4vRPgU8BmwBnVKEddSHjRw7i++/enV6lwe9nT32Iu5+uzqLoLy1bzZ8feq7UzkD2a8dFxCRJkiT1TNVIlscD/yl7fRgwNzM/lJnfp1gM6+1VaEddzP7bb8YZ/7UDUCz4dfIV9/LcSyvafN3rps9l1ZpigfFjpoynV69Gp6NLkiRJUqtVI1keCJQveXwQ6++z/AgwpgrtqAv6yBu35Z27bgnA/JdX8rEr7mHlmrVtumbDEOwIOHrKuDbHKEmSJEmVqpEszwV2BYiIrYAdgX+UlY8C2t6dqC4pIvjW0buyw+hinbfpsxfz5akPtfp6D859iYefrQPgjdtvxphNBlYlTkmSJEkqV41keSrwsYj4PsWCXiuAG8rKdwaeqUI76qIG9evDj4+fwvCBxYJfv7prNr+8s3U/Ei7sJUmSJKkjVCNZPgf4J/BxisT4k5n5AkBEDKRY7OvmKrSjLmyrUYP53rt3J0rTi7889SHueWbjFvxasXot102fC8DIwf14y45bVDtMSZIkSQKqkCxn5qLMfDPFqtfDM/OSiioHAP/X1nbU9R3wms3437e9FoDVa5OPXXEvz9e1fIT+nx98jiUr1gBwxO5j6den3bYJlyRJktTDVS3byMy6zFxdcWx5Zs7IzOrsGaQu7+QDtuMdk0YD8OKSlZx8xT3rVrbeEIdgS5IkSeooVUuWI6J3ROwcEW+IiDdWflWrHXVtxYJfu/GaLYYAcO+sxZz9+w0v+PXMgqXc8dQCAHafsAmv2WJou8YpSZIkqWerSrIcEWcA84H7gVsp5ihXfkkADO7fh4uP35NhA/oA8Ms7Z/Hru2Y1e85vp81Z9/y4Pe1VliRJktS+2pwsR8SHgHOB6cAXgAAuAL4FLASmAR9sazvqXrbedDDf/e9XFvz64vUPce+sRY3WXVufXH1PkSwP6tebQ3Zz225JkiRJ7asaPcsfA/6dmQcCF5eO3ZCZn6XYf3lroHcV2lE3c+AOm/OZg18DwKq19Zx8xT28sOTVC3794z8v8lxpIbB3TtqSIf37dGickiRJknqeaiTLOwK/LT3P0mMfgMx8liKB/mQV2lE39PEDJ/JfOxcLfj1ft5KP//LeVy345cJekiRJkjpaNZLltcDLpedLS48jy8qfBravQjvqhiKCbx+7GxM3Lxb8uvvpRXz1hofXlc9/eSU3PfI8ANtuNpgpW42oSZySJEmSepZqJMuzgAkAmbkSmA3sX1a+F8XcZalRQ/r34eLjpzC0NLz68jue4appRW/ytffOZU19MWDhuD3HEw2TnCVJkiSpHVVj8uc/gEOBs0qvfwt8KiIGUiTj7wMuq0I76sa23WwIF/z3ZD50+TQy4cxrH+CumQv484NFr3LvXsGRe4yrcZSSJEmSeopq9Cx/F/hRRAwovf4S8CfgA8DxwF+Bz1ahHXVzb95xCz79lmLBr9Vrk6vvmcvLK9cAxYrY//jPi7UMT5IkSVIP0uZkOTMfy8wfZ+aK0uulmXkoxbzl4Zn59sx0GLZa5NDdtmyy7PSr72fWgmUdGI0kSZKknqoaPcuNysyXMvPlDdeUXtGwn3Jj1mbym2mzOjAaSZIkST1VuyXLUmvMWbS8TeWSJEmSVA0bvcBXRNTzyn7KLZWZWY3FxNTNjRsxsE3lkiRJklQNrUlgL2fjk2WpRY7dczwX3fIUa/PVP2K9Izhuzwk1iEqSJElST7PRyXJmntAOcUgAbDVqMN88eldOv/r+9RLm3hF865hdmTBqUA2jkyRJktRTODRanc5RU8ax19Yj+c20WcxZtJxxIwZy3J4TTJQlSZIkdZhWJcsR0Q/4HvBoZl7QTL3TgInAJzJzTasiVI80YdQg/vdtO9Q6DEmSJEk9VGtXw34/cBLwlw3U+yvwEeC9rWxHkiRJkqQO19pk+WjgT5n5cHOVMvMB4I/Aca1sR5IkSZKkDtfaZHl34JYW1r0V2KOV7UiSJEmS1OFamyyPABa0sO6CUn1JkiRJkrqE1ibLdcBmLay7KbCkle1IkiRJktThWpssPwi8rYV13wo81Mp2JEmSJEnqcK1Nlq8BDoqII5urFBFHAG8Grm5lO5IkSZIkdbjWJssXA48Cv46IcyNim/LCiNgmIr4G/LpU75K2hSlJkiRJUsfp05qTMnNlRLwDuAE4Azg9IpZQzGUeCgwDAngEOCQzV1QpXkmSJEmS2l1re5bJzGeAKcD/ALcBa4DRwFrgH6XjUzJzZhXilCRJkiSpw7SqZ7lBZq4EflD6kiRJkiSpW2h1z7IkSZIkSd2VybIkSZIkSRVMliVJkiRJqmCyLEmSJElSBZNlSZIkSZIqmCxLkiRJklTBZFmSJEmSpArdKlmOiNdGxC8j4pGIeCkilpaefyciRjdSf4uIuCwino+IFRFxf0R8uJF6gyLi+xHxbETMj4jLI2JkI/UOL7W5TXu9R0mSJElS++tT6wCqbBwwGrgWmAOsASYBHwXeHRG7Z+bzABGxCfBPYCxwATATOAy4OCLGZObZZdc9FzgR+AawDDgD+AlwZEOFiBgGXAicnZkz2+8tSpIkSZLaW7dKljPzb8DfKo9HxG3Ab4CTgK+VDp8BTASOyszflY5dEhFTgTMj4vKypPcY4LzMPKd0vUUUSfWAzFxRqnMusAA4rx3emiRJkiSpA3WrYdjNaEh6R5Qdey8wsyxRbnAe0Bc4ruzYYGB+2esFQG9gAEBE7At8BPhIZq6pYtySJEmSpBroVj3LDSJiADCEIpndAfh6qeiPpfLRwHjgykZOvwNIYO+yY7cDJ0fE7cByil7phzNzcUT0BS4BLsrMO1sR63iK4ePldgGoq6tj4cKFG3vJdlVXV7feo6Tq8N6S2of3ltQ+vLfU1bTmZ7VbJsvAh4Dvl72eDXwgM28uvR5bepxTeWJmroyI+ayfwH4SmApMK72eCxxVen46RY/1ma2M9STgS40VTJ8+nRUrVjRWVHMzZsyodQhSt+S9JbUP7y2pfXhvqat49NFHN/qc7posXwc8StG7vDtwKOsPwR5UelzZxPkryuqQmY9HxCSKXuq+FL3KKyNiIvAF4D2ZWRcRpwCnAEMpkuvTM3P5BmK9FLix4tguwMWTJ09mr7322sDpHauuro4ZM2aw2267MWzYsFqHI3Ub3ltS+/DektqH95a6mgEDBmz0Od0yWc7MObzSa3xdRFwD3B0RgzLzXIoVrQH6N3GJgcBzFddcAzxYUe/HwI2ZeW1EHAd8h6KneDbwM4p5zadsINbZpfrrRAQAw4YNY+TIV+1Q1Sl05tikrsx7S2of3ltS+/DeUlfRmg91esQCX5l5P3AfrySuc0uPlXOFG+Y7j6KRIdoV9U6gmNd8aunQScA1mXllZt5GabupiOgR32NJkiRJ6k56UiI3EBgJkJnPUSTD+zVSb18ggLubulBEbAZ8Gziz1IsNReJd3kM8m2KBsU3bHLkkSZIkqUN1q2S5tMp1Y8cPpJgH/O+yw1cC20TEkRXVTwPWUOzL3JTzKbajurDs2DxgUtnrScAq1t9ySpIkSZLUBXS3Ocs/iogtgb8Dz1D07E4B/htYAnymrO7XgaOBX0TEFIrk9zDgEOCczHyqsQYi4mCKPZj3zsz6sqIrgMsi4gKKXuuzgCsr6kiSJEmSuoDuliz/CvgAcDywGcV+yc9QLMT1rcyc1VAxMxdFxBuArwEfBoYBTwAnZ+ZFjV08IgYCFwHfzcz7Kop/DmwJnAwMpliR+5NVe2eSJEmSpA7TrZLlzLwKuGoj6j8LnLgR9ZcD2zVRlhSLep3b0utJkiRJkjqnbjVnWZIkSZKkajBZliRJkiSpgsmyJEmSJEkVTJYlSZIkSapgsixJkiRJUgWTZUmSJEmSKpgsS5IkSZJUwWRZkiRJkqQKJsuSJEmSJFUwWZYkSZIkqYLJsiRJkiRJFUyWJUmSJEmqYLIsSZIkSVIFk2VJkiRJkiqYLEuSJEmSVMFkWZIkSZKkCibLkiRJkiRVMFmWJEmSJKmCybIkSZIkSRVMliVJkiRJqmCyLEmSJElSBZNlSZIkSZIqmCxLkiRJklTBZFmSJEmSpAomy5IkSZIkVTBZliRJkiSpgsmyJEmSJEkVTJYlSZIkSapgsixJkiRJUgWTZUmSJEmSKpgsS5IkSZJUwWRZkiRJkqQKJsuSJEmSJFUwWZYkSZIkqYLJsiRJkiRJFUyWJUmSJEmqYLIsSZIkSVIFk2VJkiRJkiqYLEuSJEmSVMFkWZIkSZKkCibLkiRJkiRVMFmWJEmSJKmCybIkSZIkSRVMliVJkiRJqmCyLEmSJElShW6VLEfEayLiKxHx74h4MSKWRMT0iDgzIgY3Un+LiLgsIp6PiBURcX9EfLiReoMi4vsR8WxEzI+IyyNiZCP1Do+IpRGxTXu9R0mSJElS++tT6wCq7IPAqcDvgSuBVcCBwFeBYyNi38xcDhARmwD/BMYCFwAzgcOAiyNiTGaeXXbdc4ETgW8Ay4AzgJ8ARzZUiIhhwIXA2Zk5s/3eoiRJkiSpvXW3ZPlq4OuZubjs2EUR8ThwJkUy/YPS8TOAicBRmfm70rFLImIqcGZEXF6W9B4DnJeZ5wBExCKKpHpAZq4o1TkXWACc107vTZIkSZLUQbrVMOzMnFaRKDe4qvQ4qezYe4GZZYlyg/OAvsBxZccGA/PLXi8AegMDACJiX+AjwEcyc02r34AkSZIkqVPobj3LTRlbenwBICJGA+MphmpXugNIYO+yY7cDJ0fE7cByil7phzNzcUT0BS4BLsrMOzc2sIgYD4yrOLwLQF1dHQsXLtzYS7arurq69R4lVYf3ltQ+vLek9uG9pa6mNT+r3T5ZjojewBeBNcAvS4cbkuc5lfUzc2VEzGf9BPaTwFRgWun1XOCo0vPTgREUw7xb4yTgS40VTJ8+nRUrVjRWVHMzZsyodQhSt+S9JbUP7y2pfXhvqat49NFHN/qcbp8sA98D9gW+kJmPlY4NKj2ubOKcFWV1yMzHI2ISsAPFEO2HS0n1ROALwHsysy4iTgFOAYZSJNenNywo1oxLgRsrju0CXDx58mT22muvFr3JjlJXV8eMGTPYbbfdGDZsWK3DkboN7y2pfXhvSe3De0tdzYABAzb6nG6dLEfEVymS158AXysrWlZ67N/EqQOB58oPlOYiP1hR78fAjZl5bUQcB3yHoqd4NvAzinnNpzQXY2bOLtUvjxuAYcOGMXLkq3ao6hQ6c2xSV+a9JbUP7y2pfXhvqatozYc63WqBr3IR8WWKodGXAx/NzCwrnlt6rJwrTEQMAEbRyBDtinonUMxrPrV06CTgmsy8MjNvo7TdVER02++xJEmSJHVX3TKRi4gvUcwDvgI4MTPry8sz8zmKZHi/Rk7fFwjg7mauvxnwbeDMzGxIqsexfg/xbIrVsjdt5duQJEmSJNVIt0uWI+KLwJcpFvM6oTJRLnMlsE1EHFlx/DSKxcB+00wz5wMzgQvLjs1j/a2pJgGrWH/LKUmSJElSF9Ct5ixHxMeBs4FZwF+BdzfM/y15PjP/Wnr+deBo4BcRMYUi+T0MOAQ4JzOfaqKNgyn2YN67IhG/ArgsIi6g6LU+C7iymWRdkiRJktRJdatkGWhYOnoCxQJblW6lSKLJzEUR8QaKhb8+DAwDngBOzsyLGrt4RAwELgK+m5n3VRT/HNgSOBkYDFxHseWUJEmSJKmL6VbJcmaeAJywEfWfBU7ciPrLge2aKEuKRb3Oben1JEmSJEmdU7ebsyxJkiRJUluZLEuSJEmSVMFkWZIkSZKkCibLkiRJkiRVMFmWJEmSJKmCybIkSZIkSRVMliVJkiRJqmCyLEmSJElSBZNlSZIkSZIqmCxLkiRJklTBZFmSJEmSpAomy5IkSZIkVTBZliRJkiSpgsmyJEmSJEkVTJYlSZIkSapgsixJkiRJUgWTZUmSJEmSKpgsS5IkSZJUwWRZkiRJkqQKJsuSJEmSJFUwWZYkSZIkqYLJsiRJkiRJFUyWJUmSJEmqYLIsSZIkSVIFk2VJkiRJkiqYLEuSJEmSVMFkWZIkSZKkCibLkiRJkiRVMFmWJEmSJKmCybIkSZIkSRVMliVJkiRJqmCyLEmSJElSBZNlSZIkSZIqmCxLkiRJklTBZFmSJEmSpAomy5IkSZIkVTBZliRJkiSpgsmyJEmSJEkVTJYlSZIkSapgsixJkiRJUgWTZUmSJEmSKpgsS5IkSZJUwWRZkiRJkqQKJsuSJEmSJFUwWZYkSZIkqUK3S5Yj4nMR8duIeCoiMiKe3kD9LSLisoh4PiJWRMT9EfHhRuoNiojvR8SzETE/Ii6PiJGN1Ds8IpZGxDZVfFuSJEmSpA7Up9YBtIOvAQuBe4FNmqsYEZsA/wTGAhcAM4HDgIsjYkxmnl1W/VzgROAbwDLgDOAnwJFl1xsGXAicnZkzq/JuJEmSJEkdrjsmy9tl5lMAEfEgMKSZumcAE4GjMvN3pWOXRMRU4MyIuLws6T0GOC8zzyldexFFUj0gM1eU6pwLLADOq+5bkiRJkiR1pG43DLshUW6h9wIzyxLlBucBfYHjyo4NBuaXvV4A9AYGAETEvsBHgI9k5pqNjVuSJEmS1Hl0x57lFomI0cB44MpGiu8AEti77NjtwMkRcTuwnKJX+uHMXBwRfYFLgIsy886NjGM8MK7i8C4AdXV1LFy4cGMu1+7q6urWe5RUHd5bUvvw3pLah/eWuprW/Kz22GSZYp4ywJzKgsxcGRHzWT+J/SQwFZhWej0XOKr0/HRgBHBmK+I4CfhSYwXTp09nxYoVjRXV3IwZM2odgtQteW9J7cN7S2of3lvqKh599NGNPqcnJ8uDSo8rmyhfUVaHzHw8IiYBO1AM0X64lFRPBL4AvCcz6yLiFOAUYChFcn16Zi5vJo5LgRsrju0CXDx58mT22muvjX1f7aquro4ZM2aw2267MWzYsFqHI3Ub3ltS+/DektqH95a6mgEDBmz0OT05WV5WeuzfRPlA4LnyA6W5yA9W1PsxcGNmXhsRxwHfoegtng38jGJe8ylNBZGZs0t114kIAIYNG8bIka/anapT6MyxSV2Z95bUPry3pPbhvaWuojUf6nS7Bb42wtzSY+V8YSJiADCKRoZoV9Q7gWJe86mlQycB12TmlZl5G6XtpiKiJ3+fJUmSJKnL6bFJXGY+R5EM79dI8b5AAHc3dX5EbAZ8GzgzMxuS6nGs30s8m2K17E2rEbMkSZIkqWP02GS55Epgm4g4suL4acAa4DfNnHs+MBO4sOzYPGBS2etJwCrW33JKkiRJktTJdbs5yxFxPLBV6eVmQL+I+ELp9eLMLE9uvw4cDfwiIqZQJL+HAYcA5zS1Z3NEHEyxB/PemVlfVnQFcFlEXEDRa30WcGVFHUmSJElSJ9ftkmWKecMHVBw7p/T4DGU9wZm5KCLeAHwN+DAwDHgCODkzL2rs4hExELgI+G5m3ldR/HNgS+BkYDBwHcWWU5IkSZKkLqTbJcuZ+aaNrP8scOJG1F8ObNdEWVIs6nXuxsQgSZIkSepcevqcZUmSJEmSXsVkWZIkSZKkCibLkiRJkiRVMFmWJEmSJKmCybIkSZIkSRVMliVJkiRJqmCyLEmSJElSBZNlSZIkSZIqmCxLkiRJklTBZFmSJEmSpAomy5IkSZIkVTBZliRJkiSpgsmyJEmSJEkVTJYlSZIkSapgsixJkiRJUgWTZUmSJEmSKpgsS5IkSZJUwWRZkiRJkqQKJsuSJEmSJFUwWZYkSZIkqYLJsiRJkiRJFUyWJUmSJEmqYLIsSZIkSVIFk2VJkiRJkiqYLEuSJEmSVMFkWZIkSZKkCibLkiRJkiRVMFmWJEmSJKmCybIkSZIkSRVMliVJkiRJqmCyLEmSJElSBZNlSZIkSZIqmCxLkiRJklTBZFmSJEmSpAomy5IkSZIkVTBZliRJkiSpgsmyJEmSJEkVTJYlSZIkSapgsixJkiRJUgWTZUmSJEmSKpgsS5IkSZJUwWRZkiRJkqQKJsuSJEmSJFUwWZYkSZIkqYLJsiRJkiRJFXp8shwR746IeyJieUTMj4hfRcRWFXUOiIi7I+LliHgwIo5o5Dq9S9f5UcdFL0mSJElqDz06WY6IU4ErgeXAp4ELgIOBf0XEmFKd8cANQB3wGeAR4LcRsUfF5T4FjAE+2xGxS5IkSZLaT59aB1ArETEKOBe4F3hTZq4pHf8zcBfwFeBDwNuB3sC7MnNpRFwCPAUcVTqXUk/02cCJmflSR78XSZIkSVJ19eSe5cOAIcD3GhJlgMycBvwDODYi+gGDgeWZubRUXg8sKh1v8CPglsz8bUcFL0mSJElqPz22ZxnYu/T4r0bK/gUcAOwA3A6MiIjPA1dQDNPeDfgaFHOegTcCO7cmiNIw73EVh6cA/Pvf/6aurq41l203S5cu5fHHH2ft2rUMHjx4wydIahHvLal9eG9J7cN7S13Nww8/3PB0UEvP6cnJ8tjS45xGyhqOjcvMP0bElymGZf9f6fhPMvO3ETECOB/4YmY+08o4TgK+1FjBaaed1spLSpIkSZIasS3wt5ZU7MnJcsMnCisbKVtRXiczz46IHwITgVmZObdU/i1gHvDdiJgAfI+ix3oWcEZm3tqCOC4Fbqw4NgrYCbgHWNayt9NhdgEuBj4CPFjjWKTuxHtLah/eW1L78N5SVzOIIlH+Q0tP6MnJckMS2p9iNexyAyvqkJkvAi82vI6INwIfAPYrHboBeAY4FDgC+HNEvDYzZzUXRGbOBmY3UtTif8SOFBENTx/MzDtqGYvUnXhvSe3De0tqH95b6qJa1KPcoCcv8NXQO1w5XxiaH6JNRPSn+CTtwtKCYPtQfLr2qcy8BzgLmA+8t6oRS5IkSZI6RE9Olu8uPb6ukbLXAS8DjzZx7pkU3fhnlV43JNyzATIzKRLt8VWJVJIkSZLUoXpysnw9xTDrT0TEuuHoEbEnxerWV2XmqsqTImJH4Azg1Mx8uXR4XulxUqlOf2D7suOSJEmSpC6kx85Zzsz5pe2gLgBuiYhfAJsCnwaeB75YeU4UkzMuAX6fmVPLiu4EHgcuj4gLgbcDw4DftOubqI05wNk0MURdUqt5b0ntw3tLah/eW+r2ohgx3HNFxHuBzwA7UvQ0/xX4XGbObKTuR4FvAjtm5ryKstcCPwL2oljo67OZ2SkX6ZIkSZIkNa/HJ8uSJEmSJFXqyXOWJUmSJElqlMmyJEmSJEkVTJYlSZIkSapgsixJkiRJUgWTZUmSJEmSKpgsq8Ui4t0RcU9ELI+I+RHxq4jYqtZxSV1ZRAyJiLMi4sGIeDkiXoyIf0bE+2odm9TZRcTnIuK3EfFURGREPN2Ccw6OiD9GxIKIWBERMyPiyojo1wEhS11CRLwmIr4SEf8u/b+0JCKmR8SZETF4A+eeUrofMyJGd1TMUntw6yi1SEScCnwfuB24AtgU+BSwEtirct9pSRsWEb2A24B9gZ8BdwKDgeOB3YFzMvOLNQtQ6uQiIoGFwL3AFKAuM7dupv7ngK8BNwO/B+qALYA3Akdm5rL2jlnqCiLi68CpFPfJHcAq4EDgWOB+YN/MXN7IeWOARyg65IYAW2bmcx0Vt1RtJsvaoIgYBTwN/AfYJzPXlI7vCdwFXJaZH6pdhFLXFBH7Af8CLsjMT5cdHwg8RfE72k/lpSZExLaZ+VTp+YPAkKaS5Yg4CLgJODczz+y4KKWup/Q33hOZubji+FeBM4FTM/MHjZz3O2Ab4EHgfZgsq4tzGLZa4jCKTwe/15AoA2TmNOAfwLEOX5NaZXjpcb2RGaVP6xcB9nJJzWhIlFvoTGA+8GVYNwWid3vEJXV1mTmtMlEuuar0OKmyICIOp/ib8WPA2nYLTupAJstqib1Lj/9qpOxfwFBgh44LR+o27qIYBnp6RBwTEeMjYseIOB94LaU/6iW1TWmO5QEUUx2Oj4hngCXA0oi4PiK2rWmAUtcxtvT4QvnBiBgGXAhcnJl3dnhUUjvpU+sA1CU0/GKc00hZw7FxFHNYJLVQZi4sfRJ/Ca98Wg+wGDgsM/9Qi7ikbmgi0BvYB3gr8G1gGsXaAGcAe0fEbpn5QtOXkHq20kiMLwJrgF9WFJ9LkVd8rqPjktqTybJaYlDpcWUjZSsq6kjaOIuA+4BrKUZqbAKcDFwVEUdl5p9qGJvUXQwtPW4GfDQzLy69vrbUy/wT4NP4h77UnO9RLEj5hcx8rOFgaf2NjwHvb2LottRlOQxbLdEwb7J/I2UDK+pIaqGImESxyuhNmfm/mXltZv4U2B94BrgsIhq77yRtnIZVe+uBn1eUXU4xv/LADo1I6kJKC3udQvHB0tfKjvelGB11c2ZW9jZLXZ7JslpibulxXCNlzQ3RltS8TwMDgN+WH8zMlcB1wGhcD0Cqhob/oxaV7q91MnM1xcJfIzs8KqkLiIgvUyyQdznFyIzyrXQ+DuwIfDMitm74olgYFmB8RGzVkfFK1eQwbLXE3cBHgdcBj1eUvQ54GXi0o4OSuoGGD5v6NlLWcMzf01IbZebzEfE0sFVEDM7MpQ1lETGAYnh25f9vUo8XEV8CvgRcAZyYmfUVVbam6Hy7sYlL3EUxjW9Ae8UotSd7ltUS11MMs/5ERKz7w720B98bgasyc1WtgpO6sIdLjyeUH4yIocAxwFLgoQ6OSequLgeCoies3Mcp/h66ocMjkjqxiPgixa4MvwROaCRRBrgUOKKRr5tL5SdS/H8mdUmx/kgKqXER8UngAuB24BfAphRDSFcDe2bm3KbPltSY0tC0e4ERwJXAP0vPTwK2A/5fZn6ndhFKnVtEHA80DPH8H6Af0HDPLM7MC8vqDqVYI2An4DKK1bD3oLjfHgL2K+9xlnqyiPg4xVZQsyhWwK7cN/n5zPxrM+f/DPgAsGVmPtdecUrtzWRZLRYR7wU+QzE3ZRnwV+BzmTmzpoFJXVhEjKNYgffNwASKP0imAxdm5m9qGJrU6UXELRT7JzfmmczcuqL+SOBsip6vzYHngN8BX3YVX+kVZcluU27NzDe14HyTZXVpJsuSJEmSJFVwzrIkSZIkSRVMliVJkiRJqmCyLEmSJElSBZNlSZIkSZIqmCxLkiRJklTBZFmSJEmSpAomy5IkSZIkVTBZliRJkiSpgsmyJEmSJEkVTJYlSZIkSapgsixJkiRJUgWTZUmStEERcUtEPF3rONoiIp6OiFtqHYckqWswWZYkqZUiYlhEnBUR90bEkohYFhEPR8Q3I2LzWsfX3iLi8Ij4cq3jKBcRn4qIE2odhySp64vMrHUMkiR1ORHxGuBGYCvgd8DNwGpgX+B9wEvAIZl5Z82CrKKI6Efxd8PKsmM/Az6QmVGzwCqUer+fzsw3NVLWH8jMXNXRcUmSup4+tQ5AkqSuJiIGAb8HxgKHZuYNZcUXR8QPgZuAqRExKTNfqFGcQzLz5Wpcq6MTzFJiuzYz11TrmuWJviRJG+IwbEmSNt5JwGuA8ysSZQAycxrweWBz4H8bjkfECRGREfGmynOamhMcEXtGxLURMT8iVkbEYxFxZkT0aez8iNg2Iq6OiIXAkojYvdTm/zX2RiJiamn4+PDm3nBlfKXnHyg9z7KvN5XV2T4ifhERz0bEqlJ834qIwRXX/lnp3M0i4rKIeB5YDowrlZ8SEX+JiLml6zwbEVdExNZl19g6IpKip/+A8pjKY25sznJEHBoRt5WG0i+NiLsi4t1NfQ8iYlxEXBURi0r1byyNNJAkdSP2LEuStPGOLj1e0kydnwEXAEdRljBvjIh4B3At8ATwHWAhsB/wFWAycEzFKUOAW4F/AmcCm2fmfRExDTghIr6YmWvLrj8aeDtwZWa+tJHhfQo4DdgfOL7s+COla08B/g4sBn4MzAV2BT4BvD4iDsjM1RXX/CswDzgHGAw09Ip/BvhXqXwxsAvwIeCgUs/9AuDFUhznA/OBRj8cqBQRHynF9zhwLrCKYhj9lRGxTWZ+reKUwRTf4zsoPhDZBvgkcH1E7FL+/ZUkdW0my5IkbbxdgCWZ+URTFTJzWUQ8BuzSmuHQETEA+ClwJ3BQ2XDkH0fEDOC8iHhTZt5Sdtoo4CuZ+aWKy11c+no78Iey4x+g+FvgJxsTG0BmXhcRhwP7Z+YVjVS5DHgO2DMzl5S9r79TzPF+L8UHCuVmZOYHGrnWrpm5tPxAREylGOp+EvDNUvkVEfFV4PkmYlpPRGwCnAc8DezV8IFBaRj9HcDZEXFFZs4qO21T4FuZ+c2y67wIfBN4C8U8dklSN+AwbEmSNt4wigW8NqShztBWtHEwxTDuy4FNImLThi/gj6U6b23kvPMaOfYrYAlFYlnug8BjmXlbK+JrUkRMouhF/jXQvyL2fwJLaXnsNCTKEdErIoaXrjOD4vu7TxtCPZiip/j75T3rmbkM+DbFBwnvqjinHvhexbG/lx63b0MskqROxmRZkqSNVwc0O8e3ZDhFcjW/FW3sWHq8hGKIcfnXo6WyLSrOebGx4dSlXu0rgUMiYguAiNifYt71pa2IbUMaYv8ir479BYoEtTJ2KIZCv0pEHFSaa7yUYhh2w7WGAyPaEOe2pceHGil7oKJOg3mZuaLi2ILS46g2xCJJ6mQchi1J0sZ7EHhjRExsaih2aRGr1wLPlM3NbW6/xsr/kxu2Y/oscE8T58yreL2smev/GPgoxdDrb1L0Mq8Gft7MOa3VEPsFwKsWQCtZVHmg1KO7/oUi9gb+QjFv+7PATIrFv5Ki57otH/w3t+VVU2XNzUnuNFtoSZLazmRZkqSNdw3wRuAjwOlN1DkB6AuUz51dWHoc2Uj9bSiS1wb/KT0uy8ybWh1pSWmhr3uAkyLiIorFwX7fxm2tmkr+G2Kvr0Ls7wZ6A2/PzJkNB0sfRjTWq9zcBxKVniw97syr5xrvXFFHktTDOAxbkqSN9xOKhPBTpRWr1xMRe1Ksxvws8IOyooYk8i0V9d8NjKm4zI0UQ5ZPL83RrWxjYERs7FzoiymGXv8AGEQrFvaq8HIplsqkdTrFMOaPRMTEypMiok9ENPaBQWMaenIre20/T+N/x7xMy4dm/5ViaPepETGsLL4BFCtwr6HYT1uS1APZsyxJ0kYqrXT9LuDPwB8i4hrgZorkah+KrYcWA4dl5vNl5z0WETcBH42IoEgqJwNHUAwz7lvRxvuB64BHI+Iyijm9mwA7AEeWzrtlI0K/kmLhqvcBs2n7ys13AqcCP4iIP1H0jP89M18oxf53YHop9ocoEvSJpdg/x6tXw27MtcCngT9GxMUUWzsdTLGAWGNzwe8EPhgRXwYeAzIzf93YhTNzcUR8BrgIuDsiflp6D++j+Hc5s2IlbElSD2KyLElSK5QS390o9tg9kmJbpsGl4oeAN2Tm4kZOPR74PsXWSccDtwEHAj8Ctq5o48aI2Itiru57gc0o5vo+SbFy9P0bGfPLEfEriuHjP83M+o05vxG/AqYA/w0cR9HTeyDwQmZOj4jdKZLidwEfo1iR+2mKJPlvLYz59og4CjiLYv/l5RRbRh0A/KORU75Asb3Tp3hlEbZGk+XS9X8cEc9SDKc/i6IH+0HgvZl5ZUtilCR1T5G5MVN7JElSUyKiD/Bb4HDgM5nZ6FZItRQRFwInA9tm5jO1jkeSpM7KZFmSpCqKiH4UQ4ffAZySmT+qcUjrRMRwiuHXt2XmO2sdjyRJnZnJsiRJ3VxE7ALsTrFt1EEUQ8T/VduoJEnq3FwNW5Kk7u9o4HKKhcFOMVGWJGnD7FmWJEmSJKmCPcuSJEmSJFUwWZYkSZIkqYLJsiRJkiRJFUyWJUmSJEmqYLIsSZIkSVIFk2VJkiRJkiqYLEuSJEmSVMFkWZIkSZKkCibLkiRJkiRVMFmWJEmSJKmCybIkSZIkSRX+P5gkKY322gJmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1105x780 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(8.5, 6), dpi=130)\n",
    "ax.plot(performance_history_abortion,label=\"10 Initial training set\")\n",
    "ax.scatter(range(len(performance_history_abortion)), performance_history_abortion, s=13,label = \"10 Initial training set\")\n",
    "ax.plot(performance_history_abortion1,label = \"50 Initial training set\")\n",
    "ax.scatter(range(len(performance_history_abortion1)), performance_history_abortion1, s=13,label = \"50 Initial training set\")\n",
    "ax.plot(performance_history_abortion2,label = \"100 Initial training set\")\n",
    "ax.scatter(range(len(performance_history_abortion2)), performance_history_abortion2, s=13,label = \"100 Initial training set\")\n",
    "\n",
    "ax.xaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=5, integer=True))\n",
    "ax.yaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=10))\n",
    "ax.yaxis.set_major_formatter(mpl.ticker.PercentFormatter(xmax=1))\n",
    "\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "ax.set_title('Incremental classification accuracy')\n",
    "ax.set_xlabel('Query iteration')\n",
    "ax.set_ylabel('Classification Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818a9522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analytics_course0",
   "language": "python",
   "name": "data_analytics_course0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
