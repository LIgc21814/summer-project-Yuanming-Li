{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e57c9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import pdb\n",
    "import logging\n",
    "import re\n",
    "from gensim import parsing\n",
    "import gensim\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abbb1a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baal.active import get_heuristic\n",
    "from baal.active.active_loop import ActiveLearningLoop\n",
    "from baal.active.dataset.nlp_datasets import active_huggingface_dataset, HuggingFaceDatasets\n",
    "from baal.bayesian.dropout import patch_module\n",
    "from baal.transformers_trainer_wrapper import BaalTransformersTrainer\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e673dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e677fe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-tiny\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b0d5bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"transformer_checkpoints\",  # specify the directory where models weights will be saved a certain points during training (checkpoints)\n",
    "    num_train_epochs=1,  # change this if it is taking too long on your computer\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15edeca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(a):\n",
    "    rotated = list(zip(*a[::-1]))\n",
    "    median0 = []\n",
    "    min0 = []\n",
    "    max0 = []\n",
    "    for i in range(len(rotated)):\n",
    "        median0.append(np.median(rotated[i]))\n",
    "        min0.append(np.min(rotated[i]))\n",
    "        max0.append(np.max(rotated[i]))\n",
    "    return median0,min0,max0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37e7bf5",
   "metadata": {},
   "source": [
    "# Abortion    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dec5d2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_abortion\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset with 587 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_abortion\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset with 66 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_abortion\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset with 280 instances loaded\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "cache_dir = \"./data_cache\"\n",
    "\n",
    "train_dataset_abortion = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_abortion\",\n",
    "    split=\"train\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Training dataset with {len(train_dataset_abortion)} instances loaded\")\n",
    "\n",
    "val_dataset_abortion = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_abortion\",\n",
    "    split=\"validation\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Validation dataset with {len(val_dataset_abortion)} instances loaded\")\n",
    "\n",
    "test_dataset_abortion = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_abortion\",\n",
    "    split=\"test\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Test dataset with {len(test_dataset_abortion)} instances loaded\")\n",
    "\n",
    "num_classes = np.unique(train_dataset_abortion['label']).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4cd5835e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/config.json from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\3cf34679007e9fe5d0acd644dcc1f4b26bec5cbc9612364f6da7262aed4ef7a4.a5a11219cf90aae61ff30e1658ccf2cb4aa84d6b6e947336556f887c9828dc6d\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-tiny\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/pytorch_model.bin from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\1ee037c9e1a220d5c814779ffe697080d1e6f5b1602e16cf6061aaae41a082c5.038e1aed90492a59d2283f9c44c9fe3ee2380495ff1e7fefb3f1f04af3b685b5\n",
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_original = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\", num_labels=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03855dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_mc_abortion1= []\n",
    "query_history = []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "while mcrun != 5:\n",
    "    n_labeled_examples = np.unique(train_dataset_abortion['text']).size\n",
    "    training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "    print(training_indices0)\n",
    "    active_set_abortion =active_huggingface_dataset(train_dataset_abortion,tokenizer,'label','text')\n",
    "    valid_set_abortion = HuggingFaceDatasets(test_dataset_abortion,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_abortion.can_label = False\n",
    "    active_set_abortion.label(training_indices0)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_abortion,\n",
    "            eval_dataset=valid_set_abortion,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_abortion = ActiveLearningLoop(active_set_abortion,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_abortion=[unqueried_score]\n",
    "    query = [3]\n",
    "    num = 3\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_abortion.step()\n",
    "        num = num+20\n",
    "        print(num)\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_abortion.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_abortion),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_abortion.append(eval_metrics['eval_accuracy'])\n",
    "        query.append(num)\n",
    "    print(performance_history_abortion)\n",
    "    print(query)\n",
    "    active_mc_abortion1.append(performance_history_abortion)\n",
    "    query_history.append(query)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e7ca6e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 36 198  92]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:26:02.293000Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 29.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:26:06.991568Z [info     ] Start Predict                  dataset=564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:02<00:00, 31.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:26:11.561243Z [info     ] Start Predict                  dataset=544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 33.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:26:16.243012Z [info     ] Start Predict                  dataset=524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 33.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:26:20.973828Z [info     ] Start Predict                  dataset=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 33.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:26:25.923066Z [info     ] Start Predict                  dataset=484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 33.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:26:31.255647Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 33.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:26:36.460155Z [info     ] Start Predict                  dataset=444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 32.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:26:42.151012Z [info     ] Start Predict                  dataset=424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 32.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:26:47.882349Z [info     ] Start Predict                  dataset=404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 33.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:26:53.848038Z [info     ] Start Predict                  dataset=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 32.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:26:59.929320Z [info     ] Start Predict                  dataset=364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 33.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:27:06.114671Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 32.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:27:12.542783Z [info     ] Start Predict                  dataset=324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 32.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:27:19.254052Z [info     ] Start Predict                  dataset=304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 32.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:27:26.020487Z [info     ] Start Predict                  dataset=284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 33.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:27:32.983793Z [info     ] Start Predict                  dataset=264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 32.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:27:40.490740Z [info     ] Start Predict                  dataset=244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 33.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:27:47.812090Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 32.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:27:55.343958Z [info     ] Start Predict                  dataset=204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 34.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:28:02.941414Z [info     ] Start Predict                  dataset=184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 33.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:28:10.771061Z [info     ] Start Predict                  dataset=164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 32.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:28:19.134897Z [info     ] Start Predict                  dataset=144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 33.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:28:27.254016Z [info     ] Start Predict                  dataset=124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 31.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:28:36.030194Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 29.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:28:44.594009Z [info     ] Start Predict                  dataset=84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 36.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:28:53.095312Z [info     ] Start Predict                  dataset=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 36.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:29:01.970515Z [info     ] Start Predict                  dataset=44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 34.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:29:11.001801Z [info     ] Start Predict                  dataset=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 32.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:29:20.378910Z [info     ] Start Predict                  dataset=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 45.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603\n",
      "[0.45357142857142857, 0.42142857142857143, 0.4785714285714286, 0.5178571428571429, 0.475, 0.45, 0.4857142857142857, 0.5178571428571429, 0.6142857142857143, 0.575, 0.6, 0.5964285714285714, 0.6321428571428571, 0.6071428571428571, 0.6642857142857143, 0.6642857142857143, 0.6535714285714286, 0.65, 0.6678571428571428, 0.6607142857142857, 0.6857142857142857, 0.6678571428571428, 0.6714285714285714, 0.6714285714285714, 0.6714285714285714, 0.6714285714285714, 0.6571428571428571, 0.6785714285714286, 0.675, 0.6642857142857143, 0.6678571428571428]\n",
      "[3, 23, 43, 63, 83, 103, 123, 143, 163, 183, 203, 223, 243, 263, 283, 303, 323, 343, 363, 383, 403, 423, 443, 463, 483, 503, 523, 543, 563, 583, 603]\n",
      "[535  69 215]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:29:23.901593Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 31.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:29:28.278245Z [info     ] Start Predict                  dataset=564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:02<00:00, 32.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:29:32.760080Z [info     ] Start Predict                  dataset=544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 33.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:29:37.330423Z [info     ] Start Predict                  dataset=524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 33.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:29:42.172539Z [info     ] Start Predict                  dataset=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 32.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:29:47.112852Z [info     ] Start Predict                  dataset=484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 32.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:29:52.620039Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 32.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:29:58.384761Z [info     ] Start Predict                  dataset=444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 33.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:30:03.999486Z [info     ] Start Predict                  dataset=424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 32.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:30:09.652796Z [info     ] Start Predict                  dataset=404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 32.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:30:15.698795Z [info     ] Start Predict                  dataset=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 33.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:30:21.796952Z [info     ] Start Predict                  dataset=364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 32.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:30:28.075735Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 33.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:30:34.755921Z [info     ] Start Predict                  dataset=324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 33.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:30:41.385860Z [info     ] Start Predict                  dataset=304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:30:48.202306Z [info     ] Start Predict                  dataset=284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 34.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:30:55.241198Z [info     ] Start Predict                  dataset=264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 31.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:31:02.497466Z [info     ] Start Predict                  dataset=244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 34.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:31:09.760694Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 31.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:31:17.176934Z [info     ] Start Predict                  dataset=204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 33.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:31:24.772298Z [info     ] Start Predict                  dataset=184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 31.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:31:32.454084Z [info     ] Start Predict                  dataset=164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 32.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:31:40.618049Z [info     ] Start Predict                  dataset=144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 31.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:31:48.815221Z [info     ] Start Predict                  dataset=124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 34.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:31:57.160338Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 34.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:32:05.442925Z [info     ] Start Predict                  dataset=84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 36.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:32:14.173328Z [info     ] Start Predict                  dataset=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 35.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:32:22.853773Z [info     ] Start Predict                  dataset=44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 35.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:32:31.849658Z [info     ] Start Predict                  dataset=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 32.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:32:41.363112Z [info     ] Start Predict                  dataset=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 47.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603\n",
      "[0.4607142857142857, 0.4392857142857143, 0.5142857142857142, 0.5678571428571428, 0.5178571428571429, 0.5928571428571429, 0.5464285714285714, 0.5964285714285714, 0.6142857142857143, 0.5964285714285714, 0.6285714285714286, 0.6357142857142857, 0.6428571428571429, 0.6392857142857142, 0.6464285714285715, 0.6785714285714286, 0.6571428571428571, 0.6535714285714286, 0.6714285714285714, 0.6678571428571428, 0.6821428571428572, 0.6607142857142857, 0.6571428571428571, 0.6642857142857143, 0.6714285714285714, 0.6607142857142857, 0.675, 0.6571428571428571, 0.675, 0.6678571428571428, 0.6642857142857143]\n",
      "[3, 23, 43, 63, 83, 103, 123, 143, 163, 183, 203, 223, 243, 263, 283, 303, 323, 343, 363, 383, 403, 423, 443, 463, 483, 503, 523, 543, 563, 583, 603]\n",
      "[535  69 215]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:32:44.845277Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 32.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:32:48.994948Z [info     ] Start Predict                  dataset=564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:02<00:00, 33.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:32:53.380914Z [info     ] Start Predict                  dataset=544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 32.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:32:57.929361Z [info     ] Start Predict                  dataset=524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 33.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:33:02.961095Z [info     ] Start Predict                  dataset=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 33.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:33:07.992647Z [info     ] Start Predict                  dataset=484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 33.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:33:13.091988Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 32.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:33:18.304850Z [info     ] Start Predict                  dataset=444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 32.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:33:23.899802Z [info     ] Start Predict                  dataset=424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 32.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:33:29.630196Z [info     ] Start Predict                  dataset=404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 34.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:33:35.544833Z [info     ] Start Predict                  dataset=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 32.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:33:41.709453Z [info     ] Start Predict                  dataset=364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 33.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:33:48.057293Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 33.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:33:54.310414Z [info     ] Start Predict                  dataset=324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 33.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:34:00.903995Z [info     ] Start Predict                  dataset=304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 32.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:34:07.817341Z [info     ] Start Predict                  dataset=284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 32.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:34:14.835790Z [info     ] Start Predict                  dataset=264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 32.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:34:22.030432Z [info     ] Start Predict                  dataset=244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 34.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:34:29.228816Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 32.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:34:36.707558Z [info     ] Start Predict                  dataset=204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 34.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:34:44.349825Z [info     ] Start Predict                  dataset=184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 31.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:34:52.086702Z [info     ] Start Predict                  dataset=164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:35:00.331977Z [info     ] Start Predict                  dataset=144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 30.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:35:08.497848Z [info     ] Start Predict                  dataset=124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 33.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:35:16.683629Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 35.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:35:25.043300Z [info     ] Start Predict                  dataset=84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 34.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:35:33.739304Z [info     ] Start Predict                  dataset=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 28.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:35:42.572793Z [info     ] Start Predict                  dataset=44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 37.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:35:51.582274Z [info     ] Start Predict                  dataset=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 38.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:36:00.946873Z [info     ] Start Predict                  dataset=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 62.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603\n",
      "[0.4607142857142857, 0.4392857142857143, 0.5142857142857142, 0.5678571428571428, 0.5178571428571429, 0.5928571428571429, 0.5464285714285714, 0.5964285714285714, 0.6142857142857143, 0.5964285714285714, 0.6285714285714286, 0.6357142857142857, 0.6428571428571429, 0.6392857142857142, 0.6464285714285715, 0.6785714285714286, 0.6571428571428571, 0.6535714285714286, 0.6714285714285714, 0.6678571428571428, 0.6821428571428572, 0.6607142857142857, 0.6571428571428571, 0.6642857142857143, 0.6714285714285714, 0.6607142857142857, 0.675, 0.6571428571428571, 0.675, 0.6678571428571428, 0.6642857142857143]\n",
      "[3, 23, 43, 63, 83, 103, 123, 143, 163, 183, 203, 223, 243, 263, 283, 303, 323, 343, 363, 383, 403, 423, 443, 463, 483, 503, 523, 543, 563, 583, 603]\n",
      "[535  69 215]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:36:04.386759Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 33.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:36:08.597368Z [info     ] Start Predict                  dataset=564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:02<00:00, 33.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:36:12.997944Z [info     ] Start Predict                  dataset=544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 32.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:36:17.563090Z [info     ] Start Predict                  dataset=524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:02<00:00, 32.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:36:22.411437Z [info     ] Start Predict                  dataset=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 33.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:36:27.362311Z [info     ] Start Predict                  dataset=484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 32.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:36:32.735234Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 32.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:36:38.088465Z [info     ] Start Predict                  dataset=444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 32.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:36:43.660100Z [info     ] Start Predict                  dataset=424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 32.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:36:49.462761Z [info     ] Start Predict                  dataset=404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 33.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:36:55.381603Z [info     ] Start Predict                  dataset=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 33.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:37:01.442059Z [info     ] Start Predict                  dataset=364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 33.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:37:07.724259Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 32.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:37:14.322099Z [info     ] Start Predict                  dataset=324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 32.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:37:21.069558Z [info     ] Start Predict                  dataset=304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 32.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:37:28.016477Z [info     ] Start Predict                  dataset=284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 32.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:37:35.102579Z [info     ] Start Predict                  dataset=264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 30.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:37:42.229330Z [info     ] Start Predict                  dataset=244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 33.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:37:49.375878Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 34.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:37:56.728636Z [info     ] Start Predict                  dataset=204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 33.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:38:04.293737Z [info     ] Start Predict                  dataset=184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 33.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:38:12.102605Z [info     ] Start Predict                  dataset=164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 34.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:38:20.472936Z [info     ] Start Predict                  dataset=144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 33.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:38:28.662732Z [info     ] Start Predict                  dataset=124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 35.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:38:36.915028Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 31.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:38:45.391505Z [info     ] Start Predict                  dataset=84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 35.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:38:53.970788Z [info     ] Start Predict                  dataset=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 36.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:39:02.801210Z [info     ] Start Predict                  dataset=44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 35.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:39:11.689756Z [info     ] Start Predict                  dataset=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 33.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:39:20.896024Z [info     ] Start Predict                  dataset=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 55.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603\n",
      "[0.4607142857142857, 0.4392857142857143, 0.5142857142857142, 0.5678571428571428, 0.5178571428571429, 0.5928571428571429, 0.5464285714285714, 0.5964285714285714, 0.6142857142857143, 0.5964285714285714, 0.6285714285714286, 0.6357142857142857, 0.6428571428571429, 0.6392857142857142, 0.6464285714285715, 0.6785714285714286, 0.6571428571428571, 0.6535714285714286, 0.6714285714285714, 0.6678571428571428, 0.6821428571428572, 0.6607142857142857, 0.6571428571428571, 0.6642857142857143, 0.6714285714285714, 0.6607142857142857, 0.675, 0.6571428571428571, 0.675, 0.6678571428571428, 0.6642857142857143]\n",
      "[3, 23, 43, 63, 83, 103, 123, 143, 163, 183, 203, 223, 243, 263, 283, 303, 323, 343, 363, 383, 403, 423, 443, 463, 483, 503, 523, 543, 563, 583, 603]\n",
      "[535  69 215]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:39:24.378219Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 33.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:39:28.659061Z [info     ] Start Predict                  dataset=564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:02<00:00, 32.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:39:33.394946Z [info     ] Start Predict                  dataset=544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 32.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:39:38.444265Z [info     ] Start Predict                  dataset=524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 33.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:39:43.243713Z [info     ] Start Predict                  dataset=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 33.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:39:48.074372Z [info     ] Start Predict                  dataset=484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 32.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:39:53.635115Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 33.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:39:59.054011Z [info     ] Start Predict                  dataset=444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 32.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:40:04.664686Z [info     ] Start Predict                  dataset=424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 33.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:40:10.380423Z [info     ] Start Predict                  dataset=404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 33.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:40:16.259943Z [info     ] Start Predict                  dataset=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 32.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:40:22.341025Z [info     ] Start Predict                  dataset=364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 33.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:40:28.570072Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 33.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:40:34.942922Z [info     ] Start Predict                  dataset=324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 33.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:40:41.652193Z [info     ] Start Predict                  dataset=304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:40:48.449851Z [info     ] Start Predict                  dataset=284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 33.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:40:55.463135Z [info     ] Start Predict                  dataset=264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 32.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:41:02.695104Z [info     ] Start Predict                  dataset=244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 33.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:41:09.912442Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 33.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:41:17.356850Z [info     ] Start Predict                  dataset=204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 32.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:41:25.057325Z [info     ] Start Predict                  dataset=184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 33.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:41:32.901542Z [info     ] Start Predict                  dataset=164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 31.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:41:40.998796Z [info     ] Start Predict                  dataset=144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 30.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:41:49.146039Z [info     ] Start Predict                  dataset=124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 33.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:41:57.542257Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 33.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:42:05.991396Z [info     ] Start Predict                  dataset=84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 33.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:42:14.753098Z [info     ] Start Predict                  dataset=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 33.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:42:23.650099Z [info     ] Start Predict                  dataset=44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 36.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:42:32.864597Z [info     ] Start Predict                  dataset=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 32.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:42:42.049017Z [info     ] Start Predict                  dataset=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 50.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603\n",
      "[0.4607142857142857, 0.4392857142857143, 0.5142857142857142, 0.5678571428571428, 0.5178571428571429, 0.5928571428571429, 0.5464285714285714, 0.5964285714285714, 0.6142857142857143, 0.5964285714285714, 0.6285714285714286, 0.6357142857142857, 0.6428571428571429, 0.6392857142857142, 0.6464285714285715, 0.6785714285714286, 0.6571428571428571, 0.6535714285714286, 0.6714285714285714, 0.6678571428571428, 0.6821428571428572, 0.6607142857142857, 0.6571428571428571, 0.6642857142857143, 0.6714285714285714, 0.6607142857142857, 0.675, 0.6571428571428571, 0.675, 0.6678571428571428, 0.6642857142857143]\n",
      "[3, 23, 43, 63, 83, 103, 123, 143, 163, 183, 203, 223, 243, 263, 283, 303, 323, 343, 363, 383, 403, 423, 443, 463, 483, 503, 523, 543, 563, 583, 603]\n"
     ]
    }
   ],
   "source": [
    "active_mc_abortion1= []\n",
    "query_history = []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "while mcrun != 5:\n",
    "    n_labeled_examples = np.unique(train_dataset_abortion['text']).size\n",
    "    training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "    print(training_indices0)\n",
    "    active_set_abortion =active_huggingface_dataset(train_dataset_abortion,tokenizer,'label','text')\n",
    "    valid_set_abortion = HuggingFaceDatasets(test_dataset_abortion,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_abortion.can_label = False\n",
    "    active_set_abortion.label(training_indices0)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_abortion,\n",
    "            eval_dataset=valid_set_abortion,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_abortion = ActiveLearningLoop(active_set_abortion,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_abortion=[unqueried_score]\n",
    "    query = [3]\n",
    "    num = 3\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_abortion.step()\n",
    "        num = num+20\n",
    "        print(num)\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_abortion.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_abortion),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_abortion.append(eval_metrics['eval_accuracy'])\n",
    "        query.append(num)\n",
    "    print(performance_history_abortion)\n",
    "    print(query)\n",
    "    active_mc_abortion1.append(performance_history_abortion)\n",
    "    query_history.append(query)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6092bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_abortion1, min_abortion1,max_abortion1 = calculate(active_mc_abortion1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bc83aee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[488 442 472]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='595' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 01:51]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:42:45.626158Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 32.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:42:50.158776Z [info     ] Start Predict                  dataset=544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 32.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:42:55.223747Z [info     ] Start Predict                  dataset=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 32.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:43:00.522996Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 32.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:43:06.260089Z [info     ] Start Predict                  dataset=424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 33.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:43:12.950159Z [info     ] Start Predict                  dataset=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 31.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:43:19.282320Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 32.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:43:25.996720Z [info     ] Start Predict                  dataset=304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 33.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:43:32.944509Z [info     ] Start Predict                  dataset=264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 31.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:43:40.540752Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 32.89it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:43:48.194424Z [info     ] Start Predict                  dataset=184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 33.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:43:56.218823Z [info     ] Start Predict                  dataset=144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 32.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:44:06.047883Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 33.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:44:16.477606Z [info     ] Start Predict                  dataset=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 35.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:44:25.410012Z [info     ] Start Predict                  dataset=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 35.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3964285714285714, 0.3821428571428571, 0.5464285714285714, 0.5964285714285714, 0.5678571428571428, 0.6464285714285715, 0.6142857142857143, 0.6321428571428571, 0.6571428571428571, 0.6607142857142857, 0.6428571428571429, 0.6678571428571428, 0.6642857142857143, 0.675, 0.6464285714285715, 0.6714285714285714]\n",
      "[329 188  94]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='595' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 01:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:44:38.022426Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 32.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:44:42.559690Z [info     ] Start Predict                  dataset=544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 32.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:44:47.983763Z [info     ] Start Predict                  dataset=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 31.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:44:55.414473Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 31.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:45:01.163551Z [info     ] Start Predict                  dataset=424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 32.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:45:07.046997Z [info     ] Start Predict                  dataset=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 32.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:45:13.361513Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 33.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:45:19.895792Z [info     ] Start Predict                  dataset=304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 33.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:45:26.955940Z [info     ] Start Predict                  dataset=264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 33.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:45:34.336797Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 31.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:45:42.204971Z [info     ] Start Predict                  dataset=184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 34.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:45:50.068930Z [info     ] Start Predict                  dataset=144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 34.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:45:58.293389Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 32.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:46:07.074693Z [info     ] Start Predict                  dataset=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 35.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:46:16.059119Z [info     ] Start Predict                  dataset=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 34.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39285714285714285, 0.36428571428571427, 0.5107142857142857, 0.5892857142857143, 0.6214285714285714, 0.6178571428571429, 0.6535714285714286, 0.6607142857142857, 0.5928571428571429, 0.675, 0.6678571428571428, 0.675, 0.675, 0.6571428571428571, 0.65, 0.6714285714285714]\n",
      "[329 188  94]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='595' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 01:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:46:28.900625Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 33.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:46:33.350174Z [info     ] Start Predict                  dataset=544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 33.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:46:38.230837Z [info     ] Start Predict                  dataset=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 32.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:46:43.551929Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 31.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:46:49.893531Z [info     ] Start Predict                  dataset=424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 33.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:46:55.876964Z [info     ] Start Predict                  dataset=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 33.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:47:02.161304Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 32.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:47:08.888178Z [info     ] Start Predict                  dataset=304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 33.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:47:15.962863Z [info     ] Start Predict                  dataset=264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 32.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:47:23.216774Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 32.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:47:30.931800Z [info     ] Start Predict                  dataset=184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 30.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:47:39.009289Z [info     ] Start Predict                  dataset=144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 33.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:47:47.379375Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 33.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:47:56.038943Z [info     ] Start Predict                  dataset=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 33.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:48:05.318125Z [info     ] Start Predict                  dataset=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 31.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39285714285714285, 0.36428571428571427, 0.5107142857142857, 0.5892857142857143, 0.6214285714285714, 0.6178571428571429, 0.6535714285714286, 0.6607142857142857, 0.5928571428571429, 0.675, 0.6678571428571428, 0.675, 0.675, 0.6571428571428571, 0.65, 0.6714285714285714]\n",
      "[329 188  94]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='595' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 01:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:48:18.348221Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 32.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:48:22.819470Z [info     ] Start Predict                  dataset=544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 33.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:48:27.700697Z [info     ] Start Predict                  dataset=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 33.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:48:33.480509Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 33.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:48:39.107736Z [info     ] Start Predict                  dataset=424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 33.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:48:45.055751Z [info     ] Start Predict                  dataset=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 33.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:48:51.302651Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 33.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:48:58.008035Z [info     ] Start Predict                  dataset=304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 34.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:49:05.115667Z [info     ] Start Predict                  dataset=264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 33.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:49:12.462137Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 32.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:49:20.076240Z [info     ] Start Predict                  dataset=184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 30.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:49:28.023508Z [info     ] Start Predict                  dataset=144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 31.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:49:36.321814Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 33.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:49:44.899086Z [info     ] Start Predict                  dataset=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 34.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:49:53.864836Z [info     ] Start Predict                  dataset=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 37.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39285714285714285, 0.36428571428571427, 0.5107142857142857, 0.5892857142857143, 0.6214285714285714, 0.6178571428571429, 0.6535714285714286, 0.6607142857142857, 0.5928571428571429, 0.675, 0.6678571428571428, 0.675, 0.675, 0.6571428571428571, 0.65, 0.6714285714285714]\n",
      "[329 188  94]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='595' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 01:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:50:06.594944Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 33.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:50:11.143444Z [info     ] Start Predict                  dataset=544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 33.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:50:16.092745Z [info     ] Start Predict                  dataset=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 33.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:50:21.390021Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 32.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:50:27.103622Z [info     ] Start Predict                  dataset=424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 32.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:50:33.185951Z [info     ] Start Predict                  dataset=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 33.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:50:39.574892Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 32.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:50:46.430495Z [info     ] Start Predict                  dataset=304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 33.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:50:53.348958Z [info     ] Start Predict                  dataset=264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 31.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:51:00.764098Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 32.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:51:08.557317Z [info     ] Start Predict                  dataset=184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 32.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:51:16.591168Z [info     ] Start Predict                  dataset=144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 33.89it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:51:25.018458Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 33.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:51:33.865481Z [info     ] Start Predict                  dataset=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 34.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:51:43.095810Z [info     ] Start Predict                  dataset=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 36.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39285714285714285, 0.36428571428571427, 0.5107142857142857, 0.5892857142857143, 0.6214285714285714, 0.6178571428571429, 0.6535714285714286, 0.6607142857142857, 0.5928571428571429, 0.675, 0.6678571428571428, 0.675, 0.675, 0.6571428571428571, 0.65, 0.6714285714285714]\n"
     ]
    }
   ],
   "source": [
    "active_mc_abortion2= []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "query_history_abortion2 = []\n",
    "while mcrun != 5:\n",
    "    n_labeled_examples = np.unique(train_dataset_abortion['text']).size\n",
    "    training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "    print(training_indices0)\n",
    "    active_set_abortion =active_huggingface_dataset(train_dataset_abortion,tokenizer,'label','text')\n",
    "    valid_set_abortion = HuggingFaceDatasets(test_dataset_abortion,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_abortion.can_label = False\n",
    "    active_set_abortion.label(training_indices0)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_abortion,\n",
    "            eval_dataset=valid_set_abortion,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_abortion = ActiveLearningLoop(active_set_abortion,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 40, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_abortion=[unqueried_score]\n",
    "    query = [3]\n",
    "    num = 3\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_abortion.step()\n",
    "        num = num + 40\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_abortion.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_abortion),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_abortion.append(eval_metrics['eval_accuracy'])\n",
    "        query.append(num)\n",
    "    print(performance_history_abortion)\n",
    "    active_mc_abortion2.append(performance_history_abortion)\n",
    "    query_history_abortion2.append(query)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "635de9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_abortion2, min_abortion2,max_abortion2 = calculate(active_mc_abortion2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "10c7f225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10 181 409]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='420' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 01:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:51:56.009045Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 33.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:52:01.138680Z [info     ] Start Predict                  dataset=524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:02<00:00, 27.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:52:07.058481Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 32.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:52:13.033516Z [info     ] Start Predict                  dataset=404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 33.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:52:19.431455Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 33.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:52:26.396730Z [info     ] Start Predict                  dataset=284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 33.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:52:33.879582Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 31.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:52:41.957146Z [info     ] Start Predict                  dataset=164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 29.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:52:51.307127Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 26.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:53:01.572345Z [info     ] Start Predict                  dataset=44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 33.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37142857142857144, 0.3357142857142857, 0.4607142857142857, 0.5964285714285714, 0.5857142857142857, 0.6607142857142857, 0.6678571428571428, 0.6571428571428571, 0.6535714285714286, 0.6714285714285714, 0.6571428571428571]\n",
      "[489  72 508]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='420' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 01:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:53:16.149822Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 32.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:53:21.448048Z [info     ] Start Predict                  dataset=524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 33.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:53:27.006525Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 34.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:53:32.811817Z [info     ] Start Predict                  dataset=404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 32.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:53:39.289800Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 32.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:53:46.468825Z [info     ] Start Predict                  dataset=284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 31.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:53:53.984074Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 32.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:54:02.065476Z [info     ] Start Predict                  dataset=164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 34.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:54:10.429334Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 33.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:54:19.424245Z [info     ] Start Predict                  dataset=44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 36.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3892857142857143, 0.375, 0.4, 0.5607142857142857, 0.625, 0.6571428571428571, 0.6785714285714286, 0.6464285714285715, 0.6571428571428571, 0.6642857142857143, 0.6535714285714286]\n",
      "[489  72 508]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='420' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 01:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:54:32.187699Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 33.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:54:36.986023Z [info     ] Start Predict                  dataset=524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 33.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:54:42.807240Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 31.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:54:48.749787Z [info     ] Start Predict                  dataset=404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 34.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:54:55.239715Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 33.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:55:02.176456Z [info     ] Start Predict                  dataset=284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 33.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:55:09.808262Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 33.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:55:17.673301Z [info     ] Start Predict                  dataset=164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 34.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:55:26.192344Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 32.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:55:35.350708Z [info     ] Start Predict                  dataset=44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 35.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3892857142857143, 0.375, 0.4, 0.5607142857142857, 0.625, 0.6571428571428571, 0.6785714285714286, 0.6464285714285715, 0.6571428571428571, 0.6642857142857143, 0.6535714285714286]\n",
      "[489  72 508]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='420' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 01:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:55:48.296283Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 31.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:55:53.562289Z [info     ] Start Predict                  dataset=524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:02<00:00, 31.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:55:59.076047Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 33.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:56:05.007392Z [info     ] Start Predict                  dataset=404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 33.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:56:11.423030Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 32.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:56:18.286219Z [info     ] Start Predict                  dataset=284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 33.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:56:25.808138Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 33.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:56:33.789697Z [info     ] Start Predict                  dataset=164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:56:42.364543Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 31.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:56:51.458360Z [info     ] Start Predict                  dataset=44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 35.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3892857142857143, 0.375, 0.4, 0.5607142857142857, 0.625, 0.6571428571428571, 0.6785714285714286, 0.6464285714285715, 0.6571428571428571, 0.6642857142857143, 0.6535714285714286]\n",
      "[489  72 508]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='420' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 01:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:57:04.568600Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 32.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:57:09.668940Z [info     ] Start Predict                  dataset=524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:02<00:00, 26.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:57:15.500241Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 32.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:57:21.398262Z [info     ] Start Predict                  dataset=404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 32.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:57:27.828385Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 31.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:57:34.859378Z [info     ] Start Predict                  dataset=284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 33.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:57:42.506779Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 32.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:57:50.771672Z [info     ] Start Predict                  dataset=164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 34.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:58:00.606147Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 33.66it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T16:58:10.498375Z [info     ] Start Predict                  dataset=44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 36.51it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3892857142857143, 0.375, 0.4, 0.5607142857142857, 0.625, 0.6571428571428571, 0.6785714285714286, 0.6464285714285715, 0.6571428571428571, 0.6642857142857143, 0.6535714285714286]\n"
     ]
    }
   ],
   "source": [
    "active_mc_abortion3= []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "query_history_abortion3 = []\n",
    "while mcrun != 5:\n",
    "    n_labeled_examples = np.unique(train_dataset_abortion['text']).size\n",
    "    training_indices0 = np.random.randint(low=0, high=n_labeled_examples, size=3)\n",
    "    print(training_indices0)\n",
    "    active_set_abortion =active_huggingface_dataset(train_dataset_abortion,tokenizer,'label','text')\n",
    "    valid_set_abortion = HuggingFaceDatasets(test_dataset_abortion,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_abortion.can_label = False\n",
    "    active_set_abortion.label(training_indices0)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_abortion,\n",
    "            eval_dataset=valid_set_abortion,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_abortion = ActiveLearningLoop(active_set_abortion,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 60, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_abortion=[unqueried_score]\n",
    "    query = [3]\n",
    "    num = 3\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_abortion.step()\n",
    "        num = num + 60\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_abortion.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_abortion),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_abortion.append(eval_metrics['eval_accuracy'])\n",
    "        query.append(num)\n",
    "    print(performance_history_abortion)\n",
    "    active_mc_abortion3.append(performance_history_abortion)\n",
    "    query_history_abortion3.append(query)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4eae5a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([489,  72, 508])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_indices0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2d59e235",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_abortion3, min_abortion3,max_abortion3 = calculate(active_mc_abortion3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "83d7625a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(median_abortion3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "67152719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_history_abortion3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2270fa4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1105x1040 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(8.5, 8), dpi=130)\n",
    "ax.plot(query_history[0],median_abortion1,label=\"Queue size 20\")\n",
    "ax.fill_between(query_history[0],min_abortion1,max_abortion1,color='blue', alpha=0.1)\n",
    "ax.plot(query_history_abortion2[0],median_abortion2,label=\"Queue size 40\")\n",
    "ax.fill_between(query_history_abortion2[0],min_abortion2,max_abortion2,color='orange', alpha=0.1)\n",
    "ax.plot(query_history_abortion3[0],median_abortion3,label=\"Queue size 60\")\n",
    "ax.fill_between(query_history_abortion3[0],min_abortion3,max_abortion3,color='green', alpha=0.1)\n",
    "ax.scatter(query_history[0], median_abortion1, s=8,marker = \"v\")\n",
    "ax.scatter(query_history_abortion2[0], median_abortion2, s=8,marker=\"^\")\n",
    "ax.scatter(query_history_abortion3[0], median_abortion3, s=8,marker = \",\")\n",
    "ax.xaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=8, integer=True))\n",
    "ax.yaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=10))\n",
    "ax.yaxis.set_major_formatter(mpl.ticker.PercentFormatter(xmax=1))\n",
    "\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "ax.set_title('Different query queue sizes in abortion target')\n",
    "ax.set_xlabel('Volume of labeled data')\n",
    "ax.set_ylabel('Performance(median)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0836fb67",
   "metadata": {},
   "source": [
    "# Atheism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcb25ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_atheism\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset with 461 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_atheism\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset with 52 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_atheism\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset with 220 instances loaded\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "cache_dir = \"./data_cache\"\n",
    "\n",
    "train_dataset_atheism = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_atheism\",\n",
    "    split=\"train\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Training dataset with {len(train_dataset_atheism)} instances loaded\")\n",
    "\n",
    "val_dataset_atheism = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_atheism\",\n",
    "    split=\"validation\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Validation dataset with {len(val_dataset_atheism)} instances loaded\")\n",
    "\n",
    "test_dataset_atheism = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_atheism\",\n",
    "    split=\"test\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Test dataset with {len(test_dataset_atheism)} instances loaded\")\n",
    "\n",
    "num_classes = np.unique(train_dataset_atheism['label']).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efc7c4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_original = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\", num_labels=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8466eb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[272 331 360]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 03:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:28:28.845687Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:03<00:00, 18.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:28:34.389685Z [info     ] Start Predict                  dataset=438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:02<00:00, 20.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:28:41.170272Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:02<00:00, 24.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:28:45.868270Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 27.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:28:51.056799Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:02<00:00, 23.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:28:56.851798Z [info     ] Start Predict                  dataset=358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 23.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:29:02.902797Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 23.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:29:08.743797Z [info     ] Start Predict                  dataset=318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 26.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:29:15.356799Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:02<00:00, 18.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:29:22.347309Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 25.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:29:30.419309Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 26.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:29:37.402868Z [info     ] Start Predict                  dataset=238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 25.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:29:44.703869Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:01<00:00, 22.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:29:53.186902Z [info     ] Start Predict                  dataset=198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 21.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:30:01.635426Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 24.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:30:09.611423Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 26.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:30:20.283996Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 22.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:30:28.499545Z [info     ] Start Predict                  dataset=118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 23.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:30:38.683883Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 28.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:30:48.294977Z [info     ] Start Predict                  dataset=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 24.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:30:58.264505Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 25.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:31:08.242021Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 23.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:31:17.659073Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 34.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2318181818181818, 0.2681818181818182, 0.33636363636363636, 0.41363636363636364, 0.5545454545454546, 0.5727272727272728, 0.6545454545454545, 0.6818181818181818, 0.7045454545454546, 0.7318181818181818, 0.7272727272727273, 0.7227272727272728, 0.7136363636363636, 0.7227272727272728, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7227272727272728, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n",
      "[248  76 179]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 02:57]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:31:33.597782Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 30.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:31:41.105436Z [info     ] Start Predict                  dataset=438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 28.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:31:45.989420Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 27.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:31:52.216151Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 27.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:31:57.424152Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 24.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:32:03.008151Z [info     ] Start Predict                  dataset=358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 23.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:32:08.802664Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 29.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:32:14.554667Z [info     ] Start Predict                  dataset=318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 21.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:32:20.952663Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 29.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:32:27.082665Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 24.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:32:34.098664Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 23.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:32:40.508664Z [info     ] Start Predict                  dataset=238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 27.73it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:32:48.177702Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:01<00:00, 25.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:32:55.645703Z [info     ] Start Predict                  dataset=198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 26.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:33:03.395703Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 25.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:33:11.335702Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 24.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:33:19.181702Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 24.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:33:27.681704Z [info     ] Start Predict                  dataset=118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 25.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:33:35.772703Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 26.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:33:44.801707Z [info     ] Start Predict                  dataset=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 24.51it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:33:52.997704Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 24.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:34:02.577703Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 25.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:34:13.430225Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 22.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19090909090909092, 0.20909090909090908, 0.21363636363636362, 0.3181818181818182, 0.4681818181818182, 0.5409090909090909, 0.6545454545454545, 0.7045454545454546, 0.7045454545454546, 0.7272727272727273, 0.7272727272727273, 0.7227272727272728, 0.7227272727272728, 0.7227272727272728, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n",
      "[248  76 179]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 03:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:34:30.511335Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:02<00:00, 21.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:34:35.341907Z [info     ] Start Predict                  dataset=438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:03<00:00, 16.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:34:42.765425Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:02<00:00, 18.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:34:48.519501Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:34:53.403015Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 26.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:34:59.222639Z [info     ] Start Predict                  dataset=358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 22.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:35:05.320495Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 28.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:35:11.467899Z [info     ] Start Predict                  dataset=318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 22.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:35:18.070556Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 25.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:35:25.014569Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 19.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:35:31.938240Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 27.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:35:38.807124Z [info     ] Start Predict                  dataset=238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 22.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:35:45.682571Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:01<00:00, 23.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:35:53.364358Z [info     ] Start Predict                  dataset=198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 23.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:36:01.965012Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 22.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:36:10.034990Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 24.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:09, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:36:23.106688Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:01<00:00, 16.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:36:32.093324Z [info     ] Start Predict                  dataset=118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 29.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:36:41.106657Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 26.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:36:49.987126Z [info     ] Start Predict                  dataset=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 27.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:36:58.986237Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 24.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:37:09.625901Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 25.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:37:18.905021Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 20.89it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19090909090909092, 0.20909090909090908, 0.21363636363636362, 0.3181818181818182, 0.4681818181818182, 0.5409090909090909, 0.6545454545454545, 0.7045454545454546, 0.7045454545454546, 0.7272727272727273, 0.7272727272727273, 0.7227272727272728, 0.7227272727272728, 0.7227272727272728, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n",
      "[248  76 179]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 02:51]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:37:32.869014Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:02<00:00, 21.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:37:37.744956Z [info     ] Start Predict                  dataset=438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:02<00:00, 20.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:37:43.368883Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:02<00:00, 21.66it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:37:49.643340Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:02<00:00, 19.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:37:56.319388Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:02<00:00, 20.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:38:02.741075Z [info     ] Start Predict                  dataset=358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 22.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:38:08.855565Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 27.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:38:15.035100Z [info     ] Start Predict                  dataset=318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 23.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:38:21.554553Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 29.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:38:28.018171Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 23.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:38:34.635275Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 28.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:38:41.656862Z [info     ] Start Predict                  dataset=238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 24.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:38:48.704040Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 29.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:38:56.297199Z [info     ] Start Predict                  dataset=198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 22.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:39:04.417540Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 24.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:39:11.729521Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 29.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:39:19.244724Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 25.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:39:28.004920Z [info     ] Start Predict                  dataset=118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 24.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:39:35.671760Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 25.03it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:39:44.753994Z [info     ] Start Predict                  dataset=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 25.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:39:53.321307Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 29.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:40:02.304979Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 26.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:40:12.060125Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 28.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19090909090909092, 0.20909090909090908, 0.21363636363636362, 0.3181818181818182, 0.4681818181818182, 0.5409090909090909, 0.6545454545454545, 0.7045454545454546, 0.7045454545454546, 0.7272727272727273, 0.7272727272727273, 0.7227272727272728, 0.7227272727272728, 0.7227272727272728, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n",
      "[248  76 179]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 02:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:40:25.927140Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:02<00:00, 27.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:40:30.133524Z [info     ] Start Predict                  dataset=438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:02<00:00, 23.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:40:35.086667Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:02<00:00, 24.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:40:40.179721Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 28.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:40:44.949071Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 24.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:40:51.293583Z [info     ] Start Predict                  dataset=358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 35.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:40:55.243386Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 33.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:40:59.993342Z [info     ] Start Predict                  dataset=318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 29.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:41:06.123190Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 24.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:41:12.565660Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 23.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:41:19.139237Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 30.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:41:25.727048Z [info     ] Start Predict                  dataset=238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 24.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:41:32.754369Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 31.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:41:40.008833Z [info     ] Start Predict                  dataset=198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 24.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:41:47.318920Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 29.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:41:55.246493Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 22.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:42:02.983849Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 28.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:42:11.401975Z [info     ] Start Predict                  dataset=118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 23.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:42:21.268422Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 25.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:42:30.383620Z [info     ] Start Predict                  dataset=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 21.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:42:40.120624Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 28.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:42:49.109113Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 24.89it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:42:58.955040Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 35.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19090909090909092, 0.20909090909090908, 0.21363636363636362, 0.3181818181818182, 0.4681818181818182, 0.5409090909090909, 0.6545454545454545, 0.7045454545454546, 0.7045454545454546, 0.7272727272727273, 0.7272727272727273, 0.7227272727272728, 0.7227272727272728, 0.7227272727272728, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n"
     ]
    }
   ],
   "source": [
    "active_mc_atheism1 = []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "query_history_atheism1 = []\n",
    "while mcrun != 5:\n",
    "    n_labeled_examples = np.unique(train_dataset_atheism['text']).size\n",
    "    training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "    print(training_indices0)\n",
    "    active_set_atheism =active_huggingface_dataset(train_dataset_atheism,tokenizer,'label','text')\n",
    "    valid_set_atheism = HuggingFaceDatasets(test_dataset_atheism,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_atheism.can_label = False\n",
    "    active_set_atheism.label(training_indices0)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_atheism,\n",
    "            eval_dataset=valid_set_atheism,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_atheism = ActiveLearningLoop(active_set_atheism,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    query = [3]\n",
    "    num = 3\n",
    "    performance_history_atheism=[unqueried_score]\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_atheism.step()\n",
    "        num = num +20\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_atheism.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_atheism),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_atheism.append(eval_metrics['eval_accuracy'])\n",
    "        query.append(num)\n",
    "    print(performance_history_atheism)\n",
    "    active_mc_atheism1.append(performance_history_atheism)\n",
    "    query_history_atheism1.append(query)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63a76f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_atheism1, min_atheism1,max_atheism1 = calculate(active_mc_atheism1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "796ed031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[341 101 393]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='392' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 01:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:43:12.633521Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:02<00:00, 26.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:43:17.068600Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 27.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:43:22.278201Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:02<00:00, 22.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:43:28.621868Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 26.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:43:34.416276Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 22.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:43:41.933994Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 25.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:43:49.005967Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 28.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:43:57.236598Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 21.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:44:06.128425Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 28.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:44:14.093107Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 29.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:44:24.066993Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 24.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:44:33.771376Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 32.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22272727272727272, 0.2681818181818182, 0.45454545454545453, 0.5727272727272728, 0.7181818181818181, 0.7136363636363636, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n",
      "[202  40 104]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='392' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 01:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:44:47.003302Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:02<00:00, 28.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:44:51.902190Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:02<00:00, 19.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:44:58.697526Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:02<00:00, 19.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:45:05.018185Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 28.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:45:11.820361Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:02<00:00, 17.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:45:19.935675Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 23.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:45:26.805066Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 30.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:45:34.099941Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 30.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:45:41.861657Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 24.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:45:50.475190Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 31.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:45:59.402565Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 26.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:46:08.816301Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 30.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18181818181818182, 0.24545454545454545, 0.2590909090909091, 0.37272727272727274, 0.5772727272727273, 0.6590909090909091, 0.7136363636363636, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n",
      "[202  40 104]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='392' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 01:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:46:21.525365Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:02<00:00, 24.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:46:26.558488Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:02<00:00, 23.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:46:31.866232Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 29.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:46:37.534995Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 28.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:46:43.191764Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 24.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:46:50.184549Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 23.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:46:57.287393Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 28.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:47:04.991761Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 24.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:47:12.955940Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 29.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:47:21.511525Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 26.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:47:29.912110Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 32.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:47:39.650299Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 31.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18181818181818182, 0.24545454545454545, 0.2590909090909091, 0.37272727272727274, 0.5772727272727273, 0.6590909090909091, 0.7136363636363636, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n",
      "[202  40 104]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='392' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 01:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:47:52.282095Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:02<00:00, 23.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:47:57.992269Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:02<00:00, 24.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:48:03.311781Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 27.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:48:08.510960Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 28.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:48:14.783361Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 23.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:48:21.698421Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 28.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:48:28.019299Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:01<00:00, 24.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:48:35.905120Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 28.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:48:43.775191Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 28.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:48:51.636708Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 25.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:49:01.066096Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 29.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:49:10.122134Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 24.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18181818181818182, 0.24545454545454545, 0.2590909090909091, 0.37272727272727274, 0.5772727272727273, 0.6590909090909091, 0.7136363636363636, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n",
      "[202  40 104]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='392' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 01:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:49:23.782198Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:02<00:00, 27.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:49:28.640213Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:02<00:00, 23.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:49:33.979101Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 30.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:49:39.756594Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 24.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:49:46.479323Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 24.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:49:52.726082Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 28.73it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:50:00.216913Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:01<00:00, 24.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:50:08.190783Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 27.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:50:15.751962Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 25.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:50:23.772243Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 25.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:50:33.120969Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 25.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:50:42.330433Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 31.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18181818181818182, 0.24545454545454545, 0.2590909090909091, 0.37272727272727274, 0.5772727272727273, 0.6590909090909091, 0.7136363636363636, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n"
     ]
    }
   ],
   "source": [
    "active_mc_atheism2 = []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "query_history_atheism2 = []\n",
    "np.random.seed()\n",
    "while mcrun != 5:\n",
    "    n_labeled_examples = np.unique(train_dataset_atheism['text']).size\n",
    "    training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "    print(training_indices0)\n",
    "    active_set_atheism =active_huggingface_dataset(train_dataset_atheism,tokenizer,'label','text')\n",
    "    valid_set_atheism = HuggingFaceDatasets(test_dataset_atheism,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_atheism.can_label = False\n",
    "    active_set_atheism.label(training_indices0)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_atheism,\n",
    "            eval_dataset=valid_set_atheism,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_atheism = ActiveLearningLoop(active_set_atheism,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 40, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_atheism=[unqueried_score]\n",
    "    query = [3]\n",
    "    num = 3\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_atheism.step()\n",
    "        num = num+40\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_atheism.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_atheism),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_atheism.append(eval_metrics['eval_accuracy'])\n",
    "        query.append(num)\n",
    "    print(performance_history_atheism)\n",
    "    active_mc_atheism2.append(performance_history_atheism)\n",
    "    query_history_atheism2.append(query)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dfdc21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_atheism2, min_atheism2,max_atheism2 = calculate(active_mc_atheism2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1b44c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[425 380 239]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='280' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 01:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:50:55.288285Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:02<00:00, 23.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:51:00.645467Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:02<00:00, 23.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:51:06.342130Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 28.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:51:12.746908Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 29.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:51:19.453257Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 28.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:51:27.492132Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 23.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:51:35.889324Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 29.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:51:45.395803Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 25.03it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18636363636363637, 0.2636363636363636, 0.4954545454545455, 0.6136363636363636, 0.7136363636363636, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n",
      "[ 69  89 259]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='280' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 01:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:51:59.100818Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:02<00:00, 23.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:52:04.645573Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 27.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:52:10.187572Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 23.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:52:16.716015Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 30.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:52:24.073146Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:01<00:00, 23.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:52:31.901146Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 28.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:52:40.071574Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 24.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:52:49.141557Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 28.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17272727272727273, 0.2590909090909091, 0.5409090909090909, 0.6318181818181818, 0.7090909090909091, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n",
      "[ 69  89 259]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='280' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 01:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:53:02.249210Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:02<00:00, 23.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:53:08.249563Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 29.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:53:13.504339Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 26.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:53:20.043550Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 27.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:53:26.666030Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:01<00:00, 23.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:53:35.040793Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 23.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:53:43.352595Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 27.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:53:52.510151Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 25.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17272727272727273, 0.2590909090909091, 0.5409090909090909, 0.6318181818181818, 0.7090909090909091, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n",
      "[ 69  89 259]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='280' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 01:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:54:06.254666Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:02<00:00, 24.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:54:11.341095Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:02<00:00, 24.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:54:17.406870Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 30.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:54:23.757335Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 24.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:54:30.774585Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 29.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:54:38.615090Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 24.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:54:47.020756Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 30.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:54:56.515713Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 23.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17272727272727273, 0.2590909090909091, 0.5409090909090909, 0.6318181818181818, 0.7090909090909091, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n",
      "[ 69  89 259]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='280' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 01:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:55:09.805350Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:02<00:00, 28.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:55:14.415754Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 29.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:55:20.064962Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 23.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:55:26.802244Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 23.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:55:33.564438Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 28.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:55:41.575857Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 25.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:55:49.573651Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 31.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15752-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T01:55:59.379933Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 26.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17272727272727273, 0.2590909090909091, 0.5409090909090909, 0.6318181818181818, 0.7090909090909091, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n"
     ]
    }
   ],
   "source": [
    "active_mc_atheism3 = []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "query_history_atheism3 = []\n",
    "np.random.seed()\n",
    "while mcrun != 5:\n",
    "    n_labeled_examples = np.unique(train_dataset_atheism['text']).size\n",
    "    training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "    print(training_indices0)\n",
    "    active_set_atheism =active_huggingface_dataset(train_dataset_atheism,tokenizer,'label','text')\n",
    "    valid_set_atheism = HuggingFaceDatasets(test_dataset_atheism,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_atheism.can_label = False\n",
    "    active_set_atheism.label(training_indices0)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_atheism,\n",
    "            eval_dataset=valid_set_atheism,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_atheism = ActiveLearningLoop(active_set_atheism,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 60, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_atheism=[unqueried_score]\n",
    "    query = [3]\n",
    "    num = 3\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_atheism.step()\n",
    "        num = num + 60\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_atheism.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_atheism),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_atheism.append(eval_metrics['eval_accuracy'])\n",
    "        query.append(num)\n",
    "    print(performance_history_atheism)\n",
    "    active_mc_atheism3.append(performance_history_atheism)\n",
    "    query_history_atheism3.append(query)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8db44089",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_atheism3, min_atheism3,max_atheism3 = calculate(active_mc_atheism3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edfb7bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1105x1040 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(8.5, 8), dpi=130)\n",
    "ax.plot(query_history_atheism1[0],median_atheism1,label=\"Queue size 20\")\n",
    "ax.fill_between(query_history_atheism1[0],min_atheism1,max_atheism1,color='blue', alpha=0.1)\n",
    "ax.plot(query_history_atheism2[0],median_atheism2,label=\"Queue size 40\")\n",
    "ax.fill_between(query_history_atheism2[0],min_atheism2,max_atheism2,color='orange', alpha=0.1)\n",
    "ax.plot(query_history_atheism3[0],median_atheism3,label=\"Queue size 60\")\n",
    "ax.fill_between(query_history_atheism3[0],min_atheism3,max_atheism3,color='green', alpha=0.1)\n",
    "ax.scatter(query_history_atheism1[0], median_atheism1, s=8,marker = \"v\")\n",
    "ax.scatter(query_history_atheism2[0], median_atheism2, s=8,marker=\"^\")\n",
    "ax.scatter(query_history_atheism3[0],median_atheism3, s=8,marker = \",\")\n",
    "ax.xaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=5, integer=True))\n",
    "ax.yaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=10))\n",
    "ax.yaxis.set_major_formatter(mpl.ticker.PercentFormatter(xmax=1))\n",
    "\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "ax.set_title('Different query queue sizes in atheism target')\n",
    "ax.set_xlabel('Volume of labeled data')\n",
    "ax.set_ylabel('Performance(median)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d97857a",
   "metadata": {},
   "source": [
    "# Climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6b223836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_climate\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset with 355 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_climate\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset with 40 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_climate\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset with 169 instances loaded\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "cache_dir = \"./data_cache\"\n",
    "\n",
    "train_dataset_climate = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_climate\",\n",
    "    split=\"train\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Training dataset with {len(train_dataset_climate)} instances loaded\")\n",
    "\n",
    "val_dataset_climate = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_climate\",\n",
    "    split=\"validation\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Validation dataset with {len(val_dataset_climate)} instances loaded\")\n",
    "\n",
    "test_dataset_climate = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_climate\",\n",
    "    split=\"test\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Test dataset with {len(test_dataset_climate)} instances loaded\")\n",
    "\n",
    "num_classes = np.unique(train_dataset_climate['label']).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9e53bc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/config.json from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\3cf34679007e9fe5d0acd644dcc1f4b26bec5cbc9612364f6da7262aed4ef7a4.a5a11219cf90aae61ff30e1658ccf2cb4aa84d6b6e947336556f887c9828dc6d\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-tiny\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/pytorch_model.bin from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\1ee037c9e1a220d5c814779ffe697080d1e6f5b1602e16cf6061aaae41a082c5.038e1aed90492a59d2283f9c44c9fe3ee2380495ff1e7fefb3f1f04af3b685b5\n",
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_original = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\", num_labels=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6af24e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95 44  9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='682' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 01:55]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:23:27.585165Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 30.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 13\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:23:30.478025Z [info     ] Start Predict                  dataset=342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 32.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:23:33.308747Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 33.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 33\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:23:36.226044Z [info     ] Start Predict                  dataset=322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 33.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:23:39.157480Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 33.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 53\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:23:42.174592Z [info     ] Start Predict                  dataset=302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 32.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:23:45.189965Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 32.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 73\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:23:48.435744Z [info     ] Start Predict                  dataset=282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 33.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:23:51.869011Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 33.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 93\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:23:55.385567Z [info     ] Start Predict                  dataset=262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 34.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:23:58.781408Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 34.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 113\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:24:02.335392Z [info     ] Start Predict                  dataset=242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 34.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:24:05.838792Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 133\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:24:09.598683Z [info     ] Start Predict                  dataset=222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 33.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:24:13.379641Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 33.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 153\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:24:17.278658Z [info     ] Start Predict                  dataset=202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 33.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:24:21.226572Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 33.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 173\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:24:25.275929Z [info     ] Start Predict                  dataset=182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 33.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:24:29.389753Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 34.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 193\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:24:33.587656Z [info     ] Start Predict                  dataset=162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 35.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:24:37.872394Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 34.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 213\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:24:42.253089Z [info     ] Start Predict                  dataset=142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 34.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:24:46.716272Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 32.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 233\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:24:51.378401Z [info     ] Start Predict                  dataset=122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 32.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:24:56.077408Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 33.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 253\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:25:00.842487Z [info     ] Start Predict                  dataset=102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 32.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:25:05.624509Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 35.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 273\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:25:10.609290Z [info     ] Start Predict                  dataset=82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 36.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:25:15.674791Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 33.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 293\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:25:20.591422Z [info     ] Start Predict                  dataset=62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 38.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3076923076923077, 0.3136094674556213, 0.3609467455621302, 0.40236686390532544, 0.47928994082840237, 0.46745562130177515, 0.48520710059171596, 0.5502958579881657, 0.6272189349112426, 0.6035502958579881, 0.6449704142011834, 0.6863905325443787, 0.6745562130177515, 0.727810650887574, 0.6863905325443787, 0.7159763313609467, 0.7159763313609467, 0.7100591715976331, 0.727810650887574, 0.727810650887574, 0.7100591715976331, 0.727810650887574, 0.7218934911242604, 0.7337278106508875, 0.7218934911242604, 0.7337278106508875, 0.727810650887574, 0.7041420118343196, 0.7159763313609467, 0.7218934911242604, 0.7337278106508875]\n",
      "[105 117 236]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='682' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 01:54]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:25:23.140012Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 34.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 13\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:25:25.815762Z [info     ] Start Predict                  dataset=342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 33.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:25:28.554939Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 34.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 33\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:25:31.777556Z [info     ] Start Predict                  dataset=322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 34.51it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:25:35.499852Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 34.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 53\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:25:38.450567Z [info     ] Start Predict                  dataset=302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 33.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:25:41.516118Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 33.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 73\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:25:44.681164Z [info     ] Start Predict                  dataset=282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 33.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:25:47.931343Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 33.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 93\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:25:51.296653Z [info     ] Start Predict                  dataset=262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 34.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:25:54.579209Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 34.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 113\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:25:58.108578Z [info     ] Start Predict                  dataset=242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 34.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:26:01.606467Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 133\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:26:05.325816Z [info     ] Start Predict                  dataset=222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 33.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:26:09.075412Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 33.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 153\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:26:12.837833Z [info     ] Start Predict                  dataset=202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 33.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:26:16.788057Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 31.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 173\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:26:20.844522Z [info     ] Start Predict                  dataset=182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 34.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:26:25.000295Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 34.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 193\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:26:29.196066Z [info     ] Start Predict                  dataset=162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:26:33.464553Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 34.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 213\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:26:37.766333Z [info     ] Start Predict                  dataset=142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 33.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:26:42.197084Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 33.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 233\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:26:46.843080Z [info     ] Start Predict                  dataset=122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 34.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:26:51.475231Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 33.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 253\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:26:56.297758Z [info     ] Start Predict                  dataset=102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 34.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:27:01.123993Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 35.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 273\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:27:06.053670Z [info     ] Start Predict                  dataset=82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 38.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:27:11.103022Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 34.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 293\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:27:16.151900Z [info     ] Start Predict                  dataset=62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 36.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41420118343195267, 0.40828402366863903, 0.4437869822485207, 0.46745562130177515, 0.5739644970414202, 0.5680473372781065, 0.5621301775147929, 0.6094674556213018, 0.6272189349112426, 0.6449704142011834, 0.650887573964497, 0.6923076923076923, 0.6745562130177515, 0.7218934911242604, 0.6745562130177515, 0.7159763313609467, 0.727810650887574, 0.7159763313609467, 0.7100591715976331, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.7337278106508875]\n",
      "[105 117 236]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='682' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 01:55]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:27:18.750870Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 33.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 13\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:27:21.514706Z [info     ] Start Predict                  dataset=342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 32.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:27:24.180939Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 33.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 33\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:27:27.078706Z [info     ] Start Predict                  dataset=322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 34.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:27:30.060170Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 33.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 53\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:27:33.094336Z [info     ] Start Predict                  dataset=302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 33.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:27:36.579831Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 31.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 73\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:27:40.158669Z [info     ] Start Predict                  dataset=282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 32.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:27:43.643033Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 33.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 93\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:27:47.060474Z [info     ] Start Predict                  dataset=262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 33.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:27:50.424423Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 35.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 113\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:27:53.890224Z [info     ] Start Predict                  dataset=242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 35.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:27:57.499546Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 133\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:28:01.374250Z [info     ] Start Predict                  dataset=222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 34.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:28:05.129263Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 34.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 153\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:28:08.979259Z [info     ] Start Predict                  dataset=202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 33.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:28:12.979182Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 34.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 173\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:28:17.010186Z [info     ] Start Predict                  dataset=182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 33.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:28:21.258113Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 34.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 193\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:28:25.505751Z [info     ] Start Predict                  dataset=162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 35.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:28:29.759360Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 35.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 213\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:28:34.186789Z [info     ] Start Predict                  dataset=142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 35.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:28:38.635927Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 30.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 233\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:28:43.257884Z [info     ] Start Predict                  dataset=122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 33.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:28:47.886762Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 33.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 253\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:28:52.620044Z [info     ] Start Predict                  dataset=102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 35.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:28:57.478329Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 36.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 273\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:29:02.410057Z [info     ] Start Predict                  dataset=82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 36.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:29:07.375349Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 34.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 293\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:29:12.492390Z [info     ] Start Predict                  dataset=62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 37.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41420118343195267, 0.40828402366863903, 0.4437869822485207, 0.46745562130177515, 0.5739644970414202, 0.5680473372781065, 0.5621301775147929, 0.6094674556213018, 0.6272189349112426, 0.6449704142011834, 0.650887573964497, 0.6923076923076923, 0.6745562130177515, 0.7218934911242604, 0.6745562130177515, 0.7159763313609467, 0.727810650887574, 0.7159763313609467, 0.7100591715976331, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.7337278106508875]\n",
      "[105 117 236]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='682' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 01:54]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:29:14.993199Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 33.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 13\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:29:17.596036Z [info     ] Start Predict                  dataset=342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 33.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:29:20.276093Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 33.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 33\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:29:23.109371Z [info     ] Start Predict                  dataset=322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 35.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:29:26.022930Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 33.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 53\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:29:29.006868Z [info     ] Start Predict                  dataset=302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 33.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:29:32.020880Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 34.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 73\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:29:35.186490Z [info     ] Start Predict                  dataset=282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 33.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:29:38.468772Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 32.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 93\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:29:41.786350Z [info     ] Start Predict                  dataset=262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 32.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:29:45.284197Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 33.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 113\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:29:48.863134Z [info     ] Start Predict                  dataset=242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 34.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:29:52.576994Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 133\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:29:56.130896Z [info     ] Start Predict                  dataset=222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 34.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:29:59.941800Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 33.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 153\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:30:03.923885Z [info     ] Start Predict                  dataset=202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 34.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:30:07.906213Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 33.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 173\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:30:12.022179Z [info     ] Start Predict                  dataset=182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 33.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:30:16.203705Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 32.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 193\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:30:20.535048Z [info     ] Start Predict                  dataset=162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:30:24.864616Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 33.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 213\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:30:29.348566Z [info     ] Start Predict                  dataset=142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 33.89it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:30:33.829882Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 35.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 233\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:30:38.383005Z [info     ] Start Predict                  dataset=122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 35.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:30:43.414922Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 32.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 253\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:30:48.062920Z [info     ] Start Predict                  dataset=102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 33.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:30:52.843761Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 34.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 273\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:30:57.729053Z [info     ] Start Predict                  dataset=82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 34.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:31:02.837520Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 33.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 293\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:31:08.051551Z [info     ] Start Predict                  dataset=62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 37.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41420118343195267, 0.40828402366863903, 0.4437869822485207, 0.46745562130177515, 0.5739644970414202, 0.5680473372781065, 0.5621301775147929, 0.6094674556213018, 0.6272189349112426, 0.6449704142011834, 0.650887573964497, 0.6923076923076923, 0.6745562130177515, 0.7218934911242604, 0.6745562130177515, 0.7159763313609467, 0.727810650887574, 0.7159763313609467, 0.7100591715976331, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.7337278106508875]\n",
      "[105 117 236]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='682' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 02:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:31:10.555340Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 33.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 13\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:31:13.154514Z [info     ] Start Predict                  dataset=342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 33.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:31:15.885870Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 33.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 33\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:31:18.705270Z [info     ] Start Predict                  dataset=322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 34.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:31:21.683918Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 32.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 53\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:31:24.667991Z [info     ] Start Predict                  dataset=302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 33.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:31:27.732112Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 34.66it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 73\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:31:30.797499Z [info     ] Start Predict                  dataset=282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 33.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:31:34.031360Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 32.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 93\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:31:37.924401Z [info     ] Start Predict                  dataset=262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 27.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:31:41.692548Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 34.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 113\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:31:45.110343Z [info     ] Start Predict                  dataset=242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 33.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:31:48.691448Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 133\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:31:52.357777Z [info     ] Start Predict                  dataset=222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 33.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:31:56.055576Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 35.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 153\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:31:59.954507Z [info     ] Start Predict                  dataset=202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 34.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:32:03.878421Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 31.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 173\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:32:07.969978Z [info     ] Start Predict                  dataset=182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 32.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:32:12.119398Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 34.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 193\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:32:16.348822Z [info     ] Start Predict                  dataset=162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:32:20.681843Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 32.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 213\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:32:25.097081Z [info     ] Start Predict                  dataset=142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 30.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:32:31.801576Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 33.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 233\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:32:38.197436Z [info     ] Start Predict                  dataset=122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 37.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:32:44.322181Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 27.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 253\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:32:50.305064Z [info     ] Start Predict                  dataset=102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 34.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:32:55.036805Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 31.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 273\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:32:59.951860Z [info     ] Start Predict                  dataset=82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 35.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:33:04.893894Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 33.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 293\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:33:09.997455Z [info     ] Start Predict                  dataset=62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 36.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41420118343195267, 0.40828402366863903, 0.4437869822485207, 0.46745562130177515, 0.5739644970414202, 0.5680473372781065, 0.5621301775147929, 0.6094674556213018, 0.6272189349112426, 0.6449704142011834, 0.650887573964497, 0.6923076923076923, 0.6745562130177515, 0.7218934911242604, 0.6745562130177515, 0.7159763313609467, 0.727810650887574, 0.7159763313609467, 0.7100591715976331, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.727810650887574, 0.7337278106508875]\n"
     ]
    }
   ],
   "source": [
    "active_mc_climate1= []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "query_history_climate1 = []\n",
    "while mcrun != 5:\n",
    "    n_labeled_examples = np.unique(train_dataset_climate['text']).size\n",
    "    training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "    print(training_indices0)\n",
    "    active_set_climate =active_huggingface_dataset(train_dataset_climate,tokenizer,'label','text')\n",
    "    valid_set_climate = HuggingFaceDatasets(test_dataset_climate,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_climate.can_label = False\n",
    "    active_set_climate.label(training_indices0)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_climate,\n",
    "            eval_dataset=valid_set_climate,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_climate = ActiveLearningLoop(active_set_climate,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 10, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_climate=[unqueried_score]\n",
    "    num = 3\n",
    "    query = [3]\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_climate.step()\n",
    "        num = num + 10\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_climate.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_climate),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_climate.append(eval_metrics['eval_accuracy'])\n",
    "        query.append(num)\n",
    "    print(performance_history_climate)\n",
    "    active_mc_climate1.append(performance_history_climate)\n",
    "    query_history_climate1.append(query)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e217c3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_climate1, min_climate1,max_climate1 = calculate(active_mc_climate1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aba22798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[273   3 192]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='440' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 01:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:33:12.630408Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 33.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:33:15.380101Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 31.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:33:18.679327Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 26.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:33:22.143877Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 33.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:33:25.443008Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 32.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:33:28.792518Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 33.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:33:32.342432Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:33:36.179556Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 35.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:33:40.323016Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 27.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:33:44.938103Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 35.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:33:49.268955Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 34.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:33:53.766895Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 34.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:33:58.391664Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 33.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:34:03.179551Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 37.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:34:08.161081Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 34.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:34:13.310290Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 37.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:34:18.727562Z [info     ] Start Predict                  dataset=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 36.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:34:24.390514Z [info     ] Start Predict                  dataset=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 29.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 355\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35502958579881655, 0.3668639053254438, 0.44970414201183434, 0.5857988165680473, 0.5976331360946746, 0.6627218934911243, 0.6923076923076923, 0.6863905325443787, 0.6982248520710059, 0.7218934911242604, 0.7159763313609467, 0.727810650887574, 0.7159763313609467, 0.727810650887574, 0.7218934911242604, 0.727810650887574, 0.7337278106508875, 0.7159763313609467, 0.727810650887574]\n",
      "[335 117 232]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='440' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 01:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:34:32.755393Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 33.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:34:35.536047Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 34.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:34:38.468741Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 33.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:34:41.600299Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 33.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:34:44.907531Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 31.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:34:48.381777Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 33.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:34:51.998847Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:34:55.763997Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 34.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:34:59.811576Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 31.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:35:03.944498Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 34.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:35:08.308323Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 34.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:35:12.857458Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 34.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:35:17.552275Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 33.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:35:22.699444Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 37.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:35:27.800893Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 33.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:35:33.462537Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 28.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:35:39.214647Z [info     ] Start Predict                  dataset=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 34.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:35:44.830996Z [info     ] Start Predict                  dataset=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 37.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 355\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40828402366863903, 0.40828402366863903, 0.4556213017751479, 0.5739644970414202, 0.6153846153846154, 0.6804733727810651, 0.6982248520710059, 0.6923076923076923, 0.7218934911242604, 0.7218934911242604, 0.7159763313609467, 0.7218934911242604, 0.7159763313609467, 0.727810650887574, 0.7218934911242604, 0.727810650887574, 0.7218934911242604, 0.7218934911242604, 0.7337278106508875]\n",
      "[335 117 232]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='440' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 01:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:35:52.892594Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 32.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:35:55.625996Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 33.89it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:35:58.658705Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 32.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:36:01.825051Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 34.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:36:05.203863Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 32.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:36:08.821302Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 34.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:36:12.383813Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:36:16.110029Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 32.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:36:20.150187Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 33.03it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:36:24.466592Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 27.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:36:29.248711Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 32.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:36:33.730501Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 34.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:36:38.460380Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 34.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:36:43.341854Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 35.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:36:48.504145Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 33.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:36:53.675479Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 37.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:36:59.295661Z [info     ] Start Predict                  dataset=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 33.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:37:04.751464Z [info     ] Start Predict                  dataset=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 39.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 355\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40828402366863903, 0.40828402366863903, 0.4556213017751479, 0.5739644970414202, 0.6153846153846154, 0.6804733727810651, 0.6982248520710059, 0.6923076923076923, 0.7218934911242604, 0.7218934911242604, 0.7159763313609467, 0.7218934911242604, 0.7159763313609467, 0.727810650887574, 0.7218934911242604, 0.727810650887574, 0.7218934911242604, 0.7218934911242604, 0.7337278106508875]\n",
      "[335 117 232]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='440' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 01:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:37:13.354884Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 32.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:37:16.147763Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 34.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:37:19.083582Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 32.73it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:37:22.163426Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 34.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:37:25.578899Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 33.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:37:29.210886Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 33.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:37:33.244083Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:37:36.926403Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 34.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:37:40.972514Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 33.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:37:45.672567Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 27.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:37:50.386065Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 33.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:37:54.903159Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 33.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:37:59.601269Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 33.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:38:04.349263Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 35.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:38:09.280783Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 33.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:38:14.447026Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 36.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:38:20.077031Z [info     ] Start Predict                  dataset=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 34.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:38:25.459783Z [info     ] Start Predict                  dataset=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 42.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 355\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40828402366863903, 0.40828402366863903, 0.4556213017751479, 0.5739644970414202, 0.6153846153846154, 0.6804733727810651, 0.6982248520710059, 0.6923076923076923, 0.7218934911242604, 0.7218934911242604, 0.7159763313609467, 0.7218934911242604, 0.7159763313609467, 0.727810650887574, 0.7218934911242604, 0.727810650887574, 0.7218934911242604, 0.7218934911242604, 0.7337278106508875]\n",
      "[335 117 232]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='440' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 01:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:38:34.055395Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 33.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:38:36.822780Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 33.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:38:39.654789Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 27.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:38:43.234547Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 27.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:38:47.114113Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 33.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:38:50.484107Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 33.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:38:54.000163Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:38:57.816017Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 34.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:39:01.928837Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 33.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:39:06.090407Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 34.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:39:10.488379Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 32.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:39:14.974142Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 35.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:39:20.151927Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 27.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:39:25.116632Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 35.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:39:30.086819Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 30.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:39:35.263411Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 34.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:39:40.610499Z [info     ] Start Predict                  dataset=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 36.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:39:46.226348Z [info     ] Start Predict                  dataset=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 41.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 355\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40828402366863903, 0.40828402366863903, 0.4556213017751479, 0.5739644970414202, 0.6153846153846154, 0.6804733727810651, 0.6982248520710059, 0.6923076923076923, 0.7218934911242604, 0.7218934911242604, 0.7159763313609467, 0.7218934911242604, 0.7159763313609467, 0.727810650887574, 0.7218934911242604, 0.727810650887574, 0.7218934911242604, 0.7218934911242604, 0.7337278106508875]\n"
     ]
    }
   ],
   "source": [
    "active_mc_climate2 = []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "query_history_climate2 =[]\n",
    "np.random.seed()\n",
    "while mcrun != 5:\n",
    "    n_labeled_examples = np.unique(train_dataset_climate['text']).size\n",
    "    training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "    print(training_indices0)\n",
    "    active_set_climate =active_huggingface_dataset(train_dataset_climate,tokenizer,'label','text')\n",
    "    valid_set_climate = HuggingFaceDatasets(test_dataset_climate,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_climate.can_label = False\n",
    "    active_set_climate.label(training_indices0)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_climate,\n",
    "            eval_dataset=valid_set_climate,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_climate = ActiveLearningLoop(active_set_climate,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_climate=[unqueried_score]\n",
    "    query = [3]\n",
    "    num = 3\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_climate.step()\n",
    "        num = num + 20\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_climate.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_climate),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_climate.append(eval_metrics['eval_accuracy'])\n",
    "        query.append(num)\n",
    "    print(performance_history_climate)\n",
    "    active_mc_climate2.append(performance_history_climate)\n",
    "    query_history_climate2.append(query)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "589527a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_climate2, min_climate2,max_climate2 = calculate(active_mc_climate2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a81398b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[132  33 225]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='308' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:59]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:39:54.211848Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 33.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 33\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:39:57.111211Z [info     ] Start Predict                  dataset=322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 31.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:40:00.711484Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 27.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 93\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:40:04.818914Z [info     ] Start Predict                  dataset=262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 34.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:40:08.502240Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 153\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:40:12.525189Z [info     ] Start Predict                  dataset=202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 33.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:40:16.749422Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 33.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 213\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:40:21.235789Z [info     ] Start Predict                  dataset=142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 35.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:40:28.793513Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 34.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 273\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:40:34.126737Z [info     ] Start Predict                  dataset=82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 37.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:40:39.491716Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 38.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 333\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:40:44.879831Z [info     ] Start Predict                  dataset=22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 37.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 355\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40828402366863903, 0.40236686390532544, 0.46745562130177515, 0.591715976331361, 0.650887573964497, 0.6982248520710059, 0.727810650887574, 0.7159763313609467, 0.7159763313609467, 0.727810650887574, 0.7218934911242604, 0.727810650887574, 0.7396449704142012]\n",
      "[ 49 254 148]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='308' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:59]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:40:56.960966Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 34.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 33\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:41:00.318999Z [info     ] Start Predict                  dataset=322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 34.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:41:04.902787Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 27.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 93\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:41:09.320614Z [info     ] Start Predict                  dataset=262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 32.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:41:13.281687Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 153\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:41:17.344390Z [info     ] Start Predict                  dataset=202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 34.73it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:41:21.559634Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 34.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 213\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:41:25.917025Z [info     ] Start Predict                  dataset=142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 33.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:41:30.793515Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 32.66it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 273\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:41:35.890674Z [info     ] Start Predict                  dataset=82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 37.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:41:41.127480Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 35.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 333\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:41:46.702836Z [info     ] Start Predict                  dataset=22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 37.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 355\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3136094674556213, 0.3136094674556213, 0.4260355029585799, 0.5443786982248521, 0.621301775147929, 0.6982248520710059, 0.7159763313609467, 0.7159763313609467, 0.7159763313609467, 0.7218934911242604, 0.7218934911242604, 0.7218934911242604, 0.7337278106508875]\n",
      "[ 49 254 148]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='308' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:54]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:41:54.672275Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 33.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 33\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:41:57.636222Z [info     ] Start Predict                  dataset=322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 34.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:42:00.737490Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 33.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 93\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:42:04.135530Z [info     ] Start Predict                  dataset=262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 33.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:42:07.886770Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 153\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:42:11.926018Z [info     ] Start Predict                  dataset=202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 32.03it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:42:16.178213Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 35.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 213\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:42:20.740707Z [info     ] Start Predict                  dataset=142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 32.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:42:25.872522Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 26.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 273\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:42:31.078087Z [info     ] Start Predict                  dataset=82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 34.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:42:36.502096Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 39.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 333\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:42:41.925858Z [info     ] Start Predict                  dataset=22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 35.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 355\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3136094674556213, 0.3136094674556213, 0.4260355029585799, 0.5443786982248521, 0.621301775147929, 0.6982248520710059, 0.7159763313609467, 0.7159763313609467, 0.7159763313609467, 0.7218934911242604, 0.7218934911242604, 0.7218934911242604, 0.7337278106508875]\n",
      "[ 49 254 148]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='308' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:56]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:42:49.986628Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 32.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 33\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:42:53.016410Z [info     ] Start Predict                  dataset=322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 27.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:42:56.781826Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 26.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 93\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:43:00.764875Z [info     ] Start Predict                  dataset=262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 33.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:43:04.661830Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 153\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:43:08.857931Z [info     ] Start Predict                  dataset=202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 27.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:43:13.572959Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 35.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 213\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:43:18.004753Z [info     ] Start Predict                  dataset=142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 33.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:43:22.821658Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 34.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 273\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:43:27.920659Z [info     ] Start Predict                  dataset=82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 36.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:43:33.233470Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 36.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 333\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:43:38.831609Z [info     ] Start Predict                  dataset=22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 35.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 355\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3136094674556213, 0.3136094674556213, 0.4260355029585799, 0.5443786982248521, 0.621301775147929, 0.6982248520710059, 0.7159763313609467, 0.7159763313609467, 0.7159763313609467, 0.7218934911242604, 0.7218934911242604, 0.7218934911242604, 0.7337278106508875]\n",
      "[ 49 254 148]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='308' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:55]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:43:46.805042Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 33.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 33\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:43:49.733736Z [info     ] Start Predict                  dataset=322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 27.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:43:53.431623Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 27.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 93\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:43:57.197374Z [info     ] Start Predict                  dataset=262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 32.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:44:01.156652Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 153\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:44:05.206179Z [info     ] Start Predict                  dataset=202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 34.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:44:09.640342Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 35.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 213\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:44:14.137331Z [info     ] Start Predict                  dataset=142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 31.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:44:18.933312Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 33.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 273\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:44:23.981523Z [info     ] Start Predict                  dataset=82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 35.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:44:29.249594Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 38.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 333\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:44:34.729815Z [info     ] Start Predict                  dataset=22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 39.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 355\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3136094674556213, 0.3136094674556213, 0.4260355029585799, 0.5443786982248521, 0.621301775147929, 0.6982248520710059, 0.7159763313609467, 0.7159763313609467, 0.7159763313609467, 0.7218934911242604, 0.7218934911242604, 0.7218934911242604, 0.7337278106508875]\n"
     ]
    }
   ],
   "source": [
    "active_mc_climate3 = []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "query_history_climate3 = []\n",
    "while mcrun != 5:\n",
    "    n_labeled_examples = np.unique(train_dataset_climate['text']).size\n",
    "    training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "    print(training_indices0)\n",
    "    active_set_climate =active_huggingface_dataset(train_dataset_climate,tokenizer,'label','text')\n",
    "    valid_set_climate = HuggingFaceDatasets(test_dataset_climate,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_climate.can_label = False\n",
    "    active_set_climate.label(training_indices0)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_climate,\n",
    "            eval_dataset=valid_set_climate,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_climate = ActiveLearningLoop(active_set_climate,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 30, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_climate=[unqueried_score]\n",
    "    num = 3\n",
    "    query = [3]\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_climate.step()\n",
    "        num = num + 30\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_climate.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_climate),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_climate.append(eval_metrics['eval_accuracy'])\n",
    "        query.append(num)\n",
    "    print(performance_history_climate)\n",
    "    active_mc_climate3.append(performance_history_climate)\n",
    "    query_history_climate3.append(query)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f259ad47",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_climate3, min_climate3,max_climate3 = calculate(active_mc_climate3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fcacc9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1105x1040 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(8.5, 8), dpi=130)\n",
    "ax.plot(query_history_climate1[0],median_climate1,label=\"Queue size 20\")\n",
    "ax.fill_between(query_history_climate1[0],min_climate1,max_climate1,color='blue', alpha=0.1)\n",
    "ax.plot(query_history_climate2[0],median_climate2,label=\"Queue size 40\")\n",
    "ax.fill_between(query_history_climate2[0],min_climate2,max_climate2,color='orange', alpha=0.1)\n",
    "ax.plot(query_history_climate3[0],median_climate3,label=\"Queue size 60\")\n",
    "ax.fill_between(query_history_climate3[0],min_climate3,max_climate3,color='green', alpha=0.1)\n",
    "ax.scatter(query_history_climate1[0], median_climate1, s=8,marker = \"v\")\n",
    "ax.scatter(query_history_climate2[0], median_climate2, s=8,marker=\"^\")\n",
    "ax.scatter(query_history_climate3[0], median_climate3, s=8,marker = \",\")\n",
    "ax.xaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=5, integer=True))\n",
    "ax.yaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=10))\n",
    "ax.yaxis.set_major_formatter(mpl.ticker.PercentFormatter(xmax=1))\n",
    "\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "ax.set_title('Different query queue sizes in climate target')\n",
    "ax.set_xlabel('Volume of labeled data')\n",
    "ax.set_ylabel('Performance(median)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32cde60",
   "metadata": {},
   "source": [
    "# Feminist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "90d72029",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_feminist\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset with 597 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_feminist\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset with 67 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_feminist\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset with 285 instances loaded\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "cache_dir = \"./data_cache\"\n",
    "\n",
    "train_dataset_feminist = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_feminist\",\n",
    "    split=\"train\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Training dataset with {len(train_dataset_feminist)} instances loaded\")\n",
    "\n",
    "val_dataset_feminist = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_feminist\",\n",
    "    split=\"validation\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Validation dataset with {len(val_dataset_feminist)} instances loaded\")\n",
    "\n",
    "test_dataset_feminist = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_feminist\",\n",
    "    split=\"test\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Test dataset with {len(test_dataset_feminist)} instances loaded\")\n",
    "\n",
    "num_classes = np.unique(train_dataset_feminist['label']).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c6c8c7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/config.json from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\3cf34679007e9fe5d0acd644dcc1f4b26bec5cbc9612364f6da7262aed4ef7a4.a5a11219cf90aae61ff30e1658ccf2cb4aa84d6b6e947336556f887c9828dc6d\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-tiny\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/pytorch_model.bin from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\1ee037c9e1a220d5c814779ffe697080d1e6f5b1602e16cf6061aaae41a082c5.038e1aed90492a59d2283f9c44c9fe3ee2380495ff1e7fefb3f1f04af3b685b5\n",
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_original = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\", num_labels=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9ae88e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[372 399 464]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1116' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 03:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:35:01.751788Z [info     ] Start Predict                  dataset=594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 30.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:35:06.228742Z [info     ] Start Predict                  dataset=574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 72/72 [00:02<00:00, 32.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:35:10.895988Z [info     ] Start Predict                  dataset=554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 32.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:35:15.536834Z [info     ] Start Predict                  dataset=534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 33.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:35:20.451581Z [info     ] Start Predict                  dataset=514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 32.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:35:25.482175Z [info     ] Start Predict                  dataset=494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [00:01<00:00, 32.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:35:30.598633Z [info     ] Start Predict                  dataset=474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 34.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:35:35.913278Z [info     ] Start Predict                  dataset=454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 32.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:35:41.476833Z [info     ] Start Predict                  dataset=434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 33.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:35:47.159449Z [info     ] Start Predict                  dataset=414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 33.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:35:53.139538Z [info     ] Start Predict                  dataset=394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 34.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:35:59.097823Z [info     ] Start Predict                  dataset=374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 33.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:36:05.335353Z [info     ] Start Predict                  dataset=354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 33.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:36:11.700837Z [info     ] Start Predict                  dataset=334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 33.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:36:18.314407Z [info     ] Start Predict                  dataset=314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 34.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:36:25.161966Z [info     ] Start Predict                  dataset=294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 33.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:36:32.193030Z [info     ] Start Predict                  dataset=274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 34.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:36:39.322900Z [info     ] Start Predict                  dataset=254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 34.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:36:46.572518Z [info     ] Start Predict                  dataset=234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 33.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:36:54.088156Z [info     ] Start Predict                  dataset=214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 33.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:37:01.967271Z [info     ] Start Predict                  dataset=194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 35.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:37:09.631554Z [info     ] Start Predict                  dataset=174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 33.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:37:17.347130Z [info     ] Start Predict                  dataset=154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 35.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:37:25.408406Z [info     ] Start Predict                  dataset=134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 33.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:37:33.772389Z [info     ] Start Predict                  dataset=114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 35.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:37:42.041344Z [info     ] Start Predict                  dataset=94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 35.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:37:50.684215Z [info     ] Start Predict                  dataset=74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 35.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:37:59.365533Z [info     ] Start Predict                  dataset=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 34.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:38:08.227315Z [info     ] Start Predict                  dataset=34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 32.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:38:17.331369Z [info     ] Start Predict                  dataset=14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 34.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5263157894736842, 0.4982456140350877, 0.5017543859649123, 0.5263157894736842, 0.5403508771929825, 0.5929824561403508, 0.5929824561403508, 0.5754385964912281, 0.6105263157894737, 0.5929824561403508, 0.5929824561403508, 0.624561403508772, 0.5964912280701754, 0.624561403508772, 0.631578947368421, 0.6210526315789474, 0.6210526315789474, 0.631578947368421, 0.6, 0.624561403508772, 0.6385964912280702, 0.6421052631578947, 0.6140350877192983, 0.6350877192982456, 0.6421052631578947, 0.6526315789473685, 0.6385964912280702, 0.624561403508772, 0.624561403508772, 0.6210526315789474, 0.6385964912280702]\n",
      "[252 477 368]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1116' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 03:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:38:21.238659Z [info     ] Start Predict                  dataset=594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 32.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:38:25.554778Z [info     ] Start Predict                  dataset=574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 72/72 [00:02<00:00, 33.66it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:38:29.954942Z [info     ] Start Predict                  dataset=554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 33.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:38:34.551873Z [info     ] Start Predict                  dataset=534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 33.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:38:39.383533Z [info     ] Start Predict                  dataset=514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 33.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:38:46.332252Z [info     ] Start Predict                  dataset=494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [00:01<00:00, 34.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:38:52.278129Z [info     ] Start Predict                  dataset=474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 33.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:38:57.744591Z [info     ] Start Predict                  dataset=454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 33.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:39:03.265997Z [info     ] Start Predict                  dataset=434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 34.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:39:09.011184Z [info     ] Start Predict                  dataset=414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 33.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:39:15.055939Z [info     ] Start Predict                  dataset=394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 33.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:39:21.133976Z [info     ] Start Predict                  dataset=374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 33.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:39:27.470082Z [info     ] Start Predict                  dataset=354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 33.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:39:33.786984Z [info     ] Start Predict                  dataset=334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 33.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:39:40.413465Z [info     ] Start Predict                  dataset=314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 33.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:39:47.310709Z [info     ] Start Predict                  dataset=294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 34.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:39:54.343618Z [info     ] Start Predict                  dataset=274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 34.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:40:01.588214Z [info     ] Start Predict                  dataset=254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 32.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:40:08.954230Z [info     ] Start Predict                  dataset=234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 34.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:40:16.589175Z [info     ] Start Predict                  dataset=214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 32.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:40:24.290094Z [info     ] Start Predict                  dataset=194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 34.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:40:32.134654Z [info     ] Start Predict                  dataset=174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 33.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:40:39.959480Z [info     ] Start Predict                  dataset=154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 35.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:40:48.175322Z [info     ] Start Predict                  dataset=134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 34.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:40:56.487133Z [info     ] Start Predict                  dataset=114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 35.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:41:05.065681Z [info     ] Start Predict                  dataset=94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 34.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:41:13.699282Z [info     ] Start Predict                  dataset=74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 35.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:41:22.478471Z [info     ] Start Predict                  dataset=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 33.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:41:31.702705Z [info     ] Start Predict                  dataset=34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 31.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:41:41.139310Z [info     ] Start Predict                  dataset=14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 42.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.512280701754386, 0.49122807017543857, 0.49122807017543857, 0.519298245614035, 0.5649122807017544, 0.5754385964912281, 0.5614035087719298, 0.4982456140350877, 0.49122807017543857, 0.6175438596491228, 0.5964912280701754, 0.5333333333333333, 0.6175438596491228, 0.5894736842105263, 0.6070175438596491, 0.6280701754385964, 0.6280701754385964, 0.631578947368421, 0.631578947368421, 0.6280701754385964, 0.6421052631578947, 0.6421052631578947, 0.6385964912280702, 0.631578947368421, 0.6035087719298246, 0.6421052631578947, 0.631578947368421, 0.6421052631578947, 0.6105263157894737, 0.6350877192982456, 0.624561403508772]\n",
      "[252 477 368]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1116' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 03:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:41:44.988638Z [info     ] Start Predict                  dataset=594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 33.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:41:49.321348Z [info     ] Start Predict                  dataset=574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 72/72 [00:02<00:00, 33.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:41:53.757224Z [info     ] Start Predict                  dataset=554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 32.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:41:58.791251Z [info     ] Start Predict                  dataset=534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 28.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:42:04.003018Z [info     ] Start Predict                  dataset=514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 33.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:42:08.984807Z [info     ] Start Predict                  dataset=494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [00:01<00:00, 33.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:42:14.149672Z [info     ] Start Predict                  dataset=474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 33.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:42:19.609175Z [info     ] Start Predict                  dataset=454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 32.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:42:26.190261Z [info     ] Start Predict                  dataset=434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 33.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:42:31.988790Z [info     ] Start Predict                  dataset=414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 33.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:42:38.977801Z [info     ] Start Predict                  dataset=394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:02<00:00, 24.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:42:46.055755Z [info     ] Start Predict                  dataset=374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 33.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:42:52.516581Z [info     ] Start Predict                  dataset=354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 33.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:42:58.979323Z [info     ] Start Predict                  dataset=334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 32.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:43:05.616463Z [info     ] Start Predict                  dataset=314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 33.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:43:12.507986Z [info     ] Start Predict                  dataset=294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 29.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:43:20.966026Z [info     ] Start Predict                  dataset=274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 26.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:43:28.303081Z [info     ] Start Predict                  dataset=254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 34.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:43:35.527354Z [info     ] Start Predict                  dataset=234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 32.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:43:42.806679Z [info     ] Start Predict                  dataset=214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 33.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:43:50.298751Z [info     ] Start Predict                  dataset=194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 33.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:43:57.812689Z [info     ] Start Predict                  dataset=174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 34.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:44:07.927257Z [info     ] Start Predict                  dataset=154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 36.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:44:15.947864Z [info     ] Start Predict                  dataset=134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 33.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:44:24.245624Z [info     ] Start Predict                  dataset=114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 33.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:44:32.601998Z [info     ] Start Predict                  dataset=94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 32.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:44:41.309915Z [info     ] Start Predict                  dataset=74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 26.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:44:50.745257Z [info     ] Start Predict                  dataset=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 35.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:44:59.815448Z [info     ] Start Predict                  dataset=34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 39.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:45:09.037365Z [info     ] Start Predict                  dataset=14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 51.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.512280701754386, 0.49122807017543857, 0.49122807017543857, 0.519298245614035, 0.5649122807017544, 0.5754385964912281, 0.5614035087719298, 0.4982456140350877, 0.49122807017543857, 0.6175438596491228, 0.5964912280701754, 0.5333333333333333, 0.6175438596491228, 0.5894736842105263, 0.6070175438596491, 0.6280701754385964, 0.6280701754385964, 0.631578947368421, 0.631578947368421, 0.6280701754385964, 0.6421052631578947, 0.6421052631578947, 0.6385964912280702, 0.631578947368421, 0.6035087719298246, 0.6421052631578947, 0.631578947368421, 0.6421052631578947, 0.6105263157894737, 0.6350877192982456, 0.624561403508772]\n",
      "[252 477 368]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1116' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 03:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:45:12.493522Z [info     ] Start Predict                  dataset=594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 32.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:45:17.101526Z [info     ] Start Predict                  dataset=574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 72/72 [00:02<00:00, 27.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:45:22.192745Z [info     ] Start Predict                  dataset=554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 33.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:45:26.809685Z [info     ] Start Predict                  dataset=534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 33.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:45:31.620219Z [info     ] Start Predict                  dataset=514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 32.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:45:37.317992Z [info     ] Start Predict                  dataset=494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [00:02<00:00, 26.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:45:43.119526Z [info     ] Start Predict                  dataset=474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 33.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:45:48.497464Z [info     ] Start Predict                  dataset=454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 33.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:45:54.052934Z [info     ] Start Predict                  dataset=434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 34.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:46:00.125820Z [info     ] Start Predict                  dataset=414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 26.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:46:06.627717Z [info     ] Start Predict                  dataset=394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 33.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:46:12.822376Z [info     ] Start Predict                  dataset=374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 33.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:46:19.626294Z [info     ] Start Predict                  dataset=354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 31.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:46:26.088154Z [info     ] Start Predict                  dataset=334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 32.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:46:32.839365Z [info     ] Start Predict                  dataset=314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 33.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:46:40.227432Z [info     ] Start Predict                  dataset=294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 31.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:46:48.123773Z [info     ] Start Predict                  dataset=274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 27.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:46:55.495822Z [info     ] Start Predict                  dataset=254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 34.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:47:02.826686Z [info     ] Start Predict                  dataset=234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 33.89it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:47:10.963204Z [info     ] Start Predict                  dataset=214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:01<00:00, 26.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:47:18.955332Z [info     ] Start Predict                  dataset=194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 34.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:47:26.602993Z [info     ] Start Predict                  dataset=174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 33.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:47:35.141147Z [info     ] Start Predict                  dataset=154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 28.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:47:43.599748Z [info     ] Start Predict                  dataset=134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 33.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:47:52.322429Z [info     ] Start Predict                  dataset=114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 27.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:48:01.208073Z [info     ] Start Predict                  dataset=94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 33.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:48:10.461535Z [info     ] Start Predict                  dataset=74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 36.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:48:19.179729Z [info     ] Start Predict                  dataset=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 28.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:48:28.697921Z [info     ] Start Predict                  dataset=34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 42.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:48:37.862725Z [info     ] Start Predict                  dataset=14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 42.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.512280701754386, 0.49122807017543857, 0.49122807017543857, 0.519298245614035, 0.5649122807017544, 0.5754385964912281, 0.5614035087719298, 0.4982456140350877, 0.49122807017543857, 0.6175438596491228, 0.5964912280701754, 0.5333333333333333, 0.6175438596491228, 0.5894736842105263, 0.6070175438596491, 0.6280701754385964, 0.6280701754385964, 0.631578947368421, 0.631578947368421, 0.6280701754385964, 0.6421052631578947, 0.6421052631578947, 0.6385964912280702, 0.631578947368421, 0.6035087719298246, 0.6421052631578947, 0.631578947368421, 0.6421052631578947, 0.6105263157894737, 0.6350877192982456, 0.624561403508772]\n",
      "[252 477 368]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1116' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 03:36]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:48:42.738990Z [info     ] Start Predict                  dataset=594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 30.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:48:49.774407Z [info     ] Start Predict                  dataset=574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 72/72 [00:02<00:00, 27.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:48:55.095455Z [info     ] Start Predict                  dataset=554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 28.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:49:00.045862Z [info     ] Start Predict                  dataset=534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 34.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:49:04.818832Z [info     ] Start Predict                  dataset=514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 33.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:49:10.311900Z [info     ] Start Predict                  dataset=494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [00:02<00:00, 26.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:49:16.219222Z [info     ] Start Predict                  dataset=474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 33.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:49:22.286570Z [info     ] Start Predict                  dataset=454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 33.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:49:27.725191Z [info     ] Start Predict                  dataset=434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 34.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:49:33.469042Z [info     ] Start Predict                  dataset=414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 31.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:49:40.378385Z [info     ] Start Predict                  dataset=394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 26.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:49:46.870299Z [info     ] Start Predict                  dataset=374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 33.89it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:49:53.130699Z [info     ] Start Predict                  dataset=354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 31.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:50:00.531451Z [info     ] Start Predict                  dataset=334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 31.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:50:07.310956Z [info     ] Start Predict                  dataset=314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 34.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:50:14.006569Z [info     ] Start Predict                  dataset=294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 33.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:50:21.293943Z [info     ] Start Predict                  dataset=274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 27.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:50:29.606800Z [info     ] Start Predict                  dataset=254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 26.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:50:37.343638Z [info     ] Start Predict                  dataset=234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 34.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:50:45.195277Z [info     ] Start Predict                  dataset=214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 27.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:50:53.459868Z [info     ] Start Predict                  dataset=194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 34.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:51:01.571511Z [info     ] Start Predict                  dataset=174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 33.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:51:11.007517Z [info     ] Start Predict                  dataset=154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 28.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:51:19.499743Z [info     ] Start Predict                  dataset=134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 33.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:51:28.406544Z [info     ] Start Predict                  dataset=114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 30.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:51:36.634258Z [info     ] Start Predict                  dataset=94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 28.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:51:46.521659Z [info     ] Start Predict                  dataset=74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 36.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:51:55.510043Z [info     ] Start Predict                  dataset=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 30.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:52:05.942564Z [info     ] Start Predict                  dataset=34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 39.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:52:15.028184Z [info     ] Start Predict                  dataset=14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 36.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.512280701754386, 0.49122807017543857, 0.49122807017543857, 0.519298245614035, 0.5649122807017544, 0.5754385964912281, 0.5614035087719298, 0.4982456140350877, 0.49122807017543857, 0.6175438596491228, 0.5964912280701754, 0.5333333333333333, 0.6175438596491228, 0.5894736842105263, 0.6070175438596491, 0.6280701754385964, 0.6280701754385964, 0.631578947368421, 0.631578947368421, 0.6280701754385964, 0.6421052631578947, 0.6421052631578947, 0.6385964912280702, 0.631578947368421, 0.6035087719298246, 0.6421052631578947, 0.631578947368421, 0.6421052631578947, 0.6105263157894737, 0.6350877192982456, 0.624561403508772]\n"
     ]
    }
   ],
   "source": [
    "active_mc_feminist1 = []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "query_history_feminist1 = []\n",
    "while mcrun != 5:\n",
    "    n_labeled_examples = np.unique(train_dataset_feminist['text']).size\n",
    "    training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "    print(training_indices0)\n",
    "    active_set_feminist =active_huggingface_dataset(train_dataset_feminist,tokenizer,'label','text')\n",
    "    valid_set_feminist = HuggingFaceDatasets(test_dataset_feminist,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_feminist.can_label = False\n",
    "    active_set_feminist.label(training_indices0)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_feminist,\n",
    "            eval_dataset=valid_set_feminist,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_feminist = ActiveLearningLoop(active_set_feminist,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_feminist=[unqueried_score]\n",
    "    query = [3]\n",
    "    num = 3\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_feminist.step()\n",
    "        num = num + 20\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_feminist.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_feminist),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_feminist.append(eval_metrics['eval_accuracy'])\n",
    "        query.append(num)\n",
    "    print(performance_history_feminist)\n",
    "    active_mc_feminist1.append(performance_history_feminist)\n",
    "    query_history_feminist1.append(query)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e4ab34eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_feminist1, min_feminist1,max_feminist1= calculate(active_mc_feminist1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9c5d7364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[129 169  48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='612' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 01:57]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:52:19.274864Z [info     ] Start Predict                  dataset=594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 27.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:52:24.828537Z [info     ] Start Predict                  dataset=554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 33.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:52:30.292308Z [info     ] Start Predict                  dataset=514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:02<00:00, 26.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:52:36.261064Z [info     ] Start Predict                  dataset=474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 34.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:52:41.816019Z [info     ] Start Predict                  dataset=434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 33.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:52:48.592087Z [info     ] Start Predict                  dataset=394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 27.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:52:55.889082Z [info     ] Start Predict                  dataset=354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 34.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:53:02.493803Z [info     ] Start Predict                  dataset=314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 35.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:53:09.907081Z [info     ] Start Predict                  dataset=274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 28.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:53:18.497440Z [info     ] Start Predict                  dataset=234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 34.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:53:26.390287Z [info     ] Start Predict                  dataset=194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 28.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:53:35.134050Z [info     ] Start Predict                  dataset=154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 35.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:53:43.534185Z [info     ] Start Predict                  dataset=114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 28.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:53:53.808994Z [info     ] Start Predict                  dataset=74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 35.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:54:03.057038Z [info     ] Start Predict                  dataset=34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 30.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 597\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 75\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.512280701754386, 0.48771929824561405, 0.543859649122807, 0.519298245614035, 0.5859649122807018, 0.5649122807017544, 0.5929824561403508, 0.5859649122807018, 0.6210526315789474, 0.631578947368421, 0.624561403508772, 0.6140350877192983, 0.6210526315789474, 0.6385964912280702, 0.631578947368421, 0.631578947368421]\n",
      "[272 441 502]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='612' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 01:56]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:54:16.684075Z [info     ] Start Predict                  dataset=594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 31.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:54:21.641822Z [info     ] Start Predict                  dataset=554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 27.51it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:54:27.554221Z [info     ] Start Predict                  dataset=514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 33.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:54:32.766746Z [info     ] Start Predict                  dataset=474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 34.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:54:39.220463Z [info     ] Start Predict                  dataset=434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 33.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:54:45.191721Z [info     ] Start Predict                  dataset=394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 28.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:54:52.445940Z [info     ] Start Predict                  dataset=354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 33.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:54:59.170066Z [info     ] Start Predict                  dataset=314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 34.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:55:07.226419Z [info     ] Start Predict                  dataset=274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 28.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:55:14.913867Z [info     ] Start Predict                  dataset=234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 34.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:55:22.604613Z [info     ] Start Predict                  dataset=194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 27.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:55:32.342571Z [info     ] Start Predict                  dataset=154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 29.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:55:41.086165Z [info     ] Start Predict                  dataset=114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 37.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:55:50.449410Z [info     ] Start Predict                  dataset=74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 30.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:56:00.062338Z [info     ] Start Predict                  dataset=34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 34.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 597\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 75\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.519298245614035, 0.512280701754386, 0.5824561403508772, 0.512280701754386, 0.5789473684210527, 0.5333333333333333, 0.5964912280701754, 0.5684210526315789, 0.6070175438596491, 0.6070175438596491, 0.5719298245614035, 0.6350877192982456, 0.6280701754385964, 0.624561403508772, 0.6491228070175439, 0.6350877192982456]\n",
      "[272 441 502]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='612' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 01:59]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:56:14.155303Z [info     ] Start Predict                  dataset=594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 27.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:56:19.911870Z [info     ] Start Predict                  dataset=554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 34.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:56:25.110160Z [info     ] Start Predict                  dataset=514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:02<00:00, 27.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:56:31.161164Z [info     ] Start Predict                  dataset=474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 33.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:56:37.284919Z [info     ] Start Predict                  dataset=434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 27.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:56:43.905239Z [info     ] Start Predict                  dataset=394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 33.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:56:50.956356Z [info     ] Start Predict                  dataset=354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 34.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:56:57.464177Z [info     ] Start Predict                  dataset=314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 31.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:57:05.595080Z [info     ] Start Predict                  dataset=274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 27.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:57:13.421991Z [info     ] Start Predict                  dataset=234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 34.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:57:22.805082Z [info     ] Start Predict                  dataset=194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 26.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:57:31.439467Z [info     ] Start Predict                  dataset=154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 33.66it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:57:41.041680Z [info     ] Start Predict                  dataset=114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 28.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:57:50.229123Z [info     ] Start Predict                  dataset=74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 36.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:58:00.470738Z [info     ] Start Predict                  dataset=34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 32.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 597\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 75\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.519298245614035, 0.512280701754386, 0.5824561403508772, 0.512280701754386, 0.5789473684210527, 0.5333333333333333, 0.5964912280701754, 0.5684210526315789, 0.6070175438596491, 0.6070175438596491, 0.5719298245614035, 0.6350877192982456, 0.6280701754385964, 0.624561403508772, 0.6491228070175439, 0.6350877192982456]\n",
      "[272 441 502]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='612' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 01:59]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:58:14.046604Z [info     ] Start Predict                  dataset=594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 27.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:58:19.515499Z [info     ] Start Predict                  dataset=554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 27.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:58:25.231124Z [info     ] Start Predict                  dataset=514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:02<00:00, 27.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:58:31.064500Z [info     ] Start Predict                  dataset=474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 32.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:58:37.564067Z [info     ] Start Predict                  dataset=434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 34.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:58:43.587609Z [info     ] Start Predict                  dataset=394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:58:51.738805Z [info     ] Start Predict                  dataset=354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 31.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:58:58.510001Z [info     ] Start Predict                  dataset=314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 32.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:59:07.053814Z [info     ] Start Predict                  dataset=274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 28.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:59:15.106875Z [info     ] Start Predict                  dataset=234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 33.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:59:22.879869Z [info     ] Start Predict                  dataset=194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 33.73it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:59:31.921790Z [info     ] Start Predict                  dataset=154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 27.73it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:59:41.397587Z [info     ] Start Predict                  dataset=114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 35.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:59:50.447593Z [info     ] Start Predict                  dataset=74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 28.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:00:01.181160Z [info     ] Start Predict                  dataset=34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 30.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 597\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 75\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.519298245614035, 0.512280701754386, 0.5824561403508772, 0.512280701754386, 0.5789473684210527, 0.5333333333333333, 0.5964912280701754, 0.5684210526315789, 0.6070175438596491, 0.6070175438596491, 0.5719298245614035, 0.6350877192982456, 0.6280701754385964, 0.624561403508772, 0.6491228070175439, 0.6350877192982456]\n",
      "[272 441 502]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='612' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 01:59]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:00:14.174496Z [info     ] Start Predict                  dataset=594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 32.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:00:19.241640Z [info     ] Start Predict                  dataset=554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 27.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:00:25.147991Z [info     ] Start Predict                  dataset=514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:02<00:00, 27.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:00:31.360674Z [info     ] Start Predict                  dataset=474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 33.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:00:36.981066Z [info     ] Start Predict                  dataset=434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 30.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:00:43.918530Z [info     ] Start Predict                  dataset=394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 27.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:00:51.186502Z [info     ] Start Predict                  dataset=354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 34.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:00:58.819450Z [info     ] Start Predict                  dataset=314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 27.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:01:06.386250Z [info     ] Start Predict                  dataset=274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 33.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:01:14.099792Z [info     ] Start Predict                  dataset=234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 26.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:01:23.156816Z [info     ] Start Predict                  dataset=194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 33.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:01:31.870353Z [info     ] Start Predict                  dataset=154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 26.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:01:40.851991Z [info     ] Start Predict                  dataset=114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 34.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:01:50.269866Z [info     ] Start Predict                  dataset=74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 30.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:02:00.189854Z [info     ] Start Predict                  dataset=34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 40.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 597\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 75\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.519298245614035, 0.512280701754386, 0.5824561403508772, 0.512280701754386, 0.5789473684210527, 0.5333333333333333, 0.5964912280701754, 0.5684210526315789, 0.6070175438596491, 0.6070175438596491, 0.5719298245614035, 0.6350877192982456, 0.6280701754385964, 0.624561403508772, 0.6491228070175439, 0.6350877192982456]\n"
     ]
    }
   ],
   "source": [
    "active_mc_feminist2 = []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "query_history_feminist2=[]\n",
    "while mcrun != 5:\n",
    "    n_labeled_examples = np.unique(train_dataset_feminist['text']).size\n",
    "    training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "    print(training_indices0)\n",
    "    active_set_feminist =active_huggingface_dataset(train_dataset_feminist,tokenizer,'label','text')\n",
    "    valid_set_feminist = HuggingFaceDatasets(test_dataset_feminist,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_feminist.can_label = False\n",
    "    active_set_feminist.label(training_indices0)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_feminist,\n",
    "            eval_dataset=valid_set_feminist,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_feminist = ActiveLearningLoop(active_set_feminist,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 40, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_feminist=[unqueried_score]\n",
    "    query = [3]\n",
    "    num = 3\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_feminist.step()\n",
    "        num = num +40\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_feminist.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_feminist),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_feminist.append(eval_metrics['eval_accuracy'])\n",
    "        query.append(num)\n",
    "    print(performance_history_feminist)\n",
    "    active_mc_feminist2.append(performance_history_feminist)\n",
    "    query_history_feminist2.append(query)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "76295454",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_feminist2, min_feminist2,max_feminist2= calculate(active_mc_feminist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2f5919a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 49  29 542]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='432' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 01:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:02:14.560955Z [info     ] Start Predict                  dataset=594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 27.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:02:19.965816Z [info     ] Start Predict                  dataset=534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 33.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:02:26.493458Z [info     ] Start Predict                  dataset=474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:02<00:00, 28.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:02:33.429842Z [info     ] Start Predict                  dataset=414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 30.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:02:39.821067Z [info     ] Start Predict                  dataset=354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 30.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:02:47.981343Z [info     ] Start Predict                  dataset=294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 26.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:02:56.081817Z [info     ] Start Predict                  dataset=234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 33.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:03:05.364309Z [info     ] Start Predict                  dataset=174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 27.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:03:14.548034Z [info     ] Start Predict                  dataset=114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 36.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:03:23.525693Z [info     ] Start Predict                  dataset=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 37.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 597\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 75\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45263157894736844, 0.43859649122807015, 0.5508771929824562, 0.6035087719298246, 0.6105263157894737, 0.6350877192982456, 0.6210526315789474, 0.6070175438596491, 0.6350877192982456, 0.631578947368421, 0.6385964912280702]\n",
      "[174 288 480]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='432' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 01:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:03:38.576837Z [info     ] Start Predict                  dataset=594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 26.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:03:44.097400Z [info     ] Start Predict                  dataset=534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 33.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:03:49.443919Z [info     ] Start Predict                  dataset=474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 32.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:03:56.196701Z [info     ] Start Predict                  dataset=414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 32.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:04:02.580292Z [info     ] Start Predict                  dataset=354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 32.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:04:10.606972Z [info     ] Start Predict                  dataset=294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 27.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:04:18.797885Z [info     ] Start Predict                  dataset=234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 34.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:04:27.339237Z [info     ] Start Predict                  dataset=174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 34.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:04:37.546686Z [info     ] Start Predict                  dataset=114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 25.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:04:48.769447Z [info     ] Start Predict                  dataset=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 26.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 597\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 75\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4245614035087719, 0.40350877192982454, 0.4982456140350877, 0.5368421052631579, 0.5228070175438596, 0.5859649122807018, 0.5824561403508772, 0.5929824561403508, 0.6, 0.631578947368421, 0.6385964912280702]\n",
      "[174 288 480]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='432' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 01:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:05:02.161101Z [info     ] Start Predict                  dataset=594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 28.51it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:05:07.767193Z [info     ] Start Predict                  dataset=534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 27.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:05:13.778317Z [info     ] Start Predict                  dataset=474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 34.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:05:20.739271Z [info     ] Start Predict                  dataset=414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 27.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:05:28.429390Z [info     ] Start Predict                  dataset=354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 33.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:05:36.099838Z [info     ] Start Predict                  dataset=294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 34.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:05:44.234977Z [info     ] Start Predict                  dataset=234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 27.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:05:52.701787Z [info     ] Start Predict                  dataset=174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 34.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:06:02.473217Z [info     ] Start Predict                  dataset=114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 34.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:06:11.372172Z [info     ] Start Predict                  dataset=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 34.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 597\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 75\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4245614035087719, 0.40350877192982454, 0.4982456140350877, 0.5368421052631579, 0.5228070175438596, 0.5859649122807018, 0.5824561403508772, 0.5929824561403508, 0.6, 0.631578947368421, 0.6385964912280702]\n",
      "[174 288 480]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='432' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 01:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:06:26.113611Z [info     ] Start Predict                  dataset=594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 33.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:06:31.333311Z [info     ] Start Predict                  dataset=534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 27.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:06:37.195033Z [info     ] Start Predict                  dataset=474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 33.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:06:43.712380Z [info     ] Start Predict                  dataset=414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 26.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:06:50.624995Z [info     ] Start Predict                  dataset=354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 31.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:06:58.449273Z [info     ] Start Predict                  dataset=294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 34.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:07:06.239230Z [info     ] Start Predict                  dataset=234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 28.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:07:14.713793Z [info     ] Start Predict                  dataset=174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 34.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:07:24.585827Z [info     ] Start Predict                  dataset=114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 27.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:07:33.771386Z [info     ] Start Predict                  dataset=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 36.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 597\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 75\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4245614035087719, 0.40350877192982454, 0.4982456140350877, 0.5368421052631579, 0.5228070175438596, 0.5859649122807018, 0.5824561403508772, 0.5929824561403508, 0.6, 0.631578947368421, 0.6385964912280702]\n",
      "[174 288 480]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='432' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 01:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:07:48.264955Z [info     ] Start Predict                  dataset=594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 27.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:07:54.016843Z [info     ] Start Predict                  dataset=534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 27.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:07:59.918165Z [info     ] Start Predict                  dataset=474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 34.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:08:06.166000Z [info     ] Start Predict                  dataset=414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 27.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:08:13.754701Z [info     ] Start Predict                  dataset=354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 27.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:08:21.309268Z [info     ] Start Predict                  dataset=294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 33.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:08:29.036708Z [info     ] Start Predict                  dataset=234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 28.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:08:37.721638Z [info     ] Start Predict                  dataset=174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 33.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:08:48.660976Z [info     ] Start Predict                  dataset=114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 32.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T13:08:57.757679Z [info     ] Start Predict                  dataset=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 28.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 597\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 75\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 00:09, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4245614035087719, 0.40350877192982454, 0.4982456140350877, 0.5368421052631579, 0.5228070175438596, 0.5859649122807018, 0.5824561403508772, 0.5929824561403508, 0.6, 0.631578947368421, 0.6385964912280702]\n"
     ]
    }
   ],
   "source": [
    "active_mc_feminist3 = []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "query_history_feminist3 = []\n",
    "while mcrun != 5:\n",
    "    n_labeled_examples = np.unique(train_dataset_feminist['text']).size\n",
    "    training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "    print(training_indices0)\n",
    "    active_set_feminist =active_huggingface_dataset(train_dataset_feminist,tokenizer,'label','text')\n",
    "    valid_set_feminist = HuggingFaceDatasets(test_dataset_feminist,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_feminist.can_label = False\n",
    "    active_set_feminist.label(training_indices0)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_feminist,\n",
    "            eval_dataset=valid_set_feminist,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_feminist = ActiveLearningLoop(active_set_feminist,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 60, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_feminist=[unqueried_score]\n",
    "    query = [3]\n",
    "    num = 3\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_feminist.step()\n",
    "        num = num + 60\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_feminist.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_feminist),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_feminist.append(eval_metrics['eval_accuracy'])\n",
    "        query.append(num)\n",
    "    print(performance_history_feminist)\n",
    "    active_mc_feminist3.append(performance_history_feminist)\n",
    "    query_history_feminist3.append(query)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6c2aa0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_feminist3, min_feminist3,max_feminist3= calculate(active_mc_feminist3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "df060c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1105x1040 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(8.5, 8), dpi=130)\n",
    "ax.plot(query_history_feminist1[0],median_feminist1,label=\"Queue size 20\")\n",
    "ax.fill_between(query_history_feminist1[0],min_feminist1,max_feminist1,color='blue', alpha=0.1)\n",
    "ax.plot(query_history_feminist2[0],median_feminist2,label=\"Queue size 40\")\n",
    "ax.fill_between(query_history_feminist2[0],min_feminist2,max_feminist2,color='orange', alpha=0.1)\n",
    "ax.plot(query_history_feminist3[0],median_feminist3,label=\"Queue size 60\")\n",
    "ax.fill_between(query_history_feminist3[0],min_feminist3,max_feminist3,color='red', alpha=0.1)\n",
    "ax.scatter(query_history_feminist1[0], median_feminist1, s=8,marker = \"v\")\n",
    "ax.scatter(query_history_feminist2[0], median_feminist2, s=8,marker=\"^\")\n",
    "ax.scatter(query_history_feminist3[0], median_feminist3, s=8,marker = \",\")\n",
    "ax.xaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=5, integer=True))\n",
    "ax.yaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=10))\n",
    "ax.yaxis.set_major_formatter(mpl.ticker.PercentFormatter(xmax=1))\n",
    "\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "ax.set_title('Different query queue sizes in feminist target')\n",
    "ax.set_xlabel('Volume of labeled data')\n",
    "ax.set_ylabel('Performance(median)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a2c57d",
   "metadata": {},
   "source": [
    "# Hillary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c821b9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_hillary\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset with 620 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_hillary\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset with 69 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_hillary\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset with 295 instances loaded\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "cache_dir = \"./data_cache\"\n",
    "\n",
    "train_dataset_hillary = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_hillary\",\n",
    "    split=\"train\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Training dataset with {len(train_dataset_hillary)} instances loaded\")\n",
    "\n",
    "val_dataset_hillary = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_hillary\",\n",
    "    split=\"validation\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Validation dataset with {len(val_dataset_hillary)} instances loaded\")\n",
    "\n",
    "test_dataset_hillary = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_hillary\",\n",
    "    split=\"test\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Test dataset with {len(test_dataset_hillary)} instances loaded\")\n",
    "\n",
    "num_classes = np.unique(train_dataset_hillary['label']).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d135674a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/config.json from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\3cf34679007e9fe5d0acd644dcc1f4b26bec5cbc9612364f6da7262aed4ef7a4.a5a11219cf90aae61ff30e1658ccf2cb4aa84d6b6e947336556f887c9828dc6d\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-tiny\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/pytorch_model.bin from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\1ee037c9e1a220d5c814779ffe697080d1e6f5b1602e16cf6061aaae41a082c5.038e1aed90492a59d2283f9c44c9fe3ee2380495ff1e7fefb3f1f04af3b685b5\n",
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_original = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\", num_labels=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a636de36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[317 291 549]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1147' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 03:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:44:49.291264Z [info     ] Start Predict                  dataset=617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 78/78 [00:02<00:00, 26.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:44:54.471240Z [info     ] Start Predict                  dataset=597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 33.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:44:59.010464Z [info     ] Start Predict                  dataset=577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 32.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:45:03.708931Z [info     ] Start Predict                  dataset=557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 33.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:45:09.167854Z [info     ] Start Predict                  dataset=537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 28.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:45:14.706437Z [info     ] Start Predict                  dataset=517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 34.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:45:20.012670Z [info     ] Start Predict                  dataset=497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 35.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:45:25.328580Z [info     ] Start Predict                  dataset=477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 34.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:45:31.042744Z [info     ] Start Predict                  dataset=457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 34.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:45:36.825516Z [info     ] Start Predict                  dataset=437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 34.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:45:44.543087Z [info     ] Start Predict                  dataset=417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 34.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:45:50.777841Z [info     ] Start Predict                  dataset=397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 32.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:45:57.216746Z [info     ] Start Predict                  dataset=377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 34.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:46:03.748952Z [info     ] Start Predict                  dataset=357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 34.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:46:10.912193Z [info     ] Start Predict                  dataset=337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 32.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:46:17.836282Z [info     ] Start Predict                  dataset=317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 34.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:46:24.873924Z [info     ] Start Predict                  dataset=297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 34.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:46:32.123860Z [info     ] Start Predict                  dataset=277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 34.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:46:39.610349Z [info     ] Start Predict                  dataset=257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 35.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:46:47.733155Z [info     ] Start Predict                  dataset=237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 33.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:46:55.499544Z [info     ] Start Predict                  dataset=217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 35.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:47:03.860976Z [info     ] Start Predict                  dataset=197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 31.03it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:47:13.336890Z [info     ] Start Predict                  dataset=177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 33.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:47:22.982427Z [info     ] Start Predict                  dataset=157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 35.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:47:31.360946Z [info     ] Start Predict                  dataset=137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 34.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:47:39.948764Z [info     ] Start Predict                  dataset=117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 36.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:47:48.670617Z [info     ] Start Predict                  dataset=97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 36.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:47:57.564748Z [info     ] Start Predict                  dataset=77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 34.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:48:06.742628Z [info     ] Start Predict                  dataset=57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 37.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:48:16.903928Z [info     ] Start Predict                  dataset=37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 29.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43389830508474575, 0.4067796610169492, 0.5084745762711864, 0.5084745762711864, 0.5457627118644067, 0.559322033898305, 0.5661016949152542, 0.5796610169491525, 0.5864406779661017, 0.5864406779661017, 0.5728813559322034, 0.5796610169491525, 0.5830508474576271, 0.5830508474576271, 0.576271186440678, 0.576271186440678, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5728813559322034, 0.5830508474576271, 0.5864406779661017, 0.576271186440678, 0.5830508474576271, 0.5796610169491525, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271]\n",
      "[503 141 583]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1147' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 03:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:48:20.736027Z [info     ] Start Predict                  dataset=617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 78/78 [00:02<00:00, 33.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:48:25.169119Z [info     ] Start Predict                  dataset=597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 32.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:48:30.285937Z [info     ] Start Predict                  dataset=577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 27.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:48:35.696622Z [info     ] Start Predict                  dataset=557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 33.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:48:41.812287Z [info     ] Start Predict                  dataset=537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 33.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:48:47.710412Z [info     ] Start Predict                  dataset=517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:02<00:00, 31.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:48:53.224172Z [info     ] Start Predict                  dataset=497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 33.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:48:59.248138Z [info     ] Start Predict                  dataset=477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 32.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:49:05.019052Z [info     ] Start Predict                  dataset=457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 34.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:49:10.819566Z [info     ] Start Predict                  dataset=437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 32.89it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:49:17.351523Z [info     ] Start Predict                  dataset=417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 30.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:49:24.235507Z [info     ] Start Predict                  dataset=397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 34.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:49:30.580113Z [info     ] Start Predict                  dataset=377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 33.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:49:37.420694Z [info     ] Start Predict                  dataset=357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 34.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:49:44.093680Z [info     ] Start Predict                  dataset=337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 34.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:49:51.668781Z [info     ] Start Predict                  dataset=317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 34.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:49:58.755426Z [info     ] Start Predict                  dataset=297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 32.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:50:06.600864Z [info     ] Start Predict                  dataset=277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 31.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:50:14.151220Z [info     ] Start Predict                  dataset=257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 32.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:50:22.846265Z [info     ] Start Predict                  dataset=237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 32.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:50:30.606811Z [info     ] Start Predict                  dataset=217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 33.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:50:38.423467Z [info     ] Start Predict                  dataset=197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 34.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:50:47.203175Z [info     ] Start Predict                  dataset=177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 27.73it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:50:57.126817Z [info     ] Start Predict                  dataset=157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 33.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:51:05.727330Z [info     ] Start Predict                  dataset=137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 34.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:51:14.976244Z [info     ] Start Predict                  dataset=117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 34.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:51:23.889988Z [info     ] Start Predict                  dataset=97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 34.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:51:32.904109Z [info     ] Start Predict                  dataset=77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 31.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:51:42.170617Z [info     ] Start Predict                  dataset=57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 38.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:51:51.516375Z [info     ] Start Predict                  dataset=37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 36.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39661016949152544, 0.38305084745762713, 0.423728813559322, 0.43728813559322033, 0.48135593220338985, 0.5389830508474577, 0.5016949152542373, 0.5423728813559322, 0.5322033898305085, 0.5796610169491525, 0.5288135593220339, 0.5728813559322034, 0.5830508474576271, 0.576271186440678, 0.5694915254237288, 0.5661016949152542, 0.5796610169491525, 0.5830508474576271, 0.5796610169491525, 0.5694915254237288, 0.5830508474576271, 0.5864406779661017, 0.5796610169491525, 0.5830508474576271, 0.576271186440678, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271]\n",
      "[503 141 583]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1147' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 03:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:51:55.065332Z [info     ] Start Predict                  dataset=617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 78/78 [00:02<00:00, 31.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:51:59.896645Z [info     ] Start Predict                  dataset=597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 26.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:52:05.227111Z [info     ] Start Predict                  dataset=577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 33.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:52:10.709919Z [info     ] Start Predict                  dataset=557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 34.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:52:16.334680Z [info     ] Start Predict                  dataset=537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 31.73it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:52:23.530296Z [info     ] Start Predict                  dataset=517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 32.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:52:30.411540Z [info     ] Start Predict                  dataset=497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 34.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:52:36.970735Z [info     ] Start Predict                  dataset=477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 33.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:52:42.758312Z [info     ] Start Predict                  dataset=457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 31.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:52:50.779805Z [info     ] Start Predict                  dataset=437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 33.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:52:56.808611Z [info     ] Start Predict                  dataset=417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 33.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:53:03.040775Z [info     ] Start Predict                  dataset=397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 32.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:53:09.423201Z [info     ] Start Predict                  dataset=377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 33.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:53:16.053664Z [info     ] Start Predict                  dataset=357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 34.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:53:23.435159Z [info     ] Start Predict                  dataset=337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 32.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:53:30.233077Z [info     ] Start Predict                  dataset=317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 33.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:53:37.347383Z [info     ] Start Predict                  dataset=297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 33.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:53:44.693424Z [info     ] Start Predict                  dataset=277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 33.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:53:52.190929Z [info     ] Start Predict                  dataset=257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 33.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:53:59.889836Z [info     ] Start Predict                  dataset=237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 26.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:54:07.993899Z [info     ] Start Predict                  dataset=217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 33.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:54:15.798608Z [info     ] Start Predict                  dataset=197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 34.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:54:23.814056Z [info     ] Start Predict                  dataset=177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 33.66it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:54:32.044932Z [info     ] Start Predict                  dataset=157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 35.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:54:41.556648Z [info     ] Start Predict                  dataset=137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 35.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:54:50.287490Z [info     ] Start Predict                  dataset=117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 36.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:54:59.619002Z [info     ] Start Predict                  dataset=97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 32.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:55:08.647173Z [info     ] Start Predict                  dataset=77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 34.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:55:18.162960Z [info     ] Start Predict                  dataset=57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 38.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:55:27.509666Z [info     ] Start Predict                  dataset=37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 34.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39661016949152544, 0.38305084745762713, 0.423728813559322, 0.43728813559322033, 0.48135593220338985, 0.5389830508474577, 0.5016949152542373, 0.5423728813559322, 0.5322033898305085, 0.5796610169491525, 0.5288135593220339, 0.5728813559322034, 0.5830508474576271, 0.576271186440678, 0.5694915254237288, 0.5661016949152542, 0.5796610169491525, 0.5830508474576271, 0.5796610169491525, 0.5694915254237288, 0.5830508474576271, 0.5864406779661017, 0.5796610169491525, 0.5830508474576271, 0.576271186440678, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271]\n",
      "[503 141 583]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1147' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 03:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:55:31.189816Z [info     ] Start Predict                  dataset=617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 78/78 [00:02<00:00, 31.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:55:35.977225Z [info     ] Start Predict                  dataset=597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 26.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:55:41.153110Z [info     ] Start Predict                  dataset=577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 33.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:55:46.353641Z [info     ] Start Predict                  dataset=557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 29.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:55:51.639618Z [info     ] Start Predict                  dataset=537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 33.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:55:56.750186Z [info     ] Start Predict                  dataset=517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 33.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:56:02.078330Z [info     ] Start Predict                  dataset=497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 33.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:56:07.708846Z [info     ] Start Predict                  dataset=477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 33.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:56:14.108743Z [info     ] Start Predict                  dataset=457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 32.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:56:20.056752Z [info     ] Start Predict                  dataset=437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 33.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:56:25.977373Z [info     ] Start Predict                  dataset=417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 33.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:56:32.269076Z [info     ] Start Predict                  dataset=397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 33.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:56:39.285460Z [info     ] Start Predict                  dataset=377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 32.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:56:45.820006Z [info     ] Start Predict                  dataset=357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 33.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:56:52.697722Z [info     ] Start Predict                  dataset=337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 33.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:56:59.676568Z [info     ] Start Predict                  dataset=317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 34.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:57:07.771984Z [info     ] Start Predict                  dataset=297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 32.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:57:16.322248Z [info     ] Start Predict                  dataset=277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 33.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:57:23.951806Z [info     ] Start Predict                  dataset=257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 34.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:57:31.349337Z [info     ] Start Predict                  dataset=237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 32.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:57:39.829745Z [info     ] Start Predict                  dataset=217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 34.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:57:49.094919Z [info     ] Start Predict                  dataset=197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 34.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:57:57.274365Z [info     ] Start Predict                  dataset=177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 35.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:58:05.571080Z [info     ] Start Predict                  dataset=157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 32.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:58:15.702589Z [info     ] Start Predict                  dataset=137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 33.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:58:24.281439Z [info     ] Start Predict                  dataset=117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 36.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:58:33.197325Z [info     ] Start Predict                  dataset=97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 35.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:58:42.768701Z [info     ] Start Predict                  dataset=77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 35.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:58:53.368008Z [info     ] Start Predict                  dataset=57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 38.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:59:02.836056Z [info     ] Start Predict                  dataset=37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 36.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39661016949152544, 0.38305084745762713, 0.423728813559322, 0.43728813559322033, 0.48135593220338985, 0.5389830508474577, 0.5016949152542373, 0.5423728813559322, 0.5322033898305085, 0.5796610169491525, 0.5288135593220339, 0.5728813559322034, 0.5830508474576271, 0.576271186440678, 0.5694915254237288, 0.5661016949152542, 0.5796610169491525, 0.5830508474576271, 0.5796610169491525, 0.5694915254237288, 0.5830508474576271, 0.5864406779661017, 0.5796610169491525, 0.5830508474576271, 0.576271186440678, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271]\n",
      "[503 141 583]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1147' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 03:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:59:06.916912Z [info     ] Start Predict                  dataset=617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 78/78 [00:02<00:00, 27.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:59:12.067833Z [info     ] Start Predict                  dataset=597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 33.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:59:16.665600Z [info     ] Start Predict                  dataset=577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 33.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:59:21.428808Z [info     ] Start Predict                  dataset=557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 32.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:59:26.978508Z [info     ] Start Predict                  dataset=537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 31.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:59:32.227760Z [info     ] Start Predict                  dataset=517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 33.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:59:37.624358Z [info     ] Start Predict                  dataset=497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 33.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:59:43.125843Z [info     ] Start Predict                  dataset=477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 33.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:59:48.819583Z [info     ] Start Predict                  dataset=457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 33.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T11:59:55.022945Z [info     ] Start Predict                  dataset=437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 33.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:00:00.939717Z [info     ] Start Predict                  dataset=417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 34.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:00:07.238645Z [info     ] Start Predict                  dataset=397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 31.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:00:14.576977Z [info     ] Start Predict                  dataset=377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 32.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:00:21.544462Z [info     ] Start Predict                  dataset=357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 33.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:00:28.572822Z [info     ] Start Predict                  dataset=337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 32.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:00:35.472360Z [info     ] Start Predict                  dataset=317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 33.73it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:00:42.527807Z [info     ] Start Predict                  dataset=297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 32.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:00:50.655900Z [info     ] Start Predict                  dataset=277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 34.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:00:58.346071Z [info     ] Start Predict                  dataset=257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 33.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:01:05.975379Z [info     ] Start Predict                  dataset=237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 35.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:01:13.610520Z [info     ] Start Predict                  dataset=217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 35.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:01:21.557458Z [info     ] Start Predict                  dataset=197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 33.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:01:29.702186Z [info     ] Start Predict                  dataset=177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 35.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:01:38.050461Z [info     ] Start Predict                  dataset=157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 28.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:01:47.302517Z [info     ] Start Predict                  dataset=137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 36.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:01:56.344764Z [info     ] Start Predict                  dataset=117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 35.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:02:05.125452Z [info     ] Start Predict                  dataset=97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 36.66it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:02:13.990096Z [info     ] Start Predict                  dataset=77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 33.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:02:23.172710Z [info     ] Start Predict                  dataset=57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 36.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:02:33.320545Z [info     ] Start Predict                  dataset=37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 28.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39661016949152544, 0.38305084745762713, 0.423728813559322, 0.43728813559322033, 0.48135593220338985, 0.5389830508474577, 0.5016949152542373, 0.5423728813559322, 0.5322033898305085, 0.5796610169491525, 0.5288135593220339, 0.5728813559322034, 0.5830508474576271, 0.576271186440678, 0.5694915254237288, 0.5661016949152542, 0.5796610169491525, 0.5830508474576271, 0.5796610169491525, 0.5694915254237288, 0.5830508474576271, 0.5864406779661017, 0.5796610169491525, 0.5830508474576271, 0.576271186440678, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271]\n"
     ]
    }
   ],
   "source": [
    "active_mc_hillary1 = []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "query_history_hillary1 = []\n",
    "np.random.seed()\n",
    "while mcrun != 5:\n",
    "    n_labeled_examples = np.unique(train_dataset_hillary['text']).size\n",
    "    training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "    print(training_indices0)\n",
    "    active_set_hillary =active_huggingface_dataset(train_dataset_hillary,tokenizer,'label','text')\n",
    "    valid_set_hillary = HuggingFaceDatasets(test_dataset_hillary,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_hillary.can_label = False\n",
    "    active_set_hillary.label(training_indices0)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_hillary,\n",
    "            eval_dataset=valid_set_hillary,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_hillary = ActiveLearningLoop(active_set_hillary,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_hillary=[unqueried_score]\n",
    "    query = [3]\n",
    "    num = 3\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_hillary.step()\n",
    "        num = num + 20\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_hillary.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_hillary),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_hillary.append(eval_metrics['eval_accuracy'])\n",
    "        query.append(num)\n",
    "    print(performance_history_hillary)\n",
    "    active_mc_hillary1.append(performance_history_hillary)\n",
    "    query_history_hillary1.append(query)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6ccd23e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_hillary1, min_hillary1,max_hillary1 = calculate(active_mc_hillary1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "18e5d5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[375 432 544]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='666' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 02:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:02:37.230920Z [info     ] Start Predict                  dataset=617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 78/78 [00:02<00:00, 31.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:02:42.519525Z [info     ] Start Predict                  dataset=577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 31.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:02:47.858130Z [info     ] Start Predict                  dataset=537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 32.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:02:53.696853Z [info     ] Start Predict                  dataset=497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:02:59.806284Z [info     ] Start Predict                  dataset=457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 32.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:03:06.085318Z [info     ] Start Predict                  dataset=417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 34.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:03:12.666464Z [info     ] Start Predict                  dataset=377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 34.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:03:19.320320Z [info     ] Start Predict                  dataset=337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 34.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:03:26.579637Z [info     ] Start Predict                  dataset=297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 34.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:03:34.185653Z [info     ] Start Predict                  dataset=257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 34.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:03:41.941987Z [info     ] Start Predict                  dataset=217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 35.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:03:50.505686Z [info     ] Start Predict                  dataset=177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 27.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:03:59.490220Z [info     ] Start Predict                  dataset=137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 34.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:04:08.333319Z [info     ] Start Predict                  dataset=97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 37.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:04:18.182292Z [info     ] Start Predict                  dataset=57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 41.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 603\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 76\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='76' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [76/76 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:04:27.924368Z [info     ] Start Predict                  dataset=17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 49.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 620\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 78\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='78' max='78' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [78/78 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44745762711864406, 0.4067796610169492, 0.5220338983050847, 0.559322033898305, 0.5796610169491525, 0.5491525423728814, 0.5694915254237288, 0.5796610169491525, 0.5728813559322034, 0.5864406779661017, 0.5830508474576271, 0.5864406779661017, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271]\n",
      "[562 265 119]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='666' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 02:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:04:41.120939Z [info     ] Start Predict                  dataset=617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 78/78 [00:02<00:00, 31.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:04:46.652354Z [info     ] Start Predict                  dataset=577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 31.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:04:51.754944Z [info     ] Start Predict                  dataset=537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 33.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:04:57.684809Z [info     ] Start Predict                  dataset=497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 31.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:05:03.680081Z [info     ] Start Predict                  dataset=457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 33.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:05:09.651778Z [info     ] Start Predict                  dataset=417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 34.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:05:16.159215Z [info     ] Start Predict                  dataset=377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 34.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:05:23.091085Z [info     ] Start Predict                  dataset=337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 34.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:05:30.145159Z [info     ] Start Predict                  dataset=297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 34.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:05:38.536039Z [info     ] Start Predict                  dataset=257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 32.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:05:46.515596Z [info     ] Start Predict                  dataset=217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 34.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:05:54.712993Z [info     ] Start Predict                  dataset=177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 35.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:06:03.161274Z [info     ] Start Predict                  dataset=137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 34.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:06:12.906642Z [info     ] Start Predict                  dataset=97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 35.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:06:22.041175Z [info     ] Start Predict                  dataset=57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 39.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 603\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 76\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='76' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [76/76 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:06:31.490017Z [info     ] Start Predict                  dataset=17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 44.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 620\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 78\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='78' max='78' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [78/78 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43389830508474575, 0.4101694915254237, 0.5288135593220339, 0.5491525423728814, 0.5627118644067797, 0.5796610169491525, 0.576271186440678, 0.5864406779661017, 0.576271186440678, 0.5864406779661017, 0.5830508474576271, 0.5830508474576271, 0.5864406779661017, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271]\n",
      "[562 265 119]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='666' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 02:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:06:45.131154Z [info     ] Start Predict                  dataset=617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 78/78 [00:02<00:00, 27.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:06:50.795572Z [info     ] Start Predict                  dataset=577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 33.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:06:55.826782Z [info     ] Start Predict                  dataset=537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 33.51it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:07:01.756950Z [info     ] Start Predict                  dataset=497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 32.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:07:07.577893Z [info     ] Start Predict                  dataset=457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 34.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:07:13.786075Z [info     ] Start Predict                  dataset=417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 33.73it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:07:20.250660Z [info     ] Start Predict                  dataset=377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 33.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:07:27.114997Z [info     ] Start Predict                  dataset=337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 33.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:07:34.269359Z [info     ] Start Predict                  dataset=297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 30.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:07:42.677911Z [info     ] Start Predict                  dataset=257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 33.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:07:50.643935Z [info     ] Start Predict                  dataset=217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 35.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:07:58.819929Z [info     ] Start Predict                  dataset=177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 34.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:08:07.732132Z [info     ] Start Predict                  dataset=137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 33.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:08:16.700521Z [info     ] Start Predict                  dataset=97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 33.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:08:25.787635Z [info     ] Start Predict                  dataset=57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 38.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 603\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 76\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='76' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [76/76 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:08:35.525247Z [info     ] Start Predict                  dataset=17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 45.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 620\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 78\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='78' max='78' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [78/78 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43389830508474575, 0.4101694915254237, 0.5288135593220339, 0.5491525423728814, 0.5627118644067797, 0.5796610169491525, 0.576271186440678, 0.5864406779661017, 0.576271186440678, 0.5864406779661017, 0.5830508474576271, 0.5830508474576271, 0.5864406779661017, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271]\n",
      "[562 265 119]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='666' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 02:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:08:49.895513Z [info     ] Start Predict                  dataset=617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 78/78 [00:02<00:00, 33.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:08:54.458405Z [info     ] Start Predict                  dataset=577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 33.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:09:00.984619Z [info     ] Start Predict                  dataset=537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 33.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:09:08.531753Z [info     ] Start Predict                  dataset=497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 34.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:09:14.280782Z [info     ] Start Predict                  dataset=457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 33.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:09:20.362481Z [info     ] Start Predict                  dataset=417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 33.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:09:28.123184Z [info     ] Start Predict                  dataset=377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 34.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:09:36.039937Z [info     ] Start Predict                  dataset=337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 34.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:09:44.969419Z [info     ] Start Predict                  dataset=297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 33.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:09:52.736566Z [info     ] Start Predict                  dataset=257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 34.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:10:00.432135Z [info     ] Start Predict                  dataset=217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 33.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:10:08.578472Z [info     ] Start Predict                  dataset=177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 35.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:10:19.328660Z [info     ] Start Predict                  dataset=137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 35.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:10:28.086285Z [info     ] Start Predict                  dataset=97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 36.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:10:37.790255Z [info     ] Start Predict                  dataset=57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 31.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 603\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 76\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='76' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [76/76 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:10:47.281799Z [info     ] Start Predict                  dataset=17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 39.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 620\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 78\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='78' max='78' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [78/78 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43389830508474575, 0.4101694915254237, 0.5288135593220339, 0.5491525423728814, 0.5627118644067797, 0.5796610169491525, 0.576271186440678, 0.5864406779661017, 0.576271186440678, 0.5864406779661017, 0.5830508474576271, 0.5830508474576271, 0.5864406779661017, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271]\n",
      "[562 265 119]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='666' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 02:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:11:01.492696Z [info     ] Start Predict                  dataset=617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 78/78 [00:02<00:00, 34.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:11:06.125643Z [info     ] Start Predict                  dataset=577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 33.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:11:11.124260Z [info     ] Start Predict                  dataset=537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 33.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:11:16.489856Z [info     ] Start Predict                  dataset=497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 34.03it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:11:23.020043Z [info     ] Start Predict                  dataset=457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 33.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:11:29.484238Z [info     ] Start Predict                  dataset=417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 33.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:11:37.831828Z [info     ] Start Predict                  dataset=377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 34.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:11:46.401232Z [info     ] Start Predict                  dataset=337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 34.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:11:53.658531Z [info     ] Start Predict                  dataset=297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 33.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:12:01.181076Z [info     ] Start Predict                  dataset=257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 33.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:12:08.986758Z [info     ] Start Predict                  dataset=217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 34.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:12:17.173278Z [info     ] Start Predict                  dataset=177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 35.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:12:25.697642Z [info     ] Start Predict                  dataset=137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 34.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:12:35.844169Z [info     ] Start Predict                  dataset=97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 34.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:12:46.579113Z [info     ] Start Predict                  dataset=57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 38.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 603\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 76\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='76' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [76/76 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:12:56.405029Z [info     ] Start Predict                  dataset=17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 41.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 620\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 78\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='78' max='78' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [78/78 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43389830508474575, 0.4101694915254237, 0.5288135593220339, 0.5491525423728814, 0.5627118644067797, 0.5796610169491525, 0.576271186440678, 0.5864406779661017, 0.576271186440678, 0.5864406779661017, 0.5830508474576271, 0.5830508474576271, 0.5864406779661017, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271]\n"
     ]
    }
   ],
   "source": [
    "active_mc_hillary2 = []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "query_history_hillary2 = []\n",
    "while mcrun != 5:\n",
    "    n_labeled_examples = np.unique(train_dataset_hillary['text']).size\n",
    "    training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "    print(training_indices0)\n",
    "    active_set_hillary =active_huggingface_dataset(train_dataset_hillary,tokenizer,'label','text')\n",
    "    valid_set_hillary = HuggingFaceDatasets(test_dataset_hillary,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_hillary.can_label = False\n",
    "    active_set_hillary.label(training_indices0)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_hillary,\n",
    "            eval_dataset=valid_set_hillary,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_hillary = ActiveLearningLoop(active_set_hillary,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 40, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_hillary=[unqueried_score]\n",
    "    query = [3]\n",
    "    num = 3\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_hillary.step()\n",
    "        num = num + 40\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_hillary.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_hillary),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_hillary.append(eval_metrics['eval_accuracy'])\n",
    "        query.append(num)\n",
    "    print(performance_history_hillary)\n",
    "    query_history_hillary2.append(query)\n",
    "    active_mc_hillary2.append(performance_history_hillary)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "03b60c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_hillary2, min_hillary2,max_hillary2= calculate(active_mc_hillary2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4455480e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[417 266 352]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='481' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 01:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:13:10.663646Z [info     ] Start Predict                  dataset=617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 78/78 [00:02<00:00, 33.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:13:15.913035Z [info     ] Start Predict                  dataset=557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 32.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:13:21.415066Z [info     ] Start Predict                  dataset=497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 33.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:13:28.278765Z [info     ] Start Predict                  dataset=437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:02<00:00, 27.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:13:36.526256Z [info     ] Start Predict                  dataset=377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 28.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:13:45.255035Z [info     ] Start Predict                  dataset=317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 25.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:13:53.968418Z [info     ] Start Predict                  dataset=257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 30.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:14:03.532387Z [info     ] Start Predict                  dataset=197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 33.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:14:14.598364Z [info     ] Start Predict                  dataset=137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 36.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:14:23.592361Z [info     ] Start Predict                  dataset=77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 35.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 603\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 76\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='76' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [76/76 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:14:33.240777Z [info     ] Start Predict                  dataset=17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 43.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 620\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 78\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='78' max='78' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [78/78 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4406779661016949, 0.4067796610169492, 0.49830508474576274, 0.5322033898305085, 0.5661016949152542, 0.576271186440678, 0.5864406779661017, 0.5796610169491525, 0.5830508474576271, 0.5864406779661017, 0.5830508474576271, 0.5830508474576271]\n",
      "[149   7  28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='481' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 01:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:14:46.255410Z [info     ] Start Predict                  dataset=617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 78/78 [00:02<00:00, 33.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:14:51.072124Z [info     ] Start Predict                  dataset=557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 33.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:14:56.665267Z [info     ] Start Predict                  dataset=497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 33.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:15:03.312926Z [info     ] Start Predict                  dataset=437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 33.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:15:09.825594Z [info     ] Start Predict                  dataset=377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 32.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:15:17.004385Z [info     ] Start Predict                  dataset=317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 32.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:15:24.704904Z [info     ] Start Predict                  dataset=257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 34.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:15:32.901444Z [info     ] Start Predict                  dataset=197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 34.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:15:41.550091Z [info     ] Start Predict                  dataset=137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 32.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:15:51.629960Z [info     ] Start Predict                  dataset=77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 33.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 603\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 76\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='76' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [76/76 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:16:01.392524Z [info     ] Start Predict                  dataset=17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 42.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 620\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 78\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='78' max='78' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [78/78 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41694915254237286, 0.38305084745762713, 0.46779661016949153, 0.4610169491525424, 0.5627118644067797, 0.5728813559322034, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5864406779661017, 0.5830508474576271, 0.5830508474576271]\n",
      "[149   7  28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='481' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 01:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:16:15.454579Z [info     ] Start Predict                  dataset=617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 78/78 [00:02<00:00, 33.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:16:20.353573Z [info     ] Start Predict                  dataset=557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 32.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:16:27.999530Z [info     ] Start Predict                  dataset=497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 33.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:16:34.481378Z [info     ] Start Predict                  dataset=437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 33.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:16:40.978250Z [info     ] Start Predict                  dataset=377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 33.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:16:48.070260Z [info     ] Start Predict                  dataset=317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 34.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:16:55.524189Z [info     ] Start Predict                  dataset=257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 34.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:17:03.620536Z [info     ] Start Predict                  dataset=197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 33.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:17:12.321045Z [info     ] Start Predict                  dataset=137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 35.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:17:22.280766Z [info     ] Start Predict                  dataset=77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 34.89it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 603\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 76\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='76' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [76/76 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:17:32.023192Z [info     ] Start Predict                  dataset=17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 44.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 620\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 78\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='78' max='78' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [78/78 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41694915254237286, 0.38305084745762713, 0.46779661016949153, 0.4610169491525424, 0.5627118644067797, 0.5728813559322034, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5864406779661017, 0.5830508474576271, 0.5830508474576271]\n",
      "[149   7  28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='481' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 01:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:17:45.227895Z [info     ] Start Predict                  dataset=617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 78/78 [00:02<00:00, 32.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:17:50.736895Z [info     ] Start Predict                  dataset=557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 31.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:17:56.273243Z [info     ] Start Predict                  dataset=497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 33.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:18:02.886334Z [info     ] Start Predict                  dataset=437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 34.03it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:18:09.581712Z [info     ] Start Predict                  dataset=377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 35.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:18:16.546945Z [info     ] Start Predict                  dataset=317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 33.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:18:24.911604Z [info     ] Start Predict                  dataset=257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 35.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:18:33.040318Z [info     ] Start Predict                  dataset=197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 33.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:18:41.754114Z [info     ] Start Predict                  dataset=137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 31.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:18:50.984197Z [info     ] Start Predict                  dataset=77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 32.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 603\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 76\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='76' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [76/76 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:19:01.431818Z [info     ] Start Predict                  dataset=17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 28.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 620\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 78\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='78' max='78' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [78/78 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41694915254237286, 0.38305084745762713, 0.46779661016949153, 0.4610169491525424, 0.5627118644067797, 0.5728813559322034, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5864406779661017, 0.5830508474576271, 0.5830508474576271]\n",
      "[149   7  28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='481' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 01:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:19:14.794227Z [info     ] Start Predict                  dataset=617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 78/78 [00:02<00:00, 33.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:19:20.210196Z [info     ] Start Predict                  dataset=557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 26.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:19:26.435410Z [info     ] Start Predict                  dataset=497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 32.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:19:32.361034Z [info     ] Start Predict                  dataset=437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 34.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:19:38.834899Z [info     ] Start Predict                  dataset=377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 33.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:19:46.018305Z [info     ] Start Predict                  dataset=317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 33.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:19:54.430129Z [info     ] Start Predict                  dataset=257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 33.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:20:02.563805Z [info     ] Start Predict                  dataset=197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 35.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:20:11.691369Z [info     ] Start Predict                  dataset=137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 28.89it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:20:21.055770Z [info     ] Start Predict                  dataset=77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 35.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 603\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 76\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='76' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [76/76 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11408-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-07T12:20:30.735132Z [info     ] Start Predict                  dataset=17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 45.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 620\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 78\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='78' max='78' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [78/78 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41694915254237286, 0.38305084745762713, 0.46779661016949153, 0.4610169491525424, 0.5627118644067797, 0.5728813559322034, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5864406779661017, 0.5830508474576271, 0.5830508474576271]\n"
     ]
    }
   ],
   "source": [
    "active_mc_hillary3 = []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "query_history_hillary3 = []\n",
    "while mcrun != 5:\n",
    "    n_labeled_examples = np.unique(train_dataset_hillary['text']).size\n",
    "    training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "    print(training_indices0)\n",
    "    active_set_hillary =active_huggingface_dataset(train_dataset_hillary,tokenizer,'label','text')\n",
    "    valid_set_hillary = HuggingFaceDatasets(test_dataset_hillary,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_hillary.can_label = False\n",
    "    active_set_hillary.label(training_indices0)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_hillary,\n",
    "            eval_dataset=valid_set_hillary,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_hillary = ActiveLearningLoop(active_set_hillary,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 60, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_hillary=[unqueried_score]\n",
    "    query = [3]\n",
    "    num = 3\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_hillary.step()\n",
    "        num = num + 60\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_hillary.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_hillary),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_hillary.append(eval_metrics['eval_accuracy'])\n",
    "        query.append(num)\n",
    "    print(performance_history_hillary)\n",
    "    active_mc_hillary3.append(performance_history_hillary)\n",
    "    query_history_hillary3.append(query)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ff7bede8",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_hillary3, min_hillary3,max_hillary3= calculate(active_mc_hillary3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1c22901f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1105x1040 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(8.5, 8), dpi=130)\n",
    "ax.plot(query_history_hillary1[0],median_hillary1,label=\"Queue size 20\")\n",
    "ax.fill_between(query_history_hillary1[0],min_hillary1,max_hillary1,color='blue', alpha=0.1)\n",
    "ax.plot(query_history_hillary2[0],median_hillary2,label=\"Queue size 40\")\n",
    "ax.fill_between(query_history_hillary2[0],min_hillary2,max_hillary2,color='orange', alpha=0.1)\n",
    "ax.plot(query_history_hillary3[0],median_hillary3,label=\"Queue size 60\")\n",
    "ax.fill_between(query_history_hillary3[0],min_hillary3,max_hillary3,color='green', alpha=0.1)\n",
    "\n",
    "ax.scatter(query_history_hillary1[0], median_hillary1, s=8,marker = \"v\")\n",
    "ax.scatter(query_history_hillary2[0], median_hillary2, s=8,marker=\"^\")\n",
    "ax.scatter(query_history_hillary3[0], median_hillary3, s=8,marker = \",\")\n",
    "ax.xaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=5, integer=True))\n",
    "ax.yaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=10))\n",
    "ax.yaxis.set_major_formatter(mpl.ticker.PercentFormatter(xmax=1))\n",
    "\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "ax.set_title('Different query queue sizes in hillary target')\n",
    "ax.set_xlabel('Volume of labeled data')\n",
    "ax.set_ylabel('Performance(median)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41880d51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analytics_course0",
   "language": "python",
   "name": "data_analytics_course0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
