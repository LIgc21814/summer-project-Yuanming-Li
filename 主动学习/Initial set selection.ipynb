{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a1592d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import pdb\n",
    "import logging\n",
    "import re\n",
    "from gensim import parsing\n",
    "import gensim\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc92448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baal.active import get_heuristic\n",
    "from baal.active.active_loop import ActiveLearningLoop\n",
    "from baal.active.dataset.nlp_datasets import active_huggingface_dataset, HuggingFaceDatasets\n",
    "from baal.bayesian.dropout import patch_module\n",
    "from baal.transformers_trainer_wrapper import BaalTransformersTrainer\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a25b16cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8b611bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-tiny\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4146aaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"transformer_checkpoints\",  # specify the directory where models weights will be saved a certain points during training (checkpoints)\n",
    "    num_train_epochs=1,  # change this if it is taking too long on your computer\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3276f901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(a):\n",
    "    rotated = list(zip(*a[::-1]))\n",
    "    median0 = []\n",
    "    min0 = []\n",
    "    max0 = []\n",
    "    for i in range(len(rotated)):\n",
    "        median0.append(np.median(rotated[i]))\n",
    "        min0.append(np.min(rotated[i]))\n",
    "        max0.append(np.max(rotated[i]))\n",
    "    return median0,min0,max0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48db4f2",
   "metadata": {},
   "source": [
    "# Abortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1935353c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_abortion\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset with 587 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_abortion\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset with 66 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_abortion\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset with 280 instances loaded\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "cache_dir = \"./data_cache\"\n",
    "\n",
    "train_dataset_abortion = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_abortion\",\n",
    "    split=\"train\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Training dataset with {len(train_dataset_abortion)} instances loaded\")\n",
    "\n",
    "val_dataset_abortion = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_abortion\",\n",
    "    split=\"validation\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Validation dataset with {len(val_dataset_abortion)} instances loaded\")\n",
    "\n",
    "test_dataset_abortion = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_abortion\",\n",
    "    split=\"test\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Test dataset with {len(test_dataset_abortion)} instances loaded\")\n",
    "\n",
    "num_classes = np.unique(train_dataset_abortion['label']).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adf97cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_original = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\", num_labels=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c56a30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:44]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:14:55.198550Z [info     ] Start Predict                  dataset=578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 33.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:14:59.575549Z [info     ] Start Predict                  dataset=558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 31.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:15:04.306715Z [info     ] Start Predict                  dataset=538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 33.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:15:08.938717Z [info     ] Start Predict                  dataset=518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 33.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:15:14.492784Z [info     ] Start Predict                  dataset=498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 33.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:15:20.027359Z [info     ] Start Predict                  dataset=478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 33.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:15:27.303556Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 33.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:15:33.985650Z [info     ] Start Predict                  dataset=438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 33.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:15:41.403831Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 32.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:15:49.202327Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 33.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:15:56.430327Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 33.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:16:02.723325Z [info     ] Start Predict                  dataset=358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 33.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:16:11.747609Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 33.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:16:19.985752Z [info     ] Start Predict                  dataset=318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 33.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:16:29.537953Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 33.66it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:16:37.187495Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 33.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:16:44.283495Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 33.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:16:52.928827Z [info     ] Start Predict                  dataset=238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 34.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:17:01.007862Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 34.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:17:10.411064Z [info     ] Start Predict                  dataset=198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 33.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:17:18.573063Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 34.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:17:26.905065Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 33.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:17:34.868066Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 34.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:17:43.107065Z [info     ] Start Predict                  dataset=118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 34.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:17:51.563063Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 36.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:18:00.152613Z [info     ] Start Predict                  dataset=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 33.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:18:09.115128Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 32.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:18:18.078129Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 33.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:18:27.479128Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 41.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42142857142857143, 0.3964285714285714, 0.3892857142857143, 0.44642857142857145, 0.5321428571428571, 0.5428571428571428, 0.5214285714285715, 0.6321428571428571, 0.6178571428571429, 0.6392857142857142, 0.6071428571428571, 0.6607142857142857, 0.6535714285714286, 0.6464285714285715, 0.6678571428571428, 0.6678571428571428, 0.6678571428571428, 0.6642857142857143, 0.6678571428571428, 0.6714285714285714, 0.6678571428571428, 0.675, 0.6607142857142857, 0.675, 0.675, 0.675, 0.675, 0.6714285714285714, 0.675, 0.6714285714285714]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:36]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:18:40.762398Z [info     ] Start Predict                  dataset=578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 31.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:18:45.384864Z [info     ] Start Predict                  dataset=558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 32.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:18:49.870862Z [info     ] Start Predict                  dataset=538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 31.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:18:54.922865Z [info     ] Start Predict                  dataset=518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:02<00:00, 29.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:19:00.308850Z [info     ] Start Predict                  dataset=498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 23.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:19:06.421736Z [info     ] Start Predict                  dataset=478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 32.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:19:11.999735Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 31.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:19:18.836788Z [info     ] Start Predict                  dataset=438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 30.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:19:25.533760Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 30.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:19:32.138820Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 32.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:19:38.375929Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 33.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:19:44.365931Z [info     ] Start Predict                  dataset=358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 33.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:19:50.730928Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 32.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:19:57.530479Z [info     ] Start Predict                  dataset=318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 34.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:20:04.448480Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 33.51it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:20:12.192479Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 34.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:20:20.309557Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 34.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:20:29.241976Z [info     ] Start Predict                  dataset=238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 31.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:20:37.594070Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 34.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:20:46.855500Z [info     ] Start Predict                  dataset=198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 33.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:20:55.544806Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 35.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:21:04.030272Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 35.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:21:12.005306Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 36.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:21:19.871821Z [info     ] Start Predict                  dataset=118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 34.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:21:27.909797Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 35.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:21:36.231795Z [info     ] Start Predict                  dataset=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 35.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:21:44.965059Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 28.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:21:54.225653Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 35.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:22:03.543743Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 42.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42142857142857143, 0.3964285714285714, 0.3892857142857143, 0.44642857142857145, 0.5321428571428571, 0.5428571428571428, 0.5214285714285715, 0.6321428571428571, 0.6178571428571429, 0.6392857142857142, 0.6071428571428571, 0.6607142857142857, 0.6535714285714286, 0.6464285714285715, 0.6678571428571428, 0.6678571428571428, 0.6678571428571428, 0.6642857142857143, 0.6678571428571428, 0.6714285714285714, 0.6678571428571428, 0.675, 0.6607142857142857, 0.675, 0.675, 0.675, 0.675, 0.6714285714285714, 0.675, 0.6714285714285714]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:22:17.465775Z [info     ] Start Predict                  dataset=578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 34.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:22:21.872773Z [info     ] Start Predict                  dataset=558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 34.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:22:26.267774Z [info     ] Start Predict                  dataset=538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:01<00:00, 34.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:22:30.792292Z [info     ] Start Predict                  dataset=518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 33.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:22:35.499810Z [info     ] Start Predict                  dataset=498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 33.89it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:22:40.401933Z [info     ] Start Predict                  dataset=478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 33.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:22:45.651929Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 34.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:22:50.798930Z [info     ] Start Predict                  dataset=438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 33.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:22:56.787499Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 34.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:23:02.424063Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 34.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:23:08.237581Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 33.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:23:14.197682Z [info     ] Start Predict                  dataset=358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 35.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:23:20.285683Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 35.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:23:26.422683Z [info     ] Start Predict                  dataset=318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 35.03it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:23:32.848684Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 35.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:23:39.379609Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:00<00:00, 35.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:23:46.039881Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 35.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:23:52.908397Z [info     ] Start Predict                  dataset=238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 35.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:24:00.239424Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 35.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:24:07.569535Z [info     ] Start Predict                  dataset=198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 34.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:24:14.999526Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 35.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:24:23.110528Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 35.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:24:31.748338Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 36.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:24:39.684338Z [info     ] Start Predict                  dataset=118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 35.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:24:47.674891Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 36.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:24:56.635893Z [info     ] Start Predict                  dataset=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 32.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:25:05.903892Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 36.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:25:14.928892Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 34.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:25:24.086892Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 32.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42142857142857143, 0.3964285714285714, 0.3892857142857143, 0.44642857142857145, 0.5321428571428571, 0.5428571428571428, 0.5214285714285715, 0.6321428571428571, 0.6178571428571429, 0.6392857142857142, 0.6071428571428571, 0.6607142857142857, 0.6535714285714286, 0.6464285714285715, 0.6678571428571428, 0.6678571428571428, 0.6678571428571428, 0.6642857142857143, 0.6678571428571428, 0.6714285714285714, 0.6678571428571428, 0.675, 0.6607142857142857, 0.675, 0.675, 0.675, 0.675, 0.6714285714285714, 0.675, 0.6714285714285714]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:25:37.366890Z [info     ] Start Predict                  dataset=578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 33.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:25:41.617892Z [info     ] Start Predict                  dataset=558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 33.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:25:46.736499Z [info     ] Start Predict                  dataset=538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 33.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:25:53.167277Z [info     ] Start Predict                  dataset=518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 33.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:25:58.242274Z [info     ] Start Predict                  dataset=498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 34.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:26:04.582488Z [info     ] Start Predict                  dataset=478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 34.03it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:26:11.646602Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 34.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:26:17.796458Z [info     ] Start Predict                  dataset=438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 33.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:26:24.945393Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 32.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:26:32.406428Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 30.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:26:40.928201Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 32.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:26:47.198199Z [info     ] Start Predict                  dataset=358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 32.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:26:53.528200Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 31.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:27:00.425200Z [info     ] Start Predict                  dataset=318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 31.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:27:07.326200Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 32.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:27:14.403202Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 32.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:27:21.608715Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 32.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:27:28.954718Z [info     ] Start Predict                  dataset=238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 31.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:27:36.768238Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 34.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:27:44.335238Z [info     ] Start Predict                  dataset=198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 31.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:27:52.162241Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 32.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:28:00.290238Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 33.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:28:08.400276Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 30.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:28:16.832300Z [info     ] Start Predict                  dataset=118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 32.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:28:25.807892Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 35.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:28:34.684434Z [info     ] Start Predict                  dataset=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 33.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:28:44.015763Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 33.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:28:53.816507Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 30.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:29:03.197969Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 40.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42142857142857143, 0.3964285714285714, 0.3892857142857143, 0.44642857142857145, 0.5321428571428571, 0.5428571428571428, 0.5214285714285715, 0.6321428571428571, 0.6178571428571429, 0.6392857142857142, 0.6071428571428571, 0.6607142857142857, 0.6535714285714286, 0.6464285714285715, 0.6678571428571428, 0.6678571428571428, 0.6678571428571428, 0.6642857142857143, 0.6678571428571428, 0.6714285714285714, 0.6678571428571428, 0.675, 0.6607142857142857, 0.675, 0.675, 0.675, 0.675, 0.6714285714285714, 0.675, 0.6714285714285714]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:29:16.265008Z [info     ] Start Predict                  dataset=578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 32.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:29:20.604006Z [info     ] Start Predict                  dataset=558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 32.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:29:25.312067Z [info     ] Start Predict                  dataset=538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 33.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:29:29.953064Z [info     ] Start Predict                  dataset=518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 33.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:29:34.908066Z [info     ] Start Predict                  dataset=498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 32.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:29:39.989067Z [info     ] Start Predict                  dataset=478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 32.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:29:45.324068Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 33.03it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:29:50.765065Z [info     ] Start Predict                  dataset=438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 32.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:29:56.485618Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 33.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:30:02.381642Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 32.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:30:08.444646Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 33.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:30:14.691660Z [info     ] Start Predict                  dataset=358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 33.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:30:20.897642Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 33.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:30:27.518643Z [info     ] Start Predict                  dataset=318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 32.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:30:34.250643Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 33.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:30:41.191190Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 33.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:30:48.358187Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 34.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:30:55.546185Z [info     ] Start Predict                  dataset=238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 32.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:31:03.048184Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 33.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:31:10.627189Z [info     ] Start Predict                  dataset=198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 33.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:31:18.429185Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 34.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:31:26.387183Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 33.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:31:34.867272Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 33.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:31:43.164786Z [info     ] Start Predict                  dataset=118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 33.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:31:51.624788Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 34.03it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:32:00.312787Z [info     ] Start Predict                  dataset=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 33.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:32:10.159785Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 36.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:32:19.054788Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 34.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:32:28.265297Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 39.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42142857142857143, 0.3964285714285714, 0.3892857142857143, 0.44642857142857145, 0.5321428571428571, 0.5428571428571428, 0.5214285714285715, 0.6321428571428571, 0.6178571428571429, 0.6392857142857142, 0.6071428571428571, 0.6607142857142857, 0.6535714285714286, 0.6464285714285715, 0.6678571428571428, 0.6678571428571428, 0.6678571428571428, 0.6642857142857143, 0.6678571428571428, 0.6714285714285714, 0.6678571428571428, 0.675, 0.6607142857142857, 0.675, 0.675, 0.675, 0.675, 0.6714285714285714, 0.675, 0.6714285714285714]\n"
     ]
    }
   ],
   "source": [
    "active_mc_abortion1= []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "while mcrun != 5:\n",
    "#     n_labeled_examples = np.unique(train_dataset_abortion['text']).size\n",
    "#     training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "#     print(training_indices0)\n",
    "    active_set_abortion =active_huggingface_dataset(train_dataset_abortion,tokenizer,'label','text')\n",
    "    valid_set_abortion = HuggingFaceDatasets(test_dataset_abortion,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_abortion.can_label = False\n",
    "    active_set_abortion.label([0,1,2,3,4,8,9,15,20])\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_abortion,\n",
    "            eval_dataset=valid_set_abortion,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_abortion = ActiveLearningLoop(active_set_abortion,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_abortion=[unqueried_score]\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_abortion.step()\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_abortion.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_abortion),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_abortion.append(eval_metrics['eval_accuracy'])\n",
    "    print(performance_history_abortion)\n",
    "    active_mc_abortion1.append(performance_history_abortion)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e640730b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:32:41.102296Z [info     ] Start Predict                  dataset=578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 33.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:32:45.326296Z [info     ] Start Predict                  dataset=558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 32.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:32:49.802821Z [info     ] Start Predict                  dataset=538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 33.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:32:54.374821Z [info     ] Start Predict                  dataset=518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 33.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:32:59.422823Z [info     ] Start Predict                  dataset=498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 33.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:33:04.422374Z [info     ] Start Predict                  dataset=478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 32.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:33:09.705890Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 35.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:33:15.110920Z [info     ] Start Predict                  dataset=438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 34.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:33:20.551409Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 34.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:33:26.912411Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 34.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:33:33.743409Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 35.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:33:39.732409Z [info     ] Start Predict                  dataset=358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 34.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:33:45.946449Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 34.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:33:52.380962Z [info     ] Start Predict                  dataset=318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 33.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:33:59.127961Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 35.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:34:05.671964Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 33.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:34:12.425483Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 35.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:34:19.337486Z [info     ] Start Predict                  dataset=238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 34.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:34:26.564483Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 34.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:34:35.835741Z [info     ] Start Predict                  dataset=198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 33.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:34:44.453761Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 33.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:34:52.382400Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 33.73it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:35:00.504445Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 35.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:35:08.738467Z [info     ] Start Predict                  dataset=118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 34.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:35:17.146436Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 34.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:35:25.735436Z [info     ] Start Predict                  dataset=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 34.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:35:34.566974Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 36.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:35:43.499103Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 30.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:35:52.653633Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 42.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36428571428571427, 0.3892857142857143, 0.37142857142857144, 0.4107142857142857, 0.37857142857142856, 0.36428571428571427, 0.3892857142857143, 0.4, 0.5357142857142857, 0.475, 0.5464285714285714, 0.6178571428571429, 0.625, 0.6321428571428571, 0.625, 0.6321428571428571, 0.6678571428571428, 0.6571428571428571, 0.6535714285714286, 0.6821428571428572, 0.6321428571428571, 0.675, 0.6464285714285715, 0.675, 0.6785714285714286, 0.6714285714285714, 0.675, 0.6642857142857143, 0.675, 0.6714285714285714]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:36:05.266692Z [info     ] Start Predict                  dataset=578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 33.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:36:09.572662Z [info     ] Start Predict                  dataset=558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 33.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:36:14.110662Z [info     ] Start Predict                  dataset=538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 33.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:36:18.563794Z [info     ] Start Predict                  dataset=518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 33.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:36:25.360904Z [info     ] Start Predict                  dataset=498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 33.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:36:30.359902Z [info     ] Start Predict                  dataset=478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 33.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:36:35.650282Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 33.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:36:41.128296Z [info     ] Start Predict                  dataset=438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 33.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:36:47.666297Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 33.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:36:53.657295Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 33.51it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:36:59.676295Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 33.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:37:05.770296Z [info     ] Start Predict                  dataset=358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 33.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:37:12.050841Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 33.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:37:18.479870Z [info     ] Start Predict                  dataset=318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 33.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:37:25.145840Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 33.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:37:31.959871Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 32.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:37:39.162691Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 33.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:37:46.251548Z [info     ] Start Predict                  dataset=238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 33.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:37:54.538701Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 34.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:38:03.404425Z [info     ] Start Predict                  dataset=198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 33.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:38:11.116425Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 34.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:38:18.990426Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 33.73it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:38:26.975429Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 33.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:38:35.246455Z [info     ] Start Predict                  dataset=118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 33.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:38:43.627694Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 34.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:38:54.130451Z [info     ] Start Predict                  dataset=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 34.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:39:04.045095Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 36.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:39:12.850092Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 34.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:39:22.051122Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 44.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40714285714285714, 0.4035714285714286, 0.45, 0.4928571428571429, 0.5214285714285715, 0.5071428571428571, 0.575, 0.6178571428571429, 0.5964285714285714, 0.6428571428571429, 0.6285714285714286, 0.6642857142857143, 0.6285714285714286, 0.6428571428571429, 0.6607142857142857, 0.6535714285714286, 0.6678571428571428, 0.6607142857142857, 0.6678571428571428, 0.6785714285714286, 0.675, 0.675, 0.6535714285714286, 0.675, 0.6785714285714286, 0.675, 0.6714285714285714, 0.6714285714285714, 0.675, 0.6714285714285714]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:27]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:39:34.870602Z [info     ] Start Predict                  dataset=578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 33.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:39:39.177604Z [info     ] Start Predict                  dataset=558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 33.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:39:43.748601Z [info     ] Start Predict                  dataset=538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 33.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:39:48.506632Z [info     ] Start Predict                  dataset=518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 32.89it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:39:53.400603Z [info     ] Start Predict                  dataset=498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 33.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:39:58.486603Z [info     ] Start Predict                  dataset=478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 33.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:40:03.782118Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 33.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:40:09.128121Z [info     ] Start Predict                  dataset=438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 33.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:40:14.727119Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 33.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:40:20.540117Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 33.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:40:26.456119Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 33.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:40:32.638118Z [info     ] Start Predict                  dataset=358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 33.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:40:38.948120Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 33.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:40:45.672119Z [info     ] Start Predict                  dataset=318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 33.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:40:52.354119Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 32.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:40:59.136117Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 33.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:41:06.197117Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 34.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:41:13.318119Z [info     ] Start Predict                  dataset=238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 33.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:41:20.659148Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 34.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:41:28.205152Z [info     ] Start Predict                  dataset=198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 33.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:41:35.937150Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 33.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:41:45.240093Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 33.73it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:41:53.308570Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 34.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:42:02.640589Z [info     ] Start Predict                  dataset=118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 33.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:42:12.694701Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 34.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:42:22.292836Z [info     ] Start Predict                  dataset=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 34.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:42:31.059838Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 36.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:42:40.091555Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 34.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:42:49.299357Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 20.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40714285714285714, 0.4035714285714286, 0.45, 0.4928571428571429, 0.5214285714285715, 0.5071428571428571, 0.575, 0.6178571428571429, 0.5964285714285714, 0.6428571428571429, 0.6285714285714286, 0.6642857142857143, 0.6285714285714286, 0.6428571428571429, 0.6607142857142857, 0.6535714285714286, 0.6678571428571428, 0.6607142857142857, 0.6678571428571428, 0.6785714285714286, 0.675, 0.675, 0.6535714285714286, 0.675, 0.6785714285714286, 0.675, 0.6714285714285714, 0.6714285714285714, 0.675, 0.6714285714285714]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:43:03.203442Z [info     ] Start Predict                  dataset=578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 32.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:43:07.736443Z [info     ] Start Predict                  dataset=558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 31.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:43:12.306444Z [info     ] Start Predict                  dataset=538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 31.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:43:17.114445Z [info     ] Start Predict                  dataset=518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:02<00:00, 30.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:43:22.818952Z [info     ] Start Predict                  dataset=498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 32.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:43:28.177952Z [info     ] Start Predict                  dataset=478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 31.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:43:34.687952Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 33.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:43:40.216036Z [info     ] Start Predict                  dataset=438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 33.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:43:45.909034Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 32.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:43:51.828038Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 33.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:43:58.209566Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 33.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:44:05.434617Z [info     ] Start Predict                  dataset=358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 33.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:44:11.881017Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 33.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:44:18.543047Z [info     ] Start Predict                  dataset=318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 33.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:44:25.275018Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 33.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:44:32.474017Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 33.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:44:39.663018Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 33.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:44:46.857021Z [info     ] Start Predict                  dataset=238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 33.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:44:54.278016Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 32.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:45:01.949529Z [info     ] Start Predict                  dataset=198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 33.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:45:10.499530Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 33.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:45:18.446224Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 34.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:45:27.365194Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 35.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:45:35.511196Z [info     ] Start Predict                  dataset=118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 34.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:45:43.893195Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 35.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:45:52.439195Z [info     ] Start Predict                  dataset=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 34.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:46:01.129196Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 37.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:46:09.846707Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 34.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:46:18.995706Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 31.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40714285714285714, 0.4035714285714286, 0.45, 0.4928571428571429, 0.5214285714285715, 0.5071428571428571, 0.575, 0.6178571428571429, 0.5964285714285714, 0.6428571428571429, 0.6285714285714286, 0.6642857142857143, 0.6285714285714286, 0.6428571428571429, 0.6607142857142857, 0.6535714285714286, 0.6678571428571428, 0.6607142857142857, 0.6678571428571428, 0.6785714285714286, 0.675, 0.675, 0.6535714285714286, 0.675, 0.6785714285714286, 0.675, 0.6714285714285714, 0.6714285714285714, 0.675, 0.6714285714285714]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:46:31.691258Z [info     ] Start Predict                  dataset=578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 33.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:46:36.195213Z [info     ] Start Predict                  dataset=558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 32.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:46:41.622736Z [info     ] Start Predict                  dataset=538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 33.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:46:46.197738Z [info     ] Start Predict                  dataset=518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 32.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:46:52.700783Z [info     ] Start Predict                  dataset=498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 33.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:46:57.821757Z [info     ] Start Predict                  dataset=478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 32.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:47:03.294163Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 33.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:47:08.806163Z [info     ] Start Predict                  dataset=438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 32.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:47:14.581162Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 33.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:47:20.247162Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 33.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:47:26.191161Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 33.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:47:32.339510Z [info     ] Start Predict                  dataset=358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 32.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:47:38.652481Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 33.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:47:45.212483Z [info     ] Start Predict                  dataset=318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 33.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:47:51.987480Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 33.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:47:58.791480Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 33.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:48:05.724626Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 33.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:48:12.857626Z [info     ] Start Predict                  dataset=238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 33.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:48:20.209543Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 34.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:48:27.776058Z [info     ] Start Predict                  dataset=198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 33.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:48:35.481060Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 34.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:48:43.383061Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 33.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:48:51.472057Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 33.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:48:59.924058Z [info     ] Start Predict                  dataset=118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 33.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:49:08.371149Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 35.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:49:16.934353Z [info     ] Start Predict                  dataset=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 33.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:49:25.513354Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 37.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:49:34.203416Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 34.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:49:42.981071Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 41.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40714285714285714, 0.4035714285714286, 0.45, 0.4928571428571429, 0.5214285714285715, 0.5071428571428571, 0.575, 0.6178571428571429, 0.5964285714285714, 0.6428571428571429, 0.6285714285714286, 0.6642857142857143, 0.6285714285714286, 0.6428571428571429, 0.6607142857142857, 0.6535714285714286, 0.6678571428571428, 0.6607142857142857, 0.6678571428571428, 0.6785714285714286, 0.675, 0.675, 0.6535714285714286, 0.675, 0.6785714285714286, 0.675, 0.6714285714285714, 0.6714285714285714, 0.675, 0.6714285714285714]\n"
     ]
    }
   ],
   "source": [
    "active_mc_abortion2= []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "while mcrun != 5:\n",
    "#     n_labeled_examples = np.unique(train_dataset_abortion['text']).size\n",
    "#     training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "#     print(training_indices0)\n",
    "    active_set_abortion =active_huggingface_dataset(train_dataset_abortion,tokenizer,'label','text')\n",
    "    valid_set_abortion = HuggingFaceDatasets(test_dataset_abortion,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_abortion.can_label = False\n",
    "    active_set_abortion.label_randomly(9)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_abortion,\n",
    "            eval_dataset=valid_set_abortion,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_abortion = ActiveLearningLoop(active_set_abortion,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_abortion=[unqueried_score]\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_abortion.step()\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_abortion.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_abortion),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_abortion.append(eval_metrics['eval_accuracy'])\n",
    "    print(performance_history_abortion)\n",
    "    active_mc_abortion2.append(performance_history_abortion)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e38c07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_abortion1, min_abortion1,max_abortion1 = calculate(active_mc_abortion1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "952c7488",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_abortion2, min_abortion2,max_abortion2 = calculate(active_mc_abortion2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bda693b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1105x1040 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(8.5, 8), dpi=130)\n",
    "ax.plot(median_abortion1,label=\"Human selection\")\n",
    "ax.fill_between(range(30),min_abortion1,max_abortion1,color='blue', alpha=0.1)\n",
    "ax.plot(median_abortion2,label=\"Random selection\")\n",
    "ax.fill_between(range(30),min_abortion2,max_abortion2,color='orange', alpha=0.1)\n",
    "\n",
    "ax.scatter(range(30), median_abortion1, s=8,marker = \"v\")\n",
    "ax.scatter(range(30), median_abortion2, s=8,marker=\"^\")\n",
    "\n",
    "ax.xaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=8, integer=True))\n",
    "ax.yaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=10))\n",
    "ax.yaxis.set_major_formatter(mpl.ticker.PercentFormatter(xmax=1))\n",
    "\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "ax.set_title('Different initial data set in abortion target')\n",
    "ax.set_xlabel('Query iteration')\n",
    "ax.set_ylabel('Performance(median)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546dd554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae1da5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed30c525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f60c047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa08d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7622a9b",
   "metadata": {},
   "source": [
    "# Atheism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1fd5e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_atheism\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset with 461 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_atheism\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset with 52 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_atheism\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset with 220 instances loaded\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "cache_dir = \"./data_cache\"\n",
    "\n",
    "train_dataset_atheism = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_atheism\",\n",
    "    split=\"train\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Training dataset with {len(train_dataset_atheism)} instances loaded\")\n",
    "\n",
    "val_dataset_atheism = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_atheism\",\n",
    "    split=\"validation\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Validation dataset with {len(val_dataset_atheism)} instances loaded\")\n",
    "\n",
    "test_dataset_atheism = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_atheism\",\n",
    "    split=\"test\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Test dataset with {len(test_dataset_atheism)} instances loaded\")\n",
    "\n",
    "num_classes = np.unique(train_dataset_atheism['label']).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f239875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/config.json from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\3cf34679007e9fe5d0acd644dcc1f4b26bec5cbc9612364f6da7262aed4ef7a4.a5a11219cf90aae61ff30e1658ccf2cb4aa84d6b6e947336556f887c9828dc6d\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-tiny\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/pytorch_model.bin from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\1ee037c9e1a220d5c814779ffe697080d1e6f5b1602e16cf6061aaae41a082c5.038e1aed90492a59d2283f9c44c9fe3ee2380495ff1e7fefb3f1f04af3b685b5\n",
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_original = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\", num_labels=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "393b917c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 02:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:50:00.115831Z [info     ] Start Predict                  dataset=452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 33.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:50:03.662510Z [info     ] Start Predict                  dataset=432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 33.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:50:07.474537Z [info     ] Start Predict                  dataset=412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 33.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:50:11.315507Z [info     ] Start Predict                  dataset=392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 32.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:50:15.543505Z [info     ] Start Predict                  dataset=372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 33.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:50:19.717506Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 33.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:50:24.232506Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 34.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:50:28.763506Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 33.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:50:33.685232Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 34.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:50:38.530872Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 34.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:50:44.799937Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 34.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:50:50.546721Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:50:56.492722Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 34.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:51:02.188721Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 33.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:51:08.007429Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 33.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:51:14.072427Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 33.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:51:20.303430Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 34.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:51:27.095428Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 33.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:51:33.541429Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 34.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:51:40.172427Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 33.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:51:47.097944Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 35.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:51:54.179961Z [info     ] Start Predict                  dataset=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 33.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:52:01.500986Z [info     ] Start Predict                  dataset=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 39.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4090909090909091, 0.42727272727272725, 0.4409090909090909, 0.4909090909090909, 0.5363636363636364, 0.6136363636363636, 0.65, 0.7, 0.6545454545454545, 0.7181818181818181, 0.7136363636363636, 0.7272727272727273, 0.7227272727272728, 0.7181818181818181, 0.7272727272727273, 0.7272727272727273, 0.7227272727272728, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 02:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:52:11.879016Z [info     ] Start Predict                  dataset=452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 33.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:52:15.326988Z [info     ] Start Predict                  dataset=432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 33.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:52:18.997988Z [info     ] Start Predict                  dataset=412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 32.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:52:22.793988Z [info     ] Start Predict                  dataset=392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 33.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:52:26.792530Z [info     ] Start Predict                  dataset=372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 33.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:52:31.142527Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 32.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:52:35.678527Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 33.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:52:40.281525Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 32.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:52:48.612560Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 33.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:52:54.605561Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 32.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:52:59.683070Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 33.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:53:05.128070Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:53:10.618068Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 34.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:53:16.271074Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 33.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:53:22.161072Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 32.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:53:28.099102Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 32.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:53:34.375133Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 33.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:53:40.792103Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 33.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:53:47.431882Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 35.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:53:54.177147Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 30.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:54:01.030146Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 34.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:54:08.113174Z [info     ] Start Predict                  dataset=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 32.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:54:15.434175Z [info     ] Start Predict                  dataset=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 38.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4090909090909091, 0.42727272727272725, 0.4409090909090909, 0.4909090909090909, 0.5363636363636364, 0.6136363636363636, 0.65, 0.7, 0.6545454545454545, 0.7181818181818181, 0.7136363636363636, 0.7272727272727273, 0.7227272727272728, 0.7181818181818181, 0.7272727272727273, 0.7272727272727273, 0.7227272727272728, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 02:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:54:25.748176Z [info     ] Start Predict                  dataset=452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 33.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:54:29.118864Z [info     ] Start Predict                  dataset=432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 33.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:54:32.826805Z [info     ] Start Predict                  dataset=412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 33.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:54:36.614806Z [info     ] Start Predict                  dataset=392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 33.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:54:40.799807Z [info     ] Start Predict                  dataset=372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 33.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:54:45.068807Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 32.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:54:49.623734Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 33.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:54:54.334732Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 32.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:54:59.103732Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 32.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:55:04.109733Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 32.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:55:09.311735Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 33.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:55:14.672735Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:55:20.156763Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 32.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:55:25.875606Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 33.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:55:31.787603Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 33.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:55:37.716401Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 33.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:55:43.843916Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 34.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:55:50.106944Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 32.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:55:56.646282Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 34.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:56:03.432198Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 33.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:56:10.361200Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 30.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:56:17.439753Z [info     ] Start Predict                  dataset=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 33.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:56:24.572873Z [info     ] Start Predict                  dataset=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 39.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4090909090909091, 0.42727272727272725, 0.4409090909090909, 0.4909090909090909, 0.5363636363636364, 0.6136363636363636, 0.65, 0.7, 0.6545454545454545, 0.7181818181818181, 0.7136363636363636, 0.7272727272727273, 0.7227272727272728, 0.7181818181818181, 0.7272727272727273, 0.7272727272727273, 0.7227272727272728, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 02:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:56:35.038303Z [info     ] Start Predict                  dataset=452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 32.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:56:38.695893Z [info     ] Start Predict                  dataset=432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 32.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:56:42.539895Z [info     ] Start Predict                  dataset=412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 33.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:56:46.576408Z [info     ] Start Predict                  dataset=392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 32.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:56:50.735438Z [info     ] Start Predict                  dataset=372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 33.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:56:55.042408Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 32.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:56:59.873437Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 33.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:57:04.440410Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 33.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:57:09.444438Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 32.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:57:14.509446Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 33.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:57:19.755446Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 33.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:57:25.091445Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:57:30.601444Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 33.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:57:36.223475Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 32.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:57:42.141476Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 33.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:57:48.229474Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 33.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:57:54.415474Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 33.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:58:00.845993Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 30.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:58:07.481506Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 35.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:58:14.284542Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 32.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:58:21.224541Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 35.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:58:28.440001Z [info     ] Start Predict                  dataset=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 31.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:58:35.804998Z [info     ] Start Predict                  dataset=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 40.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4090909090909091, 0.42727272727272725, 0.4409090909090909, 0.4909090909090909, 0.5363636363636364, 0.6136363636363636, 0.65, 0.7, 0.6545454545454545, 0.7181818181818181, 0.7136363636363636, 0.7272727272727273, 0.7227272727272728, 0.7181818181818181, 0.7272727272727273, 0.7272727272727273, 0.7227272727272728, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 02:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:58:46.067998Z [info     ] Start Predict                  dataset=452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 33.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:58:49.554544Z [info     ] Start Predict                  dataset=432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 33.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:58:53.278543Z [info     ] Start Predict                  dataset=412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 32.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:58:57.243045Z [info     ] Start Predict                  dataset=392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 32.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:59:01.491070Z [info     ] Start Predict                  dataset=372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 32.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:59:05.694555Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 33.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:59:10.232225Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 32.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:59:14.787240Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 32.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:59:19.557009Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 33.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:59:24.629011Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 32.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:59:29.870040Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 32.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:59:35.292009Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:59:40.829009Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 33.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:59:46.482763Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 33.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:59:52.356760Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 33.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T11:59:58.465080Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 33.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:00:04.756597Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 34.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:00:11.103598Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 32.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:00:17.691431Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 34.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:00:24.430403Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 32.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:00:31.375405Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 33.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:00:38.474401Z [info     ] Start Predict                  dataset=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 31.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:00:46.518431Z [info     ] Start Predict                  dataset=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 42.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4090909090909091, 0.42727272727272725, 0.4409090909090909, 0.4909090909090909, 0.5363636363636364, 0.6136363636363636, 0.65, 0.7, 0.6545454545454545, 0.7181818181818181, 0.7136363636363636, 0.7272727272727273, 0.7227272727272728, 0.7181818181818181, 0.7272727272727273, 0.7272727272727273, 0.7227272727272728, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n"
     ]
    }
   ],
   "source": [
    "active_mc_atheism1 = []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "while mcrun != 5:\n",
    "#     n_labeled_examples = np.unique(train_dataset_atheism['text']).size\n",
    "#     training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "#     print(training_indices0)\n",
    "    active_set_atheism =active_huggingface_dataset(train_dataset_atheism,tokenizer,'label','text')\n",
    "    valid_set_atheism = HuggingFaceDatasets(test_dataset_atheism,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_atheism.can_label = False\n",
    "    active_set_atheism.label([0,1,2,3,4,9,11,12,22])\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_atheism,\n",
    "            eval_dataset=valid_set_atheism,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_atheism = ActiveLearningLoop(active_set_atheism,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_atheism=[unqueried_score]\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_atheism.step()\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_atheism.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_atheism),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_atheism.append(eval_metrics['eval_accuracy'])\n",
    "    print(performance_history_atheism)\n",
    "    active_mc_atheism1.append(performance_history_atheism)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d400706d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 02:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:00:57.064913Z [info     ] Start Predict                  dataset=452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 32.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:01:00.620912Z [info     ] Start Predict                  dataset=432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 31.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:01:04.495367Z [info     ] Start Predict                  dataset=412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 32.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:01:08.295150Z [info     ] Start Predict                  dataset=392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 33.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:01:12.797653Z [info     ] Start Predict                  dataset=372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 33.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:01:17.104976Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 33.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:01:21.559976Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 33.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:01:26.306976Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 33.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:01:31.894039Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 33.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:01:37.025020Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 32.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:01:42.150022Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 32.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:01:47.409018Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:01:52.947022Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 33.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:01:58.689020Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 32.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:02:04.589147Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 33.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:02:10.529149Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 32.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:02:16.814148Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 32.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:02:23.205432Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 30.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:02:29.841432Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 34.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:02:36.600432Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 33.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:02:43.399502Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 34.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:02:50.552124Z [info     ] Start Predict                  dataset=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 32.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:02:57.944124Z [info     ] Start Predict                  dataset=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 37.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5681818181818182, 0.5363636363636364, 0.6, 0.6, 0.6636363636363637, 0.6409090909090909, 0.6954545454545454, 0.7227272727272728, 0.7045454545454546, 0.7318181818181818, 0.7181818181818181, 0.7318181818181818, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 02:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:03:08.612677Z [info     ] Start Predict                  dataset=452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 33.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:03:12.237675Z [info     ] Start Predict                  dataset=432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 33.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:03:16.295896Z [info     ] Start Predict                  dataset=412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 32.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:03:20.228902Z [info     ] Start Predict                  dataset=392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 33.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:03:24.432896Z [info     ] Start Predict                  dataset=372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 33.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:03:28.771427Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 32.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:03:33.312082Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 32.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:03:37.905051Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 32.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:03:42.844644Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 32.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:03:47.996645Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 33.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:03:53.155671Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 33.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:03:58.484741Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:04:04.186741Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 34.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:04:09.916741Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 32.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:04:15.774741Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 34.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:04:21.746253Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 33.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:04:27.839296Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 34.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:04:34.125266Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 33.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:04:40.715310Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 34.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:04:47.496306Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 33.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:04:55.204833Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 30.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:05:02.348316Z [info     ] Start Predict                  dataset=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 32.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:05:09.559345Z [info     ] Start Predict                  dataset=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 37.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5636363636363636, 0.5454545454545454, 0.5818181818181818, 0.5818181818181818, 0.6636363636363637, 0.6727272727272727, 0.7090909090909091, 0.7272727272727273, 0.7181818181818181, 0.7227272727272728, 0.7181818181818181, 0.7227272727272728, 0.7272727272727273, 0.7227272727272728, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 02:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:05:19.872339Z [info     ] Start Predict                  dataset=452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 33.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:05:23.383340Z [info     ] Start Predict                  dataset=432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 32.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:05:27.118339Z [info     ] Start Predict                  dataset=412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 33.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:05:31.105908Z [info     ] Start Predict                  dataset=392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 32.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:05:35.743382Z [info     ] Start Predict                  dataset=372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 33.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:05:39.907384Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 33.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:05:44.676396Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 29.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:05:49.663944Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 31.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:05:54.736014Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 30.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:06:00.085526Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 32.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:06:05.402683Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 33.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:06:10.753742Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:06:16.247413Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 32.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:06:22.004946Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 32.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:06:27.950947Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 33.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:06:34.037945Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 31.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:06:40.423946Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 32.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:06:46.884431Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 33.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:06:53.516431Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 32.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:07:00.319977Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 31.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:07:07.409950Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 36.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:07:14.608213Z [info     ] Start Predict                  dataset=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 33.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:07:21.856213Z [info     ] Start Predict                  dataset=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 39.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5636363636363636, 0.5454545454545454, 0.5818181818181818, 0.5818181818181818, 0.6636363636363637, 0.6727272727272727, 0.7090909090909091, 0.7272727272727273, 0.7181818181818181, 0.7227272727272728, 0.7181818181818181, 0.7227272727272728, 0.7272727272727273, 0.7227272727272728, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 02:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:07:32.190583Z [info     ] Start Predict                  dataset=452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 32.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:07:35.705582Z [info     ] Start Predict                  dataset=432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 31.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:07:39.505586Z [info     ] Start Predict                  dataset=412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 33.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:07:43.350609Z [info     ] Start Predict                  dataset=392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 32.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:07:47.442611Z [info     ] Start Predict                  dataset=372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 32.66it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:07:51.726130Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 32.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:07:56.264126Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 33.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:08:00.943126Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 31.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:08:05.800127Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 33.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:08:10.794127Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 32.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:08:16.138682Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 33.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:08:21.447165Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:08:27.038166Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 33.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:08:32.645165Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 31.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:08:38.593195Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 34.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:08:44.583163Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 32.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:08:50.879164Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 33.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:08:57.308166Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 32.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:09:03.931198Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 33.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:09:10.710679Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 33.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:09:17.744195Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 35.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:09:24.805194Z [info     ] Start Predict                  dataset=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 33.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:09:32.159918Z [info     ] Start Predict                  dataset=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 40.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5636363636363636, 0.5454545454545454, 0.5818181818181818, 0.5818181818181818, 0.6636363636363637, 0.6727272727272727, 0.7090909090909091, 0.7272727272727273, 0.7181818181818181, 0.7227272727272728, 0.7181818181818181, 0.7227272727272728, 0.7272727272727273, 0.7227272727272728, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 02:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:09:42.701916Z [info     ] Start Predict                  dataset=452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 33.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:09:46.355737Z [info     ] Start Predict                  dataset=432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 32.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:09:50.228736Z [info     ] Start Predict                  dataset=412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 33.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:09:54.091738Z [info     ] Start Predict                  dataset=392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 32.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:09:58.595744Z [info     ] Start Predict                  dataset=372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 33.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:10:02.908735Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 32.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:10:07.330737Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 33.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:10:11.886736Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 33.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:10:16.769736Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 33.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:10:21.985246Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 32.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:10:27.243248Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 33.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:10:32.512246Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:10:38.243280Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 33.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:10:43.986344Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 32.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:10:49.778313Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 33.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:10:55.741314Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 32.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:11:02.166053Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 34.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:11:08.514052Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 29.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:11:15.131053Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 33.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:11:21.995052Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 33.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:11:29.091052Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 34.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:11:36.273082Z [info     ] Start Predict                  dataset=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 31.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:11:43.621662Z [info     ] Start Predict                  dataset=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 39.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5636363636363636, 0.5454545454545454, 0.5818181818181818, 0.5818181818181818, 0.6636363636363637, 0.6727272727272727, 0.7090909090909091, 0.7272727272727273, 0.7181818181818181, 0.7227272727272728, 0.7181818181818181, 0.7227272727272728, 0.7272727272727273, 0.7227272727272728, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n"
     ]
    }
   ],
   "source": [
    "active_mc_atheism2 = []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "while mcrun != 5:\n",
    "#     n_labeled_examples = np.unique(train_dataset_atheism['text']).size\n",
    "#     training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "#     print(training_indices0)\n",
    "    active_set_atheism =active_huggingface_dataset(train_dataset_atheism,tokenizer,'label','text')\n",
    "    valid_set_atheism = HuggingFaceDatasets(test_dataset_atheism,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_atheism.can_label = False\n",
    "    active_set_atheism.label_randomly(9)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_atheism,\n",
    "            eval_dataset=valid_set_atheism,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_atheism = ActiveLearningLoop(active_set_atheism,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_atheism=[unqueried_score]\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_atheism.step()\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_atheism.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_atheism),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_atheism.append(eval_metrics['eval_accuracy'])\n",
    "    print(performance_history_atheism)\n",
    "    active_mc_atheism2.append(performance_history_atheism)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dc3cf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_atheism1, min_atheism1,max_atheism1 = calculate(active_mc_atheism1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9deac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_atheism2, min_atheism2,max_atheism2 = calculate(active_mc_atheism2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8050e6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1105x1040 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(8.5, 8), dpi=130)\n",
    "ax.plot(median_atheism1,label=\"Hunman selection\")\n",
    "ax.fill_between(range(24),min_atheism1,max_atheism1,color='blue', alpha=0.1)\n",
    "ax.plot(median_atheism2,label=\"Random selection\")\n",
    "ax.fill_between(range(24),min_atheism2,max_atheism2,color='orange', alpha=0.1)\n",
    "\n",
    "ax.scatter(range(24), median_atheism1, s=8,marker = \"v\")\n",
    "ax.scatter(range(24), median_atheism2, s=8,marker=\"^\")\n",
    "\n",
    "ax.xaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=5, integer=True))\n",
    "ax.yaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=10))\n",
    "ax.yaxis.set_major_formatter(mpl.ticker.PercentFormatter(xmax=1))\n",
    "\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "ax.set_title('Different initial data set in atheism target')\n",
    "ax.set_xlabel('Query iteration')\n",
    "ax.set_ylabel('Performance(median)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dca3e56",
   "metadata": {},
   "source": [
    "# Climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0bf8a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_climate\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset with 355 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_climate\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset with 40 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_climate\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset with 169 instances loaded\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "cache_dir = \"./data_cache\"\n",
    "\n",
    "train_dataset_climate = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_climate\",\n",
    "    split=\"train\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Training dataset with {len(train_dataset_climate)} instances loaded\")\n",
    "\n",
    "val_dataset_climate = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_climate\",\n",
    "    split=\"validation\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Validation dataset with {len(val_dataset_climate)} instances loaded\")\n",
    "\n",
    "test_dataset_climate = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_climate\",\n",
    "    split=\"test\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Test dataset with {len(test_dataset_climate)} instances loaded\")\n",
    "\n",
    "num_classes = np.unique(train_dataset_climate['label']).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "91b9302e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/config.json from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\3cf34679007e9fe5d0acd644dcc1f4b26bec5cbc9612364f6da7262aed4ef7a4.a5a11219cf90aae61ff30e1658ccf2cb4aa84d6b6e947336556f887c9828dc6d\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-tiny\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/pytorch_model.bin from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\1ee037c9e1a220d5c814779ffe697080d1e6f5b1602e16cf6061aaae41a082c5.038e1aed90492a59d2283f9c44c9fe3ee2380495ff1e7fefb3f1f04af3b685b5\n",
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_original = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\", num_labels=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2751b286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='682' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 03:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T15:58:44.584933Z [info     ] Start Predict                  dataset=346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:02<00:00, 17.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 19\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T15:58:50.207024Z [info     ] Start Predict                  dataset=336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:02<00:00, 17.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T15:58:56.245109Z [info     ] Start Predict                  dataset=326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:02<00:00, 17.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 39\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T15:59:03.074641Z [info     ] Start Predict                  dataset=316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:02<00:00, 17.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T15:59:08.471642Z [info     ] Start Predict                  dataset=306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:02<00:00, 18.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 59\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T15:59:14.044717Z [info     ] Start Predict                  dataset=296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:02<00:00, 18.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T15:59:19.522760Z [info     ] Start Predict                  dataset=286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:02<00:00, 17.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 79\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T15:59:25.114760Z [info     ] Start Predict                  dataset=276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 17.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T15:59:30.858318Z [info     ] Start Predict                  dataset=266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 18.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 99\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T15:59:36.854833Z [info     ] Start Predict                  dataset=256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 18.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T15:59:42.892873Z [info     ] Start Predict                  dataset=246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:01<00:00, 17.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 119\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T15:59:49.465437Z [info     ] Start Predict                  dataset=236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 19.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T15:59:55.738553Z [info     ] Start Predict                  dataset=226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 139\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:00:02.817697Z [info     ] Start Predict                  dataset=216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:01<00:00, 20.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:00:08.731828Z [info     ] Start Predict                  dataset=206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:01<00:00, 18.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 159\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:00:15.557352Z [info     ] Start Predict                  dataset=196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 18.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:00:22.204870Z [info     ] Start Predict                  dataset=186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:01<00:00, 21.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 179\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:00:28.306950Z [info     ] Start Predict                  dataset=176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:01<00:00, 20.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:00:35.139512Z [info     ] Start Predict                  dataset=166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 20.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 199\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:00:41.813074Z [info     ] Start Predict                  dataset=156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:00:49.134218Z [info     ] Start Predict                  dataset=146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 22.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 219\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:00:56.651264Z [info     ] Start Predict                  dataset=136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 19.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:01:04.098305Z [info     ] Start Predict                  dataset=126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 20.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 239\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:01:11.354390Z [info     ] Start Predict                  dataset=116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 20.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:01:19.116445Z [info     ] Start Predict                  dataset=106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 20.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 259\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:01:26.761446Z [info     ] Start Predict                  dataset=96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 20.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:01:35.459130Z [info     ] Start Predict                  dataset=86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 24.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 279\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:01:42.814685Z [info     ] Start Predict                  dataset=76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 20.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:01:50.882805Z [info     ] Start Predict                  dataset=66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 23.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 299\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:01:58.247404Z [info     ] Start Predict                  dataset=56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 18.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17159763313609466, 0.16568047337278108, 0.21301775147928995, 0.17751479289940827, 0.28402366863905326, 0.2958579881656805, 0.33727810650887574, 0.3609467455621302, 0.31952662721893493, 0.39644970414201186, 0.41420118343195267, 0.5562130177514792, 0.44970414201183434, 0.38461538461538464, 0.5088757396449705, 0.4911242603550296, 0.5739644970414202, 0.44970414201183434, 0.5976331360946746, 0.5029585798816568, 0.34911242603550297, 0.38461538461538464, 0.378698224852071, 0.5739644970414202, 0.514792899408284, 0.5029585798816568, 0.514792899408284, 0.4319526627218935, 0.5680473372781065, 0.591715976331361, 0.5266272189349113]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='682' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 03:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:02:02.584403Z [info     ] Start Predict                  dataset=346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:02<00:00, 18.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 19\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:02:07.142924Z [info     ] Start Predict                  dataset=336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:02<00:00, 20.89it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:02:11.451446Z [info     ] Start Predict                  dataset=326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:02<00:00, 19.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 39\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:02:16.059490Z [info     ] Start Predict                  dataset=316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:02<00:00, 19.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:02:20.947490Z [info     ] Start Predict                  dataset=306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 20.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 59\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:02:25.883490Z [info     ] Start Predict                  dataset=296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 20.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:02:30.987061Z [info     ] Start Predict                  dataset=286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 20.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 79\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:02:35.885060Z [info     ] Start Predict                  dataset=276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 20.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:02:40.973582Z [info     ] Start Predict                  dataset=266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 23.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 99\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:02:46.034708Z [info     ] Start Predict                  dataset=256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 20.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:02:51.965711Z [info     ] Start Predict                  dataset=246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:01<00:00, 17.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 119\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:02:58.115751Z [info     ] Start Predict                  dataset=236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 20.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:03:04.538561Z [info     ] Start Predict                  dataset=226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 139\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:03:10.798607Z [info     ] Start Predict                  dataset=216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:01<00:00, 16.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:03:18.094284Z [info     ] Start Predict                  dataset=206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:01<00:00, 19.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 159\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:03:24.646414Z [info     ] Start Predict                  dataset=196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 20.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:03:31.261981Z [info     ] Start Predict                  dataset=186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 25.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 179\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:03:37.766018Z [info     ] Start Predict                  dataset=176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:01<00:00, 18.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:03:44.570600Z [info     ] Start Predict                  dataset=166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 20.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 199\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:03:51.455820Z [info     ] Start Predict                  dataset=156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 19.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:03:58.477516Z [info     ] Start Predict                  dataset=146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 19.73it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 219\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:04:06.520859Z [info     ] Start Predict                  dataset=136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 18.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:04:14.666380Z [info     ] Start Predict                  dataset=126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 22.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 239\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:04:23.464951Z [info     ] Start Predict                  dataset=116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 17.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:04:32.437003Z [info     ] Start Predict                  dataset=106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 20.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 259\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:04:41.188158Z [info     ] Start Predict                  dataset=96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 19.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:04:50.132792Z [info     ] Start Predict                  dataset=86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 11.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 279\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:04:59.302736Z [info     ] Start Predict                  dataset=76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 16.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:05:08.700959Z [info     ] Start Predict                  dataset=66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 24.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 299\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:05:17.165997Z [info     ] Start Predict                  dataset=56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 21.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17159763313609466, 0.16568047337278108, 0.21301775147928995, 0.17751479289940827, 0.28402366863905326, 0.2958579881656805, 0.33727810650887574, 0.3609467455621302, 0.31952662721893493, 0.39644970414201186, 0.41420118343195267, 0.5562130177514792, 0.44970414201183434, 0.38461538461538464, 0.5088757396449705, 0.4911242603550296, 0.5739644970414202, 0.44970414201183434, 0.5976331360946746, 0.5029585798816568, 0.34911242603550297, 0.38461538461538464, 0.378698224852071, 0.5739644970414202, 0.514792899408284, 0.5029585798816568, 0.514792899408284, 0.4319526627218935, 0.5680473372781065, 0.591715976331361, 0.5266272189349113]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='682' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 03:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:05:21.171601Z [info     ] Start Predict                  dataset=346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:02<00:00, 19.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 19\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:05:25.474599Z [info     ] Start Predict                  dataset=336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:02<00:00, 20.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:05:30.388149Z [info     ] Start Predict                  dataset=326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:02<00:00, 19.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 39\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:05:34.950270Z [info     ] Start Predict                  dataset=316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:02<00:00, 17.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:05:40.071266Z [info     ] Start Predict                  dataset=306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:02<00:00, 16.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 59\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:05:45.676359Z [info     ] Start Predict                  dataset=296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:02<00:00, 18.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:05:50.854878Z [info     ] Start Predict                  dataset=286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:02<00:00, 17.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 79\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:05:56.626431Z [info     ] Start Predict                  dataset=276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:02<00:00, 15.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:06:02.931484Z [info     ] Start Predict                  dataset=266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 18.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 99\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:06:08.536481Z [info     ] Start Predict                  dataset=256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 23.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:06:13.923482Z [info     ] Start Predict                  dataset=246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:01<00:00, 19.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 119\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:06:19.618482Z [info     ] Start Predict                  dataset=236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 19.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:06:25.484483Z [info     ] Start Predict                  dataset=226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 18.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 139\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:06:31.544643Z [info     ] Start Predict                  dataset=216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:01<00:00, 15.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:06:38.619640Z [info     ] Start Predict                  dataset=206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:01<00:00, 24.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 159\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:06:44.710642Z [info     ] Start Predict                  dataset=196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 14.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:06:52.017640Z [info     ] Start Predict                  dataset=186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:01<00:00, 19.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 179\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:06:58.793734Z [info     ] Start Predict                  dataset=176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:01<00:00, 17.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:07:05.711774Z [info     ] Start Predict                  dataset=166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 19.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 199\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:07:13.020288Z [info     ] Start Predict                  dataset=156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 25.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:07:19.468889Z [info     ] Start Predict                  dataset=146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 20.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 219\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:07:27.099891Z [info     ] Start Predict                  dataset=136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 20.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:07:35.132418Z [info     ] Start Predict                  dataset=126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 239\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:07:42.502989Z [info     ] Start Predict                  dataset=116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 20.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:07:50.122153Z [info     ] Start Predict                  dataset=106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 21.51it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 259\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:07:58.157837Z [info     ] Start Predict                  dataset=96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 17.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:08:05.699356Z [info     ] Start Predict                  dataset=86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 20.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 279\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:08:14.675491Z [info     ] Start Predict                  dataset=76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 18.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:08:23.688570Z [info     ] Start Predict                  dataset=66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 17.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 299\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:08:33.113617Z [info     ] Start Predict                  dataset=56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 21.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17159763313609466, 0.16568047337278108, 0.21301775147928995, 0.17751479289940827, 0.28402366863905326, 0.2958579881656805, 0.33727810650887574, 0.3609467455621302, 0.31952662721893493, 0.39644970414201186, 0.41420118343195267, 0.5562130177514792, 0.44970414201183434, 0.38461538461538464, 0.5088757396449705, 0.4911242603550296, 0.5739644970414202, 0.44970414201183434, 0.5976331360946746, 0.5029585798816568, 0.34911242603550297, 0.38461538461538464, 0.378698224852071, 0.5739644970414202, 0.514792899408284, 0.5029585798816568, 0.514792899408284, 0.4319526627218935, 0.5680473372781065, 0.591715976331361, 0.5266272189349113]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='682' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 02:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:08:37.045615Z [info     ] Start Predict                  dataset=346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:02<00:00, 19.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 19\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:08:41.586186Z [info     ] Start Predict                  dataset=336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:02<00:00, 17.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:08:46.482295Z [info     ] Start Predict                  dataset=326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:02<00:00, 18.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 39\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:08:51.075858Z [info     ] Start Predict                  dataset=316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 20.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:08:55.946376Z [info     ] Start Predict                  dataset=306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:02<00:00, 18.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 59\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:09:01.514891Z [info     ] Start Predict                  dataset=296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:02<00:00, 17.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:09:07.558282Z [info     ] Start Predict                  dataset=286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 26.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 79\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:09:11.453800Z [info     ] Start Predict                  dataset=276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 27.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:09:15.227320Z [info     ] Start Predict                  dataset=266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 29.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 99\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:09:18.902317Z [info     ] Start Predict                  dataset=256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 31.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:09:22.666455Z [info     ] Start Predict                  dataset=246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 31.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 119\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:09:26.373454Z [info     ] Start Predict                  dataset=236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 27.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:09:30.686453Z [info     ] Start Predict                  dataset=226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 139\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:09:34.972452Z [info     ] Start Predict                  dataset=216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 33.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:09:38.790451Z [info     ] Start Predict                  dataset=206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 33.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 159\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:09:43.113454Z [info     ] Start Predict                  dataset=196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 27.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:09:47.887300Z [info     ] Start Predict                  dataset=186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 34.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 179\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:09:51.936858Z [info     ] Start Predict                  dataset=176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 33.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:09:56.068859Z [info     ] Start Predict                  dataset=166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 32.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 199\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:10:00.354376Z [info     ] Start Predict                  dataset=156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 33.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:10:04.612375Z [info     ] Start Predict                  dataset=146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 33.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 219\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:10:09.090375Z [info     ] Start Predict                  dataset=136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 34.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:10:13.844376Z [info     ] Start Predict                  dataset=126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 30.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 239\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:10:18.946375Z [info     ] Start Predict                  dataset=116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 29.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:10:24.283376Z [info     ] Start Predict                  dataset=106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 28.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 259\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:10:30.475382Z [info     ] Start Predict                  dataset=96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 25.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:10:36.636892Z [info     ] Start Predict                  dataset=86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 35.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 279\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:10:41.491892Z [info     ] Start Predict                  dataset=76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 34.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:10:46.444343Z [info     ] Start Predict                  dataset=66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 34.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 299\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:10:51.455343Z [info     ] Start Predict                  dataset=56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 33.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17159763313609466, 0.16568047337278108, 0.21301775147928995, 0.17751479289940827, 0.28402366863905326, 0.2958579881656805, 0.33727810650887574, 0.3609467455621302, 0.31952662721893493, 0.39644970414201186, 0.41420118343195267, 0.5562130177514792, 0.44970414201183434, 0.38461538461538464, 0.5088757396449705, 0.4911242603550296, 0.5739644970414202, 0.44970414201183434, 0.5976331360946746, 0.5029585798816568, 0.34911242603550297, 0.38461538461538464, 0.378698224852071, 0.5739644970414202, 0.514792899408284, 0.5029585798816568, 0.514792899408284, 0.4319526627218935, 0.5680473372781065, 0.591715976331361, 0.5266272189349113]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='682' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 02:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:10:54.138372Z [info     ] Start Predict                  dataset=346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 33.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 19\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:10:56.812342Z [info     ] Start Predict                  dataset=336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 33.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:10:59.574403Z [info     ] Start Predict                  dataset=326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 27.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 39\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:11:03.007401Z [info     ] Start Predict                  dataset=316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 27.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:11:06.573955Z [info     ] Start Predict                  dataset=306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 28.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 59\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:11:10.137954Z [info     ] Start Predict                  dataset=296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 29.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:11:13.680513Z [info     ] Start Predict                  dataset=286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 30.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 79\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:11:17.311510Z [info     ] Start Predict                  dataset=276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 31.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:11:20.679507Z [info     ] Start Predict                  dataset=266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 34.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 99\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:11:24.353690Z [info     ] Start Predict                  dataset=256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 34.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:11:28.309744Z [info     ] Start Predict                  dataset=246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:01<00:00, 27.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 119\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:11:32.517779Z [info     ] Start Predict                  dataset=236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 33.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:11:36.221780Z [info     ] Start Predict                  dataset=226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 139\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:11:40.423776Z [info     ] Start Predict                  dataset=216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 33.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:11:44.262778Z [info     ] Start Predict                  dataset=206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 34.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 159\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:11:48.069995Z [info     ] Start Predict                  dataset=196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 33.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:11:51.976994Z [info     ] Start Predict                  dataset=186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 33.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 179\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:11:56.599168Z [info     ] Start Predict                  dataset=176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 23.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:12:01.857214Z [info     ] Start Predict                  dataset=166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 31.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 199\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:12:06.204046Z [info     ] Start Predict                  dataset=156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 34.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:12:10.589043Z [info     ] Start Predict                  dataset=146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 32.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 219\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:12:15.088046Z [info     ] Start Predict                  dataset=136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 33.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:12:19.560044Z [info     ] Start Predict                  dataset=126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 34.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 239\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:12:24.129043Z [info     ] Start Predict                  dataset=116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 31.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:12:29.114047Z [info     ] Start Predict                  dataset=106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 32.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 259\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:12:34.196044Z [info     ] Start Predict                  dataset=96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 31.66it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:12:39.412045Z [info     ] Start Predict                  dataset=86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 30.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 279\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:12:45.515609Z [info     ] Start Predict                  dataset=76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 26.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:12:51.544610Z [info     ] Start Predict                  dataset=66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 33.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 299\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:12:57.194610Z [info     ] Start Predict                  dataset=56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 30.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17159763313609466, 0.16568047337278108, 0.21301775147928995, 0.17751479289940827, 0.28402366863905326, 0.2958579881656805, 0.33727810650887574, 0.3609467455621302, 0.31952662721893493, 0.39644970414201186, 0.41420118343195267, 0.5562130177514792, 0.44970414201183434, 0.38461538461538464, 0.5088757396449705, 0.4911242603550296, 0.5739644970414202, 0.44970414201183434, 0.5976331360946746, 0.5029585798816568, 0.34911242603550297, 0.38461538461538464, 0.378698224852071, 0.5739644970414202, 0.514792899408284, 0.5029585798816568, 0.514792899408284, 0.4319526627218935, 0.5680473372781065, 0.591715976331361, 0.5266272189349113]\n"
     ]
    }
   ],
   "source": [
    "active_mc_climate1= []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "while mcrun != 5:\n",
    "#     n_labeled_examples = np.unique(train_dataset_climate['text']).size\n",
    "#     training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "#     print(training_indices0)\n",
    "    active_set_climate =active_huggingface_dataset(train_dataset_climate,tokenizer,'label','text')\n",
    "    valid_set_climate = HuggingFaceDatasets(test_dataset_climate,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_climate.can_label = False\n",
    "    active_set_climate.label([0,1,2,3,4,7,80,112,118])\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_climate,\n",
    "            eval_dataset=valid_set_climate,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_climate = ActiveLearningLoop(active_set_climate,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 10, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_climate=[unqueried_score]\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_climate.step()\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_climate.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_climate),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_climate.append(eval_metrics['eval_accuracy'])\n",
    "    print(performance_history_climate)\n",
    "    active_mc_climate1.append(performance_history_climate)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "63af0a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='682' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 02:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:13:00.252609Z [info     ] Start Predict                  dataset=346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 28.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 19\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:13:03.466608Z [info     ] Start Predict                  dataset=336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 25.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:13:10.225440Z [info     ] Start Predict                  dataset=326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 32.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 39\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:13:15.342960Z [info     ] Start Predict                  dataset=316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 32.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:13:20.043667Z [info     ] Start Predict                  dataset=306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 32.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 59\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:13:25.874694Z [info     ] Start Predict                  dataset=296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 31.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:13:30.210825Z [info     ] Start Predict                  dataset=286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 32.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 79\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:13:34.841798Z [info     ] Start Predict                  dataset=276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 32.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:13:39.794243Z [info     ] Start Predict                  dataset=266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 31.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 99\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:13:44.467139Z [info     ] Start Predict                  dataset=256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 30.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:13:48.655191Z [info     ] Start Predict                  dataset=246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 31.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 119\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:13:53.622189Z [info     ] Start Predict                  dataset=236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 32.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:13:58.550289Z [info     ] Start Predict                  dataset=226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.73it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 139\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:14:02.423290Z [info     ] Start Predict                  dataset=216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 32.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:14:06.329291Z [info     ] Start Predict                  dataset=206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 33.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 159\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:14:10.355301Z [info     ] Start Predict                  dataset=196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 32.89it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:14:14.469300Z [info     ] Start Predict                  dataset=186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 31.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 179\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:14:18.612331Z [info     ] Start Predict                  dataset=176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 31.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:14:22.779301Z [info     ] Start Predict                  dataset=166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 199\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:14:27.036858Z [info     ] Start Predict                  dataset=156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 30.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:14:32.207854Z [info     ] Start Predict                  dataset=146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 26.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 219\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:14:37.737856Z [info     ] Start Predict                  dataset=136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 31.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:14:42.545370Z [info     ] Start Predict                  dataset=126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 31.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 239\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:14:47.265370Z [info     ] Start Predict                  dataset=116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 30.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:14:53.025371Z [info     ] Start Predict                  dataset=106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 25.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 259\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:14:58.841382Z [info     ] Start Predict                  dataset=96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 29.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:15:03.827384Z [info     ] Start Predict                  dataset=86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 34.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 279\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:15:08.997382Z [info     ] Start Predict                  dataset=76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 34.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:15:14.306381Z [info     ] Start Predict                  dataset=66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 33.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 299\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:15:19.636896Z [info     ] Start Predict                  dataset=56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 31.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2485207100591716, 0.21301775147928995, 0.26627218934911245, 0.21893491124260356, 0.3668639053254438, 0.3431952662721893, 0.3668639053254438, 0.46745562130177515, 0.3668639053254438, 0.38461538461538464, 0.47928994082840237, 0.5325443786982249, 0.47928994082840237, 0.5680473372781065, 0.5502958579881657, 0.5207100591715976, 0.3431952662721893, 0.514792899408284, 0.39644970414201186, 0.5088757396449705, 0.41420118343195267, 0.5029585798816568, 0.4378698224852071, 0.5680473372781065, 0.4260355029585799, 0.47928994082840237, 0.5266272189349113, 0.39644970414201186, 0.591715976331361, 0.6686390532544378, 0.6449704142011834]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='682' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 02:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:15:22.551913Z [info     ] Start Predict                  dataset=346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 31.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 19\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:15:25.314911Z [info     ] Start Predict                  dataset=336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 31.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:15:28.219912Z [info     ] Start Predict                  dataset=326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 32.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 39\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:15:31.158911Z [info     ] Start Predict                  dataset=316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 26.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:15:34.888911Z [info     ] Start Predict                  dataset=306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 25.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 59\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:15:39.389433Z [info     ] Start Predict                  dataset=296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 24.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:15:43.535431Z [info     ] Start Predict                  dataset=286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 29.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 79\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:15:46.814433Z [info     ] Start Predict                  dataset=276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 32.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:15:50.159174Z [info     ] Start Predict                  dataset=266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 33.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 99\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:15:53.638176Z [info     ] Start Predict                  dataset=256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 32.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:15:57.718173Z [info     ] Start Predict                  dataset=246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:01<00:00, 25.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 119\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:16:02.242175Z [info     ] Start Predict                  dataset=236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 33.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:16:06.224174Z [info     ] Start Predict                  dataset=226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.03it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 139\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:16:10.185174Z [info     ] Start Predict                  dataset=216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 31.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:16:14.101174Z [info     ] Start Predict                  dataset=206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 32.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 159\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:16:17.952174Z [info     ] Start Predict                  dataset=196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 30.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:16:22.232580Z [info     ] Start Predict                  dataset=186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 31.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 179\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:16:26.852583Z [info     ] Start Predict                  dataset=176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 28.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:16:32.176176Z [info     ] Start Predict                  dataset=166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 32.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 199\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:16:36.967222Z [info     ] Start Predict                  dataset=156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 27.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:16:42.177853Z [info     ] Start Predict                  dataset=146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 25.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 219\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:16:47.071368Z [info     ] Start Predict                  dataset=136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 33.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:16:51.582700Z [info     ] Start Predict                  dataset=126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 32.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 239\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:16:56.049666Z [info     ] Start Predict                  dataset=116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 33.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:17:00.934664Z [info     ] Start Predict                  dataset=106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 33.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 259\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:17:06.033667Z [info     ] Start Predict                  dataset=96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 30.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:17:11.365674Z [info     ] Start Predict                  dataset=86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 31.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 279\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:17:17.220268Z [info     ] Start Predict                  dataset=76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 25.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:17:23.688789Z [info     ] Start Predict                  dataset=66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 27.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 299\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:17:30.172874Z [info     ] Start Predict                  dataset=56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 31.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1893491124260355, 0.1952662721893491, 0.20710059171597633, 0.20710059171597633, 0.2485207100591716, 0.2603550295857988, 0.31952662721893493, 0.38461538461538464, 0.3431952662721893, 0.34911242603550297, 0.4556213017751479, 0.4970414201183432, 0.39644970414201186, 0.41420118343195267, 0.39644970414201186, 0.4260355029585799, 0.40828402366863903, 0.5680473372781065, 0.39644970414201186, 0.48520710059171596, 0.4437869822485207, 0.3254437869822485, 0.378698224852071, 0.3431952662721893, 0.5443786982248521, 0.4911242603550296, 0.41420118343195267, 0.44970414201183434, 0.5680473372781065, 0.5680473372781065, 0.5857988165680473]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='682' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 02:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:17:33.008874Z [info     ] Start Predict                  dataset=346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 30.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 19\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:17:35.935931Z [info     ] Start Predict                  dataset=336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 30.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:17:38.820932Z [info     ] Start Predict                  dataset=326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 31.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 39\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:17:41.867857Z [info     ] Start Predict                  dataset=316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 31.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:17:45.026920Z [info     ] Start Predict                  dataset=306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 31.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 59\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:17:48.216918Z [info     ] Start Predict                  dataset=296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 31.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:17:51.530920Z [info     ] Start Predict                  dataset=286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 31.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 79\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:17:54.864917Z [info     ] Start Predict                  dataset=276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 31.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:17:58.559918Z [info     ] Start Predict                  dataset=266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 31.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 99\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:18:02.257024Z [info     ] Start Predict                  dataset=256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 30.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:18:05.909025Z [info     ] Start Predict                  dataset=246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 33.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 119\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:18:09.751590Z [info     ] Start Predict                  dataset=236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 26.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:18:14.831630Z [info     ] Start Predict                  dataset=226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 139\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:18:20.272718Z [info     ] Start Predict                  dataset=216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 32.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:18:24.629956Z [info     ] Start Predict                  dataset=206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 32.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 159\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:18:28.568927Z [info     ] Start Predict                  dataset=196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 32.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:18:32.749925Z [info     ] Start Predict                  dataset=186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 34.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 179\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:18:37.208314Z [info     ] Start Predict                  dataset=176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 31.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:18:41.686282Z [info     ] Start Predict                  dataset=166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 32.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 199\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:18:46.252285Z [info     ] Start Predict                  dataset=156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 33.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:18:50.657777Z [info     ] Start Predict                  dataset=146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 34.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 219\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:18:56.215848Z [info     ] Start Predict                  dataset=136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 24.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:19:04.642989Z [info     ] Start Predict                  dataset=126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 13.03it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 239\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:19:12.880989Z [info     ] Start Predict                  dataset=116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 24.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:19:19.165989Z [info     ] Start Predict                  dataset=106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 26.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 259\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:19:25.609031Z [info     ] Start Predict                  dataset=96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 20.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:19:33.065615Z [info     ] Start Predict                  dataset=86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 27.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 279\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:19:39.589176Z [info     ] Start Predict                  dataset=76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 26.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:19:45.237724Z [info     ] Start Predict                  dataset=66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 33.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 299\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:19:51.588852Z [info     ] Start Predict                  dataset=56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 21.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1893491124260355, 0.1952662721893491, 0.20710059171597633, 0.20710059171597633, 0.2485207100591716, 0.2603550295857988, 0.31952662721893493, 0.38461538461538464, 0.3431952662721893, 0.34911242603550297, 0.4556213017751479, 0.4970414201183432, 0.39644970414201186, 0.41420118343195267, 0.39644970414201186, 0.4260355029585799, 0.40828402366863903, 0.5680473372781065, 0.39644970414201186, 0.48520710059171596, 0.4437869822485207, 0.3254437869822485, 0.378698224852071, 0.3431952662721893, 0.5443786982248521, 0.4911242603550296, 0.41420118343195267, 0.44970414201183434, 0.5680473372781065, 0.5680473372781065, 0.5857988165680473]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='682' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 02:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:19:55.315420Z [info     ] Start Predict                  dataset=346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 25.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 19\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:19:58.570921Z [info     ] Start Predict                  dataset=336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 32.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:20:01.449923Z [info     ] Start Predict                  dataset=326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 32.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 39\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:20:04.409924Z [info     ] Start Predict                  dataset=316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 20.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:20:09.691479Z [info     ] Start Predict                  dataset=306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 24.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 59\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:20:13.718476Z [info     ] Start Predict                  dataset=296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 30.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:20:17.095477Z [info     ] Start Predict                  dataset=286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 28.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 79\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:20:20.681318Z [info     ] Start Predict                  dataset=276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 26.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:20:24.680949Z [info     ] Start Predict                  dataset=266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 33.73it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 99\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:20:28.355949Z [info     ] Start Predict                  dataset=256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 31.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:20:32.174463Z [info     ] Start Predict                  dataset=246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 33.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 119\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:20:35.904409Z [info     ] Start Predict                  dataset=236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 32.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:20:39.601692Z [info     ] Start Predict                  dataset=226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 139\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:20:44.325691Z [info     ] Start Predict                  dataset=216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 27.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:20:49.415694Z [info     ] Start Predict                  dataset=206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 26.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 159\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:20:54.564695Z [info     ] Start Predict                  dataset=196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 24.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:20:59.490642Z [info     ] Start Predict                  dataset=186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 29.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 179\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:21:04.789691Z [info     ] Start Predict                  dataset=176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 23.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:21:09.511690Z [info     ] Start Predict                  dataset=166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 20.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 199\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:21:14.970213Z [info     ] Start Predict                  dataset=156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 27.66it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:21:20.050756Z [info     ] Start Predict                  dataset=146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 34.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 219\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:21:24.722757Z [info     ] Start Predict                  dataset=136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 29.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:21:29.516755Z [info     ] Start Predict                  dataset=126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 34.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 239\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:21:34.809252Z [info     ] Start Predict                  dataset=116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 28.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:21:40.360806Z [info     ] Start Predict                  dataset=106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 32.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 259\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:21:46.179663Z [info     ] Start Predict                  dataset=96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 23.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:21:51.997217Z [info     ] Start Predict                  dataset=86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 26.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 279\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:21:57.452212Z [info     ] Start Predict                  dataset=76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 33.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:22:02.624212Z [info     ] Start Predict                  dataset=66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 34.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 299\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:22:08.058211Z [info     ] Start Predict                  dataset=56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 33.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1893491124260355, 0.1952662721893491, 0.20710059171597633, 0.20710059171597633, 0.2485207100591716, 0.2603550295857988, 0.31952662721893493, 0.38461538461538464, 0.3431952662721893, 0.34911242603550297, 0.4556213017751479, 0.4970414201183432, 0.39644970414201186, 0.41420118343195267, 0.39644970414201186, 0.4260355029585799, 0.40828402366863903, 0.5680473372781065, 0.39644970414201186, 0.48520710059171596, 0.4437869822485207, 0.3254437869822485, 0.378698224852071, 0.3431952662721893, 0.5443786982248521, 0.4911242603550296, 0.41420118343195267, 0.44970414201183434, 0.5680473372781065, 0.5680473372781065, 0.5857988165680473]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='682' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 02:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:22:10.861210Z [info     ] Start Predict                  dataset=346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 32.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 19\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:22:13.646765Z [info     ] Start Predict                  dataset=336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 26.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:22:17.178764Z [info     ] Start Predict                  dataset=326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 25.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 39\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:22:20.777767Z [info     ] Start Predict                  dataset=316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 24.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:22:24.584761Z [info     ] Start Predict                  dataset=306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 30.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 59\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:22:27.884763Z [info     ] Start Predict                  dataset=296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 32.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:22:30.965764Z [info     ] Start Predict                  dataset=286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 33.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 79\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:22:34.090762Z [info     ] Start Predict                  dataset=276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 33.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:22:37.557763Z [info     ] Start Predict                  dataset=266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 34.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 99\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:22:41.044899Z [info     ] Start Predict                  dataset=256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 32.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:22:44.555899Z [info     ] Start Predict                  dataset=246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 33.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 119\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:22:48.408408Z [info     ] Start Predict                  dataset=236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 34.03it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:22:52.337931Z [info     ] Start Predict                  dataset=226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 139\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:22:57.283930Z [info     ] Start Predict                  dataset=216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:01<00:00, 24.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:23:02.763062Z [info     ] Start Predict                  dataset=206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 32.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 159\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:23:06.681180Z [info     ] Start Predict                  dataset=196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 32.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:23:10.850068Z [info     ] Start Predict                  dataset=186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 34.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 179\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:23:15.170062Z [info     ] Start Predict                  dataset=176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 29.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:23:19.488062Z [info     ] Start Predict                  dataset=166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 31.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 199\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:23:23.720111Z [info     ] Start Predict                  dataset=156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 33.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:23:28.330116Z [info     ] Start Predict                  dataset=146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 26.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 219\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:23:33.691114Z [info     ] Start Predict                  dataset=136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 31.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:23:38.357628Z [info     ] Start Predict                  dataset=126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 30.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 239\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:23:43.472628Z [info     ] Start Predict                  dataset=116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 32.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:23:48.947203Z [info     ] Start Predict                  dataset=106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 29.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 259\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:23:53.985233Z [info     ] Start Predict                  dataset=96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 32.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:24:00.057233Z [info     ] Start Predict                  dataset=86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 33.03it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 279\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:24:05.482238Z [info     ] Start Predict                  dataset=76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 25.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:24:13.628235Z [info     ] Start Predict                  dataset=66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 21.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 299\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T16:24:22.887762Z [info     ] Start Predict                  dataset=56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 17.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1893491124260355, 0.1952662721893491, 0.20710059171597633, 0.20710059171597633, 0.2485207100591716, 0.2603550295857988, 0.31952662721893493, 0.38461538461538464, 0.3431952662721893, 0.34911242603550297, 0.4556213017751479, 0.4970414201183432, 0.39644970414201186, 0.41420118343195267, 0.39644970414201186, 0.4260355029585799, 0.40828402366863903, 0.5680473372781065, 0.39644970414201186, 0.48520710059171596, 0.4437869822485207, 0.3254437869822485, 0.378698224852071, 0.3431952662721893, 0.5443786982248521, 0.4911242603550296, 0.41420118343195267, 0.44970414201183434, 0.5680473372781065, 0.5680473372781065, 0.5857988165680473]\n"
     ]
    }
   ],
   "source": [
    "active_mc_climate2 = []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "while mcrun != 5:\n",
    "#     n_labeled_examples = np.unique(train_dataset_climate['text']).size\n",
    "#     training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "#     print(training_indices0)\n",
    "    active_set_climate =active_huggingface_dataset(train_dataset_climate,tokenizer,'label','text')\n",
    "    valid_set_climate = HuggingFaceDatasets(test_dataset_climate,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_climate.can_label = False\n",
    "    active_set_climate.label_randomly(9)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_climate,\n",
    "            eval_dataset=valid_set_climate,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_climate = ActiveLearningLoop(active_set_climate,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 10, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_climate=[unqueried_score]\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_climate.step()\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_climate.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_climate),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_climate.append(eval_metrics['eval_accuracy'])\n",
    "    print(performance_history_climate)\n",
    "    active_mc_climate2.append(performance_history_climate)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6792ee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_climate1, min_climate1,max_climate1 = calculate(active_mc_climate1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d2770f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_climate2, min_climate2,max_climate2 = calculate(active_mc_climate2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ec972f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8sAAAN9CAYAAACkYuvHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAABP+AAAT/gEHlDmEAAEAAElEQVR4nOzdd3wcxf3/8ddHXXKV3OTeMcY1mN4xLST0QCgBQguh5Ev7pRF6CJgk9JCEFtOCaaGEDqE3U90oNu69ypYsW126+f0xe9LpdJJVTv39fDzuobvd2d25sqf77Mx8xpxziIiIiIiIiEiVhNaugIiIiIiIiEhbo2BZREREREREJIqCZREREREREZEoCpZFREREREREoihYFhEREREREYmiYFlEREREREQkioJlERERERERkSgKlkVERERERESiKFgWERERERERiaJgWURERERERCSKgmURERERERGRKAqWRURERERERKIoWBaRDsfMlpuZi7iFzGxrsPwVM7vazIbUsf1ZwXYPx1iXZmZ/MbOlZlYalHshYv14M3vZzDYHx3VmdlyzPNF2xsweDl6Ps+K0v/eC/R3UwO0OCrZ7L071cGbm4rGvYH9xrZ9UV9f53dpqO0fife6IiEj9KFgWkY7sDeAR4FHgTWA1cBBwI7DMzO42s7QG7vNPwG+ANOD5YP/vAJhZF+Bl4MfAIuDfwfqVTX0ibUW8A8Pm0NgguqNqD+9ZQ+k9blta4wKPmV0fHPP6ljpma4i4+Dustesi0hkltXYFRESa0S3OufciF5hZKnAG8Ffg/4DhZnascy4UUex54FNga4x9nhT83d85tyRq3R7AUOBj59x+cah/R3MlcAuwLk77OxPIoOEXIz4HxgKFcaqHtC91nd9tVbzPHRERqQcFyyLSqTjnSoAHzewz/A/mo4BzgQciymyl9h/Sg4My0YFy5Tpgcdwq3IE459YRxx/7zrlGtdg75wqBBfGqh7QvOzi/26R4nzsiIlI/6oYtIp2Sc+5r4K7g4RWR62KNaQx3hQMseBw5JvqsYN0jQfGfR6x7L2rffczsFjP71swKzWybmX1qZueZmUXXM7K7qZkdamZvmtmWYNnkiHJDzezvZrbYzIrNLM/M3jWzE2I9/8iufWZ2RHCcfDPbHtw/KNZrEvE48vnXq4tvfcZjmtloM3vSzDYFz+MbM7uglv1V64obPBcHHBgUeTeqnuFyMbuMmlmymZ1hZk+Z2cLgtdhuZnPN7Nqgm33cmNnU4D3aZn5M/Ttmdkgd5RtUv/q+Z2bW18wuCz5by4PXPdfMPjCzMxv53E4ws7fMbLWZlZjZejP70sxuNbM+McrX67yo73u8g7rFHLMcudzMupnZbWa2Iqj/yqDuGY18PX5sZi8Gr0Opma0N3vv/q+f29Tl3JprZC+bzJeQHr/9uEWXPNrOvzKzAzDaa2X1m1iPGsRr0eQhex3eDhwdGvR/vRZVNMLPTg8/6luC1XWpmd5lZv/q8FsF+lgPXBQ+vizrm9RHlDjWzf5jZvOB4xcHx7jWzobXsu77fueHvzW3mv2/fMrMDbQdd0q2e39Xh/eB7K4EfOhT5PIfV9/USkcZTy7KIdGYz8N0bdzazAc65tXWU/Q/QG/h58PiRiHWLg8ejgH2BJcBHwbrKFkwzmwS8DmQDK/DjqDOAvfAt2wcDP6vl+KcA5wNzg30MBkLBfg8FngO6Ad8DrwC9gv0eZGbTnHN/qGW/vwheg7n4Md674AORN81sqnMu/DzCzzHW84+XHwB3A5uBD4E++Nfzn2bWwzn35x1svz2o1w+Bfvjnsz5i/fpYG0Xohx/fngPMB2YBWfju9TcAx5jZ/s65ooY8qVjM7PTgWAZ8gf/MjMV/Jv4ep/rV9z07HLgDWIYfaz8TGAjsA+xvZns65y5uwHO7CfgDUIY/Dz4I6jkS+H/4c2lTRPmGnBdNfY/rowf+NeiPf2++BQ4I6r4L8KP67igI9O8HzsOfr5/jcxz0BcbjP+9/i0Oddwf+ASwE/hfs+xD8xYTdgF8CFwfH/x+wP/77ZFRQLlJDPw8f4d+7I4AN+PcyLPL7Lxl4BjgW/z5+CWwBJgOXAD8xswOcc0vr8Xz/AxwKTMJ/d82JWBd5/15gAPA1/nVPCbb5JXCSme3jnPu+lmPU9Z0b7o1kwGfAUmDn4Bh311bpBn5Xr8d/1k8EugDP4l+3sMj7ItJcnHO66aabbh3qBiwHHHDQDsolACVB2UMjlp8VLHs4xjbOf3XG3F9d22VE1OtyICFi3UDgq2DdOVHbvRc+JnBWjP0OBHLxgcmpUet2jjjm1FpeoyLgqIjlBvwzWPd2Q55/Pd6Xh2M9j4jlDvhj1GtzSrA8H8io5bU5qD7LI9YfFKx/L2p5N3xytqSo5T3wP2od8PumvibBe7Y92O6MqHX/L+K1aJH64YP03WIsH4kPXh2wVz2fW1rwmdoGjIqxfhLQN47nRZ3neC11PIsY52nEche8nj0j1u0UfAYdPl9BfY8Vfj9XAj+IWpcIHNPAc6Suc+eSiOUGPBYs/wZYC0yKWD8If8HCAQc29fNALedUVJm/BmX+B2RHLE8AbgrWfdCA1/b6YJvr6yhzLNA9xuse3vb1GNuEP1u1fecOwec7CAE/jVr3K2o/f5v6XT2soZ913XTTrek3dcMWkU7L+aReW4KHvZr5cGfju9M96py7w0UkFHPOrcG38IL/sRXLG865h2MsvwzoCdzsnHsicoVzbgFVXcxr2+9dzrmXI7ZxwLXBw/2C1qCW8plz7tqo1+ZJ4Dt8oLh7cx7cObfNOfeKc648avlW/OsM8JM4HOpcfEvRa865x6KOdRs+QGyx+jnn5jvnvoyxfAk++3tD9tsNHzAvcc7VGLvvnJvrnNsYsaip50Vz2Aac7ZzLi6jLQnzwCTC1PjsJzp1wK+HpzrnZkeudcxXOuRebXl3AJxWsbNEMzuNbg4fjgGucc3Mj1q/GZ+sHH+hG1iuenwcAzKwX/j3MBU5xzlX2AAje82vwLbj7m9nEhuy7Ls65/zrn8qOWVTjnrgfWAIeZWbdaNq/tO/ccIB14yTn3dNS+78G3NMdyGU37rhaRVqBu2CLS2YUvGrpmPs6Rwd9nYq10zs0ys+3AJDNLc84VRxV5vjH7xXeBBd/NL5bXYtRlk5ltwXed7U3LJRaqUZfAAnz31wEtUQkz2x3f9XcovuXTghv4FsamOjD4+3gt6/8NTGnJ+gWB3aH4z0k/IDXYZ/+G7Df47KzAf47/Cjzoau/mCk0/L5rDV1EBfVi4S3F9P4e74c+hxc65D3ZUuInejLEs8mLF/+pYX+P5xOvzEOFg/EWUV5xzm6NXOudCZvYRvufBXsC8Bu6/VsHY5B/j69wN37IMkIz//h8FzI6xaW3fufsHf5+sZf0TwJ4xljf1u1pEWoGCZRHptMwsEX+lH6pamJvL8ODvS1Yzj1e0XvhWj0i1ZX4O7/frHey3RlKlwKpalm/D/9BPrWuncVZXXaCZ62JmXfE/gH9cR7HucTjUwODv8lrWx1zeXPUzs52B/1J3ANSQ/Z6Br+evgV+b2QbgE+BVYIbz2cjDmnpeNId4fQ6HBH/rulgQL6ujFzjnCiJe0xrrgYLgb7Xn0wyfB6h6n39iO04IWNt3VYOZ2Z+A31MVIMdS23Op7Ts3fP6uqGX98lqWN/W7WkRagYJlEenMxuETvoAf19ecwi3YL+K7ItalJMay2pJKhfc7Az8WrqFCOy7SYlq7LrfgA9Fvgd8RJCByzpWZWQqx35emaGhvhuaq33/wgdELwJ/xwV2+c67CzA7HJ9HaYSQb5pz70MxG4xM+HYFviTs+uF0TJHEKBxpNPS+aQ7w/h83dawV2UGdXfR75HYnr5yEQfp+/wydNq8u3Ddx3TGZ2InAVfqz5ZfiM3eucnz4QM/sE2Jvan0tjE/nVtr+mfleLSCtQsCwindlpwd9vI8fQNZNV+CQudzvn3o7zfkcD17rYcz9L/Z0Y/D3FORd98WRUHI+zBhgDDMO3uEYbVst2ca9f0Io4Dp/F+ETnXEU89hu0Hj8f3MJdYe/FZ7G+BTg1KNpc50VbEL4gMKZVa9EAzfV5oKq1fpZz7qxG7qOhwufLVc65h2Ksb+xzCZ+/Q4l9/g6JsQz0XS3SLinBl4h0SmY2AT9dCcBtLXDI8HQqJ9ZZqu3stzZlAGbWli+2lgZ/G1rHrOBvrG64p8ZY1ljhsYmn1bK+tunDGlu/ut6z8D7XxQiMwGcjb7KgJTmcHCoygVNjP7+NfY9b0lf4adBGm9l+rV2Zemrs52FH78c7+M/hD4PhBPGwo2PWer6Yn8+8sd2dPwz+/rSW9bW9Rh35sy7SYSlYFpFOxcxSgzkyP8BnNP0vzTNncLQH8OMGf2lmvzezGuMezWwPMzupgfu9DT+W8nozOzcYhx25zwQzO9jMjmh0zasLjxkdG6f9NYfG1jGcwOmiyIXB3Kj/r6mVivAv/NQzPzazagGzmV2GTwwVz/rV9XoswnfhHW9m4cRFmHclVcmM6sXMhgafw1gZhsNjrSPHgjb2vGjzn0PnXBm+FR3g8egsz2aWaGZHtXzN6tTYz0P4/RgV66JM0HPnn/iEgc+b2YjoMmaWbWaXNuBC3I4+A+Hz5RfBMIXwcYYFdWms6fgu2scGXb0rmdmF+K7dsTT2u7rNf9ZFOjIFyyLSkf3ezB4Obk+b2Qf4lp4H8Uld7sR3aW32sbLOuW3AUfgfPtOAVWb2lpk9aWbvm9lq/JQjDZqSJWixOwEoxj+v5Wb2upk9FWSXXY9v1Tk4Tk8lnCH27aDuD5rZg3Had7yE6/hXM3sxXEcz21F32HDL581mNsvMngjGNf4PuCtelQum7bkIP5b1cTP7zMxmmNls4Hbgb3GuX63vmXNuE757dBLwbvCZfAIfaNxI1fRD9ZWJ/xxuMrOZQR2fMbPvgSvx80tfF/FaNPa8aOx73NJuw1+MGwLMNrOPg/f6f/jn/FKr1i5KYz8PwffQbHzm7Hlm9ljwfvwmothvgOfwWbYXBJ/7p8zsVTP7Gn/R5E7q34L6Bv6i0wlm9oGZPRQc85hg/d348co/BhYF/wNeA+bjM/zH6kK9Q865lcD/BQ+fCT7nM8zsK+Aeqs7f0qjtGvtdHf6sP25m/4n4rDf3dIcigrp0iEjHFr5C7/A/0rcA7+N/JD3qnKst622zcM7NDVqXLgaOBfbAJxjbACwB/g48Xfseat3vW2Y2DrgUPz3JfviLoeuBOcAr1D5dSUNdhX89j8f/8AvPw3xenPbfZM65F83sIuCX+B/m6cGqf1NHZmLn3NPmp8y6FpiAH1/4LfBz59yjZvb7ONbxETNbi389d8O3Gs3Cf2bLqPoxHo/67eg9+79gP7/Et4oVAzOBs/CZkn/dgKe2BD9f7EHA+KCeFVQFQnc555ZHPa8GnxeNfY9bWjDf8Vlm9l98XXfDzxe+Cf+a39iK1atNYz8PJ+ATgh2IHxaQiP++/SuAc64Unw37ePxcxbsDPwC2AmvxvQxeqO/0YM659UHL/LXBfvbDJ9daDbzonFtsZlPwF2H2AY7GjyP/c7DsjXq9GrGP/S8zW4O/ADQFP877S+BwqqbXyomxXWO+q+/BX9z9Gf7CUrj3xZ/wF39FpBmZ/x4XEREREZGmMLMH8BeifuOca2jPDBFpYxQsi4iIiIjUUzDuebtzLidq+ZnAQ0A5MMI51xLzgotIM1I3bBERERGR+jsKuDPIM7ACP2xgLH46KgdcqkBZpGNQy7KIiIiISD0FY+z/H7Av0Bc/Zj4HP7b7Lufc+61YPRGJIwXLIiIiIiIiIlHa/NRRZnZlMO3EUjNzZrZ8B+X7mdl0M9tgZsVmNs/MflFH+VPN7CszKzKznGCai6Exyh1oZl+Y2XYz+ybI5hhdJjHYV1Pm7xMREREREZFW1uaDZeBmYCp++ojcugqaWU/gI+AU4F/46Q9WAveb2XUxyv8KmIGfXP5y/LQWhwGfmNmAiHKD8en88/Hdbubj59bbNWqXlwEDgLhNLyIiIiIiIiItr813wzazEc65pcH9b4CuzrlhtZSdhg9Uf+Kcey5i+YvAD4ExzrllwbJewHJgIbCnc648WL4b8Dkw3Tl3XrDsfOAuoLdzrsDMEoClwOPOuauCMkPx8xKe7ZyL13ymIiIiIiIi0grafMtyOFCup58ByyID5cDtQDJwcsSyY4GuwN3hQDk43pfAB8BPzSwlWNwFKHLOFQRlQvhW7i4R+/sn8J4CZRERERERkfavw0wdZWbZwGB8t+poM/Gp/PeIWBa+/0mM8p8ABwI7A/OAj4FMM/sD8G98V+1J+C7imNmpwAHAuEbUezAwKGpxL2AX4CugsKH7FBERERERkWoygBHAy865dfXZoMMEy8DA4O/q6BXOuRIzy6F6UFpr+Yhlg4B5zrnPzex64I/ATcG6B51zz5hZJnAHcK1zbkUj6n0uUGM8tYiIiIiIiMTd+cAD9SnYkYLljOBvSS3riyPK7Kh8cVQZnHM3mNk/8BPOr4yYbP6vwFrgLjMbAtyNb7VeCfyuHnPt/Qt4I2rZFOBvt99+O7vssssONm9ZBQUFLFq0iNGjR9OlS5cdbyAilXT+iDSezh+RxtG5I+J99913XHHFFeBzT9VLRwqWw92VU2tZnw6sr6V8UYyykWUAcM5tAjaFH5vZAcDPgb2DRa8AK4CjgeOB181sjHNuZW2Vds6tAlZFLjMzAPbaay/23nvvWJu1mi1btpCYmMj+++9PVlZWa1dHpF3R+SPSeDp/RBpH546I17179/Ddeg9zbfMJvhog3NIbPf4XM0vDjwNeXZ/y1N1FO7zPVOB+4J4gKdiewHjgMufcV8A1QA4+6ZiIiIiIiIi0Ix0mWHbOrccHt7GaYvcCDPgiYln4/j4xyu8DbAcW1HHIq/DdtK8JHoeD7lVBfVxQn8H1qL6IiIiIiIi0IR0mWA7MAIab2QlRy68AyoGnIpb9F98Ef4mZVXZHD+ZZPgB42jlXGusgZjYW+B3wK+fc9mDx2uDvhKBMKjA6YrmIiIiIiIi0E21+zLKZnQEMDR72AVLM7OrgcZ5z7p6I4rcAJwKPmdkUYBl+PuWjgBsj52x2zuUEU0HdCbxnZo8BvYHLgQ3AtbXUx/DZ015yzr0YseozYBHwqJndAxwJdKd6gC4iIiIiIiLtQJsPlvFTKx0YtezG4O8KoDJYds7lmtl++PmPf4EPVhcDFzrn7o3esXPurmBKqf+HD5oLgf8BV0Zku452Pr71+KdR+yozs6OBfwJ/Dup2gnNuUf2fqoiIiIiIiLQFbT5Yds4d1MDy64CzG1D+ceDxBpS/D7ivlnXfA1Pruy8RERERab/KysrYvHkz27dvx6eraXvKysro3bs369evZ/Pmza1dHZG4MTNSU1Pp1q0bPXr0qJxRKJ7afLAsIiIiItLWOOdYtWoVJSUlmBmJiYmtXaWYEhMTyczMbLP1E2msiooKtm/fzvbt2ykoKGDAgAFxD5gVLIuIiIiINFBubi4lJSV07dqVgQMHkpDQNvPmlpeXs337drp27UpSkn76S8fhnKO4uJh169aRn59P165d6dGjR1yP0TbPahERERGRNmzbtm0A9OvXr80GyiIdmZmRnp5O//79AcjPz4/7MXRmi4iIiIg0UFlZGWZGcnJya1dFpFNLS0sjISGBkpKSuO9bwbKIiIiISAM550hISGiWpEIiUn9mhpk1S5I9BcsiIiIiIo2gQFmkbWiuc1HBsoiIiIiIiEgUBcsiIiIiIiIiURQsi4iIiIiItEMHHXQQw4YNa9U6nHXWWR12SIKCZRERERERqdV7772HmXHLLbfUWqZr164cdNBBLVcpaVEvvPAC119/fWtXo8UpWBYREREREZFavfDCC9xwww0x1z3wwAMUFRW1cI1aRlJrV0BERERERETap+Tk5A4737halkVEREREJO7MjLPOOqvG8ocffhgz47333qtcdv3112NmLFiwgN/+9rcMHDiQ1NRUJk2axKuvvlpt++XLl2NmXH/99Tz99NNMnjyZ9PR0Ro0axUMPPQTAypUrOfHEE8nKyqJbt26cdtppbN26tdp+FixYwEUXXcS4cePo1q0bGRkZTJkyhQceeKBGnRtSv9oUFxdz/fXXs/POO5ORkUH37t3ZeeedueSSS2qUfeuttzj88MPp2bMnaWlpTJw4kXvvvbdexwFYtGgRZ5xxBv379yclJYVhw4bxm9/8hoKCghpl169fzyWXXMKIESNITU2lb9++HHbYYfzvf/8DYNiwYTzyyCNA1ZzGke9fbWOWv/nmG37yk5/Qu3dvUlNTGTNmDH/84x8pKSmpVi4er21zUcuyiIiIiIjsUGFhITk5Oc16jJ///Oekpqbym9/8htLSUu68806OO+44Fi5cWCOR1csvv8x9993HhRdeSFZWFtOnT+ecc84hOTmZq6++mkMOOYSbb76ZL774gunTp5OWlsb06dMrt3/vvff46KOPOO644xgyZAjbt2/nmWee4fzzzycnJ4crr7yySfWLdvHFFzN9+nTOOOMMLrvsMkKhEEuWLKkMSsPuv/9+LrjgAvbaay+uuuoqunbtyv/+9z8uvPBClixZwl//+tc6j/PVV18xdepUevbsyS9/+UsGDhzIvHnzuPvuu/n44495//33K1uCly9fzr777suGDRv4+c9/zpQpUygoKODTTz/lrbfe4rDDDuPOO+/k9ttv58MPP+Sxxx6rPM7YsWNrrcOsWbM44IADSEhI4OKLL2bQoEG88cYbXHfddcycOZNXXnmFhITq7bZNeW2bi4JlEREREZE4+tmDn7Imt22M4XRAKBQiISGBQZnpPH7eXo3e14033siNN94Yv8rF0KdPH1566aXKlsqDDz6YPfbYg/vuu49p06ZVK7tgwQLmz5/P4MGDATjllFMYPHgwZ555JnfccQeXXnopABdccAG5ubk89thj3H333XTt2hWAM888kwsuuKDaPi+//HKmTp3KLbfcwq9//esa3YsbUr9ozz//PD/60Y949NFHay2zbt06LrnkEk4++WSeeOKJyuUXXnghl156KbfffjsXXHABI0eOrHUf55xzDtnZ2Xz55Zd069atcvnUqVM54YQTePzxxytb/C+66CLWrl3Lm2++yWGHHVZtP6FQCIDjjjuOF154gQ8//JDTTz+9zucYdskll1BUVMQXX3zBrrvuCviLBeeffz4PPPAATz75JKeddlq1bZry2jYXBcsiIiIiInG0JreI5ZsLW7saNTR1cp9zzz2XU045Jea6o48+uol79y699NJqXXp33313unXrxqJFi2qUPe644yoDZYDevXuz00478e2339YIgvfff3+ef/55li9fzvjx4wHIyMioXF9cXExBQQHOOQ4//HDef/99FixYwIQJExpdv2g9e/bkm2++4euvv66x37D//Oc/lJSUcPbZZ9doxT/66KO5++67efvtt2sNlr/++mvmzZvHtddeS0lJSbUuz/vttx9dunThzTff5KyzzmLLli28/vrrHHHEETUCZaBGy299bdq0iY8//pijjz66MlAOu+aaa3jggQd47rnnagTLTXltm4uCZRERERGROBqYmd7aVagU2bLc1HqNGjWKQw89NOa6xMTEJu07bMSIETWWZWVlsXnz5hrLhw8fXmNZZmYm/fv3JzU1tcZyoNp+tm/fXjnuedWqVTX2lZub26T6Rbvrrrs4/fTTmThxIsOHD+fggw/mqKOO4thjj60MTOfPnw/AEUccUet+NmzYUOu68PZ//OMf+eMf/1jn9osXL8Y5x6RJk3ZY94ZYunQpAOPGjauxbvDgwfTo0aOyTKSmvLbNRcGyiIiIiEgcNaWrc7yVl5ezfft2unbtSlJS2/jpX15eXuu62oJu51y9y9YVuEfu59RTT+WVV17h/PPP54ADDiArK4ukpCReffVV7rjjjspuyI2tX7Sjjz6a5cuX89prr/Hee+/xzjvvMH36dPbcc0/effdd0tPTK/fz0EMPMWjQoJj7iRVURtfjsssu48c//nHMMuELB/Wpc2M0dr9NeW2bS9s4Y0REREREpEPJyspiy5YtNZbHalVsaXl5ebzyyiucccYZNbJMv/XWW8123MzMTE477bTKLsg33HAD119/PU8++SRnn302O+20EwC9evWqtRW/LuHtExISdrj96NGjMTPmzJmzw/3GynZdm3AX8W+//bbGutWrV7N169Y6x1y3JZo6SkRERERE4m6nnXZi5syZFBZWjd/Ozc2tnN6pNYVbMaNbLdetW8eDDz4Y9+NVVFSQl5dXY3l4TG/4osJJJ51Eamoq119/fbXXLWzr1q01pl6KNHnyZCZMmMD999/P4sWLa6wvLy+vPFZWVhZHHnkkb775Zo2M3FD9tQknRYvVNT1anz592HfffXn11VdrBOI33XQTACeccMIO99MWqGVZRERERETi7le/+hWnn346U6dO5YwzziAvL48HHniAoUOHsn79+latW7du3Tj88MP597//TXp6OrvvvjsrVqzgvvvuY/jw4XEfJ7tt2zb69+/PMcccw+TJk+nXrx8rVqzg3nvvpWvXrpXB46BBg/jnP//Jeeedx9ixYznzzDMZOnQomzZt4uuvv+aFF17gu+++q3UqJTPj0UcfZerUqUyePJlzzjmHcePGUVhYyOLFi3nuueeYNm1aZTbse+65h3322Ycf/ehHlVNHFRUV8dlnnzFs2DD+/Oc/A7Dnnntyzz33cPHFF3PkkUeSnJzM1KlT6du3b8x63H333RxwwAEceOCBXHzxxQwcOJA333yTF198kSOOOIKTTz45rq9vc1GwLCIiIiIicfezn/2MtWvXcs8993DFFVcwYsQIrr32WhISEvjss89au3r8+9//5ve//z0vvfQSjzzyCKNHj+amm24iOTmZs88+O67HysjI4LLLLuOdd97hrbfeYvv27WRnZ3PEEUdw5ZVXVktWFu6Ofeutt3LfffeRl5dH7969GTNmDDfeeCPZ2dl1Hmvy5MnMnj2badOm8eKLL3LvvffSrVs3hg0bxllnncUhhxxSWXb48OF8+eWX3Hjjjbz66qs8+uijZGZmMmnSJM4///zKcqeeeipfffUVTz75JE899RShUIh333231mB511135dNPP+Xaa6/lvvvuY9u2bQwbNozrr7+e3//+943OtN3SrDUHTEtsZrY38Mknn3zC3nvv3drVqWbLli18+OGH7L///mRlZbV2dUTaFZ0/Io2n80famvB0NqNHj27lmtStLSb4Eom3+pyPM2fOZJ999gHYxzk3sz77bR8hvYiIiIiIiEgLUrAsIiIiIiIiEkXBsoiIiIiIiEgUBcsiIiIiIiIiURQsi4iIiIiIiERRsCwiIiIiIiISRcGyiIiIiIiISBQFyyIiIiIiIiJRFCyLiIiIiIiIRFGwLCIiIiIiIhJFwbKIiIiIiIhIFAXLIiIiIiIiIlEULIuIiIiISLu2fPlyzIzrr7++tavSIt577z3MjIcffrjV6tAZXnMFyyIiIiIiUqtwYBZ569q1K7vuuit33HEH5eXlrV1FaSZ5eXlcf/31vPfee61dlVaR1NoVEBERERGRtu/kk0/mqKOOwjnH+vXrefTRR7niiiuYP38+999/f2tXT5pBXl4eN9xwAwAHHXRQtXVDhw6lqKiIpKSOG1J23GcmIiIiIiJxM3nyZE4//fTKxxdddBFjx47lwQcf5KabbqJPnz6tWDtpaWZGWlpaa1ejWakbtoiIiIiINFiXLl3Yc889cc6xZMmSyuWhUIibbrqJAw44gOzsbFJSUhgyZAgXXnghmzdvrraPyHGvL7zwAlOmTCEtLY3+/fvzm9/8JmYX75dffpnddtutstwll1xCQUFBzDoWFhZy9dVXM3r0aFJTU+nTpw8nn3wyCxcurLUeTz/9NJMnTyY9PZ1Ro0bx0EMPAbBy5UpOPPFEsrKy6NatG6eddhpbt26t12v1ySef8KMf/Yjs7GxSU1PJzs7msMMO48MPP6xWbuvWrfzud79j1KhRlfU99dRTWbp0ab2O45zjn//8J1OmTCEjI4Nu3bpx8MEH8+6778Ys/+yzz3LwwQfTs2dPMjIyGDNmDJdccgmlpaU8/PDDDB8+HIAbbrihsgt+uIW5tjHLFRUV3HrrrYwfP560tDQyMzM56qij+OKLL2oc38w466yz+Oijj9h///3JyMigd+/enHfeeWzfvr1ez7k5qWVZREREREQaJRwk9+rVq3JZaWkpt956KyeddBLHH388GRkZfP755/zrX//io48+4quvviIlJaXafl599VX+8Y9/cMEFF3Deeefx3//+l1tvvZXMzEz+8Ic/VJZ7/vnnOfHEExk4cCBXXXUVXbp0YcaMGXz88cc16lZeXs6RRx7JBx98wPHHH89ll13GihUr+Pvf/84bb7zBzJkzGTt2bLVtXn75Ze677z4uvPBCsrKymD59Oueccw7JyclcffXVHHLIIdx888188cUXTJ8+nbS0NKZPn17na/T9999z2GGHkZ2dzSWXXEJ2djYbN25k5syZzJ49m/333x/wgfI+++zDypUrOeeccxg3bhzr1q3jn//8J3vuuSdffvklQ4cOrfNYZ5xxBk888QQnnngiZ599NiUlJTz++OMcdthhPPfccxxzzDGVZa+66ipuvvlmxo0bxxVXXEF2djZLlizh2Wef5Y9//CMHHHAAd9xxB5dffjnHH388J5xwAgD9+vWrsw5nnnkmM2bMYOrUqZx//vls3ryZf/zjH+y33368/vrrHHzwwdXKz5kzh2OPPZZzzjmH008/nffee49//etfJCQktHr3fgXLIiIiIiLx9MgxsHVVa9cCgEQH3VyIBEuAnoPh5y82el+FhYXk5ORUjlm+9957mT17NrvvvjujR4+uLJeamsratWtJT0+vXPbLX/6SffbZh/POO48XXniBn/70p9X2/e233/Ltt98ybNgwAC644AImTJjA3/72t8pguaKigksvvZRu3brx+eefk52dDcDFF1/MvvvuW6O+Dz/8MB988AGXXXYZd9xxR+XyY489lv32249LL72UN998s9o2CxYsYP78+QwePBiAU045hcGDB3PmmWdyxx13cOmll1bWLzc3l8cee4y7776brl271vq6vfHGGxQWFvLkk0+y++6711rummuuYenSpXz66adMmjSpcvlZZ53FhAkTuO666+rMfv3cc8/x+OOPc++99/LLX/6ycvmll17KXnvtxaWXXsrRRx+NmfH5559z8803M3XqVF599VVSU1Mry99yyy0A9OzZk+OOO47LL7+ciRMnVuuCX5u33nqLGTNmcMIJJ/DMM8+QkOA7Mp955pmMHz+eCy+8kPnz52NmldvMmzePTz75hL322gvwn5X8/Hweeughbr/99jpf2+ambtgiIiIiIvG0dRVsWdombpa7lMS85Vju0iYH8DfeeCN9+vShb9++TJw4kX/84x8cd9xxvPhi9QDczCoD5YqKCvLy8sjJyWHq1KkAfPbZZzX2fdxxx1UGyuF9HHzwwaxfv76yO+6sWbNYtWoVZ511VmWgDD44v+KKK2rs8/nnn8fMuPrqq6st33fffZk6dSpvv/02+fn5NeoRDpQBevfuzU477URCQgIXXHBBtbL7778/5eXlLF++vLaXDPBBJ8ALL7xAcXFxzDLOOWbMmMG+++7LwIEDycnJqbx16dKFvfbaq0ZgH+3xxx+nS5cuHHfccdW2z8vL4+ijj2b58uUsWrSosizATTfdVC1QBiq7WzfG888/D/hW63CgDDBy5EhOO+00vv/+e7799ttq2+y9996VgXLY1KlT6/XaNje1LIuIiIiIxFOPwTsu00Kcg1DQsmxNrNe5557LKaecQnl5Od988w233HILGzZsqNaCHPb0009z2223MXv2bMrKyqqty83NrVF+xIgRNZaFu3Zv3ryZrl27Vnb5ju46DbDLLrvUWLZ06VL69etXrYt42IQJE3jnnXdYvnw5EydOrFweHqMbKTMzk/79+9cIKjMzMyvrV5dTTjmFGTNmcPPNN3P77bez1157cfjhh3PKKadUHm/Tpk1s3ryZt99+u9ZEaZHBZyzz58+noKCg2oWEaBs2bGCnnXaqDJojn3s8hMdWx3o/JkyYUFlm/Pjxlct39N63JgXLIiIiIiLx1ISuzvFWUV7O9u3b6dq1a5On+Bk1ahSHHnooAD/84Q/Zb7/92HfffbnwwguZMWNGZblnn32Wk08+mT322IO77rqLwYMHk5aWRkVFBT/84Q8JhUI19p2YmFjrcZ1z1R7Xt9Uzerv6rKutHg2pX7SUlBRef/11vvzyS9544w0++OADbrjhBm644QYeeughTj311Mp9HHzwwdXGaDeEc46srCyeeuqpWsuEg1TnXKNbj3dUh9r229DXvK5tWoqCZRERERERabC99tqL008/nUcffZRLLrmksivtv//9b9LS0nj33XfJyMioLL9gwYImHW/kyJEAfPfddzXWxVo2cuRIXnvtNTZv3lyjdfnbb78lISGhWtfv5rbbbrux2267cdVVV7Fu3TqmTJnC73//e0499VT69OlDz5492bp1a+UFiYbaaaed+P7779l9993p0aNHnWXHjBnD66+/zty5c9l7771rLdfQgHrkyJE45/juu+/Yddddq60Ld78Ov4/tgcYsi4iIiIhIo1xzzTUkJiZyzTXXVC5LTEzEzKq1IDvn+NOf/tSkY+26664MHjyYRx55hPXr11cuLykp4fbbb69R/vjjj8c5x7Rp06otnzlzJu+88w6HHnoo3bt3b1Kd6iMnJ6fGsv79+9O/f3+2bNkC+C7WP/vZz5g1axZPPvlkzP1s3LixzuOcccYZOOe48sorY7bIbtiwofL+aaedBsDVV19NSUlJjbLh7cPJtWJ1nY/l+OOPB2DatGnV6rBs2TJmzJjBmDFjYnbRbqvUsiwiIiIiIo0yatQoTjnlFB5//HE+/PBD9t9/f0488USeffZZpk6dyplnnklZWRkvvPAChYWFTTpWYmIid911FyeeeCJ77LEH559/Pl26dOHxxx+PGRyeddZZPPbYY9x2220sX76cqVOnVk4d1b17d+68884m1ae+/vSnP/Hmm29y1FFHVY5Rfu2115g1axYXX3xxZbmbbrqJjz/+mNNOO43nn3+evffem5SUFFasWMGrr77KlClT6syGHZ4u6p///Cdz5szh6KOPpnfv3qxevZqZM2eyePHiyjHFe+yxB7/73e/485//zJQpUzj55JPJzs5m2bJl/Oc//+Hzzz+nZ8+e9OrVi5EjR/Lkk08yatSoygRv4WRt0Q499FBOPfVUnnjiCQ477DCOPfbYyqmjKioq+Oc//9ks3b+bi4JlERERERFptKuuuoonnniCa6+9lnfffZdTTjmFbdu2cccdd/DrX/+azMxMjj76aG655ZaYybYa4vjjj+e///0v1113HX/605/o2bMnJ510EhdccEG1pFEASUlJvPbaa9x000089dRTvPjii3Tv3p0f//jH/PGPf2TMmDFNqkt9HXfccaxbt46nn36aDRs2kJaWxqhRo/jHP/7B+eefX1muR48efPzxx9x22208/fTTvPjiiyQlJTFo0CD2228/zjvvvB0ea/r06Rx88MHcf//9TJs2jdLSUrKzs9l1111rtLDfcsstTJo0iXvuuYe//OUvhEIhBg8ezI9+9KNq3ecfe+wxLr/8cn77299SXFzMgQceWGuwHC6/66678tBDD/HrX/+a9PR09t13X6677jr22GOPRryCrcdae9C01GRmewOffPLJJ3WOIWgNW7ZsqbxqmJWV1drVEWlXdP6INJ7OH2lrwtmEI+cXbovK45jgS6Stqs/5OHPmTPbZZx+AfZxzM+uzX41ZFhEREREREYmiYFlEREREREQkioJlERERERERkSgKlkVERERERESiKFgWERERERERiaJgWURERESkETSrjEjb0FznooJlEREREZEGSkhIIBQKKWAWaWWhUIhQKISZxX3fCpZFRERERBooNTUV5xxr165VwCzSCpxzlJaWsmbNGpxzdO3aNe7H0MzkIiIiIiINlJ2dTWlpKfn5+Wzbto2EhIRmadlqqlAoREVFBYmJiSQkqJ1MOgbnXLWeHampqfTq1Svux1GwLCIiIiLSQElJSQwZMoT169dTUlJCKBRq7SrFVFFRQW5uLpmZmQqWpcMwM5KTk0lKSqJbt25kZmY2y8UqBcsiIiIiIo2QlJTEoEGDWrsaddqyZQuLFi1i7NixZGVltXZ1RNoVXV4SERERERERiaJgWURERERERCSKgmURERERERGRKB0uWDazfmZ2r5mtMrNSM1tpZneZWc9ayk43sw1mVmxm88zsFzHKZZjZ38xsnZnlmNmjZlZj0IeZHWdmBWY2vJmenoiIiIiIiLSADpXgy8z6Ap8BA4D7gG+A8cCFwAFmtq9zrjAo2xP4CBgI3AksA44F7jezAc65GyJ2PQ04G/gzUAj8DngQOCHi2N2Be4AbnHPLmu9ZioiIiIiISHPrUMEycCUwFDjNOfdEeKGZfQLMAK4A/hQs/h0wCviJc+65YNkDZvYicJWZPRoR9J4E3O6cuzHYXy4+qE5zzhUHZaYBm4Hbm+/piYiIiIiISEvoaN2wDwaKgCejlj8FFONbh8N+BiyLCJTDbgeSgZMjlnUBciIebwYSgTQAM9sLOB843zlX3sTnICIiIiIiIq2so7UspwHFzjkXudA5FzKzImCEmfXGP+/B+NbmaDMBB+wRsexj4EIz+xgfjP8O+M45l2dmycADwL3Ouc8aWmEzGwxET9A3HiA/P58tW7Y0dJfNKj8/v9pfEak/nT8ijafzR6RxdO6IeI05BzpasPwdMMbMJjvn5oQXmtlkIDN4OASw4P7q6B0450rMLIfqAeylwIvAl8HjNcBPgvu/DfZ9VSPrfC5wXawVc+bMobi4ONaqVjd37tzWroJIu6XzR6TxdP6INI7OHensFixY0OBtOlqwfBc+SdfTZnYZPsHXOHwCrzJ89+oMqoLlklr2UxyUA8A5t8jMJgA7B/v4LgiqRwFX48dI55vZRcBFQDd8cP1b51zRDur8L+CNqGXjgfsnT57M7rvvvsMn3ZLy8/OZO3cukyZNonv37q1dHZF2ReePSOPp/BFpHJ07Il5aWlqDt+lQwbJz7n0z+xk+OH4lWBwCpgPfAscD+fiAFyC1ll2lA+uj9l2OD74j3Qe84Zx73sxOBm7DtxSvAh7Gj2u+aAd1XhWUr2TmY/nu3buTlVVjhqo2oS3XTaSt0/kj0ng6f0QaR+eOdHaNuVjUoYJlAOfck2b2H3zrbDdgoXNug5l9DpQDi4HwKxU9VhgzSwN6AR/WdRwzOws/rnlssOhc4Fnn3Ixg/TTgb2b2K+dcqMlPTERERERERFpMhwuWobIVeE74sZllAz8A3g/mWS40s9XA3jE23wvfTfuL2vZvZn2AW4GrnHPhcc+DgK8iiq3CJxzrDWxs9JMRERERERGRFtfRpo6qwcwSgLvxXaJvilg1AxhuZidEbXIFvgX6qTp2ewewDLgnYtlaYELE4wlAKdWnnBIREREREZF2oEO1LJtZV+Bz4Hl8MNsDOBWYgm8Ffjei+C3AicBjZjYlKH8scBRwo3NuaS3HOAw/B/MeUd2r/w1MN7M78Vm2rwFmqAu2iIiIiIhI+9OhgmV8S+484DSgP1CI7079Q+dctYzTzrlcM9sPuBn4BX4c82LgQufcvbF2bmbpwL3AXc652VGrHwmOeSHQBXgBP+WUiIiIiIiItDMdKlh2zpUCpzSg/Drg7AaULwJG1rLOAdOCm4iIiIiIiLRjHX7MsoiIiIiIiEhDKVgWERERERERiaJgWURERERERCSKgmURERERERGRKAqWRURERERERKIoWBYRERERERGJomBZREREREREJIqCZREREREREZEoCpZFREREREREoihYFhEREREREYmiYFlEREREREQkioJlERERERERkSgKlkVERERERESiKFgWERERERERiaJgWURERERERCSKgmURERERERGRKAqWRURERERERKIoWBYRERERERGJomBZREREREREJIqCZREREREREZEoCpZFREREREREoihYFhEREREREYmiYFlEREREREQkioJlERERERERkSgKlkVERERERESiKFgWERERERERiaJgWURERERERCSKgmURERERERGRKAqWRURERERERKIoWBYRERERERGJomBZREREREREJIqCZREREREREZEoCpZFREREREREoihYFhEREREREYmiYFlEREREREQkioJlERERERERkSgKlkVERERERESiKFgWERERERERiaJgWURERERERCSKgmURERERERGRKAqWRURERERERKIoWBYRERERERGJomBZREREREREJIqCZREREREREZEoCpZFREREREREoihYFhEREREREYmiYFlEREREREQkioJlERERERERkSgKlkVERERERESiKFgWERERERERiaJgWURERERERCSKgmURERERERGRKAqWRURERERERKIoWBYRERERERGJomBZREREREREJIqCZREREREREZEoCpZFREREREREoihYFhEREREREYmiYFlEREREREQkioJlERERERERkSgKlkVERERERESiKFgWERERERERiaJgWURERERERCSKgmURERERERGRKAqWRURERERERKJ0uGDZzLqa2TVm9o2ZbTezTWb2kZmdHqNsPzObbmYbzKzYzOaZ2S9ilMsws7+Z2TozyzGzR80sK0a548yswMyGN9fzExERERERkeaX1NoViCczSwDeAPYCHgbuBroAZwCPmdlOzrlrg7I9gY+AgcCdwDLgWOB+MxvgnLshYtfTgLOBPwOFwO+AB4ETIo7dHbgHuME5t6zZnqSIiIiIiIg0uw4VLAN7AvsAdzrnLg8vNLN7gaXA+cC1weLfAaOAnzjnnguWPWBmLwJXmdmjEUHvScDtzrkbg/3l4oPqNOdccVBmGrAZuL35np6IiIiIiIi0hI7WDbtH8Hdt5ELnXBGQi28VDvsZsCwiUA67HUgGTo5Y1gXIiXi8GUgE0gDMbC98IH6+c668ic9BREREREREWllHa1n+HMgHfmtmy4FPga74QHYMvis1ZpYNDAZmxNjHTMABe0Qs+xi40Mw+BorwrdLfOefyzCwZeAC41zn3WUMrbGaDgUFRi8cD5Ofns2XLlobuslnl5+dX+ysi9afzR6TxdP6INI7OHRGvMedAhwqWnXNbzOw4fPD6dMSqPOBY59zLweOBwd/VMfZRYmY5VA9gLwVeBL4MHq8BfhLc/y2QCVzVyGqfC1wXa8WcOXMoLi6OtarVzZ07t7WrINJu6fwRaTydPyKNo3NHOrsFCxY0eJsOFSwHcoHZwPPAJ0BP4ELgaTP7iXPuNSAjKFtSyz6KI8rgnFtkZhOAnfFdtL8LgupRwNXAac65fDO7CLgI6IYPrn8bdAGvy7/wSckijQfunzx5Mrvvvnt9nnOLyc/PZ+7cuUyaNInu3bu3dnVE2hWdPyKNp/NHpHF07oh4aWlpDd6mQwXLQUA7E7jMOXdfxPIZwBxgupkNo2rscmotu0oH1kcuCMYifxNV7j7gDefc82Z2MnAbvqV4FT4bdyI+eK6Vc25VUD7yeQDQvXt3srJqzFDVJrTluom0dTp/RBpP549I4+jckc6uMReLOlqCr8vxSbeeiVzonCsBXgCy8a3Da4JV0WOFMbM0oBcxumhHlTsLP675V8Gic4FnnXMznHMfEkw3FUxnJSIiIiIiIu1IRwvkwmORk2OsCy9Lcs6txwfDe8cotxdgwBe1HcTM+gC3Alc558JB9SCqtxCvwgfuvetdexEREREREWkTOlqw/F3w96zIhWbWDT9XcgHwbbB4BjDczE6I2scVQDnwVB3HuQNYBtwTsWwtMCHi8QSglOpTTomIiIiIiEg70KHGLAN3AmcC04Lxyx/hM1WfCwwBfu2cC6eXvgU4EXjMzKbgg99jgaOAG51zS2MdwMwOw8/BvIdzLhSx6t/4MdF34lutrwFmRJURERERERGRdqBDBcvOuRVmNgm4EjgEOAGowCf3uso591RE2Vwz2w+4GfgF0B1YDFzonLs31v7NLB24F7jLOTc7avUjQH985u0u+DHSl8btyYmIiIiIiEiL6VDBMkAwhvjiepZdB5zdgH0XASNrWefwSb2m1Xd/IiIiIiIi0jZ1tDHLIiIiIiIiIk2mYFlEREREREQkioJlERERERERkSgKlkVERERERESiKFgWERERERERiaJgWURERERERCSKgmURERERERGRKAqWRURERERERKIoWBYRERERERGJomBZREREREREJIqCZREREREREZEoCpZFREREREREoihYFhEREREREYmiYFlEREREREQkioJlERERERERkSgKlkVERERERESiKFgWERERERERiaJgWURERERERCSKgmURERERERGRKAqWRURERERERKIoWBYRERERERGJomBZREREREREJIqCZREREREREZEoCpZFREREREREoihYFhEREREREYmiYFlEREREREQkioJlERERERERkSgKlkVERERERESiKFgWERERERERiaJgWURERERERCSKgmURERERERGRKAqWRURERERERKIoWBYRERERERGJomBZREREREREJIqCZREREREREZEoCpZFREREREREoihYFhEREREREYmiYFlEREREREQkioJlERERERERkSgKlkVERERERESiKFgWERERERERiaJgWURERERERCSKgmURERERERGRKAqWRURERERERKIoWBYRERERERGJomBZREREREREJIqCZREREREREZEoCpZFREREREREoihYFhEREREREYmiYFlEREREREQkioJlERERERERkSgKlkVERERERESiKFgWERERERERiaJgWURERERERCSKgmURERERERGRKAqWRURERERERKIoWBYRERERERGJomBZREREREREJIqCZREREREREZEoCpZFREREREREoihYFhEREREREYmiYFlEREREREQkioJlERERERERkSgKlkVERERERESidKhg2cyuNzNXx60sqnw/M5tuZhvMrNjM5pnZL2LsN8PM/mZm68wsx8weNbOsGOWOM7MCMxvenM9TREREREREmldSa1cgzp4DFsdYPhH4DfBSeIGZ9QQ+AgYCdwLLgGOB+81sgHPuhojtpwFnA38GCoHfAQ8CJ0TsrztwD3CDc25Z3J6RiIiIiIiItLgOFSw75+YB86KXm9l9wd1/RSz+HTAK+Ilz7rlg2QNm9iJwlZk9GhH0ngTc7py7MdhfLj6oTnPOFQdlpgGbgdvj+qRERERERESkxXWobtixmFkGcAqwBng9YtXPgGURgXLY7UAycHLEsi5ATsTjzUAikBYcYy/gfOB851x5XJ+AiIiIiIiItLgO1bJci58C3YG7nXMVAGaWDQwGZsQoPxNwwB4Ryz4GLjSzj4EifKv0d865PDNLBh4A7nXOfdbQypnZYGBQ1OLxAPn5+WzZsqWhu2xW+fn51f6KSP3p/BFpPJ0/Io2jc0fEa8w50BmC5XPxwe/0iGUDg7+rows750rMLIfqAeylwIvAl8HjNcBPgvu/BTKBq5pQv+tirZgzZw7FxcWxVrW6uXPntnYVRNotnT8ijafzR6RxdO5IZ7dgwYIGb9Ohg2UzGwPsB7wdlXQrI/hbUsumxRFlcM4tMrMJwM74LtrfBUH1KOBq4DTnXL6ZXQRcBHTDB9e/dc4V7aCa/wLeiFo2Hrh/8uTJ7L777jt8ni0pPz+fuXPnMmnSJLp3797a1RFpV3T+iDSezh+RxtG5I+KlpaU1eJsOHSzjW23BZ66OVBj8Ta1lu3RgfeSCYCzyN1Hl7gPecM49b2YnA7cFx1wFPIwf13xRXRV0zq0KylcyMwC6d+9OVlaNGarahLZcN5G2TuePSOPp/BFpHJ070tk15mJRh03wZWZJwJnAFuD5qNVrgr/RY4UxszSgFzG6aEeVOws/rvlXwaJzgWedczOccx8STDdlZh32NRYREREREemoOnIgdzTQD3jMOVetu7Vzbj0+GN47xnZ7AQZ8UduOzawPcCtwlXMuHFQPonoL8Sp8tuzejX0CIiIiIiIi0jo6crAc7oL9r1rWzwCGm9kJUcuvAMqBp+rY9x3AMuCeiGVrgQkRjycApVSfckpERERERETagQ45ZtnMBgA/BD53zn1dS7FbgBOBx8xsCj74PRY4CrjRObe0ln0fhp+DeQ/nXChi1b+B6WZ2J77V+hpgRlQZERERERERaQc6ZLAMnIVPrhWd2KuScy7XzPYDbgZ+gZ+LeTFwoXPu3ljbmFk6cC9wl3NudtTqR4D+wIVAF+AF/JRTIiIiIiIi0s50yGDZOXczPgjeUbl1wNkN2G8RMLKWdQ6f1GtaffcnIiIiIiIibVNHHrMsIiIiIiIi0igKlkVERERERESiKFgWERERERERiaJgWURERERERCSKgmURERERERGRKAqWRURERERERKIoWBYRERERERGJomBZREREREREJIqCZREREREREZEoCpZFREREREREoihYFhEREREREYmiYFlEREREREQkioJlERERERERkSgKlkVERERERESiKFgWERERERERiaJgWUREREREpKMLlbd2DdqdpNaugIiIiIiIiDSj8gIo2QKJ6ZCSCQmJrV2jdkHBsoiIiIiISEdWtj0IlpMhVAYpPSEpvbVr1eYpWBYREREREemoKoqhogASksCSoXgjhEp8wJzcA8xau4ZtloJlERERERGRjqq8AMoKIbkrJKT4W9lWCJX6W0omJCS3di3bJCX4EhERERER6YhC5VC+HXA+SAYfGKf0glAFFG2EovW+m7bUoJZlERERERGRjqi8AMoLITGj+nIzSOkBFUVQmhu0MpdAck8l/4qgYFlERERERKSjcSHfqhwqhZTuscskpvsW59KtPliuKIXUTEhMa9m6tlHqhi0iIiIiItLRlBf6W0J63Um8LBFSs6qSfxWth9I8cK7FqtpWqWVZRERERESkowl3wU7Nql/5pC5+PHNZvpJ/BdSyLCIiIiIi0pFUFPsu2AnJvuW4vhJSopJ/bejUyb/UsiwiIiIiItKRlBdAeZGfLqqhqiX/2uLHMnfS5F8KlkVERERERDqKUFnN6aIao1ryr9JOmfxL3bBFREREREQ6ivBY5aSMHZfdkXDyLxKhZBMUb/DBcydJ/qWWZRERERERkY7AhXywHCqFpFqmi2qM5K4QClqZK4I5mTtB8i+1LIuIiIiIiHQE5YU+WN7RdFGNUZn8qyyYYqrjJ/9Sy7KIiIiIiEhHEE7sVd/pohrKDFJ6Bsm/NoOLaGW2jtcOq2BZRERERESkvWvsdFGNEZn8q6Kkwyb/6njhv4iIiIiISGdTtt23KscjsVd9dILkX2pZFhERERERac9CZVBR4O83ZbqoxoiV/Cu1T/zHTLcCtSyLiIiIiIi0Z5XTRaW3zvETUiAlywfKZfm+S3gHoGBZRERERESkvYqcLiqhFccMWwIkpLbe8ZuBgmUREREREZH2qjmni+rkFCyLiIiIiIi0V+UFvttzSyX26kQULIuIiIiIiLRH5UV+uihL6pDzHLc2vaIiIiIiIiLtUXlBMF1Ul9auSYekYFlERERERKS9qTZdVHLr1qWDUrAsIiIiIiLS3pQX+FtrTRfVCShYFhERERERaU8qp4sqb93pojo4BcsiIiIiIiLtSeV0UWmaLqoZKVgWERERERFpL5yDsu2aLqoFKFgWERERERFpLyqKfWIvS9Z0Uc1Mr66IiIiIiEh7UTldlFqVm5uCZRERERERkfYgVAbl2/19TRfV7BQsi4iIiIiItAflBVBRqOmiWoiCZRERERERkbZO00W1OAXLIiIiIiIibV15gaaLamEKlkVERERERNoy56CsACqU2KslKVgWERERERFpyyqni0rRdFEtSK+0iIiIiIhIW1ZeAOWFalVuYQqWRURERERE2qrK6aJM00W1sKR47cjMxgIHA+OAvoADNgHfAO87576L17FEREREREQ6hfLtmi6qlTQpWDazVOAc4EJ8kFxbWjZnZt8B/wAecs4VN+W4IiIiIiIiHZ4L+cReoXJI6tHatel0Gt0N28xOBb4H7gHygD8ABwGDgQygS3D/YOAqIDco+32wrYiIiIiIiNSmvMC3Kiema7qoVtCUluXpwP3AHc655bWUWRPc3gduMbNhwOXAg8ATTTi2iIiIiIhIx+UclG3300Wl9Grt2nRKTQmWRzrn1jZkgyCovtTMbmnCcUVERERERDq2imLfqqzpolpNo1/1hgbKUduua+y2IiIiIiIiHZ6mi2p1ukQhIiIiIiLSllSUarqoNiBuU0cBmNkQ4JfAaKAXNbNjO+fcIfE8poiIiIiISIdSEST2Uqtyq4rnPMtHAs8DKcA2YEu89i0iIiIiItIphCr8dFEVZZDcs7Vr06nFsxv2NCAH2MM518M5NzzWLY7Hq5WZ9TCzaWb2vZkVm9kWM/vEzI6PKtfPzKab2Yag3Dwz+0WM/WWY2d/MbJ2Z5ZjZo2aWFaPccWZWYGYt8jxFRERERKSDqShUq3IbEc9u2DsDVzvnvozjPhvMzAYD7wJZwEPAd/h5n3cGhkSU6wl8BAwE7gSWAccC95vZAOfcDRG7nQacDfwZKAR+h5/+6oSI/XXHzyN9g3NuWfM8OxERERER6bA0XVSbEs9gOQcojeP+GusxoAswyTm3qo5yvwNGAT9xzj0XLHvAzF4ErjKzRyOC3pOA251zNwKYWS4+qE5zzhUHZaYBm4Hb4/x8RERERESkM9B0UW1KPN+BGUS0tLYGM9sfOBD4s3NulZklmVmXWor/DFgWESiH3Q4kAydHLOuCvxgQthlIBNKC4+4FnA+c75wrb/ozERERERGRTqd8u6aLakPi2bL8L+AAM/svcBe+W3NFdCHn3Mo4HjPaj4K/S83sOeBoIMnMVgC3OufuATCzbGAwPsCPNhNwwB4Ryz4GLjSzj4EifKv0d865PDNLBh4A7nXOfdbQCgfdxgdFLR4PkJ+fz5YtbStPWn5+frW/IlJ/On9EGq+jnD/TXp3PvNV5NZZPHNSTK380tuUrJB1eRzl3OoVQGZTkQHkJJJcAJa1do4arKAIzKM6DxKLWrk01jTkH4hksz8cHmQYcVUe5xDgeM9rOwd8H8cH6uUGdLgL+ZmaZQVfqgUG51dE7cM6VmFkO1QPYS4EXgfB47DXAT4L7vwUygasaWedzgetirZgzZw7FxcWxVrW6uXPntnYVRNotnT8ijdfez5/9usHEkfBNrrFLT0fP1PCaHD788MPWrJp0cO393Ol81rR2BZqo7aVwWrBgQYO3iWew/Ed8YNqaugV/C4ADnHMlAGb2FD7R15Vmdg8+4RfUfrmmOKIMzrlFZjYBH4wn41uVS8xsFHA1cJpzLt/MLsIH5t3wwfVvnXM7uqTyL+CNqGXjgfsnT57M7rvvvsMn3ZLy8/OZO3cukyZNonv37q1dHZF2ReePSON1lPPnqxW5/O4/8ymuMFISHAOCXxtXHTWWKUMyW7dy0iF1lHOnwwuFoGQTlOVDSjv+Lgi3LKf2gcTUHZdvQWlpaQ3eJm7BsnPu+njtqwnCgemMcKAM4JwrNbPHgWuBPYFNwara3sF0YH3kgmAs8jdR5e4D3nDOPW9mJwO34VuKVwEP41vRL6qrwkESsmqJyMwMgO7du5OVVWOGqjahLddNpK3T+SPSeO39/Nm/a3dKnvKtG6UhY/l2mDS4J4dOGlH5/1+kObT3c6fDK9sGRQlAFiTVlnKpHSg3Hyyn94Sk9NauTTWNuVjU0VKshbtVr4uxLrwsi6p+DdFjhTGzNKAXMbpoR5U7Cz+u+VfBonOBZ51zM5xzHxJMN2WmNHYiIiLifbM2v0Y3vMsOHa1AWaQzq5wuqhgS21aA2dnFsxs2AGaWiO+unEmMYNw590G8jxnhU+ACfPKuaOE5ljc459ab2Wpg7xjl9sKPu/6itoOYWR/gVuAq51w4qB4EfBVRbBU+W3ZvYGNDnoSIiIh0TLNW5lZ7nJxgHDi6dyvVRkTahIqiZpsu6rwnl/Dxsm01lu87vDsPnjIirsfqiOL6bpjZ7/BTLM0D3gfejXFrTv8F8oEzzaxHRL26AT8HcvHZrsFnwh5uZtHTXV0BlANP1XGcO/Cj1u+JWLYWmBDxeAJ+3unIKadERESkE5u1Iq/a47KQ44tleTHLikgnUV4QTBcV/+7XeUUVFJW5Gre8Is12Wx9xC5bN7Dx81+M5+KRXBtwJ/BXYgs8kfU68jheLcy4PuBzIBj43s9+Y2a+Bz4H+wGXOucKg+C3AUuAxM7vJzM4zs5fw001Nc84tjXUMMzsMPwfz+c65UMSqfwM/MrM7g2Negx87HYq1HxEREelcnHOVLcuRna7/88Xa1qmQiLS+ilIfLJtBQnw7/TrnmDQg9nzNF+/XL67H6qji+Y5cAHzqnDvYzHoBNwGvOOfeMbO78EF0c04bBYBzbrqZbcLPhXwd/v/RV8AVzrnXIsrlmtl+wM3AL4DuwGLgQufcvbH2bWbpwL3AXc652VGrH8EH5BcCXYAX8FNOiYiIiLAmr4iN23z+0QNHZjN7zWa2Fpfx1vfrKK/YhaREpTkR6XRCJc0yVnlrcTlXv7KKl77Nq7FufHY6B41SZvT6iGewPBbfogxVU0glATjn1pnZ/fjgcXocjxmTc+4l4KV6lFsHnN2A/RYBI2tZ5/At69Pquz8RERHpPL5aUTVeedLALPr3SuGJz1eSW1TK+ws2c8i4Pq1YOxFpFaFSCJXFtQv2Fyu3c9nzK1iztRTwLYeRiQWH9ExtvqSCq2fDG9fDsX+HEQc3zzFaUDwvYVYA24P7BcHfyPz0y4HRcTyeiIiISLsxe2Ve5f1dh2RyzKQBlY+f+0pdsUU6HeegogRcCKzpHXDLQ47b31vHyY8sqgyU+2Qkc9ePR7JLv6qW6/eW5DfPmGXn4O1bYOsaeOsG/7idi2ewvJIg43Qwx/EqYP+I9bvjxy6LiIiIdDrh8copiQnsOrw7ewzPom+3VADeW7ye4rKK1qyeiLQ0V+67YSckN3lXq3JL+OnDi7j7g/WEghj1wGE9eO7nO3PMlO5c/8NBdE/1oV9hWYi/vx/nyXq2bYBnzofNS/zjtbNh8VvxPUYriGew/AE+OVbYM8AvzWy6mT0MnAe8GsfjiYiIiLQLxWUVfLc2H4Cx/XrQrUsCiQlW2bpcUFrOG19rpkmRTiXcBTshpUm7eeHrLfzo/gXMWu0796YmGb/ffzAPnjacwX38qNs9hnblg0vG0TXFh3//nrWJLYVxaF0uzof3b4cHfgjLP6q+7r1p7b51OZ7B8l3AP80sLXh8HfAafsqmM4D/Ab+P4/FERERE2oV5q7dSHjT3jM/OrFx+zOSqrtgvzFJXbJFOpaLEB8yNbFneVlLB5c8v57LnV7CtxE/As1OvdP590s5ccHBvkpOqj0vumZ7EuXv1BaCoPMTf3tvQ+LqXl8Dn0+H+w+GzB6C8uGaZNV+1+9bluAXLzrnvnXP3OeeKg8cFzrmj8eOWezjnjnTOqRu2iIiIdDqRyb0mDKgKlicM7MGwXj6xz8fLNrKtuKzF6yYirSRU6rtiNyJY/mpVAT+6bwHPf1313XLaxL488/Od2H10Wq3bnbNXH7qn+vHRT8zJYdP2Bn7nhCrg6+fggSPhvb9C8Va/3GoJKz+4tWH7b2OafY4C59xW59z2HZcUERER6ZjC45UB9hzZs/K+mVW2LpdWhHhpVhNaekSk/QgF45WtYZMTVYQcd3+wnp8+vJBVeT6JV6+MJO760Uj+dOxAenStO7zrkZbEL/b2rcvFDWlddg4WvQMPHwevXQXb1vnlicmw+zkw/EBITq95y8iqc7dtXXxnvhYRERGRapxzzA6C5f7d0xnar3qrzzGTBnD324sAeHHuWk7bZ1CL11FEWlh4vLLVf7zy6rxSLn9+OV+sKqhctt/Q7vzph0MY1q/+rdNn7dmHBz/dyNbiCp6am8OvDuxH3251bL96Frx/G6yZFbHQYPxxcNAfoPdO9T52e9PolmUzC5lZuZl/h4PHFTu4NUOOchEREZG2a9WWInK2+xagCf0zSYj69TWqb1fGDegOwBcrc8jZVtLSVRSRlhYq9WOW69kF+8VvcjnyvgWVgXJqovHr/QYx/bQRDQqUAbqlJvLLfXzrckmF4853a2ldzlkEz10MM35WPVAeeRCc/xb85KEOHShD01qWH8XPb10R9VhEREQkLs575As+XpzDkC4hLhoLp94/k5UFCew7qg8P/ny31q5evUR2wY5M7hXpmEkD+HZtPhXO8dyX6zj/4GEtVDtpaeHPdLT29JmWOAi3LCfX3bK8vaSC615fzbNzq1I/jcpK40+HD2OvndLr2LJuP9+jDw/M3ERuUTn/+TqH/zuoL/27B3XJXwcf3wPfvODngA4bMBkOuQZGHAJmsXbb4TQ6WHbOnVXXYxEREZGmyisso6gsREm5vx5fUu4oKguRV1jayjWrv8hgedehsYPloyYNYNprCwB45eu1CpY7sPBnuuby9vOZliZyIagoBkusM+ics6aAS59bzorcqs/GyeP7cOXhA+i5g7HJO9IlJZEL9+3LzW+tpbTCccc7G/jLEd3g0wdg1r+hIuLz2GsEHPwH2OUESEhs0nHbm2ZP8CUiIiLSWBcfPAqANYXw7tqqH5UXTx3VWlVqsHAm7NSkBH4wvFvMMgN7prP7MJ8IZ+7aXFbnFrVY/aRlhT/TNZa3o8+0NNEO5leuCDn+/uF6TnxoYWWgnJmexB1HjmTa8YOaHCiHnbF7H3pnJJFGCX2+m07ovsPhi+lVgXLXvvCjP8OFn8L4kzpdoAxK8CUiIiJt2IE79SY1KYGS8hAvrkxgUAZMGtyTg3bq09pVq5fC0nIWrN8GwNi+PemSXvuP3GMmD+CL5b6r5TOfreXyH45skTpKyzpoTB926d+N79Ztq1w2cVCPdvOZljgIlQbzK6fWWLV2aymXv7CCz1ZUTSa09+Du3PTDIYzo37j5mGuTnhjizpGfM2rhv8i2XAg3Jqd2g30uhr0uhtTucT1me9PUBF87SuilBF8iIiLSaJ8ty6Wk3HdZDTmjuAIuO3Q01k7Gy81dtZWKkO9CPqF/7C7YYT+e0J+kBP+8Xv1mbbPXTVqHmXHk+P7Vlo0f0LPdfKYlDipityy/+p1P4hUOlFMSjSv2HcQjp4+Ib6DsHCx8E6Yfw36LbvWBMlDsktk6+Vz4v6/gwCs7faAM8UnwFWlXYAKwEJgfLBsL7AR8DcxCREREpJ6e+HxltccpScnN2wK34hN4/gI4/l4Yuk+Tdxc5XnnCgLqD5awuKew3qjfvLdzEopx8Fq7fxk7ZsbttS/uWnlK9O+urX6/jyh+NoVtafFsOpQ1yDkIlnPfsJj5esZopLOAa+xdnlv2BDa5nZbERmWncdPgw9h7T+CRe1az6El69EnY7E757GdbNq1wVIoGnyg/krvIT2LNgEnd17RefY3YAcUvwZWaHACcBJzrnnotadyLwMHB5Y48nIiIincuWglJe/2Z9tWXlJDZfC1woBC//P8hbAW9eDee93eSMr7MjguU9R/XcYfljJg/gvYWbAN8V+6pjxzTp+NI2LdqwvdrjvKJS7nxzCdccs3Mr1UhaTKgMQiXkFftkhT9Nep1/VhzDMNYxzNYBcODwHpyxW2+6pX8NK3ewv/p64zrYuhrevrn68tGHUXbAH7jrsVzW5xfz8jdruGzTKIb36RKnA7dv8RyzfCPwQHSgDOCc+4+Z7Q/8CWj6ZVoREZH2yjlw5fWeW7Mze27WakorfBfsBIOQg/XbS1iXV0z/nmnxP+AzZ8Km7/z9NV/B4rdg9GGN3p1zjlkr8wAY2CODwX1qjk+Mdvi4bFKTvqakPMRr363lD8fspO65HdD3G/x45ZTEBJITEygoLeexz5Zx9v5DGJSZ0cq1k2YVJPe6eJ8+PPfMkxyWOJtjkj6rXmYt8GIz12PQFDjkWhh2IKlmXDx1Bde88A0VznHr64v4+xmTm7kC7UM8s2FPAr6vY/38oIyIiEjnVbYVitZBcU71qTmkGuccM4Iu2IkJximTB1Sue+fbmnPUxuGA8P3r1Ze9N80vb6TlmwvZUuDf4/HZmSTU41dX19QkDh3ru0Cu3lrI7BVbG318aZuccyze6FuWh2em8n/79wWgtCLETS/W9VNaOoRQKVSUcdCoHvwkeSbp1gr/B7KGw9lvwvCDKnvP/HS3QQzo4bt8v/bdmsrPaGcXz5bl7cB+wL21rD8gKCMiItI5uRCUF0DJZkjIh4oCSOoGyd0hQRNURPp82RaWbioAYP/h/Th2Uh9mzPZJrz5alMPP9h0U3wPOe9p3j4zUxNblWSuqumCP79+z3tsdPWkAr3ztu2P+54u17Dqs/ttK27d2azHbS3zO25E9kzlrcgKPfpHM2vwyXpu/ltkrhvODoT1bt5LSfCpKgApsxUwGsNEvckYRKXS1Eph4MvSOYyb8nMX++y3SlmWw9N1q322pSYn83yGjuPK5rwk5uPW1Rdz78x/Erx7tVDz/Mz8HnG9mK4C/OufyAMysJ/Bb4GTgvjgeT0REpH2pKIaKIkjM8N2wS7f64Ll8uw+Yk7p1ynksY5kRkdjruAlDGNUngW7Jjm1lxhercnDOxbd78oe3xl7+wa2ND5YjxivvPqzu5F6RDhrTh26pSWwrKefNBWu5MTSWxAR1xe4oFq6vmjJqRM9E0lIz+P2B3bnkpc0AXP/fb3nh//ZR9/uOKFQOoRKwJCo+vpcRwRjl+W4o4xOW+zK5K+CE++N3zH8dEXt5jO+2E6cM4u/vLGZ1XhFvzF/LwvWjOn2SwXh2w/498CVwJZBjZmvMbDWQE6z7IvgrIiLSOZUXQnkRJKZDYhqk9gZLhdI8KFoPxeuhLN+3QHdiuQWlvPa1T+zVv3s6R/6gN2bGTj18l+icghIWrItzZ7VQRfXHlgjJ6ZCR1ehdhscrpycnMnFo/X9wpiUn8sPx2YB/rh8v3NzoOkjbs3BDVbA8qlcCJGZw9KSBTOrvx7TPXZvHq7NXtFb1pDmFqqaMWluaRpL57/o1rhcViWlN/s6JKT3T7zf6FuM4yYkJXHLoaMBPefSXVxfFty7tUNxalp1zW81sX+Ac4Bgg3H9gDvAC8LBzTvMsi4hI5xQq992usepdrpOCwLmiEEpyfEtzUjdI7gZJXZqcjbk9ejYisdcx44aQmmoUFMCYHo6vguHK73ybw9gBcWzxyBwGW5ZUPe43Fi74uNG7215Szvfr8wEY268nGekNa584ZvIAnvlqNQDPfrmWA3bu3ei6SNuyMCIT9i7ZaWCGWSLX/nAIP3nIByfTXl/IYWO6kpKRBRbPti1pVaFSf0vqQmFq1RR4pT/4FYknnNA8xzztyQYVP+EHA7nnncWs3FLIWwvXMX9dPmP7d975luN69jnnyp1z9zvnjnLOjQ1uRznnHlSgLCIinVpFke+GnRgji7OZD4xTevnL+SUbfStz0QbfGt2JOOcq51ZOTDB+ulvV2ORwyzLAzKVxTPLlHKydVX3Zpu+hvPGJd+auyiMUVHd8ds8Gb7/3iF707upbGt9ZtJ7S8s7d26AjCbcsZyQbw/tVZb6eMrgrR47tCcDq/DIe+nAxFG0MxrhKhxAq9bMhkETvjZ8CkOu6stPktjNZUFJiApcFrcsAf3mlc7cuN8ulKjNLNbOBZpbSHPsXEZGO77xHvmDsNa/VuJ33yJetXbXGKS+sPVgOswRI7gopWb4lunhDkDl7o9+2E/hieS5LIhJ7jRhQ9XplpsLQLP941uotlFXEKYDMXQ5FudWXVZTBxu8avcvI5F6TBtZ/vHJYUmICR03sD8C2kjLe+nZTo+sibUcoFJEJu0cyySnVfyr//pABJAXj0//+SS55eesihmc0PjO7tAEuFHyPJ+K2LKVXhT+nv0iYyKhBPVu1atGOmTSA4b39PMvvLl7P16s7b1b+uAbLZrarmb0DbMNPob1fsLyvmb1tZofG83giItJx5RWWUVQWqnHLK2yH0y1VlPgu2JZcvy6VlugTfqVk+m2LNnSa6aaeiEjsdcz4ITV6oe85tAcAhWXlfLk0Lz4HjWxV7lPVosK62Y3eZWRyrz1HNTxYBt8VO+z5r9Y2ui7SdqzOLaKozI+PH5GZBAnVg+WhWamctYfvcp9fGuL2j4p9IsDijX6YRkgdNdutyvHKyeR8+37l4vWZe5KYlNyKFaspunX5r6913tbluAXLZjYZ+BA/VvnRyHXOuY1AOvDzeB1PREQ6tosPHhV7+dTYy9u0inq0KseSkAQpPX3gXF4QdM1eCyVbak5z1AHkFZZWTpmU3S2dH/2g5jjdPSOmUXpvfpwSX62JCJYnnlh1f93cRu0uFHLMXpUHwJCeXRjYu3Ed7X4wuCeDM/28px8u3UBhqQKl9u77iOReIzJTY5b5v/2z6ZHms+LPmJPLsm1d/EWz4g3+1smGZnQYFSU+YE5IpmzRB5WLbeiBbXIWhKMmDmBUn64AfLBkA3OChIWdTTxblv8IrAHG4bNeR2ckeRvYI47HExGRDuygMX3o07V6kDFpcE8O2qlPLVu0Uc75H7ehMkiI/eN4hxKSfdfsxC5Qts23Mhet81m0o7M4t2PPzlpTOTb3mPGDSUurmdxst8HdCc+i9OnyOI1bXhu0ICckwi5HVyVgW/91o3a3NKeAvEJ/MWN8/8xG52gzM46e5FuXi8sreGXOhsbtSNqMapmw+2TELNMjPYlLD/TZ0MtDjj+9sd73MklI963LxRv8BbNOnjW/3Qm3LFeE6J07B4D5oSFM2nl03du1ksQE4/LDdqp8/JfXFrZibVpPPIPl/YEHnXPb8elJoq0EBsRYLiIiUoOZ0T29ete0yw4d3f7mHq0o8reEtKZntk5MhdRevoW6JLcqaO4A001VS+xlxklTBscs1y0tiUnB+L5v1udSUNLE1tZQBayd4+/3Gu6nWekd/HjdOB9CDX9dI7tgNya5V6RjJw+svP/f2eqK3d4tigiWxw3oWmu503frzdCg5fntJXl8tmK7z5yfnAll2323bCX/aj+cq3yv3OqvSHF+OM1nCZPZZUjbncf4yPHZjOnn6/fJsk18tTx3B1t0PPEMltOAukZ/d96c4yIi0mBFpRWs3FLV3TDRjP1G9mrFGjVSeSGUN6ILdl0S04M5mpOhdHNE0Lyt3SYB+nJFbmXio32H92XUwNpfr/1G++7ZFSHHBwu2NO3AOQuhzCcUo98uwd+x/m9pAWxZ3OBdzo4IlqcMa9x45bAx2d3YKfix+umKTe1zzL5U+j6YNqprijGkb3qt5VISE7jysKo2pj++toaQc8HQjCzAoGSTb2VW8q+2L1QKoRKwZLYvqOqCnZO1B0nJbTcfckJ06/Krna91OZ7B8hJgSh3rDwEan1ZSREQ6lbmr8yirqPoBWOEcMxfntV6FGiNU4ccr43xX6ngyg6QMSOkNznz3zKL1/lZe0O5+PD/xWVVir+NiJPaKtO+oqrHM7y9oYlfsyPHK2eP933DQDFVdtBtg1oo8ADKSk5g0rOmtRscGib7KQ47nv1zf5P1J66gIOZZs8sHyiJ4pJCXW3dPkiDE92H2wz0j87cZCXpgXXIQxC+Zh7+qHYij5V9tXmdwrBbfsIwAKXCoZQ3aL//+GODtiXD92CeZZ/mxlDp8tbeIFynYmnsHyDOAMMzssYpkDMLPfAkcAj8XxeCIi0oF9taJmd69X57azMZsVhb4LdmLtLUhNZhZMN9ULXIVvbSpa7/+2k+mm8gpLeTkisdeRu9Y9Lv0HQ3qSnuwT4nyxsonBcmQm7P4T/N++Y6uWrZvToN3lF5excKPvajsuuydpqU0fNnDMpKoWxpfmqSt2e7Vic0HlmPwRWTvuaWJmXHNE1Tzjf3l7HcWR820npvpW5ooSHzAr+VfbFQ6WCzbTvWA5ADNDu7DHyL5VORLaKDPjiojW5b92srHL8QyWbwU+BV4HPsYHyneb2XpgGvA/4B9xPJ6IiHRgXyyvunqdluQDo/eXrMe1pxbT5uiCXRtLiJpuKmhlLstv/mM30fOzqxJ7HT1uMOkxEntFSk1KZI/hWQAs2byNDVubcFEg3LKcmAJ9dvb3+46hMk9pA5N8zVmZV9moP75/z8bXK8LgrAx+MNjva/bqzazLax8XQaS6yORewzNjJ/eKNnFABseO9135128v5f6Po+bbtoQg+VdqVfKv0tx2n8Ogw6ko8Rczl39SueizhMlMGNY+RqkeMrYvEwb6afu+XLWZTxbHaSaCdiBuwbJzrhQ4DPgNsB0oxk8jtR74LXCUczpzRURkx0IhV9myPDSzC4fu0heAdflFfLtmW12bth0Vpb5lOSGpfnMrx4slBtNN9fCBckmO76rZRi8yRCf2OrGWxF7R9ovoiv3Od4384VZeChu+8ff7joak4KJGShfIGubvr/+mQa9dZHKviQOaNl45UrgrtgOe/UKty+3RwmC8MsBOfbvUe7vfHjKA1KDL9n0z17O5IMa0cUkZMZJ/aXx7mxAq8+OVE1IoXvRh5eLcXnuQmtp2xytHMjOuOLz62OV2deG6CeL639s5V+6cu905t5tzrotzLsM5N9k5d5tzTgMpRESkXhZu3Ma2Yv9vY2L/LA7bpV/lupdmt5Ou2C3RBbsuCcm+xalsexAwb2mTAfNXK3Irg4h9hvdlp0H1a4WPHLf84cJGdsXe8E1VQBE5ThmqumIX5cLWVfXe5ayIuUj3HBW/YPnHEwdUTpn1yjcKltujheurenmMG1D/3iYDe6Rw7l7+gmFBaYi/vFXLuPVw8i9HkPwr6Fmybp5f38ip0KSJwl2wSSBx5acALA/1Y+CgUW1+vHKkg3bqw+Sgh8uctVv4aFHnaF1uwUvdIiIi9fPF8uqtcwfv3JekIFJ4b2E7SHAUj7mV48ES/Y/n8mIfMJfktLnumTM+r0rsdewOEntF2jm7G1ldfKvMl6tyGtfKsTZGcq+wakm+5tRrd6GQq8yEPSyzK/17xe+HcJ9uqew90l8gmL9hK0s2FsRt39IyFm7wwXKP1EQGZDVsnOqF+/WjV4bf5j/zcli0sZau+NWSf+VC0QaS372OsWufwWbe0yYvmHV4oVJ/27CA5HJ/YfCD0ER2H9q1XQXLZsb/O7z62OXO0Loc12DZvMPN7CIzu8bMro26XRPP44mISMf0VcR45T1HZtE9LZm9g2mjvt+Uz+otRa1VtfqpKA7mVk5t+tzKTRUe0xgqrwqY20jW3K2FZbwyzyf26tc1jR/vILFXpIQEq2xd3ri9mMUbGhE8ronIdN1/YvV1/SKSfK2fU6/dLdm0vbJHxPj+PeP+1oe7YgP853O1LrcnZRUhlm3231sjstJ2mAk7WrfURC4/qD8AFQ7++PqaujdITPVJ/759ia45c9hpw0t0WfMRLPpfo+ovTVBRCq4cls+sXPS5TWTX4d3A2nZyr2j7jerNbkN9j5l563J5r6mzEbQDcQuWzWwXYAHwGnAPcANwfYybiIhIncIty5npKYwd5BPhHB7RFfvltt4Vu6IQyluxC3Y0Mx8wY1C8yd9CMcY9trDnZ6+mpDKx15AdJvaKtt+oqnm33/62ET/awi3LKV2g16jq6yKD5XVz67W7yPHK47Pj1wU77Ihx2SQn+p9ur367plO06nQUy3MKKqfCG5HZuO+FU3btxajevvv2h8vz+XDJjvI3GHz+SDhVHSmhQnj9d2pdbkmhCggVgyVRvsRPGVXqEino8wMyMtJa/2JqA0WPXb719Y7fuhzPluV7gYHAZcCuwPAYtxFxPJ6IiHRA67YWsSbPt8BMGpBFcrL/MXFoRLD89oI2HCyHKvw8x4TaXhe75O5gyUHW3I0+Q2sr8Ym9/FjgBIOTdqtfYq9IkeOWP1nSwGC5tAA2LfD3+46pOX1LeiZ09y15bPi2XruMnO5st+HxD5Z7pCdz8Bjf+r4it4BvVrf9TOfifb8ur/L+8HpMGxVLUoJx1WFVvQtufH0NFaE6ApWlH0Du8urLtiyF+S826vjSCOHxysWFJG703yNfhcawc/+stvf/oZ72GdmbPYPZCL7dkMfb323awRbtWzyD5d2Bvzrn/uacm+OcWxHrFsfjiYhIB/RlxHjlCf2rAo7+PdIrp66YtWYzWwtbv2U0pooi3w27rbQqR0vuCokZULLZB8zlrdOlfdbKPL4PptLZZ1i/eif2ijQoM4NhvXxW4VmrN1Ne0YDx2OvmVo3fzt4ldpm+wfL8dVCw42Q24eReXVOSmDCka/3r0gDHTh5Yef8ZdcVuNxau31p5f0zfxk8ld9Co7uw7vJvf5+Yinpm9pfbCn94fe/mrv2n08aWBwuOVV36J4S9svB+ayO6D29d45WiR8y7f+kbHbl2OZ7C8Gej4HddFRKRZVWudG5ZVbV24K3ZFyPH6vI0tWq96q+yC3QJzKzdWUnqQAGgLlGz0GbNb2BPVEnsNbnRvxP1G+67Y20vLmb186w5KR1gTmdxrQuwykV2xI5OBxbC1sIzFG/3ruEt2T1JTm6d75SFj+5KR4ucdf2P+WkJ1tSxKm7FoY1WX6V2yG38hzcy3Loc/Xbe9u47C0orYhdN6EJ4vvMKSCZn/3LB9Q/Xx+tJ8QqVQUQYrPq1cNJNJ7Dasi+/l007tOaIX+wYJBxds3MobX7fR/8dxEM9g+Ung2DjuT0REOqEvguReqUkJTBnRvdq6w8ZVdcV+45s22BW7otR3wU5I9Jmo27LEND8Xc2men2amtAGBZhNtLSrj5Xm+VbRv1zSOmtK30fuqNt/y/AZcs48MfqOTe4VFZsReV3dwMXtV7B4R8ZaWnMgR47IB2LC9mM+W5u5gC2l1zvF9kIAuKz2J/r2altRpl+wMTprsLyRuKizjnx/W0g32hL9Dqm+F3pbWn8L9r6xa99IlfsiINB8X8r2MgNAyP155o+tJYu/RdO+W2q5blgGuOHx05f3b3lzYYS/cxTNYvgooNrNnzewgMxtuZkOib3E8noiIdDDbS8qZv86PwxzXryddM6r/mxrTrxtDsnzCr09XbKSkvI392GvrXbCjJaRAciaUbQvmYs5tkeQ/L8xeQ3FZOLHX4AYn9oq094jela1sny1rSLAcBL/pmdCjlvHS1TJi1z1HbeT8ypMGNl+wDHBMRFbsZ79QV+y2rqS0hBVbfH6AEZlplfNlN8X/O3gAaUn++/HBzzawcVuMYSkFm6DEf59uSxtI6ZijYeCuft36efDZfU2viNQuVOZbljevIKHQD+P4MDSBXfun+mzl7Sy5V7QpQ7M4cCefQ2FRTj6vzmsH0zo2QjyD5TJgPnAc8DawGFgW4yYiIhLT7JW5hC9OTxiQVWO9mXFY0BW7sKyC9+fveBxpi6mcW7kUEtpwF+xoCUnBXMyFUJzjxzI341zMPrGX74KdYHDSlIYn9orUIyOZCYP8WPZ563IpLK3HtFhFuT7REUC/nX1PgFi69vPBNMD6b+rc5axg+IABe47qWY+aN95+o3rTM8O3Sr31/TrKGjJWW1rc0o15BImwGZEVnwtp/bol88t9fI+MovIQt/xvXc1Cm5dU3t2eNtBPI3fE9VWf93dvgnxdbGk24eReK7+oXPR+xSSmDEhv963KYZdHjF2+/X+LOmTrcjyD5b8AvwZmAX8D/ljLTUREJKYvIpJ7/WBQ7Na5yCmkXpvXhrpiVxT78cptYW7lhrIEHzCHSiLmYm6eVvvZq/JYsN6P39x7aF/GDG568BDuil0ecnz0fR0Jj8LWRnSpzh5XezmzqtblLcugJPbY7oqQY86qPACGZXWlb2bz/hBOTkzgqIk+U3decSnvNaT7ubS4yOReIzLjdyHtl/v0pU8X36X7hW83M399VLK+nKpgeVta0Buh92jY41x/v3Q7vKZkX80mHCwH8yuHnPGJG8+eI7u26/HKkSYP7snUnf1Fm6Wbt/HinBgXbdq5eAbLZwDPOed2d85d5py7IdYtjscTEZEO5qsVPtAxYK9RQbAcMe4LYMrQzMpWtQ+Xbmg7V7IrivytLSf2qouZ75LtQsHUUpsgVI9W2gZ64rOqxF7HTRgSl+sKkeOW31tQj8CxWnKv8XWXrRy37Gqdb3nRxm1sL/Gv1fj+mS1yreSYSVVZsZ/7Sq2DbZZzLNxQldxrpyZkwo6WkZLIb6b6IDjk4IbX1lQvsHlx5d1taVWfF/a+AHoEj+e/DAvfiFudJOCc/79Vsh0XJFOb54bTv08fsrqndJiWZaieGfvO/y2qezqzdiiewXIG8L847k9ERDqRsooQs4NxnyN7d6NfVvBjojTPT3EUZGxOSkzg0LG+dTmnoISvlue1fGWjhedWdiE/Dri9MoOUnkAilIbnYi6N2+7zi8t4KSKx14937ROX/e46NJPUYPzmFyvq0TU/smW5tuReYX0jxi3XkuRr1oq8yvvNmdwr0m5DM8nu7gOv9xevp7isjY3fFy9UxsKNBZUPxw2I78W0n0zKqpyK6tNV23hnUcTc20HLsktIoiA1Iolecjocdl3V41f+H5QWxrVenV54vPKaeVhw0fGD0ER+0C9I7NWBguXxA3tU9vhanrudF2Z1rIt38QyWPwXG7rCUiIhIDPPX5VdOgTKxf5ZvnSsvgrKtULLF/w26Bh8W0RX7lTltoCt2ZatyO0nstSPJ3fy46/BczBEt+03x34jEXkftMpiM9Pj8DElLTmSP4X6M+6KcfDZtK6l7g3DLcrd+0DW77rKRSb5qaVmetbJq+MDuw1smWE5IMI4NEn0VllW03anUOrtQCQs3+c9jny7J9OnZtEzY0RITjGsOr2o1/tPraygPt+wFY5YregzFRWfnH7E/jPmhv791Fbw3La716vRqHa+cHAzViWcI1vouO7SqdfmutxY1bM77Ni6e79SvgVPNTNNHiYhIg30ZMV554oBM342tdKvP1JyQCmX5PmAG9h/du7Il8b1FbSFYLgyyYLfTLtixJGX4W+kWHzCXF+x4mzo453j8s6rEXic2MbFXtH0jumK/+20drcvb1sO2oOWj39gdjy/PHArJPgN7bUm+wsm9uqUmM25wl3rXuamOnlSVFfv5WWvqKCmtpai4iJW5PlN1vDJhR9tvRHcOGuWn2VuaW8yMLzdD4RafyA6oyBwee8OpV0JKV3//03/Ahu/iX7nOKlTqe+UE45XzXQbzGMVewzI6VKty2C4DutO3WyoAK/MKGHvt64y95jXGXvMa5z3yZSvXrmniGSzfAWwDnjOzFWb2vpm9E3V7O47HExGRDuTLFVWJmfYeleWD4/J83605pYcfP1uWDxXFZKQksf9o34V3ee52Fm+InXipRYTKfCZpS2j7cys3VGI6JHXzU0oVb/IXLhppTkRir72G9mXskPi2wkeOW/5wYR3jliPHK0fOo1wbS6hqXc5ZBOXVu6XnFpSyNMdfSBif3ZOUlJZL7jZuQHdG9PbB+czlm8gvjjF9kLQe51iycSvhEZwjsprvYtpVhw0gMfjo3fH+OgrXLaxcV5E5IvZG3frCAZf5+6FyeOn/INRxWgRbVUUJ5K2ArasB+Cg0nhFZGfTN7FjjlSP16Zpaeb+swlFUFqKoLEReYfyG8rSGeAbLI4AkYCUQAoYAw6NutZytIiLSmTnnKluW+3VNY1R2km9Frij2wRr4rsFl+VCSB85Vy4r98uxWbF0uL+xYXbCjJaZCcs/gtd/kx5A3Yi7m8HRRAMeOj09ir0i79O9OZpD47fNVObja6rg2Ilje0XjlsPC45VAZbKjeujx7VVWPiPEtNF45zMw4drLvgltaEeLFrzrmPKftVqiU7yOSe43IbL7viNF90jllV3/BKLeonA8+m1O5rtaWZYDJp1RlhF/9Jcx6uNnqGDehCn8BL9RGLw6Fyv3MAiuqumB/EJrID7LTsMSONV450q+PGBNz+cVTR7VwTeIrbsGyc26Yc274jm7xOp6IiHQcq7YUsTEYZzphQBaJFXk+OEvqWtVNNiHF38rzoXwbh4ztW9ml8Z3vWylYbq9zKzdUQjKkZPokayU5/odqAwLm/OIyXprrpxTp0yWNo+KU2KtaFROMfYLW5Q3bili6qZaERZEty/0n1G/nkS3Qa6sn+YpM7jW5lunOmtMxk6u6Yv93TsdKrNPuhUpZuLFqOqcx/Zr3O+Lyg7LpkuJ/2uesmF9VjZ51/PxOSITDb6gaQ/vW9bB9UzPWsolcCEo3+54upVt3XL41VI5Xrup+/EHFRH6QneLnte8g00ZFO2hMH8b061pt2aTBPTlop/h/37ekjjW6XERE2qXILtiTsrv4QBmrOQY4qatvxS3No1dGArsO9cHJ1+ty2Zi/g6ROzSFU4scrW0r7m1u5oSzRz8VcXhzMxbzZ/3Cth//OWUtRkK356HGD6ZLRPD8/Irtiv/NtjK7YzlW1LGcOgbR6BreRSb7WV0/yFU7ulWCwx8ieDaluXAzv3YUJA3sA8NXqnNY5DyS2ihIWbapKjrdL/+YNlnt3Seai/XyPmxH47r9YIhU9htS9YfY42PV0f794K7xxZTPWsglcyH/vlOT4HArl29tm63Ko1M9hHST3WhQayFp6s+/wJP+/IqGDDdcJmBm/P7J6rufLDh2NtfP/jQqWRUSk1X0Rkdxr94HmfwQld69Z0BJ8wFyWD6VbOWIXn8nYAa/NbYXW5XAX7KQO2gU7miX4FuZQme+SXZJTmaG8Ns45ZgSJvYz4J/aKFBksf7w4RrCcu7wy6VG9knuF9RoJiUFrUESSr/KKEHNW5QEwolc3esc503F9hbNihxw8/+W6VqmDRHEOQiV8v8kHc9ldU+jVvfmDpHP37Ev/7smMTvAJ34q7Da767NZlv0t8dniAr5+Bpe81XyUbwzk/K0LJZv+Fn9zdX6hsYuLBZhEq9T1Qyv2FkvdDExmemcrArGRIbMdTC9bDQWP6MGmQv3jXEVqVoQnBspl9ZGZTG7HdVDP7qLHHFRGRjufL5b5lOSM5kUn9yyAxo/ZkWeGxwWVbOWxMt8rF//uuhYNlF/I/1EIV7Xtu5YYy8wGzw3eFLN5YZ+vOvNVbmb/Oz/2617A+cU/sFWlwVgZDsnzm6q9Wb6YiFNVVPHK8cnicZn0kJkPvYGqUjd9VXiD4fsO2yunOxmdntlrngqMmDiB86JfmKSt2mxAqpaCokDX5/vMxIiutRT4fackJXL1/F/qY76I8u6h/7eP3I6V2gUOuqnr88uVQ3kZ6KTjns/KXbgFXAck9/LCXULkfGlLPHi4twoV8ro0a45XTscSkDjteOczMuOrHuzA4K52rfjS23bcqQ9NaltcAb5nZPDP7f2ZWa0pJM9vFzH5tZnOB/+GTgImIiJBXWMqijT6b9YS+aaQnV/hguS5J3aF8O8O6lTG6rx8j9fnKHApLy5u7ulUqioLpojpJq3K0lB5+7F1JMH6wlh/k4VZlgGPHxT+xV7TwFFLbSsqYvSJqTGNjxiuHhbtilxVBjs80PGtlXuXqlk7uFSm7Rxp7jvDzTH+zPo+Vm2sZry0tJ1TCoo1VrZ4jMlsup8GRfaumTvuiqB/vLqln6+voQ2HkQf7+lqXw4a3xr1xjlOX5PAkVpT7ZoJm/Jaa3vdbl8HjlFZ8DUOyS+Sw0lh9kp/lAuYOOV460x/AsPvztVPYYntXaVYmLRgfLzrmTgX2BtcBfgK/NbKuZzQmmiXo3uL8V+Bq4BVgN7OucOy0elRcRkfbvqxVVXbAn90v0Wa93FFElJEFCOpTlc/jOvstXaUWIt76pY8qgeOtsXbBjSe7q34uKIj9+O8q24jJenOuTTvXuksrRU/o2e5Uiu2K/+13U5yGcnCshEfqOb9iOI8ctr/P7mR3x2d19eM+G7S/Ojpk0sPL+M58r0Verqyhl4caqixbNOW1UtITNSyvvLw4N4s4Pc6ioT+OrGRx6NSQFdf3oTshZ3Cx1rLfSPN/9urwIUnpW/9+QmO6/e8oKGpWhv1mESiF/TeXr9lloLCWksPewJLCO37LcETVpzLJzbqZz7ofAKOAPwEdAT2BPYHegB/AB8FtglHPux865T5tUYxER6VC+jAg4dh3Qpf5dmpO6QKiUw0ZWlX9tXgtNnRMqC1ozOuDcyg2VkOpb2CuKa6yKTOx11C7Nl9gr0t4je1V2Sf50WUSwHKqAtXP8/V7DIbVr9KZ16xsZLPv9hJN79UhLZpfBXRpV33g5cnw2SUF6+Fe/UbDcqpyDiiIW5lQNT9i5XwteVNtcFeAucgNZva2MjzcYpz66kLHT5nDek0tr37bHQNj3V/5+RSm8fGnrBaJl+b7rdXkBpGRy3lPLGDttTtXtlnmMvW0N5z3xfczvn1ZRUQrLP6l8+H5oEoO6pzCiN8GMDq2T10AaLy7/tZxzy5xzfw6C4WHOuS7Oua7BdFFHO+duc84tj8exRESkY/lyme8ymGiw28he9d/QDJK7M7FPOf26+qv1Hy/fSHm9mlCaqLN3wY6UkAKuzLf8RIhO7HVSMyb2ipTVJYVxA3xyuHlrcykKxhSTs9C3QEH1qaDqq8+Yqul11n/D5u0lLA+6O4/PziQ5uXXH5mV2SeHAIJnOks3bmL922w62kGYTKvXTRuX4z54BYwe04NRym5cAUEECS11/AF5fnUBBKRSVOfKKdjBcZbczofdof3/5RzDvyeasbWxl2/0Qj7LtPkeCJZBXVEFRmat+K3fkFZa1ja7YQVI3VnxWuej90EQmZ3chIcE6V26LDkTZsEVEpNWUlFcwd7UfVzqmdxq9ejSwi1pCCgkJyRw62o9xzi8uY+bi3B1sFAdlBf5HUfTUVp2RmR+HFyqulujr6zVb+S6c2GtoH3YZuoNx6HG072jfFbssFOLjhcG0ZJHjlbPr6IIdKvPBTrSUDMgK5qtd/y2zInpEtOZ45UiRcy7/R12xW0+oBEKlLApalgd2T6Fnlxb8yZ3jg+WSLgMpwQdoBeXG6qBX+G6Du1BUVsdFxcRkOOIGCPfReOMqKNxSe/l4Ky/0mfbL8iG5J44EZq0uoEda7F48F+/dw8+gUBHjvG1JoTJf92B+5dWuN0vcACb3Tw+GDqkLdnsU9zPXzIab2XlmdpWZDQuWpZjZEDPTJRUREan0zcqNlFb4Ln4Ts7vtoHQtkrtx+KiqHyGvNPcUUhXFwdzKyR1/buX6SkiDipJqXSGf+Lwqsdcx45s/sVekyHHL7y8IumKvrWdyr7Kt/har62m4K3ZxHosWza9cPHlQzybUNn4OHduP9GQfULz23dr6ZUGW+KsoYWthCeu2+Rbc4ZnpLff5L9kG2/13YHr/0YzLTifRwp8DX4l7P9nIlFu/5ooXVvDhkvyaWeMBBv4AJp3k7xduhv9d2wKVx/dQKcmBsq0s25bOHR9s4qB7vuOE6Qt5e1F+jeIT+6dz0E6Z/ju5opVbl0OlsG4eFPt6flAxATD2GZrq/18oWG6X4hosm9mfgYXA/cAfgRHBqjTgO+CieB5PRETaMRfiiyVVY4wn9W/gGNIwS2Cv4Vl0SfE/BN9fvL55gwR1wa4pMdX/UAyC5e0l5fx3Tssm9oq0+7AsUhL9T5zPVwTBcrhlOTEF+uwce0MX8kFyQkrMhGWR3bcLVvjWowSD3Uf1jFfVm6RLahKH7uLnyl2bX8hXy/Nat0KdUTB10OKcqq7OLZkJO9wFG8B6j+LXB/dnQAYcM6SC5ISq78XCshDPzdvCGY8vYa87vuHGN1bzzbrC6t+dB14BGUFG49mPwcpmTjtUUULOlvU89Mkqjn1sMwf/YxF3fbCeFblVLcYZydVDl6PGZWJJGVBRFiT6asVppEKlsOzjyofvhybRt0syO/Vzallux+I2ytzMfgn8BrgbeBl4M7zOOZdvZi8CRwN3xuuYIiLSjpVt5cuIqXf2HtH4BEmpaV04aEQ6rywoZF1+Ed+u2cb4Qd3jUMkoLuS72YXKISU1/vuPg/OeXMLHy2qOV913eHcePGVEjC3iwBIAC7JiV/DfOWsq5x/+8S6D6doCib0ipSUnstuwTD5ZspmFm/LZvHU7vTZ841f2HV2V7TdaqCz4UZvif/hGd7OPyIidsXk+sAujenenV/e2k7TnmEkDeCnIQP7M52vZbXjb6CLeaYTHK2+pCtpG9mrBYDmnKlim10gOGtWdMX1SOaR/IYUJqVx+2HCe+SqXV7/PZWOB7ya+qaCcf322iX99tomRvVI5fmIWx47PZHBmD5h6Jbz8G7+/ly6BCz723bTjqLC0nDe/XsMLs1fw4ZJtVERd60xJNPYf2oMjRmdxxPiuHPvQApZv8QH016uD3ixJGVXTSCU3spdSU1WUwAp/QaHcJfBJaDx79+9KUkKF/06xtvM9IfUXz3ftIuA559xlZhYrQ8s84FdxPJ6IiLRXFSW40q18FfzQGdQ9hSF9mvYD7PCde/HKAj8o7+XZ65snWK4o8sFyGx6rHE6CU3N5M89BnRC0LodKKrtgG3DSri2T2CvafqN788mSzThgzmefcEh4PGNdyb1ceZCxNtUnFor+SPatapHeyS0DfHKvttQb/8Cd+tAjLZmtxWW89f06KkK7kJjQhirY0QXB8vcRLcs7Z7dOyzK9RmJmnLVHHzavWsFZe/RhXP8Mxh2VwbU/HsAnS7fzzKxc3l6Sx/bg4taSzSXc+u46bn13HVMGd+H48Xty8qC9SF79KWz6Hj75G+x/RZOrWV4R4qPFOfx3zlre+HZ95cW1MAOmDOjKD0dncfTEnvTLrBqvPO3HQzj934upcPDm4lzyiwfRPTUdSoOEYEldW36ITKgcCjfBej88Y5YbzTYy+EF2l6reKm3pi0LqLZ6XencC/lfH+k1A7zrWi4hIZ+AclG1lyfot5Bb51peJ2V1p6u/5g3bqSVLwX+3d75spuVF52++CffF+/WIuP2+vPs174EQ/hdTXq3L4Zo0fs7fHkD6MG9Zyib0iRY5b3rwoovvojpJ7JST5myX4H8CR0nv6qXWA8QnL/d/+PeNT4ThJSUrgyAnZAGwuLOHD71b6REnSMipKoKIquVeCwc79WzJYDk8bZdDL9yTZJTuj2l9fL2O/kd2466Qh/H/2zjo8juvs2/dZFLMtkwwyM8UOOnG4wabhpH3TpkkxhZTfNuV+5abwpphS0jRp2iRt0jCD7ZCZmUmWZTHv7pzvjzOzM5JW0kqaBcnnvq69NDs7tKuF85zn9/yeVV+cxa/eO4FzxudH248BrD7YxNefPcR79lxPyJw5kq//GGr29+vSpJSsP1jLd57czGk/fJkP/XUl/1l7uEOgPKU4k0+fNooXPjKTR26bzO3nFHcIlAFOn5DLHUvUe7wtLPnX6mr1eRUBs3Y5BW2kjDbYtyIqA38jMgeAU8dlaAn2IMfNYLkV6KngbBxQ6+L5NBqNRjMYCTdCqJ5Vh23n5DkjBt6jNj/Dx+njlfxue1UTh6pcDhCMsGkgI9K6V+bZE3Pxxvh1//ozh3hwdRWhzhpHt/D4QUZ4aKU9UfHeWWUpS6bMHJVPfqYaoGadWGc/MHJO9zvJsDLi8WXbddidMU2+RopqiqhncXn6yZyvnGu7Yj+28jC016TeKfhkwKxXRnjYcVwFbGX5QXIzk++ETf5o8Mc3qZfh8/DeuQXcf0s5q74wi29dWMZ8h4fEbmME94TeC4AIt7Llzx/lzZ3HYxuDxeDAiWb+7+WdnH/367z3Nyv464p9VDXa78cR2V5umVvIv26exrOfmMYXLipl8shAj98dN8wvjk6wPry2StVa+7KU8icVbaRi1CsXZviYPdqjvht1sDxocfPX/l3gfcDdnR8QQmQCtwArOj/mNkKInj65hVLKWse2pcAPgcuAfJQ52T1Syj92OmYW8GPgWpQo6xngTilldaftrgIeBGZJaeqzNBqNRmNjhKG9DsJNrDxsZxNOHd9Pc69OXDg1n2V7VL3u06v387GLZrknfYs0q8xyGkuwAbYeayVWq+mqpjB3PX2QP75ZyZfOH8ml0wsQLkeyje0+/rtJtVQqzgpy5Smxs9zJwOsRnDGxmGc3VTApvEOlBwLZUDwp9g5Sqps3oJQDnoCa2KFTZrx0Oux8CYBTMw4xbUxqMuc98efle6LLT26v4cUf1CA8Wzhz0jD+9MFTUnhlQxxTgl3T6uV4o+WEnZG8CaP2Jqg3J6uKJ/brEAWZPm49vYRbTy/hYE07j6yu5smtNfy+5gre613BRM9RZjS+zcf/+mvuzF7CVfNHs/5gDesP1nb4PpFSMq44h+yglzUObwqL3KCP88oLuWyil3OmZRHMyu/TdY7OD7B0Uh6v7KxnV3Uraw81s6AsGxBmG6k89VlOFmG7XvmEzGWTHM/SkTn4PWFV1iF0sDxYcTNY/inwvBDi78B95rrRQojLgG8Do4GbXDxfTyxDOXJ3JjrVJIQoAJajruuXwF7gvcC9QohRUsrvOPb7IXArKmBuBr4C/Am42nG8PODXwHd0oKzRaDTdYLXl8eaw+tBxAPKCXmaOcccs64Ip+Xzz2UMAvLy9io+d1wR+dwJxQs1Kahdw6XgJYvmejuZeM0ozmFaSzRNbThCRsK+mjTse3ceckVn87wWjOGOCe2Y4T25vpaldReqXzRiTdGOvzpw5qYTXNu1jslDvCYZP7V4VIEO2XNLjUwGz1ULKEQTU5U3BGtafm3sEny/96hDrOtWnt0aAiEFtcwyHb417RNrAaOtg7lVemMSSjROO4WdJ/4JlJ2WFAT5/wQg+d34pm4628PrrX2DiwS8C8G3//VzQMIt733C+pzrmq7Yf6/hd5Pd4OHPCcC6eOorLZnrI81WrXQJ9C5QtblpQwitmO6n73q5SwbJl9BVpSl6wbETg+BZoVL9py4zZSDzMG5ltqlVydGZ5EONasCylfEkI8QngV9hB8X3m33bgI1LKt9w6Xy/skVL+vZdtvgJMAq6RUv7bXPdH07X7LiHE3xxB73XAz6WU3wMQQtSgguoMKaVVGPFD4ATwc1efiUaj0QwVwi3R4ON4q4991WqQNWdENgGXAo5R+QFmjcxk09EWVh9tpq7hBPkFmeDx9r5zT0TawLB6K6c2AOwNpxP2yFw/335PGYvH5fDJs4fzg+eP8MqeOgA2HG3m5gd2saQ8l/+9YBQzRww8Q/qPtXXR5esWjB3w8QbKWZNKmCn22X1mR/Rg7mWE1YDWygB5g8q91mhXyyZrw+NYai7P8e5LxGUPmDvOncSt963sun5J6jL9riENQKSnWZLRDpEQO6rsoDGpTtjRemW6V1D0AyEEs0dlMfumyzCeegPPlv8yQtTwlcBjfKP9f3rdf/7oIi6eOpor5o9kdIkP2qtVL2XDgED/yxjOnZzH8Bw/lY0hXthZq4y+MjIg1GAafeUN/Ls/Hox22PN69G60XnlsNtBsfpek4ftVExeu/uJLKe8FJgB3Ar8D/gB8AZgkpbzPzXP1hhAiIIToabr8/cBeR6Bs8XOU1PoGx7psoMpx/wTgRfWPRghxGvBR4KNSygTbjWo0Gs0gRBrQXgvtDeDPY/VBu6Zs7gh3M7UXTS0AICLhufXHIFQ78INGJdjpa+wF0Bo2ePdAI6CMct68cxaLx6nXd9KwDP7ygXL+/eEpLBhlv+bL9jRw2b3b+ey/93Ggpv+Zx01Hm9lwtAWAU0fnMGtcEiWQ3TCuOIuzsw9G7xsjZne/sbNtFCjppDejS93yW5WZHJfKab0stKvzUdKCpVOHMWdUxyHQnBF+lo7zDu7aZWlAyzFoO5HqK+mKNJRbvvCw47j9OZqeTCfsKsf70YXMciw8530FMlQm+APe5/nLBQHOnNC1j3rQ5+ETZ0zl2U+cx78/dTofv2gso4f5Vf18W7X6vPkLBnQtPo/gxvmqAU9r2OCRNWZ1ZDS73Dyg48eN0Q5734zeXWbMISfgZd5YPwivzioPclyfHpdSVkgp75FS3iGl/KSU8pdSysNun6cXrkXJpeuFECeEEH8SQoywHjSXy4BYme63UKKQxY51K4BPCCEWCiFmoLLSW6SUtUIIP/BH4PdSyncS9Hw0Go1mcBOqh3C9Cj48PlaaAR3AwjEDN/dyctFUW9L3wvYm89wt/T+g1VtZhjtkGNORNQebaAurrNai0bkxkxkLxmTz2G2T+PMN5UwqsgfyT2yq4bzfbOVbzx6iqinUdcdeeGiNPad81dQchJECR9pOCCFY4giWtzK5+40tcy9Lpu0Nmv2WO04grDnczBZjPADZTQegtY50QwjB587r2LLrpvkliEgThLv24B40hOqVOiXcoNQe6USkzZxwCUTNvbwemDIyid8ZzrZRRYkJlskqgqVKii2kwXm7v8eDH1nA/904r8Nmv715IV+5chLTx2Xa30PtNSqrHGkFf6Er2dbr5xdjHeXhtSeU0Zc3U50j1KjKKBJNWx0cXgfAZmMcxylg7ohsMnyRjmoVzaDENRm2EGICytjqyW4evwLYKKXc59Y5u2El8CiwE+XKcS6q3vgiIcSpUsqjqDplgEOdd5ZStgkhqoAxjtWfBf4LrDLvHwauMZe/DBQCd/XnYoUQZZ3OBTALoL6+nurq6q47pZD6+voOfzUaTfyctJ8fI6QyQaEGlUkQjbyzT70Gfo9gUrFBdW1j9/tXboU3fwdnfCLqRNwTwwKS0Xk+DteHefNQCxWVlQQyQhAs6p+EOtKqrt+Q0NLDdaYBL261M25zhvt6fF3nl3p5+P1jeGpLA797+wTHmsKEDcn9K4/zr3VV3LKgkA/MLyQ70Ptr1txu8PgG9XtVmOFlyfgI1SeOQ8C9LGZ/Pz+T2rcDUCXz+O+eTEaOivGaSKkmRAKZ0FZrr28PQVsr+OpAeAlFJBuONLNJjOccNqjr2bGc8JjT+/WcEsmc4ghTiwTbq1Ww0NxiUF3XCk0VEAzZGfTBghFR0t1wPeCFoIRAQaqvyibUCG21SBFg+zGV0SzLDdDe2kx1kuaN8it34gUi2aXUtdjfV/WNzR3+Dpiyi8gtfRT/sfVwdD1Nr/6SM+d9iAvKs9hV2cSk0hzmlXo7jmFDjWqiI9Ki5NEt7jhWZwFnjMtixf5mdp5o4Y3tJ5g9IgNCEfBWQZDETnJKiX/ni+Saio3XjbkATC/2U11brybf2hvBM4gVHUOI/oy/3DT4+j4qWxszWEbJsQ8CvRc3DAAp5eJOqx4UQrwO/A34DkoubRVmdTct2erYBinlTiHEbGAaSqK9xQyqJwFfB26WUtYLIT4JfBLIRQXXX5ZS9pbOuA34VqwH1q1bR2tr6mfmY7F+/fpUX4JGM2g5uT8/FbRFYEulFxCMyTZYu3F795tLg1G179Kafx7V+4H9W+M6y+RsD4frPbSEJfe9cYzphRWuXH268/JW9bp6hUTUH2BZ17LVLhQCX54Fy48JXjjkoSksaAlJ/vBONQ+uOcHFow3OKJXRHtaxeOuYoDmkagMXFoVYvfUocNSNp9SFvnx+/OEmLm1RmeUNRjmv7T7BjODxHvbo7n2insv+RmiL+NjsGR99ZP87z7Bnb3pWYF02GrZXq6He69uOUtJmGU+lp3y8byRbtBgf9e1Q26pe80JfK8tWxvedNVC8RhuXNSgn7CrPcN6Ocd71W/vXHzkWuYU3sPTYJjxECKz4Ccuri7iitAhKAepYvnx5D3u7+90wLUOwAvX98/vX9nPjRGc7gD2xd3KRWYeewyp6eMNQ9cq5oWMsW5u8a9DEx7Zt2/q8j5vB8lnEdqC2eAEVqCYdKeUDQojvolpEgZJog5pvikUmnX4xzVrkTZ22+wPwvJTyP0KIG1Bts25DTQrch6pr/mQvl/dn4PlO62YB986bN49Fixb1sntyqa+vZ/369cydO5e8vLxUX45GM6g4KT8/4RZTdtcOfjWcWHmwGeNdNdBdPLaIJYtKut096/kvkbH/NSRQlzEW44JvwKh5vZ42a2Qzr/1bneNQpJCPzguCL1dll/tSPxbNZjWCv3+OrcmivjXCwbfUoGzW8CwuOK2zaKlnzgU+1xbhLytreXhDDa1hSWNI8Ng+L29X+7nj9GIumpKDJ4Z08t5/HsCaf/7wGROYNtys/80Y5loGsz+fH9+BZbBRLW+Q5ext9LJ4/mSCnSP/SBsQgeAw8Dnq0o0QtB1XbWH8uRxaVwscZ7McH91kSk4Do5csGchTc59wC7Qd57QI/HrLEdojkspwFksWlSkpsy8DgiWDJ7tstCt1R7hZfQ5lSC0Hi9MjuywNaD0O4SberfDBavXdM3t0CUsWFSflErxV2xHrlYogf/xsliyyVTj1jc2s37qfudPHkZfjVquz6bRlbCdz3f34jVbObX2WxvN/33WzSIvyqwibhlvCfcOt0w3JEwf3UtUcYW21lx+/bxI5Qa/5Xs803+sJkkKHm8l/UIlLm8lgtTGFDK/gmjOmkeWthUCx+t3RpAUZGX33EHAzWB5O91OyAJWY800pYh9wprlsTUd2GUkIITKAYlT7qW4RQnwIVddsfRvdBjwmpXzIfPyHwD1CiE9JKWN0vFRIKQ+igmvnsQHIy8ujqCg9P2DpfG0aTbpz0nx+jAi0tkCbAYHh0UHSjg22DHbx2EKKCrox+NrwGOx/DQABFLQegNX3wPSHe611Ozcvm4JnK6htifD24WYKCkfhibRApgcy+vDahxqgxQMUKtOYNObdrbXRxi2njS3o/nXtgSLg25fn88mlo7j7pQoe3VRFxIDD9SG+9nwFf1+XyVcvGMWSiXawuuloM5uPqUB58ZhcTp9ehDDalLlOVobrwUyfPj+bdkYX1xsTaTck26sFS6d0em1CBniyIKukq2Sz2YC2SgjmsPWEykofkMOJ+HPwhhoJVm8nmG6f57YT0OwFfz4zR9Sw9nAzu6vbyM7JIij8EG6CTF/fPguppPU4eA3wOyZf2lGj2Mys1Pc+D7dAoBaMXCr22orAmSPz+/U57BeHj0QXM0ZNIyPGefNysty9nnM/C3tfgrrDBHY/T1HVSphysf14uBnaGsAXAf+IhBpd3bSwhHuWHaM1LHlpd4gPn5EPEZ8K1rMCA3Ld7pFjB6FODeNXRGYSwse8ETmMGZ4JoZCq8dbBctrQn0SFmwZftUBPbgKTgJS4SggVfU7CDOallBWoeuVYRUanocZl3YrXhBDDgJ8Bd0kprbrnMXQMeg+i3LK7T5loNBrNUCbaUzm7QzZh5UE7WD69vBtzr6Mb4YVvx1i/Afb2OJcJKJfU86eoTHBVc5jVhw0VYIfqVaAQL+FmlXVM9WA8DpY7WkadMW5gvZOH5/j58VVlvPSJGVw0uSC6fsuxFv7nwd3c/LedbDiiRFoPr7XrpK+aXqzmMTwBM/s3AGM1NzgS1UGywSgH4PUdMYYiVtuoWIN5X4Z6/xrtrD2k3jtFWQE8pdPU4yd2qcxzuiAN83WX4PExzzTQCxmSDYdazDY2pKdJVizCzepzKzwdM+G+HAg1qQmtVGO0qey3J8D2Svs9P31kMttGOcy9StxrG9Uj/ky48Jv2/ae/AO2meDPSqlQ57bXgz0u4I3RHo68q0+grQ322Q41q8jYR7H4luvi6KcGePzKnY992zaDGzWB5GXC7EKKLf7zpPn070FMBw4ARQnSXuf40Kpj9r2PdQ8AEIcTVnbb9PBAG/tnDqX4B7AV+7Vh3BHD2pJiNmvd0tpzSaDSak4NIqwqUjUiHjGzEkNGAY0JhBiOLYgicmk7A459Rg5xYvPWHuC7hQocr9jMb69SALdyoBm/xDJwiZnZUeNO+tzLA8j0qaMgJeFk00Z0s+ITiIPfeNIEnbp/K4jF2AP7mvkau/NN2yr+3lr+vsn/mvvPKPm5/eI+amBB+MFqVlDlVHF4DgJFTSr23AIB3DsYKrsKqVVSs/7PZQupYbTOH69RzmTU8G1FqCsuMMFRsTMDF95NImwrezMBy3mj7vbByvxnIRAPNNDcblBLa68yeuZ0mgDxmz/NwQ+onZYz2qBP2TtMJ2+8RTCpNphO2s8dyefLOW342TDWzyXUH4e6psPd1aDUDZV9eUuT+ZQVBzp6o3iM7TrSw7rD5nkhkGykj1KG/shUsnzImu+cJOM2gws1f/++jjK3WCyG+JIS42Lx9BVgH5AA/cPF8sfiqEGKTEOJHQohPCCE+L4T4L/ArlDv2tx3b/ghVcf+AEOL7QojbhRBPAlcAP5RSxqzGF0JciOrB/NFO8uq/A5cKIX4phPgi8A3goZ4k2BqNRjMkkVI5CodUT2Un2ytbaDBNhuaUZndVU0dC8MSd0GBW9QgPeB2DDY8PMgviuoyzy3MJ+tQJXt2j3IzxZtntZ3oj0qJuad5bGeBgbRv7qlWWcOGoHLKCA2/J4mTuqCz+9eFJ3H/zRKaW2K+H0akrS1sEalvMSQ6P2aM4kiKjyoYKMA2PPCOmR1uUbT3eTE2zYyLGCAM9ZIA8qoXUmkN2kD27NBtKZ9jbODLYKcdoU6+5RwVq80fb6o31h01VhSdgZpcbU/f/iYdwo7p5g3ZLLydW0J/KdlhGxHwNvUiIto0aX5jh+uewR6rMzHL2sGgf5KRx3tcgYMq72+pVhrntBPiyk9pu76aFtpjzb2+bk3iJbCMVaoID7wJw2DOKg7IUv0ewuDzbzizrtlGDHteCZSnlOlR/Yx/wY+AZ8/ZD8zzXSSlXdXsAd3gFJa/+ACr7+32g3Py7SEoZnf6WUtagTMn+BXwElSWeAHxCSvlNYiCEyAR+D/xKStn5l/F+VPuoq4GvAo+jWk5pNBrNyYXVU9kT6BKArD5oS6DnjowhwX7tp3DI/KkomgBf3Alf2m0fp2g8XP2buC4jK+BlSbnKNOyrbWXX8VY1eDPC6hp7ChKkVHJtIxQNOtKZN/fa0vZFowcmwe6Jcybl8ewnpvLLq8ZTnBXb9uSOs0yRlzdgZudTFIyZWWUASmdwlvlekMBrOxzto3qTS3q84M1kzWH7eSwY0ylYrkgjh/twi/mcVDavrCBAkfm/2lzpyK75csx2PmkgY46FETE/p83qWmNhZZdDKcwuG+1RCfaxhhD1rUq1MqEwiRLscDvUHlDLyZJgO8kdDtMvs+9X7YSD65M+0Xj+5HyGZav3+nM7amhsi5jy/aCZXXb5PXLwbWhXv2kvh2YBMHN4FgU5HpAREAH1/aEZ1LiqK5NSPgWMRQWM/4sKGt8HjOuu/7LL5/+vlPI9UsoxUsoMKWWmlHKWlPLrUsouaQQp5VEp5a1SyuHm9rOklDGs/KLbt0gpJ0opvxjjMSml/KGUcqyUslhK+UEpZZrrmzQajcZljJDZS7O1q2wSWOkIlk8d32kAvOlxWP2AWg5kw/X3QXaJypJMPE+tr9oFJ/bGfTkXTS2ILj+10fwZ8OeqQXhbbfeZBiur7An2aiaWDizfY//cnDUxccEygEcIrppTyJt3zmBUXscAc+6oLJZOMtUEQrWxItKi6miTzRFHsDxyDmdOsF+XZbscAWI8cklvkNVHlATb5xEsHJ+lJnO8pry0onOzjBQRaVfSd+GPvm+FEFEp9qH6NqqbrMx/QG0TbkjP7HK4QQXB3qyeyyB8OWpiK1XZZaNNTQp5/NGsMkB5MoPlmn32ZywVwbKUULG547oVv3U/k9sLfq/g+vnKfbwlbPDomhr1gDdL1b73xa8iHna/Gl18NaL6K88bmaMCZTz294NmUON6EZYZUD4upfyplPInUson4ug1rNFoNJqhQHut2a4jJ2aQueqAyugVZ/mYOsoxkKjY3NHQ64pfwIh59v0Z77WXtz8d9+WcNyUvavryyi4zWPYE1C3c0P0AO9IC4dZBIcE2pIxmlktz/MwqS04mPOjz8v3Lyjqsu/OcEdGODoCabEiVFNuZWR45m9mjssgNqizPuw5JdTxyyTbDz6aKdgCmlGSSn22WBwybojao3Jo4A6G+EA3czEDt4Cr4w4XMy6mNbvLuXkfA4MtNH5MsJ0bIzCq3qUCnJzx+EL7UZZcjbSDD4Al0CJYnlSTxu6PKWa/ck9dugtjzBhzrNGFUuTUuM0a3ubGT0Rdgfr6FCpYj7e6cyIhE65XDws/bhvIwWDg6x1QkaXOvoUL6O5ZoNBqNZnAQtgyDREz36MN17RypV9m5uSNy8HnNIU1zNfzn07aj8BmfglnXd9x56iV2zeL2F+O+pJJsPwvLlNx7Y0UTxxtNsylfjpLltdd1NaAyImYGQg6Kwc62Yy2cMGtwF43OtV/XJLB0Uh5zR6lgpkNW2cIbUIFysoNlKe3McuFYyCjE5xGcbqoZDtW3caDGfL8Z4V7lkpsrWmiPqCzZ7OGO8gFLih1uhePbXH8afSbSqiYnvEH1GrzyY6g7xLzDtmfp6oMOKXY6mWQ5CdWbngexJ926kKrsshExM/leEIIdDifsGalywk5FsPz2vbHXv/m75F4HUFYYZImprtlW1cK6w+b73ZtlBssuZZcbDsOxrQBs8c2ghQy8Ak6f6DD30vXKQwJXg2UhxI1CiBVCiEohRCTGrRtrU41Go9EMaoyIyiqHG7uYelmscrSMmlNqBhxGGJ74HDQcVffLz4Hzv911gJxVBBPOUcvHd0D1/rgv7SLTFVsCz2wy5crCY9Zs1qmA2YlV2zYI2kUBrHC0jEpkvXIshBDcdeFoygoC3HXh6I5ZZTBbSJkGSMmUZNbsgxZTglk6Pfp+suqWAV7Z1mjWFXp7lUuuOVAbXZ5d6nhfDJ9uLx9NscmXETFrMoV6fzuyfafVPYNAyXQ3VnQKFtLBJMtJpFUFy1LGr+zw+BzZ5QS4HneH0aYylUK9f6zMctAnmFiaRAluh7ZRKQiWM/JVizWrzZpFilqq3bzAYfT1lmX05XIbqd0vRxefbZ0JwNSSLIrzvEqtInRmeajgWrAshPgS8CAwGXgb+FuM2wNunU+j0Wg0aUS4Xg1wvVkdB0sOnOZep5SZ9cqv/QwOKjdRCsfBNX/q6H7tpIMU+9m4L83ZQurF7bX2A9ZAPFTXsZZtEEmwwW4ZBXDOlOQGywCLx+Ww7DMzWTyuGxMmETBbSLkkf4wHZ73yiJnRRWfd8oo99XHLJdc6guVTxzqMzUqdwfKGfl+uK0Ql2GZW+Y1fRB8KiAjf8P8DgC2VzaoHrUU6mGRZSGlmlRtVVrkvWNnlUEPyJmYscy9vAClltG3UhIIMgv5kOmGbMuysYsgsTN55La75LXx+rbp9+Al7vfAkvW4Z4Pwp+ZRYRl87TaMvcLSRciG77KhXfiWsWkbNG5mj5uWMsFnuE9sEUTO4cDOzfAfwDsrM60rTOKvLzcXzaTQajSYdiLSacuZwj/WFKw+oAUqGz8O8cZmw+b+w6n71oD8Lrr8fsod3f55pl9uB+I4X4r68CcUZTC5R2cCVhxpobndkFXx5aoDdXqcMciLt6r7HNyh6K7eFDd41X9eJRRmMHZaGmYxUuGI765VHzI4ulhcHGZGrXqNVhxsxIqG45JJrDqgs9bBsH+XDHGZlw6ba78mKFAfLkVYVMHuDKqt8fHuHhz/keZpzPWupb4uwu6pTxi/VJlkWkWYV7Apv33vzWnXn4Ub3XY+7w6pXFn4O14VoalfvjfKiJE60RUJQYyptUiHB7kzxRBh/plo+thmOrEv6Jfi9guvnKaOv5pDBY2stoy+rjVTTwIJ4Ixytx270l7BdKu+GhaNz1O+IEEnpLa1JDm6OBEYAf9dmXhqNRnMSEe2pXK9cprupL6xvjbDtmPp5mDU8i5z6rfC8o0vfFT+HkfN7Pld2MUxYopaPbYXaQ3FfppVdbotIXtrqCAg8PmWGZPVeHmQS7LWHmmgJqQH6otG5eNLRuNsTVEGFkURJptX32OOF0lnR1UKIqBS7pjXMpiPNvcolj9S2cLROBfqzS3Pxiog90PZnQPEEtVyxOSVZNECdN9KqZOUeP7z1hy6beAT8yv8bxoujvLu3k1Q51SZZoIKM9noVtPv7qZDwZausdHt94v8XRrhDvfLO4/brltS2UbUHzF7hpEaCHYuFH7CXV6dGVHrjguLo8sNrT6gFt9pIHVmjvDaA1b55gEAAZ0zM1uZeQxA3g+XdQJK7oGs0Go0mpViO0sLf40z62kNNWEPXU0sinQy9Pgmzb4zvfP2UYl80zf55em5rpxplX7aSUobqVb2jEbLdhNMcZ73yqWXJl2DHhfCowWOkxR7UJxIjYmeziidAsKOcd4mjbvm1nU29yiWtrDLArBEFahDsDPytuuW2eqiNv5beVQyrZZT5GXROWglPNPudJ5q51/9zNu8/3vUYqc4uhxvVuT3Bbks5esXjU//PSJMKiBKJ0a6UKGYfdqcTtqVkSQpVKTb3ikX52VAwVi1vfwEaKpJ+CWMLg9GJsa3Hm1nfwehrgG2kdtkmk080KZO/iUUZjCj0RZUGOlgeOrgZLP8CuF0Ikaa/1hqNRqNxFSOs5MuR5l4zQZa5l5cIt1Z9H+qPqAfKz4bzvhN/L+Npl9vy6D5IseeMymJ4jgqIlu+vI2w4sk5CKFOy9vpB1VsZ7HplrweWTO5jjWcySWZ2uWqHklmC7Vbt4AxH3fJbB9p6lUuu2V8bXZ4/tthuh2XhPMfh1f265AETaTXbLJltw4ZNth+79k/w1QMYI1Uf2Cmew1x68EddM6+pMskC0yDQ/Pz5snvfvif8OWZ2OcG1y4b5fjaDou2VdrA8Y1Qy20bttJeLU9Bj2YmU6rWXBix4v7kuAuseTsnl3OzILv/tbTO7HG0j1dj/NlK7XwNACg+vtCtPBLteWWeWhxpuBsvtwHFgqxDiu0KIW4UQt3S+uXg+jUaj0aQSKxPkzem1vneVae71v76HKalepVYWlMHVfwJfH2q7cobDOLMe7ugmqDsS124eIbhwagEA9W0R3t7b2GmDgBko1A8aY6+61jDrj6igZvbwbEry+5mNSwZWsJyMuuUO9cqzujw8LMfP1OEq87f2WBttRs+vm5VZ9ns8nDKp2HTV7SZYPrq+/9c9EIw2dU2eoFJsbDVVF1lFMOVSCOTgueb3VAtl/nRm+G1Cb8Vo95MKkyxQBoHhBvBmD9wrwKp3jjQmNrscabeziBCVYWf5PUxIpndAqp2wnYSbQLarkpbZ71NeFADr/pUSZ+wLpxZEjb6e3VFNk+VXYWWX+2P01VoX/Y6pzJlKLWrybcEoc7LS7LmN0OZeQwU3g+X7gMXAKODrwJ/Ndc7bX108n0aj0WhShZSqttEI9VrfG4pI1h5q4krPm3zE97Ra6c+E6+6DnNK+n9spxd7xXNy7OV2xn95U13WDQD4ESwZNRuDtfY1YCfJFY9Jc1OXxAVZdbYKDMKcT9sjZMTc5y8wut4Ylb+/pPqBqDUXYfES9V6YOzyM3x2e+34XKmAEMn2bvcGzjgC69XxhhlZE1a2fZ9YqShIP6rPjNyZ/Cch6f+A3apZoc8C3/FexZ1vFYVnY5qSZZZgmEEXJvosqfo4KhRNUuR19zlaU0nE7YhRn4fUlUpljBcka+csNOFVYNt79QvQ99fhUwg2rjtvWZpF+S3yu4LqbRV4b6/PanjdTuV6PlJG+LedHVZ0zMUe81Kc1geXCokzS942awfG4ct/NcPJ9Go9FoUoXRprI2ovdBwZaKZiZE9vFjvyOTdfndMPqU/p172uWAec7t8UuxTx+fQ3ZA/ey9vqeuY/sci/7WSqYAZ73yGePSPFgGM9vXmngptpVZ9gZg2LSYmzj7Lb+2I8bEicmmw3WEIup9Mmuk2ZLHE7QdvgEy8iBfueFSsWlg194fLAm2WTvLpsftx+bdbC97Mxg27Qy+Ff4QAAIJT37RdlK28Jky5mRll0P16ly+HPcCjGh2uWlgtandYbSZclv1mh+saac1rF6r8mSaexlhqN6rlksmpTZAC9WrSQp/jirLCTfB/Pfbj69+ICUGeDfOdxh9rTlhP+DtZxup3S9FFx+pU6qScQVB1YlAagn2UMS1YFlK+Xo8N7fOp9FoNJoUEmlRg/Q4XKM37DnCvf6fkylM6eppH4M5N/e8U0/kjYSxp6nlIxug4VhcuwV9HpZOylO7NbSz+WgSWxklAKteOcvvYVH5AOs8k4EnaAZ2CXzdw+1wzAxYh08GX+z35+JxOfjMEdC7+2tibgMdzb1mW8GyN2jWLTuCfqvfcmNl3O9H13D2V26shL0r1PrhU7tMSM0bN5x/RM7nofC5akVbvTLba3cEDJZJVjjBMmZQ6pSwmQV324Hel62yy4kI+o12s15ZlZA4zb0mJLNtVO1B1ToKUmvuFW4xs8l5SqHjM0tzCkbaHQwqt3YskUgS44qC0f7qW443s+GIZfSV0fc2UlJG+ytHAnm81TYegHkjclQnAiOsAmUdLA8p0r+JpEaj0WjSCynVIFRGbEOh7jDCnLL2m5R5lPtu08gz4IL/N/AMSFSKLWF7/FLsi5xS7I3dZxTTnSN17ew5oYK1haNyyckcBJI/T0BlXhLZmujYJtu0J4a5l0W238OCUSrQ2VpZS11zKOZ2TnOvUydamWW/CkxlyB5kW8EydJSBJxqrHAKpgtwtT9ny8DnXdan/HVNcSHG2j2+HP8QmMUWtrNoJz369Y8CQDJMsKc2sciP4EqCMsLLL4Ub3s8thR5suYIejbdSUZDphO+uVUxUsS0PVh/vzIVCg1vnzTCl8U6c2Un9PySXevDCG0Ve0jVRT/CUHJ3ZDnWpZeCB/IRGUEmneSLNe2TL36qVvu2Zw4XqwLIQ4RQhxhxDi60KIb3a6fcPt82k0Go0myVjZwV5chAHkG79keus6AA5RSsaNf+2boVd3TL/SXu6DK/bSyXnRjOIru2sHfh0pwinBTvt6ZQsh1CDSaFWDykRwpGdzrygyxJnjlfmQIeH1rSe6biJlNLNcmptJ+UhHEOTLNJ+LGZgPdwTLFUk0+bJk7Z6ACj4tCbbwxmzHJjwe5pfl046fD7d8lkhWiXpg+3Pw7p8cGybBJMtqU5XINju+bHX9bmaXjbB6zR0GTjs6OGGnqG1Uqsy9Qg1K0hzIt1uwefxqAkR4YOxCKByn1u94EeqPJv0SL5yaT1GWurZntlfT3NnoK97JlJ3PRxeXy7nR5TMnOsy9dNuoIYdrwbIQIlMI8SzwDnAP8B3g2+btW45ljUaj0QxmIi3q1ptscusziHf/DECzDPLn0u/hzR/hzjXkj4Yxi9Xy4XXQVBXfbhk+TjPre7dXtXCotp+tQ1KMM1h21t+mPR7TSTpRUuzDa+3lkXO6384Ic1a53Wrr9e1d3z+Ha1uobFDZ+1kjCvA4R0yeoFJVGDGy2Ml0xDZMh3FPEI5tsdsIlZ9t11F3Yt5YlWWrpJB35/w/O8B5/Rewd7m9YdQkKwHZZWmYLaqa1HkShfCq95yb2eWo87g96WfJsHMCXsaWpMgJOxVtowzTEdySXjvx56r/baQFFpjZ5RS1kQp4PVw3rwhQRl//XlerHvD4VEAfbxup3S9HF/9RPRWAETkBJo4wJ6sstZU29xpSuJlZ/iZwEfB9lJmXAD4IXAIsA1YC3WuiNBqNRpP+SMNsD2L0nFmu3A7PfT1698uhj1I84TR3r8WSYksDtj/f87YOLpo2uKXYUspovfKwLD+zy3qRwqcTljFWooLlI2awHMjuOXgwQswZnUN2QMkoVx7sGiyvdtQyR829LKJ1y+YAO2cYZJtZ2mSafIVbTFOhQCdjr65Z5ehDZfZzebl+PJz/NfOeafhVe1DdTWR2OdSgapU9mYk31XM7uxzpGCyHDcnuKvV+Li/KwOdNYqBUtUv9DeSotnrJxJLR+3OVBLtzgGhllz0+mH6x+kwCrP8XhJLvF3HTgpLo8j/WOD7v0exyY4y9HIRaYZ/yA2grmMiWZvU7Mn9kNl4PZssobe41FHEzWL4WeERK+U3A+qU4LKV8HrgACAAfcvF8Go1G4x6JkoUONSxjL08PWeWWWnj80xBSdWC/D1/OU8bpLJpQ2P0+/WFG/6TYF0yxg+WXenBCTld2HG+lqkm1Llk0Jje5bWoGivACQr2PpOHusdub4PhWtTx8ip0xjYUM4/cFOH2iyrIeqGniUHXHusW1B2qjywvGdnrvCo+prJD287DqlmsPqM9AojFCStIu/Gp561NqfUYeTL2i293mlOVbXvJsrGiCuTfA7KvVitY60/DLDI4tkyw3WzAZYRVkRVrV8RON8Diyy70ERPEQaetQr7y/uo32SCqcsCNQvUctl0xMfjYz0qwmDAL53XtX+HNVxtkr7PdYSy1sfTppl2kxvijImRNU9ntzZTObjzqMvmRETQL31EbqwFuqVh3Yk2cb580fZSp7LHMvXa885HAzWC4DLLdr690WAJBShoF/AN1PdWo0Gk2qiLRCS6UymtH0TLgXF2wjAk99KZqdWu2dw0/DN5AT8DF3vMty4YKxMGqBWj64Gpq7dzV2Mio/wKwRyrF2zdEG6lrD7l5XgrGyygCLRg8iCbaFlZF1O7t8dIMjcO1ByCYlYIA3yFmT7GzTq1s6ZpeteuWA18OCCXldj+PNMDOvbV3PeXRdP55AH4m2jMqAPW/YAfqM99pZvBjkZfiZOFwFDVuqQhiRFrjwm7Zs/bipCpEyMSZZoXpVq+x1sVVUb0Szy40Dm6SJTlDYEzE7nU7YyQyW649A2HzvJdvcS0bU6+nPVQ7Y3eHxq208Pph7jb1+zd9T0kbKmV2+zzL6gvjaSO2yW0a9GrHrlU8bb37WZEi9L3RmecjhZrDcAHgdywYwyvF4HeBSsZpGo9G4SLhZDd7idcQ8WTEithyzu6zdsl9F6x4juaO4rekOIniZNbKQjGACBsZRKXakb67Y0wrUNRrw3OZ6968rgTjrlc+ePAiDZW8gMS2knOZeI2d3v50Mm0Ggn7Mm24PnZTvtYLk1FGHLEfW+mDY8n9zsGMMlq9+y1UJqeAqCZaNdZfU2Pm6vn3dTr7vOKysAoKHdYNexOvAF4apfQZbpGrztWVj5V7Xspow50q6+a42wMklLFtHscsPAgn6jvUN/ZejYNmrq8CQ+J0uCDVAyOXnnBQjVqYxxoAA8vcjofWZ2ObdY1dIDVG6DQ6sSfpmduWhad0Zfmb23kTKDZekL8s9KZVhWnOVj+mjzvaDbRg1Z3AyWdwOTAKSUEWAzSpqNEEIAVwMHXTyfRqPRDBwpVZAcblYDQmNwZRmTSm+9lbc9B+/8US37Mnh30S+oRQVzc0a5LMG26KcU+0JHC6kXtg4eKXZ7xODtfUoBMaEwgwmlg3Bg5gmYmalWd7NLzh6uvZh7WXLJicNyKM1Vg91VB08gzevZcKiOsKGWZ3euV7bwBlTNrTRLOJztoyo29PtpxIURMSf3hMoo7zGFfcXlMKZ3bwArWAZ494B5rNwR8N5fOAy/7oZ9b7prkhWqU4ZhiWgV1Ru+bPU8Q/X9zy5H2lTA7/Br2F5pT7LOGJnEzHKq2kZZk8r+/Phk9B6fnV2ed729PgVtpAJeD9fNVUZfTe0G/7GMvoTouY1U3WE4vg2A1hEL2d+gJn7njchxlMGE1TGEm6GVJh1w8z/6EnCdENF3yR+A9wghdgM7UXXLf3bxfBqNRjNwrAyX8CQm2zWU6ClYPr4Dnr3Lvn/Zj3mtaVz07oKyosRcU1E5jDADo4Mr464VnTY8g7ICNeB962A9bWGX62cTxLpDzTSH1LUuGp2LZxCVK3dABMwWUi66kVuZ5cwCyB/b/XYOuaQQgjPN7HJ1cxtbDqusvdPca3ZPEz3eoAomjRDkj4GgGQRWbBzIM+mdqCNzUNV/WpN8c67vPdNHx2B57RFDTRYClC2C8/5XLUsD/vt5qD3kTnY53GK2iqL3/uyJQHjU5Ea4qf+1y5E2INJBWWPJsPMzvIwq6qFO3m2cwXKy2kZJQ712/jxVqxwvVnZ59CwomqDW7XxJScmTzA0L7J7LcRt97X4lurg9e1F0eX60v3IY0BLsoYqbwfKPgPOsY0opfwt8CSW/rgG+BvzExfNpNBrNwDFaVRDozzWzBlqKHRMjbEqwPV3day1ToJA54F58G8z7IKv2qYDD6xEsnlSQuGuzpNhGBHa+GNcuQohodrk5ZPDGzsFRr77cIcE+tWwQSrAtLFdsS8I8UFpqbLOj0mk9B4yd5JLOuuWXN6vBs1WvDHDqxILuj+XNMDNSbSo7ZfVbrtodNbhLCNbEnjcIG/+j1gkPzO1dgg0wbUQuGX41BNx83Lx2q/Z6/s0w631qubUOHv+Mqo0diEmWlNBep2qGe6pxTTS+LDO73ND37LLTUM2kPWKw54TphF2YmWQnbDNY9mdB7sjknDPcqCTLgYK+BYZWdtmXYWeXpQFr/5GQy+yJ8uIMTh+vgtxNlc1srmixr1F41GRKpNP3kqNe+YWQXeJx6nirv3JIO2EPYVwLlqWUjVLK7aaZl7XubinlAinlIinlj6VMQTW/RqPRdIeUaiZZGmoAgMeUYvfgiHmy0l1WOWrodUDdH3saXPQDWsMGGw8pefO0YfkU5SWwPcyMq+zlvrSQckixn9lc6971JJAVprmXV8DZkxPYnzbReIJKzuqWksNqGQVQOrOXjTvKJc90BMtv7a1CSslaM1gemZfJuNIepLXRumWr37IZLMtI4rLLUpoS9gic2AuVpgP4+DOgYHxch/B5Pcwerd7/O0800yozbXMjIeCib8GIWep+5VZ47pu2CVJ/TLLCTaoFlfD37FKeaKLZ5X4E/Z1aRgHsO9GGJUpJqhO2lHZmuThJTthGSD1/X17/ZPRWdnnKuarVFcD6RxI7qdQNTqOvv73lzC6b7u/OcoNIGPa8ppbzRvLM0QK1GPQyZ6z5P9f1ykMaLazXaDQnL4bZ79Ua/HiDOrvcHZEW1TbDGSwfXAX3nA57lqn7eaPgur+CL4ONh+toj6hRZI8yVjcomWQHSPvfgbaGnrc3OWVsDgUZKohftq8OI83ncxvaIqw7rAZxM4ZnU5Kf4P60iUR4VPY30uKOT8DhOM29YsglS/MymGy6Q687XM2eqiaqGlXwO2tEIZ6eRkoer5pokxEVQCbDEdtoNzOcnXorz72hT4expNgRQ7LmiAckdtDvC8JV/wdZZvnE1qdg9QP9M8mShqpVDjep7GKq8WWbZk59zC4b7RAJdQiWneZeE4qSGCw3HLWVPMmSYIfqlfw6WNC/4NzKLmcWwCzTa6K1DrY85eZVxsXF0/IpzFSTNk9vr6HFLG3BGzTbSDXak+ZH1kBrLQDNo09nX436jMwbmUPQb74OVmZZt40akrgaLAvFRUKITwohviGE+Gan2zfcPJ9Go9EMiM7ZUm+GrluOhRFSs+0er21eIqWqUbYCU18Qrv0L5KomCCv3VUd3nzsqQfXKTqzsshGOW4rt8wjOM3suVzWHWX2gOUEX5w7v7GvEbOfK4jG5SW+r6jqWfNkNKbYzs9yTuVc3ckkru9wSinDv63uj67s193LizbCzy06Tr6Pr47r0PmO1jBIe2PKkWhfIgelX9ekw88rs57bqQEjJeZ1BcN5IuPIXdtnFaz+Dwxv7bpIValDBhyczPcyPhDDrU/uYXY60Kid1R2Y8dU7YSTb3CjebwW5e9waP8WBll2dfAVa37xS0kQr6PFw3T/0uNbZH+M86R9tBq3bZUlrsejn60ObMhdHleSMdyh4ZUd9ncfgFaAYfrn1rCSFmANuAZ4FfA98Bvh3jptFoNKknKsEO25kC4QWElmJ3xppU8DgGgxses6XXAAtvgbGnR++u3mcPPs6YkuDMMth1ywDb+iDFnuaQYm9Kb1dsZ73y6WPTIEM3UNyUYluZ5dxSyOmhS2U3ckln3fJja+zGHQvGxfHe9QTtfstFE9TEESROhm20qXPtXw1NpoR0+mUQ7Fst8LyxBdHl9UcaVRAjIx0z/WMXw3lfUcsyAk9+ERprTZOsOLLLRlhllSNt8TknJwtvlp1djue7PtKuXndHVhlgh8MJe2YynbCdbaMSHSzLiAoc/XnKAXsgeLwqu1xUDuVnqXXHdyhzxiRzYwejL2fP5Uz1v7baSFn1yh4vz7fYypHFZVa9cgTwaAn2EMbNKb7fA6OBO4EFwIQYt3IXz6fRaDT9JyrB7uTKGs0uayl2lHCLer2sjIKUsPxXHbc5tCaaHTAMySrTTbisIJuyYUlwvh02FYZNU8v734a2+DJGZ5fnEjRbf7y2J72DZau/cpbfw2mT0ijw6C8eH2AMvIVUQwU0mK66pdN7loh2I5c8tbwIr7mf1TIq6PMwf0IckxKegPpsGO3q2MOmqvXHt6l6Rzcxwuq7yeODzU/Y6+PordyZUfkZDMtRn80tx2pVsOzL7hoEL/gAzDRlsy018ORXoK02vuxyqN40hcpOTl1tvPQ1u2y02+7jDqzMclGmjxFJdcJ29lielNhzherVe8Of707m1Mouz7nKXrf6gYEft4+UF2dw2jgV8G481sQWy+jL2Uaq4ZDtsj9yNm8cUt8NWX4PCyaYk8eGNvca6rgZLC8CfiqlvEdKuU5KuT/WzcXzaTQaTf+JZktjBcttWoptEWlXmXbhswe7u1+3M1oWh1dHZ+B3H2+krkX1np0zqpeaTzexssuR9g7SuZ7ICnhZUq4Cor01reyuSs//+7GGULRFzfyROeRkplHgMRA8AfVZG4gU21mv7KwZjoWMqFrfToP+3Ax/h0wrwPThBWRnxvHmFUJ9bwivCmYtKXa4DY5vjeMJ9AFLgt3War/HC8bCuLP7fCghRPQ5H61vobLJo4JaGTKzZdEN4aLv2E7flVvh5Z/b8upur7VNBVpGBHxJlCjHS1+yy4bVX9kOiFrDBvur1fu2vCgjuW3cLHMvX4byikgU1kSWPw/8LhkKWtnl8WfabaR2vaJ6GSeZmxba2eW/ve3MLptS7N0vRSeEmkefHp0cmVOaTVbQ/Ic7+rZrhiZuDmFOAFW9bqXRaDSpRkqVLZXhrv0+rfo8LcVWRFrUzesY7C7/v9jbvvEzAFY6JNhz4qn5dAunFLsPrtiH6+xevxf/fivTf7iO6T9cx+0P73Hz6gbECocEe9HoISDBtvAEbZVHfzkSp7mXJZf0BmI+XN3UMWDfeLSa6d94ltvvX9X7NTjrlocn0OTLkmDvfFWZTQHMubbfGT9nv+V3d9epgMibafddtvBnwPvugUzz87ztWVjzYM8mWaF6s1VUmrq2x5tdllK95tLoUK+8p6o16iFQXpjEyQAp7ZrlogmJq5OVUr0uARfk153x5aiAea7ZokwasPYhd88RBxdPK6AgU71+T2+rto2+PD41FtjwaHTbdUG7Xnn+KGe9st23XTM0cTNYfhh4b69baTQaTaoxTMdrEXvQHM0uG+mZZUwaVl13Z/lh2BFUePzgz1Q30zl31X7b3OvU8iSYe1kMnwHFpiRx7wpoj8+xN+C1fwrDBrSEJC0hSW2LyxLaAbB8jx0sn1k+lIJlM8AMD6DsoYMTdg/mXr3IJQPejkFHREJLyKC2uT3m9h2w6paN1sSZfFmTfEjY/F97/dyb+33I+Y5gefW+WiXD9uWo59E5CM4f3dHw643fwN7XYwea4WYVLAvRdUIynfBmmfWpPWSXrf7Knd43Ox3mXkltG9VYCe3ma55ICXa4Uf3v/PndTjD1Gyu7PPNKCFptpB6F9uSaLGb4PFw7V/1GNbRHeHy9w+hLZKiSHvN6X64bE31oUZkjWDZM35NUtkTTJBQ3g+W7gFYhxGNCiKVCiAlCiLGdby6eT6PRaPqH5XjdnaunJ6geH8gAfihgtJkS7GDHesMMM1gTHvjcJrirQt1u+gcAq8zMckFGgJljk1hbK0RHKfbu1+La7c5zYhtC3XFWqUsXNjCklCzfUw+o2sh545I4ME80Qij5otGqgpK+IqWdWS4cCxk9KBl6kUt+8eIpMdffcV4cAYnHZ7eQKplsB5QVG3rfN14M0zm89ggcNY879jQo6n/ANHtMvuVJzKajter/4c82JwxjfP+NOxWWflEtywg89VU4sb1joCkltFtZ5TSf2BHC7K3bqFpixcJoMydaYtcrA0wdkcTPpLNeOVHmXkZI/Qb68hLX7suXA1nDYcal6n5bfUraSN3o6LncwejrrXttszsjwru7jgMQ9ApOGZ+l1kvDrHF2eTJBk1a4GSyHgK3AVcDLwC5gb4ybRqPRpA6nBLu7HzhrhjjScnJLsTu31gKV1ThiZsvGLITcjoFmZX0rB6pVdmD2qEL8/iTX1naQYj8X1y5LJ+UxKq9jADV3VBZLJ/XNXThR7KpqpbJRDdoWjc7F7xsi9coWHtMcqz9S7Jp9ynQK4jP36kEuecH0UgqzOr0PygpYOmVYfNfiDZpO28LufXtsi3ttcaxJvq2OEoO51w/IOCs3w8/kUpUl23KsFsOQptFXjpooi3Xtp3wQpl+ulltq4T+fghZHFZ4VeHqDgyPb5s1U77/usstGu5p865Rd3V5pv19nJDNYdraNSlSP5VCDkl8HChLX7svKLs+/CbuN1ANJbyM1qSSDxWPVZ2BDRRPbjrXAgZXw9h+i27TIAJur1TXOLM0mL9t8TbS510mBm5+AnwBfBNYA9wDf7eam0Wg0qcOwDKsCPQ8yrezyySrFdrbWcsood71mL0+9pMtulgs2wNxRSaxXthgxBwrHq+W9KyDUuzpACME3Lx7dYd3/nFKCSBP3XqcEe9GYNM/U9QdvoP+mes565REze962F7mkEIIfvq9jzfOdF0yO/33gzTBrsNttM6y2BqhxKU8QNievtjyt7vszYebVAz6sVbfc1B5m+9FGFRz5sm3ztc4IAe/5rv0cj22DZ7+snL+NiJJfR1rSt1a5Mx1qlztll6U0Ta4MWy1gsvO4+m4Zlu1nWEEynbAT3GM53AwejzL1SrQxmy8HSqZC+RnqftUuOPBOYs8Zg/c7jL5efPVtePSjgB20v21MwzBDpvkjnPXKYaVU0cHykMbNYPl/gH9LKRdJKe+UUn4n1s3F82k0Gk3fiVhtkHqpo4u2kDpJg2XruXd2C7d6TgJMu7zLbiv32fXKC8YmsV7ZQgiYcZVaDrXAntfj2u3iaQUdsstv7Ymv3jkZOM29zpk8BIPlaH/zlt5bEXXGWa88oidzr/jkkhfPGsHcMcrMqE9ZZTAD8YD6fnG6cjsD+v5i1c0eWg+Nx9S6aZf0LDuPk3ll9jHe3V2rFqw2UpFuPgf+TGX4lWEaP216HH42Efa8rLKS3szEZSQTgTdTvcahho59po1QzP7KLSGDAzWqln1iYYqcsL1+KChz99jSUJPJvgSYesVCeFR2eYGj9dnqvyf+vJ24eHoB+RleJorDvH//VyDc8Xf/XcP2IVg4xlmvrDPLJwNufpNlAS+6eDyNRqNxF0uCHaP+rAseH2BlV/s4gB8KRF2wHfLCtibb8GTYVCjuWuO52swsB7weFk1MkYzZKcXeFp8UWwjBj68YGx30Pr7lBAdrBtDOyCVCEcnb+5SZz7iCIBNHDNHaOCsj29fJqSNrzf29UDqr++3iHNQKIbjrshmUFWVy16XT+6YuEB7bNX74VMc1rov/GN0RaVWvz9YX7HVz+95bORZOR+x1B2vVgsenghiPr/ue8/mj4cqf20FxSy08awYa3ixXri1pdKhddhiWWS2jOkmwdx1vjeYdJxQlUYItpcq+gumE7XJGO1QPviwI5CdPQu/LgQnnQtF4dX/XK1B7KDnnNsnwefjw9DB/C/yIImFOTgqPmlT3ZfCuVJNfPgxOm+jw4bDKuXSwPKRxM1h+G5je61YajUaTKox2MFqUbCqeQbDnJM0uS8Ou13ZmVPYus9vVTLmoy2vY1BZm8xFlRDW9tIDc7AS1NOmNUfMh38y47Hmjo3t3DyyZmMc3LlJy7IgBd798LFFXGDcbjjTR2K4maxaNzk1uBiuZeAN9/6wZETsQLZ5gu+rGog9yycUTilj25fNYPKEfyghvUN2Ky+11xzb2/TidibRC8wnY9aq6nzdKBRguMKU0h0y/+qxurqi1H7Cyy53bSDkZfwbMusq+f2IPHN4woDrqlOHNUIFxqN7OLkcsc6+OwfKO4/YEQlLbRjWfgNY6tey2BDvSpkzb/HnJldALj6qPjmaXZfLbSDWd4BOHv8ZooQy+Nvhmw+fWwBfW0fLp1WxATQxPL82lKNcMnaShJi+0udeQx81g+YvATUII3T5Ko9GkJ725YHfGaiHVXWZlqBJp7ZpVBjXjbzHtsi67rTtYS8RQ+ZaU1CtbOF2xQy0qYI6TmxaWMDxHBVRPbj3BvhOpzS4765UXD8V6ZQtPQA3UI63xG/xU7YCQKRN2yp5jkSy5pDdDPRe/z5bIVmwe2DGNiPo87nzNlofOvlbJcF3A5/Uw25Se765qoKXdNLny+FXQJIT6HoyFlFC5o+O6Fb9LukmTKwihnm+4SdUuS6kyy8gu9cpOJ+xppSky93IzWJZSPedAHvgLkj/Z4cuBWdfYE14bHo279d+AaWuARz5CoH4/AOuMcm5qvJPt1WqScu2hJkLm79q8kZ2zylqCfTLgZrD8C6AB+LcQYr8Q4nUhxCudbi+7eD6NRqPpG7F6BveExwcYJ58UO9JiSikdg8BICHab9b+5pTB6cZfdrJZRAHNHpzBYBrtuGeJ2xQYlx/v0EtUyKiLh7pcrXL6wvmHVK3sEnDNlCAfLoEz3DFNuHA8d6pV7kGCDnVkWCZaWevxKkSLDUGoajjUdh/qj/T+m0WZKsJ0u2P3vrRwLq99yRErW7K2zH+itdnnPG3BsU8d1x7YoFcpgxOeoXY40q8mbGK3GdjicsKePSlHbqJLJ7h033JS4nsrxIDyQPcJWKbQ1wOYnE3/eUCs89gmo3ApAffZ4bm3/Mk1kcv/bKsv87gFblr9wdOf+ytrc62TAzWC5HPABBwADGAtM6HQr73ZvjUajSSSRNlOC3YsLdmc8GWbd2kkixZbm5ABGx0HAoVWqDybA5ItUjWgnVu23zb1On5wCcy8noxcqqSrA7jcgHGcABlw/v5iRueq5P729mt1VqfnfN7VHWHNIBSkzhmUxvCBFsvZkYbliG3Fm853GWSN7MveS6uYNJidj5stQQflwR03/QEy+Iq0qSLIk52MWwrBpA7rEzjjrllfuqbUf8AZVwCxl7D7Yb98b+4Bv/SH2+sGAz6xdDtWr5xwjeLQyyyNyAhTnJvFzeSIBbaOMsJqk8uUpCXaq8GXDKR+ya+DX/D2xCoVICJ64Ew6tVvfzRhG46c8YpmneU1uraQ0ZvLNfBcseAaeXxzD36qZvu2bo4FqwLKUcL6Wc0NvNrfNpNBpNn+irBNvCG1RZ1pNFim31VvZ0ep12OiXYl3bZLRwxWGOae5UX5zKyOMUDCI8HpptS7PZG2Lc87l2DPg+fPlv1jzYk/Oyl1GSX393fSNgUNCwakzsoy0D7hCeoakbjnZiyMsveQM/Bo0yyY63HrFt2BjMV6/t3LKt10ZZn7XVzbnA96J83tiC6vOFwbccHfTnK9CkcI7ucka8mBzp3F7Bcsgcj3kwzgAyZSqSOwXJjW4TDdaYTdlFGcj+Xlgzb44OCse4cM1wP/hxl6pVKB3PhgZJpUH62un9iN+x/KzHnkgY881W7W0J2CdzwFzKKRnH1XDXRW98W4dG1NdEJy8nFmR0nLHXbqJMGVz4VQohsU2Z9mxvH02g0GtcJN8fngt0Zj5+TSopt9XJ1TipICTvNKppgbkxjoW0VDTSZtY5zRhamR2DndMXugxQb4Np5RYzOV4Pk53bUsLMy+dllZ73y6WOHuAQb1GDZ4zXN5cI9bxtut+W/wyergK07ki2XtOqWix35gaP9DJatvvBbzfevLwNmXTvwa+zEyPxMSnPVd+PmY7UdH/RlKmdsI9T1/3LNb+Hza+EL62DGFfb6JZ91/RqTii9bZZYhRn9l+7tgQmESJdhgZ5YLx7lTsx5uAYTKKvvSwMHcyi5bJKKNlJTw4vdgq9mvPJgL1/1RvabAzQvsnst3v3aEtrDKbs8fmWP/rkmpPBaSpVbRpBRXgmUpZROwyI1jaTQajetE+uiC3RlP8OSQYhsRNTBHdGwbUrkVGsyay4lLVY/VTlgtowDmpNLcy0nZqZCjMsTses128o6DgNfDZ83ssgR++tIAak77yXKzXjnD5+nYrmQo4wnGJ8U+tkl9riF+c69kySWtFlJZBZAzXK3rr8lXpFW1a2sw1Q1TLoSs4p736SdWdvlYQwvH6jp91/mywZ9tfj90w4Sz7OW98Ss50hJvpnq/xHCFdgbL5clsG9Vco9ywAUomDfx40oBIo6pTDhQM/HhuIDww8QLbvGz3a1BzwN1zLP8VrHtYLfsy4Jrfw3BbmTJ5WCanlKnv25pWe3Jo/ijHe0Gbe51UuKm3WIduHaXRaNKRSIsagHeWCsaLN8OUYg/xYDlWb2Wws8oAUy+JuevKfXa98qkTU1yvbOHxwIwr1XJbQ58lfe+bU8TYApVdfnFXLVsrkifFr2wMsd3MZs8bmU1edgrlkckkXim21V8Zeu6vDKmRS1otpKy65bqD0FLT8z6xMNo6Gh251Fs5FvPK7Emud3bVdnzQm6X6EBtt3Stsxp9pLw/2YBlUNj1G2Y6zbdT0EUlsG3XCZSfsUIP6vwbyktdTOR78OXDKB807LreRevevdj29xw9X/R+MWdBls5ZQpMu6b760l9sf3qPuWGoVXa98UuDmr++3gNuFEOe4eEyNRqMZOBHTYbdzHW68ePxmW5uWoS3FjjSbLtidJhWsllEeH0zpGixLKaNO2CXZQaaOTuIAsjecUuxtz3a/XQz8XsFnz7Gzyz9LojP2m3ttCfai0SeBBNvC44uvhVRfzL0wki+X9ATNWmqHydfRdX07hhGGlhOwy6yrzBkOEy907RI74zT5Wr2vtuODQpjBYze1ywDZxXaW//Dq5LX+STLWJJYApo1MZtsohxP2QINlo11NIvnzwJdm3y9CKLf3oGk2tuExd95LGx6D135inQQu/zGUL4m5adDbNTxqi0Bti5lpliFl4qczyycFbgbLHwAOAq8IIVYLIR4WQvyl0+3PLp5Po9Foeidi1vwJ38AGy94MO0M9FDFCqi7b4+1Yo1d7CCq3qeVxp0Nm16zx4doWKurVAHLuqCJ8vjSq4Rp7OmQPU8u7Xu29FrYT751dxPgiNXnw8u5aNh3tQYbqIs565TMnpNlgNtF4g+YEVw+ftcNmZjmQ3XMLHRlW7+dkD2o9ATU5V+JoAuLMhsdDpFXV2ofMTObsq8GXuLY+c8bk4zE/upuO1nbdwJelbkYPExkTzOAjEoID7ybkOlONJcMenRegIJmKjw5O2AOQYUup6rH9uUp+nY41t5klMPd6tdzeCJufGNjxtr8Az3/Tvn/Rt2FabJUUEDV47MwdZ6m2grpt1MmFm5/yDwEzUZNt84HrzXWdbxqNRpM8jH66YHfGGsAPVVfsqAt2p6zwLocL9tT3xNzV2V959sg0qVe28Hhhumk81FoHB97p0+4+j+Bz59gDp58mwRlbShntr1yY4WP++DTK1CeD3jwCQs1wXPVFZfiUniWkqZJLCqG+cxy1kFRs6NsxjDbY5JRgv9+da+uG7KCPyaVqYmbrsToiRqeAWHhsaXJ3tcsTHFLsfSsSdKWpo641TEWD8j4oL8pMbpxp9VgWHigc3//jRJrVZE4gv/+lSYlGCFj8Edude/WD/Vd17VsBT33R3v+cz8O863vcZemkPKYN7zhmmDsqi6WTrNZaEfU9lUr3cE3ScLN1lCeO2xBvEqnRaNKOcMvAJNgWnoBpgNWS2N6PqSLcogbnnQdPznrlaVcQC2d/5UXj06Re2ckApNgAl88sZGKxev+8vreO9UcSm13ec6KNo/VqQH7K6ByC/jTM/CQST0B9ZsOxJ6Z8xzfbA9/ezL1SKZf0BqFgnC0nrdgU/75SQvVuuwfsyDlQ2oPc3CXmm1Ls5lCY7Ucau27gzVa37r4HR81T2X6APcsSdp2pwumKn3QnbKttVMHY/isMpGni6M9VDtjpTPFUmHy+Wq7eA/v60UbqyDr4z2dsc8dTb4dTP9LrbkIIvnL+qA7r7jxnBEIIU52UArWKJmXoKRGNRjN0cUuCbRHNLg8xo68Or5PjZ6GltuNgPT92X08rs5zp9zI/HSXD486y5eM7X1GTHn3A6xF8bqkju/xiYp2xVzjrlcek+YAW4OAq+MOF6q8bCKEywUarKg/ohPeYI0PbU70ypFYu6ckAX1C1tgIlo22Pc6LFaINN/7Hvz7k+KXJZZ93yu7tru27g8SoDJo8/9veg1w/jTlPLtQfcdzJOMTscTtgTk+mE3VoHTcfVcskA6pXDTcrhO1Cg/pfpjBBw6sft+6sf6Nv+x3fAox9XShSAOdfB2Z+Pe/elk/KYO0q10+qQVU5233ZNyklIsCyEmCGEuNy8aYdsjUaTGoxW0wXbpUFNtG55iEmxLQl259dpz+sqEwEw9eKYg/W6lhDbj6ngbtaIQrIy03AO1uuD6Zer5ZYaOLSyz4e4dEYBU4ap12f5/nrWHEqceZGzXvnsSWk4+eCkYjP851NQdwhe+bF7qgtPhtljuGtA5usQLM/p5UDh1MklPV7VgmiYWV8qjfil2OEW2Pxftez1w+yeZaNuYbWPAlh7sDb2Rr4c1Uoq0s1nYILDNGnfEHDFduAMlpPrhL3HXi4eYNsof776/w0GJpwHw6aq5T2vQ/W++ParPQj/uk1NMoAqIbroW32acBJCcNeFoykrCHDXhaNVVhkcE3CJ8w/QpBeu/noIIc4RQmwBNgJPmLdNQojNQoiz3TyXRqPR9IolLfa4VJflCZi9KYeYFDvcHFuq3qFl1OUxd11zoCb6UqRdvbKTDlLs5/q8u0cIPr90ZPT+TxKUXQ4bkrf2KflrWX6QKaPSeEC2Zxk8+H57QHpsE7z0//rUz7pbvAE10RXDUC8aLGcWdKt2AEy5ZIozQJ4gDHfkDOJ1xN7/pjLXA5h0AeSUun5psZg8PJfsgMo4bqmojb2Rx6cCZuGNnV3u0G95aNUt76hUE6VeAdNGJrHed6BO2NaXtC9b1SoPFjweVbtsEU8bqYZK+OeHoalK3Z9wlnK+7kcmffG4HJZ9ZiaLxzl7LIe0uddJhmvBshDiFOB5YDzwV+DzwBfM5fHA80KIhW6dT6PRaHrECKmgtrO0eKB4AkNLih1pA6NFyV6ds+6hVnugWziu23rJVY7+ygvK0rBe2WLCOZBRoJZ3vtQvs5iLpuUzvVRlk94+2MA7+2PUdA6QjUeaaWhT2fxFo3Oj7sRpx6bH4d+f7BrMrn0I/nKFmpAYyISS8AJClQc4/lf+cBPeun3qTum0ngfA6SCX9AZhhKMP9NH1ve9jhGDTo/b9uTe6f13d4PUIZo9RwdTuE/U0tXXjHm9ll8MxZOX5o6Foglre/7Yq8xgiWJnlMflBcpKpounghN2PYNkw/we+7MEX5M19v/3dvfE/0NaDqqelFh65TSldAEbPh/f+Sk2+uYWMqHGANvc6aXC7z3IdMEtKebuU8ldSyl9KKW8HZgH15jYajUaTeKLuzi7XlXkzzLY2QyVY7kaCvf8tu9ZrykXdBiVWvbJXCE6dVJDACx0gXj9Mu0wtN52wa7H7QOfs8s9ecj+77KxXXjwmDSXYUsLb98IzX+2+DVfNfvjv5+CBG1Sw1F88wS5S7ILmvfbjpTN73j8d2rt4glAyFXzm56tiY+/7tNbAtufVclZxzN7miWRemVKIGBJW762LvZE3oAJmsAMxJ1Z2OdQMh9e5f5EpoLo5TFWTes9PKMxIshO2FSwLeyKiL1i/V95B6KwfyIIFH1DL7Y2w+fHY27U3waMfs7Pww6bCNb9T+7uFjKDMvdJY8aNxHTeD5TOB30op93R+QEq5F/gdcFaXvTQajSYRRKx6ZZelcp6A6t0abh78UmwpTQl2qKtUvUPLqEtj7t4eNlhn1jVOKsmlpKCHFj7pwIyr7OV+uGIDXDAlj1lmreLKw4286Qhu3WCZWa8sgHOm5PS8cbIxIkpm/cYv4tu+YiP881Z45CNwbGvfz+cNdOm3XNDsGGL0Zu5lZZaT3TbKiRDgz7azgce39y5T3/aUGvgDzLpKmYQlEafJ16o9td1v6M8Bf5YyjepMByn20HDFtiTYABMLkxx0Rp2wx4C/j+c2QqhvFNLf1Ks7Fn/MVJsAa/7eVRkUblfeCUfNEo2CsXDdHyHDZcm5kQZqFU3ScTNYzgRO9PB4lbmNRqPRJBYjpIJAjzcxUilPsMsgflBitKnMsifYUYJtRGDXq2o5qwjGxp7n3HykjrawGrTMGVWU3ExLfyg/x27js/PlfkmxhRB84Vw7u/zTlyqQLk2aNLdHWHNQBR7Th2UxojCNJh/CbfDfz9s1g8KranH9mermy1TZU18GjDkFyhbb++5dDvdfDU9+SRnvxIsnoDI5YdsjoNCZWe7N3EtGQARSHyB4glBq1i1H2qFyW/fbSgM2OCTY8xLbWzkW8x0mXxsO13a/oTcDfLnqmju7lpctsqWvQ6RueafD3Ku8OIlO2G2N0GCqWPpTrxxpSd9+yvFSMBammQqL6n2w7037MSOs+ihbKpac4XDDXyBnmPvXYYR1sHwS4uYochdwZQ+Pv9fcRqPRaBKLVVPsSdD8nBUsD3ZXbMvZu7ME++gGaDbnPied121PT0uCDTBnVBqbe1n4gnaWvLESjsRRPxoDZ0uRtUcbWb7Hndrldw80ETJUULhodG76TD601sG/bocdL6j7vgyVtfnk23BXhXk7Ap9bDZ98AW5+AG68D669F4ZPs4+z9Sn402Xw0veVFD4eRMBsIaWkvtHMcm4p5Izofj8ZATzu1ir2F2+wo2T86Jrut63Zq0ogQE1GjFyQ2GuLQWleBiPz1XfClmO1PW/sywFfjOyyPxPKTlHLlVuh8bj7F5pkOjphJzFYrnY6YfcxWJbSXZPLVHLqJ+3lVX9Tf6WE578FO15U9zPy4fo/q7r5RCDbTR8UHSyfTLgZLN8PXCCE+JcQYq4QImDe5gkh/gmchzL70mg0msQSaUmMBNvCGzSl2IPYFTsqwY50rb/q4IJ9WbeHWOkw9zp9Uhqbeznp4Ir9TL8O0SW7/PJRV7LLKxwto04blyb1yg0V8NAH4JDZQzmzED7wCMy4puN2wqPkxh6fmkgSAsqXwAcfg8t+Yg9ejZCSUd57Eaz4Tc9mPWC7YhttiKZKMkPmBE3p9J7bwKSTXNLjh5Fz7fs9mXxt+KeteJibnN7KsbCk2JWNrRyt7cGfwZepAmYjZLeZsxjvUKTsG/zZZStY9nkEU5LqhO009+pj26hIqwqUfUNA2DnuDCg1zfL2LlMZ5ld/Ahv/rdb5s+C6e/v+GvUFw2xFl2q1iiapuBks/xz4B3AtsAZoAZqB1cB1wMNAnIVOGo1G00+McGIl2BYioILywSrFtjLjsXpQW8GyL0O1renE7fevZNrXn+GFLccAVQ13+e9f5fb7VyXwgl1i4nkQMHuM7nip35MdS8pzWThGHWdDRROv7epD7fLBVfCHC9VfB8vN+uegV3DGpDTog1q1E/5+k22Ykz8aPvRfGN9NJ0hvlsoyOhUXwgMzr4DbnoHzv6aCbVDGTyt+DX+8GNY82L1jsieoHou04jvmCDJLZ/R87Za5V7pkgEpn2QPs7ky+DAM2mhJsjw9m35Cca4uBs275nZ21PW/sz1ETJZ2zy+XOuuXB3W9ZShmtWR6bHyQnI5lO2ANoGxVpVoGy20aXqUAIOO0T9v2/XA6r7lPL3gBc/Zs4+q4PAGmo77N0UKtokoprn3YppSGlfD9wEcrM63ngRXP5Qinl+6VbhV0ajUbTHVYAm+jBgeWKPVhbSEWaIRzDBfvEHqjZp5bLl9g1vg5qm0O0hu2vcwm0hgxqmwdBixh/hu0u3FARnztxDDpnl38Wb3a5rUk5Sdcdgtd+Gg3Wq5pCbD2mBuNzR+aQn53itiQHV8GDH1CvEShJ8Iefg9IeBqPeoGpNY4S7Zhl9AVj4P/DRF+CMT6osECi5/0v/D/58OWx5umsdufCoIDPSgq/CESzHY+4l0iSzDBDIswOdY5tVYNyZw+/arscTz4G8BElJ48AZLK/eX9vzxt4s8Gar713n/694kt0fet+b/fIISBeqmsLUtKj39ITCJAeezsxycXn8+1nGXt7soZMJnXWt8tEApYoC5Z9w5c9h3GmJPXc6qVU0SaXfv8ZCiJ8LIeY77o8VQmRKKV+SUn5KSnmplPISc/nlno6l0Wg0rhFpiR0Euk3UFXsQSrGlYfZHNbr+8HeQYHdtWSOlZNH42JLrO85LoPzNTTpIsfvnig1w+vgcTh2rHKs3Vzbz8o767jeOhGDtP+D359k9QI9ugHUPA/DmXrvuedHoFEuwd7wA/7oN2sznM/4M+NAzkD+29329WSqTFe6mnj+YA2d9Gj76PMy/WQ0+QRl/PfVFuP/arpJdTxAibXgrncFyLxkkI6w+o9bxU403aGfD25ugpkvjEFj3oL0896bkXFc3zB6Tj9eUgG8+WtPzxkKo7LI3s2PfZSFsV+yWGqjYkqCrTTxOc6+JRUmWNFsTKHmjbFVMPERaTJl8GqhU3MKfARPO6bhu4f/A5PMTf24jZPZX1sHyycZApq7vBKY77u8F3jegq9FoNJqBYIRNd+cES7BBDQRFQGVoY/UZTWd66kG9ywyWhQemdGwZtWJXFe/9zQp+9/ruLrvNLStg6ZQEuI8mgkkX2JnNHS/2e7JDCMHnltomUzGzy9KArc+ozOmL37UDUIsXvwtPfYXNO2yp5RnjUxgsr3kQHr/TlkXPuALe/5idzekNX5YKmHszv8sugQu/Abc9BdMc77PKrcpM7J+3wtFNap0nCOE2fMeUCiCSPwYyejCUk4b6fKZTL1ThgRGOAP/I2o6Ph9tg8xNqObOgR6+AZJAV8DFlhHofbqusI2L08hnxZZuqgk6Th0OkhdR2Z9uoZDphtzdD3WG1XNIHCbaUyhjPm5X4ieNkIqUqD3Fy8N3ue767eu40U6toksZARpM1gPPXKl18OzUazclKT0FgIvAG7fZLg4mw+Tp1HkQ5HaLHLIRcJTPedLiO//nzO7z/T++w4VBdzEPeecFkRNrYN/dCIAsmX6SW6w7Dsf5nvE4bn8sZ41V2eVtVC89vdQTD+9+Cv10PT34Bag90f5At/+ULuz7M130PMC6jiVPKU2DGIyW88UslicYMdk79CFzzV3tiIR46GH3FUc9fOA6uvBtueVRlsC32vw0PXAdPfA5qD0HdITxt6r0XLpk2eMy9nIyaZy8fXdfxse1PK9dxgBlX9u01TxCWFLs5FGHL4V5q8oVHTZR4/B19HMafbk9cDmKTrw5O2COT6YS9l+jnsbgPyh3rd9CXlTKTuISw80U4tqnjumNbYOezEGpIrNTf8kFIF7WKJmkM5D++GviSEMIL1JrrlgghejymlPJvAzinRqPRdE+kVQ3QA0lqY+QJQrhBBZ/+/MExKDEiKhsOXX/0d71mL099D/tPNHH3Czv47/ojHTZbMLqIT541jf9bsZkNh+oGV1bZYuZVsOVxtbztGRgxs6ete+TzS0fy5n0q23H3q0e5qOgQnjd+3rEXKKiMYUttzGMECHO771luFq8TXPURWHiLCuqTQSSk2q9s+o+5QsAFX4czP98/hUZUit0cvyP9iJmq5cu+N+H1n6u6XoDtz8HOl2DkrOim4YxiejyqDCupZLoFyyPmo/IKEio2dHzMKcGed3Myr6pb5pcV8I931STPu7trmV3W1b+gA1YWM+wwDszIV5L5I+vg8Dpoa4Bgmji99wFLhh3wCiaVJtEJu7/mXpEWCOQOLQk2wLK7Y69f9TBMPBfaT5jvQ5cnCaJqlSHQgkvTZwYSLH8O+A/wS/O+BD5m3rpDAjpY1mg07mOEzSDQoww/koEQalButCgpdqJaVblJpJusMsCul6KLvzw8k18/8zphh/xyckkenzhjKlcuHobPJ8grmMEXHlnHXZdOHzxZZYtJF9q1tTtehHO+2O/B1Sljc1hSnsv+vbv4dP2/8PztrY4bjD0Vzv8mrLgH9r7e8TEpWR04hfKmdRSKRrJkMyz7lZJDn3EHzLkGvAkM+tqb4L+fgz2mRNbrhyt+AXM/0P/Bpjeo2gm1Nyijr758HsefoYx6tj+vMt21B9Rn+/C66CaR43tVJry76zNCpgNwmgXLWUVQOBZq9kPFJvs5NFbCrlfVNiWTYfTi1F6nybyxBdHldQdrgV5q1r1BZSZlZfisiZYJZ6lgWUaU2mLKRQm64sQgpWR7pQqWxxVkkBVM4nddh7ZRcQbLRgiQprHXEMuCZhaqHt6dySmFzJEQqodwoxk0Z7vXMitd1SqapNDvT5GUcrMQYjpQDowEXgO+D7zU034ajUaTEKyscrLrs6Ku2C2DK1junH1va0LufxsBbJdj+eVaW842Mi+Tj542lZvOGEVGhj1QXDyhiGVfPi9JF+4ywRyYfAFsfVKZSx3fDsOn9e9YTVX8PPtvFAT+jV84XKCHT4Pz7oIpl6k6+nFnxdz9jw+s5s3Nu/mo7yk+GXweT6QVmqrgxe+o1ihL7oSpF7uvXGg6AY99XAVuAIEcuPZPtlv4QHAafflz+rav8MC0S9T/Z8Mj8Obv1OsBGMJLuKFK1b+Wd9PCSprmXj0L3VLDiNkqWG6uhvojqh3Xhn/Z7uFzrksb5+KJw3LIDvpoaguzpaI2vp18WfZ3os9URkw4S7UJA9izfNAFy8caQjS0pcgJ+4TTCTvOYDnSol77oZZVBrj54Z4f95mTNaF6pfpqa1ITdwMdF6SrWkWTFAbkgCOljEgpd0op3wBeB16TUr7e082dy9ZoNJpORDOmSQ5YPUGVVe7O/Ted6Cb73h4xePXFZxCREADPRRYCUJAR4M6zZ/D8Z87h1vNGdwiUhwQzrrKXtz3T9/3bmmD5PXDvxQzb+Ug0UD5gDGPVvO/Dx5bDtCt7DH4ihuTN3VXUk81DWbciP70OFtxi/39q9qvM7wPXqTpet6g5AA/ebAfK2cPglv+4EyhD/EZfPeH1K8fs25+FnOGERYAtI69TwfSK38Q2ZpNS3TyB9CyLGDnXXrZMviwJtvDAnNS6YDvxegRzx+QDsLe6gcbWOEyUvJlmsOz4v4+YpeTYAPuWD7ruATs6OGEnu22UKcPOKY1Pvj5Ujb3iRXggkK+yzJkj1XKkBdqqB2bEqTPLJzWu2MUKIazpq/FuHM9NhBBZQog9QggphPh9jMdLhRB/EUIcE0K0CiE2CCE+0s1x7hFCHBVCVAkh/iaE6GIPKoS4SgjRJISYkKjnpNFoOhGtw02iBNvCcsU2WuIzNEolnSTYhpQ8sbGa83+zldqNz0c3e4PFfHjxZJ779FLuvHQCeTnpkelynckX2ZMrO/ogigq3w+oH4I8XwZu/hZCqAQ8HC/lm6IOc3343X9oxm0gcmc1Nh+uoN4OQRWNL8BaMhCvvgTvegWkOR+SKzcoh+l+3DciQLHqsB2+2TceKJsCtz8AYF+W/fTX66olDq6GxkvrMsewuNZ2zj26I7a4s03xQO3K+vVyxTj2PSvP/OeEsKIijPVcSsUy+DAmr98Y29+uAx6fkr2A7FHu8tnlb/VGojtE2K43ZUWkHy5NKkmi+F2q128zFK8EeqsZefcXjU+qpzFGQOUKpW0KN0F5jytT7iJVZTke1iibhuBIsSymbgFPcOFYC+C4Q03lGCFEALAduBP4MfBo4ANwrhPhWp81/CNwK/NZcfg/wp07HywN+DXxHSrnXvaeg0Wh6JGIGqqmSQUel2K29b5tKzB7U0hPk9V31XP7H7Xz2P/s5WtvMeR6V5ar1lvDTj3+Ib149hRHFaRpwuEVGHkwy+3NW74XjO3veXhqw5Sn482Xw8g+UlBaUc/GZn8H32TUcnXILIXzsrW7kiTVHej4esHxXVXR5UVmJ/UDJZLjxIbj9ZRh3ur1+35tw/zXw5BeVfLyv7F0O/7gFmk+o+6Pnw63PQsmUvh+rNywptmUo11/evjf2+rf+0HVd1LE2Td+7oxzB8tENsP4f9v05NyT/enrBCpYBVu6pjW8nn/V/d2SXJyyxl/cud+XaksWO4/bzmD4iidnamn22u3OfJNhDrLfyQPD4IVhsZppL1WsTqoP2Wrv0oTcstYo3eHJPQJzEuNmIdB0d+y6nHCHEfFQ/6G93s8lXgEnAB6SUX5NS/lFKeTnwJHBXp+zwdcDPpZTfk1LeDfwvcKUQwvnN+UPgBPBzd5+JRqPpEStQTZXszBNUs9XhAQYFicS8vvXHItz89z188KHdbKlQg8DFnm3kC3Xt+XMvoXxM6tvWJI0Z77WXtz8bexsplQHW/dfCU1+ysz0en3Kt/vS7cOH3IKuIOy+cHN3tly/tJBzpuZXJCjNYFsA504u7bjDmFPjQs/D+R2D4DHv91qfhT5eqVk9NJ+J5pqqP72OfiGbCmXQ+3PLfaIsw17EMn4xw/APTWGTkgy8DfGbfZF9A3c8s6LqtJZcUaRosZ5fYr/fR9apeGZTE1lkWkCY4g+WNR2ri28mboeTYHVpInWkvD7pgWU2CBn2CiaVJ7N3tNPeKp23UUDb2GijeIGQMg4yRkFGq7rfXqNrm3tpNpbtaRZNw3AyWvwXcLoQ4x8Vj9huzpdUfgeeBx7rZ7P3AXinlvzut/zngB5zTvNlAleP+CcALZJjnOw34KPBRKWUSuqNrNBrAIcEWyZdgWzhdsSMDqItKIHuOneCTj+7jvfcf5a19jdH1i8fk8tMp9qBMTL00FZeXOqa8xx4E7Xix6+NHNyj586Mfhcqt9vrpl8MnlsMV90BeWXT1zFH5vGfmCAAO1Dbx2Orus8st7RFW7VMByJRheYwZ1s1AXAglGf/4CnjfHyB/jFpvhJVr9r0XwfJfqxrqWEgJ7/wJnv5fWxo770aVuQ720g5ooPhMR9qBqC6u+S18fi3ceL+6f+P96v7Vv+m67WAw4hkxR/1tqIBmc1gx/VJlsJZmDM/LYGS+moTcHK/Jl9VzWXhtCX7ucBg2VS0fXKkkxoMAKWW0bdSEggyC/iRmFp1to+KRYUeNvU6iyc6+4suEjOFKmh0cpt6j7SeURLu7Wvp0V6toEo6bU08fAA4Crwgh1gE7gc5pFimlvM3Fc/bEncAMVEa4C0KIEUAZ8FCMh99CtblyFnCtAD4hhFgBtKCy0luklLVCCD8qMP+9lPKdvlykEKIMGNNp9SyA+vp6qqur+3K4hFNfX9/hr0aTciIt0FoNCGhp7HXzhGFEwKiFoK9b999UfH6ON7Zz74pDPL7hGBHHWGByUZDb55dw/vRMCv/xGgBGIIfagrmQZt87iSZn7FkE9r0KVbuo3bsJo3A8ntr9ZK38HYG9L3fYtn3MabSc/kUiIxaoIDbGa/XhxaU8v7kCCfzqxW2cW56Jz9N1kP32vlrazczz3BE51NTE8bqXXQTvP4fgxgfJXPlrPK01KlP85m8w1jxIy4LbaZt+td1uShpkvfVzMjb9M3qI5kWfoPXUL0B9M11/pl1GGtAaURmcwMCMneobmzv87XouqV6LjCxoizMLmgIyC6eSyfMd1tWVX0kkTT93M0dkcbSulaqmNjbvPcrI/DjKXYx2aDMgXA1+ZUyVOXIxmce3Q7iNhm3LCJWd3stBUs+R+hBN7eozWpbno7o2eb8xOUe3Y02f1fhKkT2dW0oI14G/ENpbQHScjNBjtxjIAEQyIWyoCXejBjyZSinmlFuHGsHnh/ZG8KS5L4mmV/rzGXAzWP6QY3m+eeuMBBIeLAshxgHfAb4npdwrhBgfY7PR5t9DnR+QUrYJIaroGMR+FvgvsMq8fxi4xlz+MlAI3NWPy70NlZXvwrp162htTc/Z1/Xr16f6EjSaNKX3OtJkfH5awvDyEQ+vHxW0G/YPf0lQctlYg3nFTXiam9i0bB9Lm44BcCR7FqvfXtXdIYcsZcYkFqD63J547Y94jBDjTryOB1ueV5M1gS2jbqAqdwbsaoZdPUtJ5xV7WHvCw5GGNn7xnxWcNrxroPjf/R4sgVdx+CDLlh3ow1VPxjflR0ysfJZJlc/iM9rwtNaS/ebPYNXf2Dryao4WnMKC/fdSVPsuAAYe1pd9iAPh02HFm304l1tUuHKU9Vv3J+U8iWJEreBUx/3G4Ahe2xOObViWBmS3CpSQDh59dSXzivs36VHSPBpLjH1s1dNsrihw5foSyeYa+7lnhmtZtjJ5kzDnHd1GAGj15fPGxqPA0Tj26vm9r8duA2FwGdNpYrNt27Y+7+NasCyldFPSPVB+B+wHftbDNpZOpbtpolbHNkgpdwohZgPTUBLtLWZQPQn4OnCzlLJeCPFJ4JNALiq4/rKUsqfeGX+GTlPMKrN877x581i0aFEPuyaf+vp61q9fz9y5c8nLS7B8T6PpDcOAtuMQbgR/fqqvRmXPfBlK3hVDspXoz8/X/r2RbRUN1Iegtg0M7CC5MMPDB2bnc8P8YrIcLaAyV9kD9IJF17Jk2hJONkTrbOSf/oowwkw8/kKHxyJ5ZTSf9lnk5KuY7o1f5j96RjPX/Xk9EnjlWBZ3XjUPv7fjz+Tv9mwAmvB7Bdefdzr52f0pI7iIhuavkfnOrwhu/ifCCJPdXskp+3+PccCHx6wKkt4gTRf9jHGTLmNcsk1qjHbzc9oG/v6/7+sbm1m/dT9zp48jLyeG1DTSBkTU58+XRNfiPuJpKIe9v7LvZ+SyZMmStDUPyj5YzxP7NwPQFCxjyZJx8e0YboLWKuUg7A1CZCJy3y8R4VYmhHZQtCitbG5isnt1NarqDk6bXMaSmUkyzoqEyFlXCYB3+GSW9PZaheqV/Do4LGarOj12iwPDgEiT8h4JN6HqvzPVumCJctfWDHoyMvrubTPkHACEEDcDlwDnSCl78oe3dFzd6Yky6TRFZ9Yib+q03R+A56WU/xFC3ADcjcoWHwTuQ01JfrK7i5BSHqRTKkqYP5h5eXkUFXXpTpUWpPO1aU4iwk3Q7AMK0sP9M+JVgUFWZo9BQaI+PzecNZ1b71vZZf0lk4v47vkZDBs2vOuA/JAZLHt85My7GrJOxs91EZTOVIZLFhl5sPTLeBfeTq6/74FXUVERV847zhPrjnCssY3ndzRzy5l2W6Dqpna2V6oa4zkji5hQFrNpQ7wngzG/haVfgJe/C1seB4gGygBi6VfIPfWW/p9joLQIaKmAYOaAvQXycrIoKohR6hAywJMFWSWpc8aPh8JCVZ/crmS1WXU7yapeA5MvTPGFxebMnHy8YgsRKdlxojX+7y4jD1oMaG+AoPn/Gnca7H4Nb+1eijz1kDcqcRfuAocabPO8U8oLKSpIksFX1c6oKZ6/dErs97uFEYJQEDKHQ0ZJ99uhx269U2K+nvUQalASbJGtfhd1sDwk6M9kkevZYCFEthDiAiHE+4UQpW4fv5dzB4BfAE8BB4QQ400JtiWnzjXX5aNk1NC1XhjT4bqYGBLtTtt9CFXX/Clz1W3AY1LKh6SUyzDbTQkh0inrrtEMHcJm32BPmgyMPRkqWA73JCZJHEunDiPL3zEQmTY8h99eN4xhBRldA+W6w1BpSpLGnQ5ZMdyYTwakhLZO9YAFE+DUT0E/AmWLz54/GatU+Tev7aItbDtCv7X7RNRPZtHYnge4cVM8Ea6/H25/FQK5HR/b9nT3BjbJwA2jr94YTEY8nd9Xr/0wtf+fHsgMeJk6Qr2ftlXW9erwHsXjU+3DMGxjuQln2Y8PAlfsnWbbqCy/hwnDkvi+cjph92bupY293KVzuyl/PniS6IKuSTtcDeKEEJ9ABaEvAH8DZprrhwkhWoUQH3XzfDHIAoYDlwN7HTdLZ3izef8TUsoKVDAcy2HiNFQnj64pGhMhxDCUzPsuKaUVVI+hY5b4IMot26WRkEajiSINu49nurTJEEJJDiPNKXHFXnewluZQxxY9X7moDGG0xW6rtdNhXjX1PQm+ujRm54tQvbvjuor1sOulAR22fFgO75uv5mOPNbTw4Jv2/Kuzv/KZE13+iWiuUtk8J4dXD/j5DAhflpI0JrS9Wtg050nz+emdL0LT8Y7rUv3/6YV5YwsAaA1H2Hy4DyZX1v/dmiTpECyvcO8CE4DhdMIuzMDvS6YTdpxto6RULbq85uuscQ+r3VTmyPRQrmlShmu/KEKIa4DfAK8Ct4NdLCelPA48B7w39t6u0QS8L8btY+bjz5v3rVZSDwEThBBXdzrO54Ew8E+65xeowPvXjnVHgNmO+7OBdjq2nNJoNG4QSbOssoU3Q9VOGsk357vvzX0d7s8dk8/SCQHVTieWLHXXK/bytCsSe3HpzLK7Y69/oyfbi/j4zPmT8JoZ/d+9votWczJj+S4VLOUG/Sya5HK9fQKfT78RHjXg9PjsdkJuYoSBQdILNR3/P73g7Le8cndt/Dt6M1XAbE1sFo6DArPV2v637IxzGnKwpp3WsMr2lxf2vc5xQFQ52kYV95BZjrSqrKcvK21r3gc96TIZr0kZbr4DvgS8IqV8nxCiGPhTp8dXAR9x8XxdMGuUH++83uGGvU9K6Xz8R8C1wANCiIWo4Pe9qMz096SUMa3vhBAXonowL5ayQzfzvwN/EUL8EpW1/gbwUKdtNBqNG0Ra1S0djL2ceILKcCzcMiAzo75yrL6Vpzcot9SS7CBBv+Cu90xEGM2xJxRaauGg6Xw9cg7kj+26zclCZmFsubUL9dvjirO5ZuEY/rXqIMebWnlgxQEunl3KwWoVPCwcU0xG0OVBbgKfz4CwpNjhFvdrimVIDWoHQ7Ccrv+fHpjvCJbXHawB4vy+EB4VMHvMnsveoMour/0HtDXAkQ0wZkFCrnmg7DhuT3iWFyU5a2tlljMLen5fRFpUyYWWYGs0CcPNYHk2qoVSdxxFSaTTBilljRDiLOAHqEA+D9iFkmn/PtY+QohM4PfAr6SUazs9fD8wEvgEkI0K3D+bmKvXaE5ipGHKOWX6zfoKjy3FNkJJG7w/+M4BwobKgty8oJzPX1YObdXQcgJ8Mcxh9rweNZBhysUnd1bi5ocTevhPnzeJf685RNiQ/P6N3Xgdb1nX6pWdJPj59BtvELzZSiIuDXfl0oOpXjld/z89MHFYDjlBH41tYTZX1PZtZ6cU2xuE8WawDKpdVroGy5W298TkkiRmlo0wVO9Ty8WTuv9uNsIox+bswfG+12gGKW4W9kSwmtHFZhRKJp10pJT7pJRCSvnxGI8dlVLeKqUcLqXMkFLO6i5QNrdvkVJOlFJ+McZjUkr5QynlWCllsZTyg1JK3QFeo3EbK6vsSbI0Ll48phQ7khyjr7ZwhIfeUb1nM/1ebjy1zJ5QMCKxzUmc9crTLk/KdZ6slBVlcf0pSnp6ormNn72wPfrYkiknmaVF1OjL5c+GlVkWOmhIBB6PYG6ZUvHsq26kvqWnZiOddw6qmlrZrmpsx55qB3dpXLfszCzPGJXE35qag2qiFXo294o0q8+SziprNAnFzWB5PXBxrAeEEF7genowzNJoNJq4ibTYkj43OLgK/nChLUseKN6gGSwnp2756Q1HqWpUhmKXTBvDqBK/OrfRGtvYK9xmD1ILxkLp7K7baFzljvMmRY08mtttE7br/vw6t9/v0vtuMODNTIzRl4yooCxGj1mNO1h1yxJYtacu/h2FUAGdJ6i+l4LZMHq+eqxiEzTX9HqI2x/ezfQfrutyu/3hmNVyrmAFy7kBL2NLkjgJc2KnvdyduVfU2CtbG3tpNAnGzWD518AlQoj/h+3+7BNCzAT+DcwA/s/F82k0mpORqATbcEd6JiW8/EOoOwSv/dSd9i3Cowbt4WY7Q5AgpJT8dcW+6P2bThmnFiItEG6NPZDa/xaEzGBl6sU6wEgCowsyKcnpOrnTFpbUNiffOT1leLzuG33JCODRUtQEM6/M7jO7am9t33b2ZamJO8NUFJRbrtgS9r3Z6+61LRFaQrLLrbYlMQZhYUOyu8p0wi7KwOdNYplKPG2jtLGXRpM0XAuWpZT/RNX+fg3YYq5+FtgAXAF8W0r5rFvn02g0JymRVjWj7pYEe8NjUGl+ZR3doGro3MCTacvFE8iaA7VsPKyyPIvHlrBwcq6SXoeb6Lamu0PLqEsTen0am/+9ZFrM9Xec10NrmKGI21JsYxCZew1inI7YG4/U9m1nj1/936WhJjfGO1tI9f6de8dZpTHXG1Lyi9eO8uzWWvaeaCViuNOren91G+2RFDlhd2gb1V2wrHsrazTJwhVnHLPncDnwV1QW+f3ANFT7qB3A36WUJ5HOTKPRJAwrY+rPHfixpITXO7Vxef3nMGHJwGfrvUFoa1TX68a1doOzXdR1c8fjMVog3KCy2rEk2EYEdr2qlrOKYOxZXbfRJISrF4zmR89u5XijnUmeW1bA0inDUnhVKcBtoy/L3EvXKyeUYblBRhdkcri2hS0VtUgpEX35noxK8Ftg+DTILoGmKti3otf3weKx2WT5PTSHOjYXWXOomTWHbEl/pt/DlGEZTC/NZFppJlOHq+WCzL4Nd3emgxN2MA+yY3w3aGMvjSapDChYFkJ4gN/Ssa/yu8D7pJQVA7w2jUaj6Yg01EDLLQn2un9Ca23Hdce3w44XYepFAzt2Byl2OCGu3RV1rTy7UbWLGp2fyRWzBbQehVCjcuT2xQjSj26A5hNqedJ54Ith/qVJCEIIfnT1HG77mz13fOcFk/sWcAwVfFl2dtmXPbBjyRAIHTgkg3ljCzhc28KJ5jYOVbdSVtyHQNKSYrfXgMiB8WfC5idUwFy5HUqnx9ytLWzw8Uf2dQmU84Ne6toiHda1hAzWH2lm/ZGONfEjcv1MK81k2nA7kC4vzsDfjbx6u8MJe8qwZDphR+CEWYddMjH2pK029tJokspAR2+fAj4KHAHeAiYDpwJ/REmvNRqNxj0s06pYfYP7w/JubBSe/yZMuWDgGS9PhpKMR1rA4352+cF39kfbRV0/I5+MSCUYqN7T3QUOWoKdUs6bPpy5Y/JZf6ju5MwqW3jNdkLtNQMPlo2wqt9MtzZyQ5D5ZQXRfu7v7KrtW7AsPOp/HaoDo10peDY/oR7btzxmsBwxJJ9/fD/L9jQA4PMIwoZk7qgsHr9tCtXNETYebGHz0Ra2HW9l94kWdte00BbuKMeuaAhR0RDitV12gxK/RzBxWJDpwzPNQDqTP719jJUHGsmJ1KO6icJnn9zFki35/OnG8j68Uv2k7hBETOVJLAm2Zezlz9PGXhpNkhjoL8stwFbgNCllA4AQ4o/ArUKIQill7xaHGo1GEy9WDXCsjGlfOb4DWqyvKAG+oJJ3A7TWwVu/hzM+ObBzeDOg7URCpNitbe089M4+ALJ8ghvm+NRAtDeHcCtY9mXApAtdvSZN7wghuOuyGXzhkXXcden0kzOrDLbRV6huYM720lDZt1jt0TSu46xbXr2/hmtPHdm3A1g9l8MtMP4MlChRJyd3EgAAZsdJREFUwp7lcOpHOmwqpeSupw/y9JZaAPKCXj535mj+sqaCuy4cjRCC4mwfS6flsnSa/f0aMSR7qtrYeKiVLUdb2HmihV3VLRyu72ikFzIk2461su1YK2x0Dlclc8UhbvDu4KnIaeyPlCbMSKwLVb3UKxuWsVe2NvbSaJLEQIPlqcB3rUDZ5B7gNmAK8M4Aj6/RaDQKKVXQaUTckVu++Vt7+Yq7YeFtcHAl3Hepmtlf/msonQETl/b/HJYUO9Ji1pm5gDQg1MBTq/dzokkd89Ip+YwojSNDeWIP1OxTyxPOUjVxmqSzeEIRy758XqovI/X4slXwFG7pf7Cszb2SyqzR+dHs7paK2r4fwOq5HG6AzGEwYhZUbITDa6GtSbWVMvnRy0d4eK0qGcn0efj5JRO5YE42t55V3OMpvB7B5OEZTB6ewdUURNc3tEbYdKSVzUda2HashV0nWthV3Upje0cp9xhxnPsCPyFTtHOT9xV+FL6Ra876QN+fa39wmnuVxDD+C7eAP0dLsDWaJDLQYDkbJcF2Yt3Xn2SNRuMekVYVdMYyreorldtg+/NquXA8zDUHQmWL4NKfwZOfASQ8+SW45REoGt//c3ky7GsfCFJCuBFC9chQA399x7aFuHlBnNkdpwR7mpZga1KMZfQVauy/0ZcMK2MvHSwnhQy/l2kjc9l0uJ5tlXWEIgZ+bx/+b1bP5VBQZUknnKmCZSMEB96ByWoS6XcrjvGHNysBJZf+8cUTuGDOwOT6uRleTi/P5vRy+zhSSg7Whth4qIUtR1vYUdnMbQe/R6ZQWegxnip+FvgjwTH/M6Bzx82JXfZy58yyZezly9Hvd40mibjROqqzT791X+tDNBqNe0RaVNDZ3wyUkxW/tpfP/pySYFss/CAs/JBabm+E/9yhMh79xRtUMtP+tpCSUrWBaqlQt7YqVh9qZ/Mx1b/5tLJc5k2IcwJhlxksCw9M0cGyJg2wTJ/6O5mkM8tJx5Jit4UNNh9q6HnjWFhS7EiLqlu22LccgAdXV/Hjl1XexSPgu+eP58qFiVHBCCEYWxjgstn5fOmiEfyx7HFO827tsE0GbYh/fADCLvUF7wlLhu3PgtwRHR/Txl4aTUpwww3jciHEGMf9LFTAfKMQ4pRO20op5U9dOKdGozmZ6CDBHmBtYsVmO8NaXA6zb+66zSU/gWOb4dBKJV1+5n/hqv/rX42Y8AIeNdAx+jjICbdAqF5llMNNSsIYKOavq/dHN7l+1jA88VxWYyUc2aCWxyyE3D7WGmo0iWCgRl/SNPcS2twrWcwrK+Tvbx8A4N3dtcwbl9+3A3j8KuBrr4ORMyGYC20NsHc5T26u4etPH4xu+tWzx3LjaQUuXn0PtDXAyvtiP1a1E564E953T+KM5KQB1ZYT9qSOvzfa2EujSRlufOJvNG+duT3GOgnoYFmj0fQNy9jL7azyki/Ebp3kC8INf4c/nA2Nx2DnS/DOvXDax/p3Tq8pxTbi/MqNtJlBcoPZBsoPgUIQXo7Wt/Pc1loAyvKDXDYvzozLrteICn+mvqevz0CjSQwDMfqShgoiPAFtdpREnCZf6w7WAuP6fhCv2TpMhmHc6bDjBag9yC//8zYSlVH9zOmjue3s4uT9a5f9SikVAEN4aZc+/B6J1zCNwXa/Bs98DS770cA7JcSi/iiETIVFFwm2NvbSaFLFQIPlc125Co1Go+kJw6z59eUM7DhHN6gBD0DJZJh9Q/fb5o6A6x+A+y5TA6g3fgXDp0P52X0/rzeoMmdGL1JRI6SC5JAVJIsubaD+vqqKiBnzXjdrGEF/nAOnXc565cv7+AQ0mgTiy+qf0ZcMawl2CigvySY3w0dDa7h/Jl+gsqOWomDCmSpYBs4U69nNCG5dUMpnzx8en2rGDY5uhDUPqeXMAjyffIuM3FHq/pF1cP/lKvO85UnIyIXzv+5+0FrVQ72yNvbSaFLGgIJlKeXrbl2IRqPRxERKCDerLNJAJdjLnbXKXwRvL4PssafCpT+Bpz6HMvz6ItzyKBSO7dt5o1LsbuqWjbCZRTYDZYkaGHV6vq0hg4dWVwGQ5fdww4Ki+M7f1gT731LLw6ZA8dS+Xb9Gk0i8Gf0z+jLCKlDWwXJS8XgE88oKWLaziv01jdS1hMjP7OP/wOONSrF3ZM1lirn6bM8Gmqa+n6+9ZyR98Q0bEEYYnv8WUeXN+XeBFSgDjJoHN/0T/v4+Vbe85iHIKISzPuXudXRwwnYEy1Fjr2z9XtdoUkCyvoo0Go2mfximOdZAA+XDa2HvMrU8fBrMvCa+/U75MCz4oFpua4B/3wHt/TD88gbBkvNZGBFVt9dyVN3a65Q8MVgU8/n+d3MNNS2qzcnlU4spLfTGd+59yyGi5IVMvkjL+DTphy/LNMPrg9GXZe4ldACRbCwptgRW7q7r30G8Weyt93LzE23sNEYDsMS3he9fOhy/L4nfUWsegkrT1GvMKTD/w123GX+mUhpZ9cpv/gZW/c3d63AGy8WOtlGRFtPYa2Bu4BqNpn/oYFmj0aQ3URfsAbaMWn6PvRxPVtnJpT+F0QvV8old8OzXVMa7L3gz7GDZ7JVMa4UZJNeACEKwpNvnKaXkvnePR+/fPL8k/nM7W0ZN1xJsTRrizVK3vgTLum1UynDWLa/eW9OvYxxtlHzgoUNUNUd43ZgDQFC2kXF8rRuXGB8NFapWGVQgfPnd4O1GdDnlYnjfH4g2e3nlh7DxcfeuxZJh+zIg38xsS6nKkCzZukajSTo6WNZohhpGWAVjQwEpVa2W5XjbXw6utGXIpTNhxtV9298y/Moepu5vfwHe+VPfjiG8RAdZbdUqSG6rUusDxSpz0AMrDzSxpUIFEmeMzWPu+DgnDyIh2G1WzOSWwujFfbtujSYZWEZfwqOMvnpDSpARlY3WSomk4wyWNx6p7fP+1U3t/M9fVnK4Tk0gHs5fZD9oKYCSwcs/gFCzWj7tozBiXs/bz74WLv2Zff+5r8OOlwZ+HVLameXicrsUIWrslaPf5xpNitDBskYzlDDCpqS3Mr4BZzpjRKC92m6ZNBCctcrnfEkNzPtK3qiOMrxlv4Q9y/t2DCvgD9WowVGgOG53U2dW+fpZw+IfNx1aDW31annyRf177hpNMrCMvuLJLmtzr5RSnBOkrFBN8G2uqEX2QWnT0BriQ399l12VjQBMLcngo1edY/e737vC9euNya5XYceLarmgDM75anz7Lb4dzvuGWpYRePILsP+dgV1L4zG7vMdp7hVuURllbeyl0aQMHSxrNEMJo00NNNsqofWYMozqq1w4HYi0QmulukXaBuaCvf8dOPiuWh45G6Zd2f9jjTsdLvmxWpaGGiTVHux5HyceMxvsywN/btxGRofr2nl+W626hIIgl8zNjf+cTgn21Evj30+jSTaW0ZcM9a6Oscy9dL1yypg3thCAmpZ2DpyITz7fGorwkb+tYsMhVec8tjCbP1w7jZHFflUvDHB8OzRUJuSao7Q3w0vfs+9f8kMIxtmGD1TbwdNNg69IO/z7k8pRu784nbBLJqu/2thLo0kLEtRZXaPRpASjXd28mdBeq5b9bapHr2cQfNylNB2ha5XZlScDgvkDO94KR63yOV/ukFm9/f6VrNhV1WW3MycN408fPCX2MU+5TZmFrfu7ytj++w74wMMQiGPm30oHi75ldzu0i5rZh3ZRUtotowI5UL60T+fVaJKOL8vsS97Ss6GRDGkn7BQzr6yAJ9cfAeCdXbWMK+n5OzAUMfjUQ2t5e081AKU5GfzuhlMZPzoMLU0w/lTYZ2aV962A2e9L3MW/+RvV1xhg2mUwpY9eDkLARf8PWmpg3YNKyv3IR+Dmv0PJpN7370ystlHa2EujSQt0ZlmjGUpE2s06viwIFKmsbKuZZQ43p/rqesYIQdtxdb1tteDPU+2TBsL+N5UMGWD0fJhyWYeHa5tDtISMLrfa5vYYBzMRAi67G0YtUPerdsJzdyUsg98aMvjHGhXQZwc83LAwznZRoBxerQHhpKXg11I+TZoTr9GXbhuVcpx1y2v21/a4rWFIvvLoBl7aegyAgswAv772VGaOzzT/5xlQtsDeIZF1y5XbYeX9ajmYC5f8qH/1wELAFf9n961vrYN/3QZ1h/t+rM5to7Sxl0aTNuhgWaMZKkhDybDxqh9x4TEzyhnKSKr1mDKWSkfzr1AjtBxTtdZGSLlCD7RVlJQdHbDP+UqXet2rF4yOuesd5/WSGfBnmIZfpiP1tudg5V8HcrXd8sSmGmrNdlFXTC1mWEEfstI7X7GXp17i8pVpNAnAafTVudVaB8LKyyDenswa15k5Kg+/RwWZmytqu91OSsl3n9rCv9eqIDI74OOXVy1m0TRzMtT6nxeOh9yRat2+N5VvhdtIA174lppUBlj6Zcgf2//jeX1w7V9gwjnqfmMl/PNWaDze836dsYJlbwDyxziMveLztNBoNIlD/8poNEMFo93sO9op0+LLBH+hCkhbK9PL/Esa0HZCBfLtJ9S1BgrcGRzsXQZH1qvlMafApIvs00rJP949wPee2tplt9EFmSydMqz34+ePhuv+ZsvbX7/bdWMaKSV/fVfV7gngxnlxXJcTS4Lt8cFkHSxrBgm+LJVN604NIyOANvdKNRl+L9NHqTrf7ZV1hCKxJ2J/9fJO7ntzHwABr4efXHEKS+d2Kq/xZirlyzjTrb+1Dio2uX/R6x+xfxdGzoZFHx/4MX1BuPEhu71g7UF45DZorY9vfymhyuGE7fEqZYVXS7A1mnRAB8sazVDBqleONYD0+JQsG2FKndPA/CvSqrLJrZXK8TNQ5J7crHNWeamdVa5paufjf1/NV/+9kZZQ18zF0bpW3o23b+j4M+HiH5rnNA2/+iPB64Z39jey7VgrYLWL6oMreN1hqNymlsedDlnFrl2XRpNQejP60k7YaYMlxW6PGGw40NDl8b8s38svX9oJgNcj+P6lC7hsUYzvIm+m+r+Pc3hF7O1jt4HeaKqC13+uloVXtYDyDVDBZBHMgfc/CsOmq/vHd8KjH1VGYr1e13G7Y0HxRLv9ozb20mjSAh0sazRDhUg3mWULIZQDsy9HmX+1Vip5thFO6mUipTLvaj2mAne8ECzqs+lVj+x+zc5KjD0NJl4AwJu7q7jkV8t4frOqmxPABxdNYtZI2wXVkJKPP7Cao3Xxubuy+CMw9ya13FqnDL9Cce7bCx3aRc3uQ7so6OSC/R5XrkejSRr+bNvoqzNGRNcrpwnOuuWVezpOMj62+hDffWoLoL5rv3HhXK49ozT2gYRQweG40+zfAreD5Vd/Ygelp3wQyk5z9/hZRXDL41AwTt0/sh4e/7T6be4JZ71y8UTT2CtLt4vSaNIEHSxrNEMBKVW9spS9B53eYOrMv5wmXu117ph4daZLVvnLtEfgR89u4/1/eoeKepWpLc3J4NfXnMa3r57KN6+cyZjCDE4vVxmPmpZ2PnLfGlpjZJ67IARc/ksYNU/dP74dnvvGgLP2h2rbeWG7aq8yviCDS+b0oV0UwC5HvfK0KwZ0LRpN0unJ6MvKLOu2USnHGSyvP1gbXX5hcwVffmxD9P4Xls7ilnNG9zzh582ErGEwcpa6f3SDmoB0g31vwpYn1XLuCLtPstvkjoBbnoCcUvu8T3255/rrqk7BctTYSwfLGk06oINljWYoIMPdS7BjETX/CjpqhmsSa/4VbrJl10ZIBewDNfGKxc6XlAs0wPgz2Zt7Ktf+/k1+//ruaPx6/uSRPPbRs7lsUTFCwOIJRSz/yvn8+UOnMGW4Cko3Ha3la49tQsYT9Poz4IYHbanz1qdh1f0DehoPrDqOYbWLmlVCIN52UQAttXBwlVoeOWdgBjYaTSro0egror67PC6qUTT9YkJJNvmZ6ndn87FaQCl4PvWPtUTML7CPnj6FT1w4Dk9vI05vUAWI4xap+9KAfW8N/CLDbfDid+37F/8/yOxDV4G+UjQB/udxyChQ97c/Dy98u/sJ1BOOtlGFY9TvuDb20mjSBh0sazRDgai5Vx+DT18W+As6mX/1IhnrK9JQLtyWiZfXMvFKwNePNGDFr6N3XxpxO5fds5wNh1R2ItPv5WsXzOH3t8xnzPCuEwtZAR9/+uAp5GWox/697hAPvHUgvnPnj4Hr7rcz+6/9DPa/06+n0RIyeHjNCQByAl6uX9DHgd2e12231ykX60GXZnDSrdGXR0uw0wQhBHPN7PKBmibe2HGcj9y/ivawmni9af4EvnTpJLzxzmv4smDCWfZ9N6TYb98LNfvV8qTzYeY1Az9mb5TOUDXMVru+DY8qE8hYWJlljx9yS9SEgTb20mjSBh0sazRDgZ7MvXrDMv+S0pRIV0CowR3zr0ibmU0+BqFmd028YrH9BTi+A4BNmYu4/bUgze0qaJw2PJ8Hb1nCRy8ow99DlnZscRa/ef98zI4ofPepzazcWx3f+ScsgYt/oJZlBP57Z78Mvx7fWE1dq9kualpR39pFAWx4zF6edln322k06Ux3Rl/Cq4PlNOH2+1fy5i7bW+GWv7xLk/mde/mMMXznfdN7/L7tgjcTRs2HzAJ1f+/ygf0WndgL7/xRLfsz4ZKfJK/dWNki5ZLtNSex3/2zCty7XKMZLBeOA49HG3tpNGmGDpY1mqFApF1JsYWvf/sLoeqHfTlKjt16TMmz+2v+FTXxqrBNvAKF7pp4dcaIdMgqf7X2vYAylrnllIk88rEzWDA5vtn6JZOH8aWLpwEQNiQfe2ANFXWt8V3HqR+DOTeo5ZZa+M+nIBTnvqh2UZaxlwBunt+HdlFSQv1ROLRa3fcGYPjs+PfXaNKNqNGX4zOk65XThtrmEOEY1Tt5GX5+fO1sAoE+qlo8PvU7NNaUYjce6yhT7gtSKvlzJKTun/05KJ7Uv2P1l4nnwjV/tgP0N34B6/5pP95cDS2mMVrROG3spdGkITpY1mgGO0ZEmXvhG7jc1huEQLFp/nWsf+ZfRli5bHc28UqwFDi85dnoDP2LkYVslOUMy87gnqtP4zvXTCM3u29fdx8/p5xLZo4EoLq5jY/cv5q2cJyGX1f8CkaYQWrlNnj+m3FnR97a18j2ShUYnDUun1lju2kXFWqBo5tUFvnlH8DDH4JfnwG/P8/OwkXaYc+rcZ1Xo0lLvKYUO+L4HhLexPgdaPrMHefGDj5/8N45ZGf1c4jZWYq9p59S7M1PwMF31fKwqXD6Z/t3nIEy40r1m2Dxwndg6zNqucoxEVBUpo29NJo0pJ9pKI1GkzbIUM8to/qKZf4Vbjazy+2qxtif37t8LdwEbTUQqgU8SnadBMnb/qomfM/9gtHm/V+Gr2HpxBF878rZlJX2b1AthOBn189h928a2VHZwMYjtXz935v56fVzet/Zn6nkd/eeozIHW56EEbNg0tW97upsF3XD7GEIDKg9oly2j29XMvPK7VB7ID5Dttd+CJMu0HXLmsGJZfQVqlffdaCyytrcKy1YOnUYc8fks/6Q7Vo9Y0Q+l83rpkVUPHgzoXypfX/fclh8a9+O0VKjWkUBIOCyn4Ivo//XNFAW3KKURi9+A5Dw9FcgmAt1h+xtiidqYy+NJg3RwbJGM9iJ1it3k4HsL74sFYCH6tTxw22qH7I3RvApDdW7OVSr6p29OeBLYG2ydVop+feGalY++xA/8hwB4AVjMVeeewUfPrfn2uR4yA76+OMHF3L5/y2noS3MI2sOMresgA+cHoe7dMFYZfj1t6tU/fKrP8GXNQ7oPmtw6FgVtTvf4QPegyzOOMylmyvhjZ3Q3tT7+YQXcoZDw9GO6w+vhl0vweQLez+GRpOO+LJNoy9TrurRQ5d0QQjBnRdM4db7VkbXfemSKYiBBHxCqF7FwybD8Z3K2T/UoiYh4+W1u2158/ybYNzZ/b8etzjzM9BaC8vuVgqsxz+tJlEthk3XWWWNJg3RvzgazWAnYjph+/rYhzcePH4lyw43qNpj2a6yzn7HuSJtyu06VKeuw1+YlMFsfWuErz9zkKc3VfFywDa0GvWeb3HRGe61ShpXnM09N8/n1r+uRALffnIT00fmsnB8Ye87TzgbLvwuvHAXyAg5L3yJjMnfhYpNEBmmMsTHd5i37YypP8K/rLmICHC0m+NmFcPwaTB8OpTOUpLvYdPggWu6BssAb/xMB8uawYsnaBp9VZn3db1yOuHMLs8tK2DplD74LHSH15RiH9+pfuMOroTyOAPeg6tgo/mbkF0CF3w3fbK1531DBfGr/qImoC1/CeExg2VdXqDRpBs6WNZoBjNSmvXKJE7ubJl/RVqV+ZcRUgFyoEDVEbbXqNpkT9CUXSd+ULLqQCOf/c9+Dte1c513GeM9xwAITXoPs04/0/XzLZ06nC9ePJWfPr/dNPxazTOfPYvheXHI+k6/A46uhY2P4mlv4NxtX8e/uQWIQ0LtDUDJJDMonqkC49JZkDsq9uucWRg7+5KVwJ6iGk2iEcI0+jLVM/01MtQkBCEEd102gy88so67Lp0+sKyyhTcIE8+Hd/+q7u9dHl+wHGmHF79j37/gW5DtQvDuFkLApXdDax1scnQt8PggWJCyy9JoNN2jf3E0msGMEVLBcjIGj94MZaoTqlWBc6QVjFZV2+zLtQeyCSRsSO55o4J7llVgSPAR5k7/fwCQCPzn/2/CgvVPLp3IxkN1PLe5gqqmNj5y/xoe+cRpBHy9TFIIAVfcozIjtfsJRGJLqhszRvBW0yi2ybGUjJ3LTVdeACVTwdeH1/Xmh/vwjDSaQYQ3yy410cFy2rF4QhHLvnyeuwcdd7rqUxxqjr/f8sr7bdOs8WfC3Pe7e01u4PHA+/4A1XvgyFq1LtIOe1fAlItTe20ajaYL+hdHoxnMGO2q9ilZzrDCNO0KN0N7FYhA0ky8Dta0ced/9rP6kB1sfm34SkbXm22WZlwOI+Yl7PxCCO6+fi67ft3IruONrD9cwzf+s5kfXxdHayZ/JgRyCIsA0nyt/BnZsORzUDobWTqT9/1hCztrG/EI+O+F58IIXbum0UTxeO2WOtrc6+QgUADjToVdr0L1XtWzPn9099vXHoI3f6uWfUG49Gfp+17x+MDo1CHh9R/D5IvSRzKu0WgAHSxrNIMbGVIBcyLqlXsiwb0gb394Nyv2NkTvhw1JyNG1KegTfP7UUm7d8ahaITxwzpcTPshQhl+ncMU9y2lsC/PP1QeYW5bPzaf1UiO980Wo3Ex91iSWTf0mS7Z/l6LmXVAyDcqX8uauKnZWNgJw1oRSZo7XgbJG0wV/kr/nNKnF44Pyc1WwDCq7PO+G2NtKCS99F8JmP+4z7oDhM5Jznf1h54tQsa7jOm3GqNGkJbrPskYzmIm0gwwPOcOb2pYILSEZvTkD5SnFmfz9uml8rOh1hGVmNfNKGB5HhtcFJpRkc89N87HC8m/9dzNrDtT0vNOyu2Ovf+NnAPx1xb7oquvnjdeJBY1Go4GOgePeZd1vt/152GM+XlwOS76U2OsaKL38Jmg0mvRBB8sazWDFiKia4SFYv3fHWbF7dJ4zPp9HPjiFRRMEvP0HtVJ44ezEZ5WdnDttOJ+/aAoAIcPgo/evprKhtfsdLOMtq/7YF1T3s4o4cKKZl7cpg7Ly4lwunl+c6MvXaDSawUHJNCgcp5b3vw2RUNdt2hrg5R/Y9y/9sap1Tmes34TON23GqNGkHUNvlK3RnCwYZssoMbSyygBnTsglO+Chqd12jB6bH+QvH5iA1yNgzaPQUKEemP0+GD4z6dd4x9JJbDhYx4tbj1HV1MbH7l/DPz/ejeGXZbxVXQ3LlsGHnoIiNSj621NbkGbp2nVzxw+4N7RGo9EMGYQHJp4Lq+5T/eaPrIOyRR23WfYraFLeFcy6GsoHgYxZmzFqNIMGnVnWaAYrVrA8xCTYAD946UiHQBngO5eOVoFyqBXeMrPKHl/K5HYej+AXN86jvCQHgLWHavj2E1v6dIymtjD/XHUQgNygn+tP7cG8RqPRaE5GJl1gL+9d0fGxoxthzUNqObMALv6+NsjSaDSuooNljWawYoTMYDlJTthJ4rH1J7jvXZUl8Jhjnrmjslg6KU/dWf9PO4sw5xoYNi0FV6nICfr40wcXkh1QIp2HVu7n4XcOxr3/v9cepqE1DMCVs8oozk9T51aNRqNJFeXngdecFHbWLRtheP5bgCnNOe9rqge9RqPRuIgOljWawYiUqr8yJKVtU7LYeKSZrz5lB5sfPWUkZQUB7rpwNEIIaG+Gt/+oHkxhVtlJ+bAc/u+medH733hiE+sO1va6n5SS+1bsBdSkwM2LxiXoCjUajWYQE8iGslPV8rEt0HRCLa95CCq3quUxp8CC21JzfRqNZkgzdEbZGs3JhBFSwfIQqlc+0RTiY//aQ3tEZQluWzCCL79nBMs+M5PF45TUmXUPQ7M5UJp3AxRPTtHVduT86aXceb5t+PWR+1ZzvKGtx33+f3v3HSZ3We5//H1vyW7apkBIIAGSEDohIE2QjqCoWED0WDigoByRn6KcA0exoR6xIKKgIiiKIioWFGyAChKKVAk9QAg1tJTNpm6b5/fHM5tsJrvJ7mb7vl/XtdfMfNvck/Al+5mn3frkQua9mteMPnj6JHbZtp9PSCNJfaV1V+ynb8tzVsz+dn5dVgFv+SaUOw2PpO5nWJYGokE2XrmpkPjob55mQV2e6fR129TwP0dNWtMNG8iTu9z5w/y8fBgc9N+9X+gGfOyIGRyxU57F+9UVq/mvn95HY3Oh3eN/0mq5qONdLkqS2rf9UWufz5+dZ79uXJlfv/bDMGmPPilL0uBnWJYGokEWlr9y4wv865nlQJ71+vy3TqV6WEl6vO8qWFVcz3iP98C46b1c5YaVlQUX/scspm42EoB7n1vMuX94tM1jn12yin/MfQWAGZuP5qg9XC5Ektq1xS4welJ+PvcGePzG/Hzs1nDIp/quLkmDnmFZGogKjZCaBkVYvuaBxVx+Z56wa0RlGd84ehpbji+Z6Kp+Odz1o/y8ogoOOrOXq+yY0dWV/PDEvddM+HXlXU9z9d3Pr3fc1fe97HJRktRREbDdEfl5c8Pa7W/8ClTV9E1NkoYEw7I00BSaobAaYuCPz3roxZX87x+fXfP6s4duy347DF//wHt/BquX5ud7vg/G9t/JsGZsMYpvvXvWmtef+f2DPPB87ZrXq5vh2gdzq3JNdSXH7+tyUZK0Ua3HLQPs9CbY8Zi+qUXSkGFYlgaali7YMbCXjFq8solTr55PfVNuYj1pz4m8+7Vj1z9wdR3c/ZP8vKIaDvxEr9XYVUftOon/d3iefKyhOU/4tXB5nvDr7leD5Q3NALxt120Y73JRkrRxLd1xWuz0ZtdUltTjDMvSQFNoyD8DuAt2UyFx+m/m88LS3J3ugG1qOPuoLded0KvFPT+F+rr8fK//hDHb9F6hm+ATr9+ew3bYAoCXl6+d8OuWF/P/dssjeM++/beFXJL6jZTgjovX3Xb35esHaEnqZoZlaaApNEDzwJ7c62t/W8DtT+cJvabUVHH+MdsyvKqNpPzkzXD79/LzyhEDolW5RVlZ8O337sHU8XnCr3ueXcyhF97JK6vz50wkLrj54b4sUZIGhiduhAX3rbvthXvhyb/1TT2ShgzDsjSQpATN9bnrWQzM2/cPDy3msn/lMbvDK/KEXltt1sb465Tg+s8BxZaDvU+E0Vv1XqHdoKa6kstO3GtNi/mq5rX7CglqVza0faIkaa3Z32x7+y3n924dkoacgfnbtjRUFRohNUAMzFblh19aydnXtprQ67Bt2X/HNib0Anj0T7Di1bWvt3xND1fXM7afOJrTDp2xzrZhZfkLgI8ePqOtUyRJrQ0fB5XD1/8Z4bJ7knrWwJ9OVxpK1qyvPPAm91pSnNBrdXFCrxP3mMh/tDWhF+RW5X+ct+62Oy+BmccPyAldzjxqB66+5zleWZYn+aqphMlbjOXQHSb0cWWSNAC895d9XYGkIcqWZWkgGaDjlZsKif/326d5vjZ3O37tlNHtT+gFcP/VsHLxutsG8Pi0iOC8Y2eyWVXi+GnNjKyAM16/PTEAg78kSdJQYViWBpLmeqAZygZWp5Bv/GMBt85fBsDkmmGcf8xURlRvICjO/lbb2wfw+LTDd9qCPSeP5MBJie0njbJVWZIkqZ8zLEsDRaG5OF55YK3Le93DS/jB7XlCr+qKMr7xxulMmbCBsP/MnbB6afFF5LWVB8H4tIjgpAOmAXDS/lNtVZYkSernBlbzlDSUtYxXjoEzXvnRl1dxVqsJvT5z6DYcsFM7E3oBpALc9LW1r9/1Y9jlHT1YYe/aZasaZs/Lj5IkSerfbFmWBopCQ/4ZIOOVa1c1cerVT7GqsQDA+2dtwXv3H7fhkx6+Fl55ND/fdn/Y6a09XKUkSZLUNsOyNFAMoMm9mguJj/3uaZ5dkif02m/KaD79hq3an9ALoHEV3HJh8UXAUV+EsoHV5VySJEmDh2FZGghSgubVedmk6P+37fk3vcgt8/KEXluNHsY3NzahF8DdP4blL+fnM4+Frfbp4SolSZKk9vX/37ol5Vbl1AjR/1uV//TIEr5/Ww69VRXB1984bcMTegEsfwXu/FF+XlENR3xuQK6nLEmSpMHDsCwNBIXG/FPWvyf3mvvKKv7nD60m9DpkWw7cecTGT7z1ImhcmZ/v92EYO7VnCpQkSZI6aFCF5YjYMSJ+HhGPRsTSiFhRfP7NiJjUxvETI+LyiHg5IlZHxAMR8aE2jhsRERdFxIsRsTAifhoR661hExFvL77ntJ76jBqiBsB45aWrmvjwr55iZXFCr/ftvgXvO2AjE3oBvPo4PPi7/HzkBDjozB6sUpIkSeqYwbZ01BRgEnAN8DzQBMwETgXeExF7ppReBoiIscCtwGTgQmA+8Dbg0ojYKqV0bqvrngd8APgasBI4G/ghcGzLARFRA1wMnJtSmt9zH1FDUnM90Axl/fOWbS4kPn7NMzxTnNBr78mj+PQbNzKhV4ubvp6XjAI49H+gemyP1SlJkiR1VP/8zbuLUkp/B/5euj0iZgO/Ak4GvlLcfDYwAzgupVRs1uKyiLgWOCciftoq9B4PXJBS+lLxekvIobo6pbS6eMx5wCLggh74aBrKCk1QqIfovzNDf+vmF7n5yToAJo0axjePmcbIjU3oBfDUbHj6tvx8wo6w5wd6sEpJkiSp4wZVN+wNaAm9rfuEvg+Y3yoot7gAqATe3WrbSGBhq9eLgHKgGiAiXgt8GPhwSqmpG+uWipN7NUH0z/HKf320lotvXTuh1zfeOI1tt+jA93CFJrj562tfH/l5qOifn1GSJElDz6BqWW4REdXAKHKY3Qn4anHXn4v7JwFbA1e1cfodQAL2bbXtNuAjEXEbsIrcKv1ISqk2IiqBy4BLUkp39sDH0VBXaMyBuWx4X1eynideXcWZf3hmzetPH7wNB+3SgQm9AB74HSx8Mj+ffghs/6YeqFCSJEnqmkEZloFTgItavX4OODGldFPx9eTi4/OlJ6aU6iNiIXn8c4uPA9cC9xRfvwAcV3x+FrnF+pyuFBoRW5e8F8BuAHV1dSxevLgrl+0xdXV16zyqFzTUwuplUFkO0djX1ayxrL6Zk3/1HCsa8njj43Yay5t3Hcbi2uUbP7lhBWNnf5syIEU5S/c7k8KSJT1bcD/g/SN1nfeP1DXeO1LWlXtgsIbl3wOPkVuX9wSOYd0u2C1NX/XtnL+61TGklJ6IiJnkVupKcqtyfUTMAD4DvDelVBcRpwGnAaPJ4fqslNKqjdR6MvD5tnbcf//9rF69uq1dfW7OnDl9XcIQ9FJfF7BGIcFlj5XxbG0eybF9TYHXjV3Ibfcs3MiZ2U4LfsP4VfmLoKc3O4QHHquFx2b3VLn9jveP1HXeP1LXeO9oqHvsscc6fc6gDMsppedZ22r8+4j4LXB3RIxIKZ1HntEaoKqdSwynJJkUxyI/VHLcD4DrU0rXRMS7gW+Sw+9zwE/I45pP20i5PwKuL9m2G3DpHnvswT777LOR03tXXV0dc+bMYdasWdTU1PR1OYNfoQFWv5rH91aM7Otq+PSfnuWRl1ZT2wB1jXkCr/JITB5TzaH7btuha5Qtf4kxD+T/5FPlCMa+9cscNGrLHqu5P/H+kbrO+0fqGu8dKauuru70OYMyLJdKKT0QEf8mB9fzyN2oYf3uzy3jnTcDNtjMFREnkcc171zcdDLw25TSVcX95wEXRcTpKbWsi9Nmbc+Rw3XrawNQU1PD+PHrLefcL/Tn2gaVxmUwbCkwAir6bsxyY3Pilnl1LG6s4NkV685y3ZyCEw+cwvixozp2sdsuKy6FBXHAaYzbZtfuLrff8/6Rus77R+oa7x0NdV35smhIhOWi4cB4gJTSSxHxPLB/G8e9Fgjg7vYuFBETgPOBc4qt2JCD972tDnuOPMHY5sArm1y9hqZCIzQ3QmXvB+WUEvc9v5LfP7iYPz1Sy+KVbU/0PmurERw6o4P/83npYXj42vy8Zks44OPdVK0kSZLUvQZVWI6ISSml9QZ2RsRh5K7NN7fafBVwVkQcW7J81CeBJvK6zO35Fnk5qotbbVsAzGz1eibQwLpLTkmd01wPNENZ792q8xau5g8PLuH3Dy3m2SUN6+3fbHgFi1atDc5nHDJpTW+IDUoJbvra2teHng1VdgeTJElS/zSowjLw/YjYEvgH8Ay5ZXcv4D+AZcCZrY79KvBO4GcRsRc5/L4NeAvwpZTSU229QUQcSV6Ded+S7tVXApdHxIXk8dKfBa7aUBdsaYMKTVCoh+j52/TV5Y1c9/AS/vDgEuYsWLne/jHV5Ry53TjetNN4DtxhOMdf8QRzFqzsXKvyk/+A54odNibtBrPe342fQJIkSepegy0s/wI4ETgBmEBeL/kZ8kRc30gpPdtyYEppSUQcCHwF+BBQAzwJfCSldElbF4+I4cAlwLdTSv8u2X0FsCXwEWAkeUZu+5iq6woNuRt22bAeufyKhmZueGwp1zy4mNueWkZzWnd/VXlw8NQxvGH78bxxZg2jhq9tPT7nyMmc+YdnOOfIyR1rVW5uhJvPX/v6yHOhvLKbPokkSZLU/QZVWE4pXQ1c3YnjXwQ+0InjVwHbtbMvkScPO6+j15M2qNCQf8pHbPzYDmoqJGbPq+P3Dy7hhrlLWdW4bseHsoC9thrNG7cfxzEzx7LFuPI2r7PvtqOY/bFOTMx1/69gydP5+fZHwvQjuvgJJEmSpN4xqMKyNKgUGnJX7MpNa1lOKTFnwUp+/+AS/vjwEhauWH+irh02H84btx/PW3cbx3aTKulIY3GHra6D27+bn5dVwJFfoHvfQJIkSep+hmWpP0qFPLlXlHUoWJ7yy3ncNn/ZOtsKKTF5TBUpwfzF9eudM2nUMN6w/TiO2WUcr5k+nLKeyq93/ABW1ebnr3k/bLFbD72RJEmS1H0My1J/VGjMLctlHRvXW7uqmVWNab3tTy1aNyTXVJVzxPSxHL3jeA7ZeSRVlT3cwlv7PNz3s/y8ajQc+qmefT9JkiSpmxiWpf5ozeReHQvLHz1wIh/4RZsTuDOsPDhw2zG8YcY4jp5ZQ83Isu6sdMP++c08uRfAgR+DUZN6770lSZKkTWBYlvqjlrDcwcm9Dp1Rw7bjhvFMq3WRR1SWccb+kzlm97FsOb4PbvUX/g1z/5qfj5kC+32092uQJEmSusiwLPVHzQ1AIU+I1QERweQx64bl775zKodtP6aHCtyIlOCmr619ffg5MGxk39QiSZIkdUEv9seU1CGFJijUQ3T8u6ymQuLhl1ateT1zy+EcOqOmJ6rrmLl/hQVz8vPJr4GZ7+67WiRJkqQuMCxL/c2a8codXzLqrmeWs3R1M5C7X3/2qClEXy3P1NQA/7xg7esjz4WyttdrliRJkvorw7LU3xQaOjUTNsCNjy9d8/yrb5jGvtuO6onKOua+K2Hp8/n5Tm+GbQ/qu1okSZKkLjIsS/1NS8tydCwsp5S44bEclkcOK+PQnfowKK9cAndckp+XD4PXf75D60RLkiRJ/Y1hWepPUgGa6yHKOxwyH315FS8szRN77b91DTUj+vC2vv17UL8sP9/7JNh8x76rRZIkSdoEhmWpPyk0droL9g1z13bBPmTq2B4oqoMWz4f7f5mfDx8HB5/dd7VIkiRJm8iwLPUnayb36sR45WJYrigLjtqlD2fAvvmbeSZvgIPOgJGb910tkiRJ0iYyLEv9SSdnwn5hacOaJaP22moUE8f10azTz94FT/49Px8/DfY5tW/qkCRJkrqJYVnqT5rrITXnMcsdcGOrLtgHTR3TU1VtWCrATV9b+/qIz0Dl8L6pRZIkSeomhmWpv+jCeOUb59aueX7UTn0Ulh+5Dl5+JD/fZj/Y+R19U4ckSZLUjQzLUn9RaOxUF+ylq5r419PLAdh5wgi237Jj53WrxlVwy4XFFwFHfhHK+qgruCRJktSNDMtSoQlS6usqiuOVO96yfNOTdTQXyz546pi+Wc74nitg2Uv5+W5vhyn79UERkiRJUvczLGtoa26AVS9C/at9H5gLDZCaIDoWlm94bO145dfv0AddsJe/Cv+6LD+vqIbDP9fhtaElSZKk/s6wrKErJWhcCg3Fn8a6PqylAM2rgfIOBc7VTQX+OS/XO7lmGHtOre7hAttw28XQuDI/3/cUGD+992uQJEmSeohhWUNX04ockCOgeRU01ubZqPvCmiWjKjp0+B3zl7GioQDkLtgV5b3covvgNTDn6vx85OZw0Jm9+/6SJElSDzMsa2gqNOdW5ablUFmTfxqWQv2S3Mrb6/W0TO7VwS7YrZaMOmy7sT1UVDsWPwN/+7+1rw8+E4aP790aJEmSpB7WsWYsabBpXJp/ykfmNY2jHMqqcutyRRUMG9e79bS0LFeM3PihKfG3x3NYHltdwYE7bPycTbZyMTz2l7xM1II56+6rmdrz7y9JkiT1MsOyhp7m1TkoF5qhasTa7RWjoGExNNRCWTVUDO/Fmupzi3ZsfNml+19YyavLmwB43TY1jKjqoS7YjavgyX/Aw9fB/FshNbd93K3nw05HO7mXJEmSBhXDsoaWlKC+FhqXQWXJDNIRuTt249K81nHZpN5ZM7jQCIX6DnfBvrFVF+xDpnXzLNiFZnj2XzkgP37j2gm81gigZNbwF+6FJ/8G2x/ZvbVIkiRJfciwrKGlsQ6a6ophuI1wWlYJ5cOLgbkKqjfv+ZrWTO7V0fHKtQBUVQSv36Vm098/JXj5kdzF+tE/wYqF6x8zYUeYeSw8+hd48f71999yvmFZkiRJg4phWUNHoTGH4ObVMGyz9o+rGJm7YzcuhfJqqBzVw3V1fLzyvIWrmbcwz9i97+Qaxo/ehDn6ap+HR/+YW5EXP7X+/tETYde3w+7vhi1fk1ven78fFs5d/9gRTvAlSZKkwcWwrKGjoTa3LFeM3Pj42sox0LAkn1Ne1eFW3y4pNEJqgtj4e6zTBXtqF7pgr1oCj12fW5FfuG/9/VWj8/jjme+CaYdCeUlN7/1l599TkiRJGoAMyxoaWtZUhtzNemOiPIfqxlooHwZVE3pmAqtUyC3dlHfo+i1huSzgqI52wW5cDfNuzgH5qdk5nLdWXgnbHQozj4cd3wzDerglXZIkSRoADMsa/ArNuYW4aTkM60R34fLheZbqhpbu2N0wPni92jo+XvnV5Y3c9/wKAHafOJKtN2/jnOfugT9/Ct74f0AhB+S5N0DD8vWPnbI3zHwn7HocjNpiEz+IJEmSNLgYljX4NdXl2a/LR3RoaaZ1VNYUl5Nakif8Kq/q3toKDfmnbOPX/fvjS9fMQ33Q1DHrN0SnBDd+GZY+D78+Zf0WZIDNtoOZx+Vu1uNnuNyTJEmS1A7Dsrqm0M6au/1NS8twoWHDk3q1J8qgYjQ01EFUwfAt8rZuq68BCk15jeeNaD1e+cgdx65/wL9/sXbyrdZBedQWsOvbckDeaq/eWQ5LkiRJGuAMy+qahsVQGNuzE19tqpSKk3otyy3EXW1FLa/K6yA3LYXGKhg2rvtqLDTkccsbafFe0dDM7KeWATB9XDW7bVPSEr2qFm762rrbho+Dt38ftjsCKoZ1X82SJEnSENCNTWQaUhrrYPXC3CraXzUty3VGRV5XeVNUjF7bSt20qnvqKzTmEN6BLxxmz1tGQ3PuhH3w1DGUtc79hWa4+pTcSt3aqiVQVmFQliRJkrrAsKyuKTRBw6JiYO6HXbILTTnYNq+EytGbfr2IvJxUY10ev9wdn3nN5F4bD7M3zK1d8/yIGSVLRt12Ebz8cNsn3nL+JhQoSZIkDV12w1bXlFXkdYEbFkFZGVRt3r1jeTfVmjWVR3VfXWWVeYbsxtrcNbuqC2OgW2uZ3Ktiw2G+qZD4xxN52asJIyrZd8aItTsfvwHu+MHa1+VV+e+jxYhOzP4tSZIkaQ3DsrqucnRuva1fBEQOj/0hMDetzDNgkzq2pnJnVIyE+sU5jJdX59dd1dwAqTl3E9+Au59dTu2q3JJ90NQxVFUW+2AvfBL+9Km1Bx5zAex1ctfrkSRJkrRGP0g2GtCGjckTadUvyiEypY2f05NSIQf4xuVQ0QPrIkP+zE3LoX5J18dsp0Ier0z5Riceu6HVLNiHTCt2wa5fBtecDo0r8+u9T4LXfLBrtUiSJElaj2FZm65yDKSm4nrEfRyYG+ugcSmUVeeu4j0hyqF8VO6O3bCka593zXjlDU/ulVJas2TUyGFlHLbzqBy0/3gWLHkmH7T1vvCGr7pmsiRJktSNDMvadBFQOS53K25YkkNkX2iuz0G50LBp3aM7omI4EPn9mpZ1/vyW8cobCcuPvryK52vzLNf7b11DzYgyuO27MO/mfMDoSXD8j6Gym7ubS5IkSUOcYVndIwKGjc3LKtUvzl2he1NKObg21OUJs3qjlbVyTB4f3VC7/rJNG9PcsZmwb2zdBXvqWHji73D79/KG8mFw/OVQM6Vz7y1JkiRpowzL6j5RBsPGQdOKPEt2Y13vvXfT8uKayuV5RujeEGU5mDcsLY7XLnTsvJTyeOWUNjohWst45Yqy4OitFsKfzl678+ivwDav62r1kiRJkjbAsKzu1RKYG5fnSb8al/f8e7asqdy0Aip7aFKv9pRX5a7UTUs7/uVAaupQF+wXljbw8EurAHjdpGDzv38cGlbknXudAHudsimVS5IkSdoAw7K6X5RD5dgcHhsW5a7KPalxaV4qqrwb11TujIrRebx0Q23uhr4xhc51wQ4KfL5wESyen3dM2Rve+A0n9JIkSZJ6kGFZPaOsIgfmhlqoX9ixENkVTatyKC8UipNu9YGIPH65YWn+vIXmDR/fwcm9bpxbC8D/K/8902tvyxtHT3RCL0mSJKkXGJbVc8oq81rHDbW5S3ZzffdePxXytRvqoHJ09167s8oqoXx4ngl8Y7OBNzfkrtjR/tJWS1c1ceczyzmi7F4+WfmbvLF8GLzzRzBmm24rW5IkSVLbDMvqWeVVUDEqr79cv7Dzs0ZvSOOyYvfr6o220vaKylG5VbmxOH66LYXmPLkXFRvsRn3Tk3Vskxbwrcrvrd34xi/Dtgd1b82SJEmS2mRYVs8rr4bykXnG6PqFebzupmpuyKG0uT6H8f6isiaH+IbaPPFYqdRYHK+84XA/+9EXubTyAmqi2H39Ne+HvT/U/fVKkiRJapNhWb2jYnjuply/GFYvbDtIdtQ6ayqP6l8TXZVV5InGGpbkn5TW3d+B8cr1jU0cPf9rzChbAECa/Bo4+ht9M3mZJEmSNET527d6T8WIPAN0w6JiYN7IRFjtaVpRXFM5cqt1f1MxHIhid+ySpbOaNz4T9gt/vYjXx90ALC3fnHjXFVA5ogcLliRJklTKsKzeVTkqT2zVuDiH5lTo3PlrxgQv7/01lTujckwO9Q1L1o7TTqk4Xpn2W4nn3czURy8DoD5V8Oh+33FCL0mSJKkPGJbV+yprIFEcw7x4/a7KG9K4NLcql4/M6zn3V1GW119uWLq2O3ahMYfl9mbBXvw06Y9nUUb+8zgvTmH3g47uxaIlSZIktTAsq29UjoHUnFuXGzoYmJtX57BcaMpduvu7llm6G5cW627ItbfVBbt+BVxzOlG/DIArm47glWnvYcRwb1FJkiSpL/ibuPpGBFSOza2t9Ytz6+uGpAT1tXmm6f7c/bpUxegc8htqc7fstib3Sgn+8mlYNA+Aewo7cG7TiRw0fVLv1ytJkiQJMCyrL0VA5bhimFySA2V7moprKpcN6x9rKndURHE5qbrcqpya1q//zsvg8RsAWBjj+EjDxymrGMYbZk3og4IlSZIkgWFZfS0Cho3Lra71i3KoLFVozEG6eXVuqR1oyoZBWXX+QqB0vPJTs+GWCwFIZRV8ePXHeZVx7LP1BMbX9OMx2ZIkSdIgZ1hW34uyksC8bN39DbU5RFeM7F9rKndGxcgcmitGrd225Bm47r+hOKHX7Omf4L60AwAHbzexD4qUJEmS1KKdaXmlXhbleQxz4xIgirNJj1y7pjJA+fBue7tTfjmP2+YvW2/766bV8MP/mN5t77NGRF42q0XDCrjm/0F98bPNejfffukwoJaygDfstkX31yBJkiSpw2xZVv9RVlEMzHVQvxAalxcnxlqeZ8/uRrWrmlnVmNb7qV3V1K3v06aU4C+fgYVP5NdbzeLVg7/Kfc/WAjBzy3FsM7Gq5+uQJEmS1C7DsvqXsso8IVZDbV5SqnEZlI/o9jWVP3pg292c29vere76Ecz9a34+cnM4/gr+Pm/5mtWzDpo+acD2NpckSZIGC8Oy+p+yYVBRDMyFxhyWu9lB00czYti6//mPGlbG/lNHtXNGN5l/G9zyrfy8rAKOuxTGTePGR15ec8iRuzheWZIkSeprhmX1T+VVedKvYeN7ZFKvH9zxCisbCutsW95Q4IzfPUtzIXX7+wFQ+xxcdyak4vse+TmYfgQr6puY/eRCAKaNH8XMqSN75v0lSZIkdZhhWf1XlPdIUH7oxZV86+YXASijwBfKf8ywaAbgr3Nr+d/rniOlbg7M82+FH74ZVi/Nr3d/J+x3OgCzn3iVhqYcoA+aPpEy70pJkiSpzzkbtoaU1Y0FzrjmGQqFAgeWPcw5VVezc5rHu8puZ0HzOAopwaOw8JkKJozsxttjybO5SznAljPhLRdCWR6HfUOrLthH7Dip+95TkiRJUpcZljV0pMQV1/2Td9f+kbdW3c7EqG1Z4pgRhRXMiBXQ0pC9uvjTE/b5EAwbDUBTc4F/PPYKAJuPrOK1O3TvrN+SJEmSumZQheWI2AF4P3AUsB1QDcwDfg1cmFJaUXL8ROA84M3AGOBx4KKU0mUlx40Avga8E6gE/gyckVJaXHLc24GfA7ullOZ39+dTFy19AR75Iyvu/z2nLnu6/f/qyytZNWwzFq9sasnQjK0uZ1TVpszEnWD5wrWtygD3XgF7/idEcPfTS6hdmfcdNH0iVVVOgy1JkiT1B4MqLAMfBE4HrgOuAhqAw4AvA++KiNemlFYBRMRY4FZgMnAhMB94G3BpRGyVUjq31XXPAz5ADswrgbOBHwLHthwQETXAxcC5BuV+YFUtzL0eHrkOnr8XgNbTZjWUVTOsUNJ03NzI8GMv5rbanTjrtw8AEPXwnffsyTGztupaHY/fAFcdv+62F+6FJ/8G2x/JDY+8tGbzIdvZBVuSJEnqLwZbWP4N8NWUUm2rbZdExBPAOeQw/d3i9rOBGcBxKaXfFbddFhHXAudExE9bhd7jgQtSSl8CiIgl5FBdnVJqSVznAYuAC3ros2ljmuph3s3w8HXw1C3rtuYCDamcmwp7Mn+Lozm1+q/wwt3rX+OW83nXydezdFUj//fnR0nAGb+6n9FVFRy60xadr2n2N9vefsv5pBmvX7Nk1IjKCg7fbXznry9JkiSpRwyqsJxSuqedXVeTw/LMVtveB8xvFZRbXAAcA7wb+Gpx20hgYatjFgHl5G7eqyPitcCHgQNTSk2b9CHUOakAz94Nj1wLc2+AhuXrHbJw3CwueGVv/tS8H9WjNud3/3EwceM9UDl8/euNyIH1QwdPp3ZlI9+9+UmaC4lTr7yXK0/Zj32mdjLQDh/X7vs89tIynl+yCoD9p06gZtSmdPeWJEmS1J0GVVjegMnFx1cAImISsDW5q3apO8jTPu3batttwEci4jZgFblV+pGUUm1EVAKXAZeklO7sbGERsTUwpWTzbgB1dXUsXrx4/ZP6UF1dXX5c0QCV6wfT3lK+6AmGPfEXhs27nvIVr6y3v3nsNOp3eAvPTX4Tx/22juXNzQRwzkHTGV6+jMVv/F77Fy/+mX9wn815pXYZv77/ZeqbCpx0+V388D27suPETqyDvIH3+cNta3vr77vVqH73d63ut+b+KT5K6jjvH6lrvHekrCv3wKAPyxFRDnwOaCJPvgVrw/PzpcenlOojYiHrBtiPA9cCLS3XLwDHFZ+fBYwjt1x3xcnA59vacf/997N6dU9Nybxp5jyxkHUb23tedcMipiy5gymL72DM6ufW27+6YizPj9+f58ftz9Lh21JoCL77p8Usb8iTZh26ZYGq2geYPbvj73lANTy1eRn3LixjRUMzH7pqDh/ftZkt2mgs7qw/PlAOBOWRGLPy0U7VpYFtzpw5fV2CNGB5/0hd472joe6xxx7r9DmDPiwD3wFeC3wmpTS3uG1E8bG+nXNWtzqGlNITETET2Ik8G/YjxVA9A/gM8N6UUl1EnAacBowmh+uzWiYU24AfAdeXbNsNuHSPPfZgn3326dCH7C11dXXMmTOHWdtvTs3YCT33Rq88Crd/n9j7Pxm2/HmGPfEXKl78N7FmnuosVY6gYfoR1O/wNpq2PpjxFZW0dJS+4s4XeLLuWQCmjRvB54+dSc3Isk6XcsDrCnzyd3O5bX4tyxuDy54cwRUn7MbE0VVd/ngv1tXz/B33ATBry7EcddguXb6WBo4198+sWdTU1PR1OdKA4v0jdY33jpRVV1d3+pxBHZYj4svk8PpD4Cutdq0sPraXdoYDL7XeUByL/FDJcT8Ark8pXRMR7wa+SW4pfg74CXlc82kbqjGl9Fzx+NZ1A1BTU8P48f1z0qeakcMYP3ZU91+4fjm8+jj843+hbgH8+V9QEpApq4DpB8PM44idjqGqasx6f5GPLKjje7fmP9bKsjK+9Oa9mLp11/+B+NEHx/H+y+7inmcX88ryBj7yq7n87qMHMH7ksC5d77rHnl7z/LAdpvTbv2f1jP58b0v9nfeP1DXeOxrquvJl0aANyxHxBXLX6J8Cp6aUWieuF4qPpWOFiYhqYDNgg51iI+Ik8rjmnYubTgZ+m1K6qrj/POCiiDg9pVTo+icZpArNsORZeHVu8efx/Lj0hZIDW/21Td4TdjsWdnsnjG5/KafVjc184lf309iczz31gB04cLdN+ya1urKcyz+4N+++5F88+lIdTy9ewQmX3cUv/2s/RldXdvp6rZeMesOuEzepNkmSJEndb1CG5Yj4PHkc8JXAB0rDakrppYh4Hti/jdNfCwTQxrpCa64/ATgfOCel1DLueQpwb6vDniPPlr05xYnFhqyVi9eG4Vcfh1fmwqIn81JPHTFqEvznNTBhZyi2um/I+dfPZe7LywB4zeTxnP766ZtS/Ro11ZVcecq+HPe9O3h68QoefmkpH/zxPfzslH2pruz4TNZLVzZy51N5Mq+dthjD9lO6YQC0JEmSpG416MJyRHwO+AJ5Mq+TNtCqexVwVkQcW7J81CfJk4H9agNv8y1gPnBxq20LWHdpqplAA709C1ZPe+nB/PjqEzBh8rr7mhpg8VM5FL/y+NpW4xUd/CMYPQlGTYAXH1x3+/KXcovzFhsf13v7kwv54a15lumRwyr44ltmUV298YDdUZuNquLnH96P4757Oy8tW83dzyzmIz+7j0tP3IvK8o6Nh75p7is0FXKr90HTJ3Yk/0uSJEnqZYMqLEfER4FzgWeBG4H3xLpJ5OWU0o3F518F3gn8LCL2IofftwFvAb6UUnqqnfc4krwG874lQfxK4PKIuJA8y/ZngasGVRfslODOH8C4d1F2z8/ziO9Xn1gbihc/DYUOLDNdORwm7Ahb7AwTd4GJu8HEmTBic7j8jW2fc8v5sP2RG7zs0lWN/Pev1870eOahu7LbtBEbOKNrJo8dzs8/vB/v/N4dLFnVwE2Pv8J//+oBvvUfsygr23jyvfGRl9c8f/3OdsGWJEmS+qNBFZaBlqmjtyFPsFXqn+QQTUppSUQcSJ7460NADfAk8JGU0iVtXTwihgOXAN9OKf27ZPcVwJbAR4CRwO/JS04NHg/9jtHP/Z2jn7+JYc0r4be3buSEgHHbwBY7wRa7wsRdczDebEaepKstw8flMF1qxMYnpPjcHx5iwdK81NYR22/Jfx48eSNndN12E0bxs1P25d0/+BcrGpr4wwMvUDO8ki++fRdiA03F9U3N3Dw398rfqmYEe203usdqlCRJktR1gyosp5ROAk7qxPEvAh/oxPGrgO3a2ZeA84o/g09KcPtFVBTq11u+CYDqMcVQvHMOxVsUg3H1mM69z3t/2aXyrp2zgD/cvwCAzUdW8YW37EZFRc/2b95t8hguP2lvTvjRXTQ0F/jZnU8zdkQlZ75hh3bPuX3eIlY0NAO5C3ZP1yhJkiSpawZVWFYPeuJGePHfNJVVs3LYBKobl1DVvBwO/h/Y8wQYMwXKOj7JVXd6cekqPnPN2nHOnzlyFltP7NqSTp213/TNuOSE1/Chn95LcyFx0U1PMGZEJaccNK3N41t3wT5sB7tgS5IkSf1Vx2YkkmZ/E4BlVZO5eef/Y0XVpLx9/mwYt22fBeVCIfHfv55D3eo8Vvr4WVN5674TerWGw3eayAXHz6KljfjLf3qE39zz/HrHFQppTVgeU13JwTuP68UqJUmSJHWGYVkd0zKWuLI6v66oyq87MJa4J/349qe57clFAEwbP4pPvWknyvrgv+q37TmZL75ttzWvz/7tA1z/8EvrHDPn+VpeXZaXy3rdtImMGO7tJ0mSJPVXdsNWx7SMJV68GGbPhpP+COP7Nig//vIyvvbXxwCoKAu+8MY9GD+mb1q4AU7Yf1tqVzbwzRsfpzklTv/5v7nig/twwIzNAbihVRfsg6bbBVuSJEnqz2za0oDU0FTgjF/eT0NTXpnrlP124OCZnZxMrAecfvgMTn5dHq/cWChwyhX3MOe5WmDteOVh5WUctfvmfVWiJEmSpA4wLGtAuuDGx3nkxToAZm01jo8dtR0bWLGp10QEn3nLzrzzNVMAWNnYzAk/uovrH36JJ19ZDsC+20xgszF26pAkSZL6M8OyBpw7n1rED26ZB8CIygq+9OY9GDG8HyTloojgq8fN5Kid8yRodasbOfVn967Z/69nXuGUK+7pq/IkSZIkdYBhWQPKstWNfPLqOaTiUs+fOGQXdt9uRN8W1YaK8jIuet8ejK5avwW5qZCoXdnQB1VJkiRJ6ijDsgaUL1z7CC/UrgLgkO0mctIhU/q4ovZVVZTz9Xfu3ua+jx4+o5erkSRJktQZhmUNGH958EV+e19ev3izEVWc+5bdqazsP92v2/LG3Sax61aj19k2a+uxHLpD764FLUmSJKlznGVIHXLKFXdz25ML2WZkgdN2hvdcegfPrijjdTMm8MMT9+7x93+lbjWfuubBNa8//frdmbrlsB5/300VEfz3UTvxgZ/cvWbbGa/fnugPs5FJkiRJapcty+qQ2pWNrGossLIxUUhQ35RY1VjolbG3KSX+5zcPULuyEYBjZ27LO167RY+/b3c5dMcJzJqSl7WyVVmSJEkaGAzL6pCPHpbH2L68Cs6+q5wFK/P2HSeN5l9PLerR0Pyzfz3DPx9/FYBtxo7k02/embIB9F9uRHDOm3dh6/HDOedNO9uqLEmSJA0AdsNWhxy64wR2n1zDAy8sBdaGvZ/f+Sw/v/NZALYcU81Ok0az05Y1+XFSDdMnjKSyvOvJ9slXlvN/f3oUgPKy4PNv2IPNx5Zv0mfpC/tOG8/ssw7v6zIkSZIkdZBhWR0SEZx68Hac/ev7GFeVeH4FJNZtIX1x6WpeXLqam+a+umZbZXkwY4vR7DxpNDttmQP0TpNGM2F01UZbWBubC3ziV/dT31QA4IP7bs/he4zt9s8mSZIkSaUMy+qwN+2+JdfcOZJjJtZx7cs1nPWWvXnwueU8sqCOJ15dxryFdSyoW7XOOY3NiUdfrOPRF+vg32u3jx8xbG143nI0O0+qYfuJozj9qvu47cmFxXMLFHMyo6sqOeOo7bAHsyRJkqTeYFhWh0UEJx0wjUXz5vCBA6ax41aj2XGr0cCWa45ZtrqJB59dxkPP1/HYi8uYt6iOJxcuY0VD0zrXWryygdvnLeL2eYvWbCsLGFZexuqWhNzK5LHDGTliAA1UliRJkjSgGZbVKbtsVcPsefmxLaOrKzhgh3EcsMO4NdtSSjy3aDUPPFvHwy8s4/FX6pi3cBnP1a6gOaU1xxUSbQZlgLPftGP3fhBJkiRJ2gDDsnpcRLDN5sPZZvPhvOU1E9dsX93QzKMLlvPAs8t49MUcoOctqmNxyczau08e43JLkiRJknqVYVl9pnpYOXtOHcOeU8ess/13973AJ6++f83rTxy1g8stSZIkSepVDgJVv/OOPbdi1pQcoGdtPdZWZUmSJEm9zrCsficiOOfNu7D1+OGc86adbVWWJEmS1Ovshq1+ad9p45l91uF9XYYkSZKkIcqWZUmSJEmSShiWJUmSJEkqYViWJEmSJKmEYVmSJEmSpBKGZUmSJEmSShiWJUmSJEkqYViWJEmSJKmEYVmSJEmSpBKGZUmSJEmSShiWJUmSJEkqYViWJEmSJKmEYVmSJEmSpBKGZUmSJEmSShiWJUmSJEkqYViWJEmSJKmEYVmSJEmSpBKGZUmSJEmSShiWJUmSJEkqYViWJEmSJKmEYVmSJEmSpBKGZUmSJEmSShiWJUmSJEkqYViWJEmSJKmEYVmSJEmSpBKGZUmSJEmSShiWJUmSJEkqYViWJEmSJKmEYVmSJEmSpBKGZUmSJEmSShiWJUmSJEkqYViWJEmSJKmEYVmSJEmSpBKGZUmSJEmSShiWJUmSJEkqYViWJEmSJKmEYVmSJEmSpBKGZUmSJEmSShiWJUmSJEkqYViWJEmSJKmEYVmSJEmSpBKGZUmSJEmSShiWJUmSJEkqMejCckR8KiJ+HRFPRUSKiKc3cvzEiLg8Il6OiNUR8UBEfKiN40ZExEUR8WJELIyIn0bE+DaOe3tErIiIad34sSRJkiRJvaiirwvoAV8BFgP3AWM3dGBEjAVuBSYDFwLzgbcBl0bEVimlc1sdfh7wAeBrwErgbOCHwLGtrlcDXAycm1Ka3y2fRpIkSZLU6wZjWN4upfQUQEQ8BIzawLFnAzOA41JKvytuuywirgXOiYiftgq9xwMXpJS+VLz2EnKork4prS4ecx6wCLigez+SJEmSJKk3Dbpu2C1BuYPeB8xvFZRbXABUAu9utW0ksLDV60VAOVANEBGvBT4MfDil1NTZuiVJkiRJ/cdgbFnukIiYBGwNXNXG7juABOzbatttwEci4jZgFblV+pGUUm1EVAKXAZeklO7sZB1bA1NKNu8GUFdXx+LFiztzuR5XV1e3zqOkjvP+kbrO+0fqGu8dKevKPTBkwzJ5nDLA86U7Ukr1EbGQdUPsx4FrgXuKr18Ajis+PwsYB5zThTpOBj7f1o7777+f1atXt7Wrz82ZM6evS5AGLO8fqeu8f6Su8d7RUPfYY491+pyhHJZHFB/r29m/utUxpJSeiIiZwE7kLtqPFEP1DOAzwHtTSnURcRpwGjCaHK7PSimt2kAdPwKuL9m2G3DpHnvswT777NPZz9Wj6urqmDNnDrNmzaKmpqavy5EGFO8fqeu8f6Su8d6Rsurq6k6fM5TD8sriY1U7+4cDL7XeUByL/FDJcT8Ark8pXRMR7wa+SW4tfg74CXlc82ntFZFSeq547BoRAUBNTQ3jx6+3OlW/0J9rk/o77x+p67x/pK7x3tFQ15UviwbdBF+d8ELxsXS8MBFRDWxGG120S447iTyu+fTippOB36aUrkopzaa43FREDOU/Z0mSJEkacIZsiEspvUQOw/u3sfu1QAB3t3d+REwAzgfOSSm1hOoprNtK/Bx5tuzNu6NmSZIkSVLvGLJhuegqYFpEHFuy/ZNAE/CrDZz7LWA+cHGrbQuAma1ezwQaWHfJKUmSJElSPzfoxixHxAnAtsWXE4BhEfGZ4uvalFLrcPtV4J3AzyJiL3L4fRvwFuBL7a3ZHBFHktdg3jelVGi160rg8oi4kNxq/VngqpJjJEmSJEn93KALy+Rxw4eUbPtS8fEZWrUEp5SWRMSBwFeADwE1wJPAR1JKl7R18YgYDlwCfDul9O+S3VcAWwIfAUYCvycvOSVJkiRJGkAGXVhOKR3ayeNfBD7QieNXAdu1sy+RJ/U6rzM1SJIkSZL6l6E+ZlmSJEmSpPUYliVJkiRJKmFYliRJkiSphGFZkiRJkqQShmVJkiRJkkoYliVJkiRJKmFYliRJkiSphGFZkiRJkqQShmVJkiRJkkoYliVJkiRJKmFYliRJkiSphGFZkiRJkqQShmVJkiRJkkoYliVJkiRJKmFYliRJkiSphGFZkiRJkqQShmVJkiRJkkoYliVJkiRJKmFYliRJkiSphGFZkiRJkqQShmVJkiRJkkoYliVJkiRJKmFYliRJkiSphGFZkiRJkqQShmVJkiRJkkoYliVJkiRJKmFYliRJkiSphGFZkiRJkqQShmVJkiRJkkoYliVJkiRJKmFYliRJkiSphGFZkiRJkqQShmVJkiRJkkoYliVJkiRJKmFYliRJkiSphGFZkiRJkqQShmVJkiRJkkoYliVJkiRJKmFYliRJkiSphGFZkiRJkqQShmVJkiRJkkoYliVJkiRJKmFYliRJkiSphGFZkiRJkqQShmVJkiRJkkoYliVJkiRJKmFYliRJkiSphGFZkiRJkqQShmVJkiRJkkoYliVJkiRJKmFYliRJkiSphGFZkiRJkqQShmVJkiRJkkoYliVJkiRJKmFYliRJkiSphGFZkiRJkqQShmVJkiRJkkoYliVJkiRJKmFYliRJkiSphGFZkiRJkqQShmVJkiRJkkoYliVJkiRJKmFYliRJkiSphGFZkiRJkqQSQz4sR8R7IuLeiFgVEQsj4hcRsW3JMYdExN0RsTwiHoqId7RxnfLidb7fe9VLkiRJknrCkA7LEXE6cBWwCvgEcCFwJHB7RGxVPGZr4E9AHXAm8Cjw64h4TcnlzgC2Av63N2qXJEmSJPWcir4uoK9ExGbAecB9wKEppabi9r8CdwFfBE4BjgbKgbemlFZExGXAU8BxxXMptkSfC3wgpbS0tz+LJEmSJKl7DeWW5bcBo4DvtARlgJTSPcAtwLsiYhgwEliVUlpR3F8AlhS3t/g+cHNK6de9VbwkSZIkqecM2ZZlYN/i4+1t7LsdOATYCbgNGBcRnwauJHfTngV8BfKYZ+BgYNeuFFHs5j2lZPNeAP/617+oq6vrymV7zIoVK3jiiSdobm5m5MiRGz9B0hreP1LXef9IXeO9I2WPPPJIy9MRHT1nKIflycXH59vY17JtSkrpzxHxBXK37P8rbv9hSunXETEO+BbwuZTSM12s42Tg823t+OQnP9nFS0qSJEmS2jAd+HtHDhzKYbnlG4X6Nvatbn1MSunciPgeMAN4NqX0QnH/N4AFwLcjYhvgO+QW62eBs1NK/+xAHT8Cri/ZthmwC3AvsLJjH6fX7AZcCnwYeKiPa5EGGu8fqeu8f6Su8d6RshHkoPzHjp4wlMNySwitIs+G3drwkmNIKb0KvNryOiIOBk4E9i9u+hPwDHAM8A7grxGxY0rp2Q0VkVJ6DniujV0d/kvsTRHR8vShlNIdfVmLNNB4/0hd5/0jdY33jrSODrUotxjKE3y1tA6XjheGDXfRJiKqyN/QXVycEGw/8rd2Z6SU7gU+CywE3tetFUuSJEmSesVQDst3Fx8PaGPfAcBy4LF2zj2H3Iz/2eLrlsD9HEBKKZGD9tbdUqkkSZIkqVcN5bD8B3I3649FxJru6BGxN3l266tTSg2lJ0XEzsDZwOkppeXFzQuKjzOLx1QB27faLkmSJEkaQIbsmOWU0sLiclAXAjdHxM+AzYFPAC8Dnys9J/Kgj8uA61JK17badSfwBPDTiLgYOBqoAX7Vox+ibzwPnEs7XdQlbZD3j9R13j9S13jvSF0Uucfw0BUR7wPOBHYmtzTfCHwqpTS/jWNPBb4O7JxSWlCyb0fg+8A+5Im+/jel1C8n6ZIkSZIkbdiQD8uSJEmSJJUaymOWJUmSJElqk2FZkiRJkqQShmVJkiRJkkoYliVJkiRJKmFYliRJkiSphGFZkiRJkqQShmV1WES8JyLujYhVEbEwIn4REdv2dV1SfxcRoyLisxHxUEQsj4hXI+LWiHh/X9cm9QcR8amI+HVEPBURKSKe7sA5R0bEnyNiUUSsjoj5EXFVRAzrhZKlfiEidoiIL0bEv4r/tiyLiPsj4pyIGLmRc08r3m8pIib1Vs3SQOI6y+qQiDgduAi4DbgS2Bw4A6gH9kkpLei76qT+KyLKgNnAa4GfAHcCI4ETgD2BL6WUPtdnBUr9QEQkYDFwH7AXUJdSmrqB4z8FfAW4CbgOqAMmAgcDx6aUVvZ0zVJ/EBFfBU4n3wd3AA3AYcC7gAeA16aUVrVx3lbAo+SGs1HAlimll3qrbmmgMCxroyJiM+Bp4HFgv5RSU3H73sBdwOUppVP6rkKp/4qI/YHbgQtTSp9otX048BT5/8N+o68hLSKmp5SeKj5/CBjVXliOiMOBvwHnpZTO6b0qpf6n+LvYkyml2pLtXwbOAU5PKX23jfN+B0wDHgLej2FZapPdsNURbyN/6/idlqAMkFK6B7gFeJfd3qR2jSk+rtP7ovhN/xLAFjANeS1BuYPOARYCX4A1wxzKe6Iuqb9LKd1TGpSLri4+zizdERFvJ/9u919Ac48VJw0ChmV1xL7Fx9vb2Hc7MBrYqffKkQaUu8hdRM+KiOMjYuuI2DkivgXsSPEXfkkbVxyDeQh5OMMJEfEMsAxYERF/iIjpfVqg1H9MLj6+0npjRNQAFwOXppTu7PWqpAGmoq8L0IDQ8j/c59vY17JtCnlsjKRWUkqLi9/iX8bab/oBaoG3pZT+2Bd1SQPUDKAc2A84CjgfuIc8/v9sYN+ImJVSeqX9S0iDW7GnxeeAJuDnJbvPI//+/6nerksaiAzL6ogRxcf6NvatLjlG0vqWAP8GriH3xhgLfAS4OiKOSyn9pQ9rkwaS0cXHCcCpKaVLi6+vKbYy/xD4BAYBDW3fIU8q+ZmU0tyWjcU5NP4L+M92um5LKmE3bHVEy5jKqjb2DS85RlIrETGTPEPp31JK/5NSuial9GPgIOAZ4PKIaOvekrS+lll9C8AVJft+Sh5/eVivViT1I8WJvU4jf3H0lVbbK8k9nG5KKZW2Nktqh2FZHfFC8XFKG/s21EVbUm7lqgZ+3XpjSqke+D0wCcf8Sx3V8m/NkuI9tEZKqZE88df4Xq9K6gci4gvkCfB+Su550XrJm48COwNfj4ipLT/kCVwBto6IbXuzXmkgsBu2OuJu4FTgAOCJkn0HAMuBx3q7KGmAaPlCqbKNfS3b/H+x1AEppZcj4mlg24gYmVJa0bIvIqrJ3bNL/52SBr2I+DzweeBK4AMppULJIVPJjWTXt3OJu8jD7ap7qkZpILJlWR3xB3I3649FxJpf6otr+x0MXJ1Sauir4qR+7pHi40mtN0bEaOB4YAXwcC/XJA1kPwWC3FLW2kfJv9f8qdcrkvpQRHyOvLLCz4GT2gjKAD8C3tHGz03F/R8g/5skqZVYt4eG1LaI+DhwIXAb8DNgc3L30kZg75TSC+2fLQ1dxW5t9wHjgKuAW4vPTwa2A/47pfTNvqtQ6nsRcQLQ0gX0/wHDgJb7ojaldHGrY0eT5wHYBbicPBv2a8j31MPA/q1bnKXBLCI+Sl4K6lnyDNil6ya/nFK6cQPn/wQ4EdgypfRST9UpDVSGZXVYRLwPOJM85mUlcCPwqZTS/D4tTOrnImIKeXbeI4BtyL/M3A9cnFL6VR+WJvULEXEzef3ktjyTUppacvx44Fxyy9gWwEvA74AvOMuvhpJWYbc9/0wpHdqB8w3LUhsMy5IkSZIklXDMsiRJkiRJJQzLkiRJkiSVMCxLkiRJklTCsCxJkiRJUgnDsiRJkiRJJQzLkiRJkiSVMCxLkiRJklTCsCxJkiRJUgnDsiRJkiRJJQzLkiRJkiSVMCxLkqSNioibI+Lpvq5jU0TE0xFxc1/XIUkaGAzLkiR1UUTURMRnI+K+iFgWESsj4pGI+HpEbNHX9fW0iHh7RHyhr+toLSLOiIiT+roOSdLAFymlvq5BkqQBJyJ2AK4HtgV+B9wENAKvBd4PLAXeklK6s8+K7EYRMYz8e0N9q20/AU5MKUWfFVai2Pr9dErp0Db2VQEppdTQ23VJkgaeir4uQJKkgSYiRgDXAZOBY1JKf2q1+9KI+B7wN+DaiJiZUnqlj+oclVJa3h3X6u2AWQy2zSmlpu66ZuugL0nSxtgNW5KkzjsZ2AH4VklQBiCldA/waWAL4H9atkfESRGRIuLQ0nPaGxMcEXtHxDURsTAi6iNibkScExEVbZ0fEdMj4jcRsRhYFhF7Ft/z/9r6IBFxbbH7+JgNfeDS+orPTyw+T61+Dm11zPYR8bOIeDEiGor1fSMiRpZc+yfFcydExOUR8TKwCphS3H9aRNwQES8Ur/NiRFwZEVNbXWNqRCRyS/8hrWtqXXNbY5Yj4piImF3sSr8iIu6KiPe092cQEVMi4uqIWFI8/vpiTwNJ0iBiy7IkSZ33zuLjZRs45ifAhcBxtArMnRERbwKuAZ4EvgksBvYHvgjsARxfcsoo4J/ArcA5wBYppX9HxD3ASRHxuZRSc6vrTwKOBq5KKS3tZHlnAJ8EDgJOaLX90eK19wL+AdQCPwBeAHYHPga8LiIOSSk1llzzRmAB8CVgJNDSKn4mcHtxfy2wG3AKcHix5X4R8Gqxjm8BC4E2vxwoFREfLtb3BHAe0EDuRn9VRExLKX2l5JSR5D/jO8hfiEwDPg78ISJ2a/3nK0ka2AzLkiR13m7AspTSk+0dkFJaGRFzgd260h06IqqBHwN3Aoe36o78g4iYA1wQEYemlG5uddpmwBdTSp8vudylxZ+jgT+22n4i+XeBH3amNoCU0u8j4u3AQSmlK9s45HLgJWDvlNKyVp/rH+Qx3u8jf6HQ2pyU0oltXGv3lNKK1hsi4lpyV/eTga8X918ZEV8GXm6npnVExFjgAuBpYJ+WLwyK3ejvAM6NiCtTSs+2Om1z4Bsppa+3us6rwNeB15PHsUuSBgG7YUuS1Hk15Am8NqblmNFdeI8jyd24fwqMjYjNW36APxePOaqN8y5oY9svgGXkYNnaB4G5KaXZXaivXRExk9yK/EugqqT2W4EVdLx2WoJyRJRFxJjideaQ/3z324RSjyS3FF/UumU9pbQSOJ/8RcJbS84pAN8p2faP4uP2m1CLJKmfMSxLktR5dcAGx/gWjSGHq4VdeI+di4+XkbsYt/55rLhvYsk5r7bVnbrYqn0V8JaImAgQEQeRx13/qAu1bUxL7Z9j/dpfIQfU0tohd4VeT0QcXhxrvILcDbvlWmOAcZtQ5/Ti48Nt7Huw5JgWC1JKq0u2LSo+brYJtUiS+hm7YUuS1HkPAQdHxIz2umIXJ7HaEXim1djcDa3XWPpvcstyTP8L3NvOOQtKXq/cwPV/AJxK7nr9dXIrcyNwxQbO6aqW2i8E1psArWhJ6YZii+66F4rYF7iBPG77f4H55Mm/ErnlelO++N/Qklft7dvQmOR+s4SWJGnTGZYlSeq83wIHAx8GzmrnmJOASqD12NnFxcfxbRw/jRxeWzxefFyZUvpblystKk70dS9wckRcQp4c7LpNXNaqvfDfUnuhG2p/D1AOHJ1Smt+ysfhlRFutyhv6QqLUvOLjrqw/1njXkmMkSUOM3bAlSeq8H5ID4RnFGavXERF7k2djfhH4bqtdLSHy9SXHvwfYquQy15O7LJ9VHKNb+h7DI6KzY6EvJXe9/i4wgi5M7FViebGW0tB6P7kb84cjYkbpSRFRERFtfWHQlpaW3NJW20/T9u8xy+l41+wbyV27T4+Imlb1VZNn4G4ir6ctSRqCbFmWJKmTijNdvxX4K/DHiPgtcBM5XO1HXnqoFnhbSunlVufNjYi/AadGRJBD5R7AO8jdjCtL3uM/gd8Dj0XE5eQxvWOBnYBji+fd3InSryJPXPV+4Dk2febmO4HTge9GxF/ILeP/SCm9Uqz9H8D9xdofJgf0GcXaP8X6s2G35RrgE8CfI+JS8tJOR5InEGtrLPidwAcj4gvAXCCllH7Z1oVTSrURcSZwCXB3RPy4+BneT/57OadkJmxJ0hBiWJYkqQuKwXcWeY3dY8nLMo0s7n4YODClVNvGqScAF5GXTjoBmA0cBnwfmFryHtdHxD7ksbrvAyaQx/rOI88c/UAna14eEb8gdx//cUqp0Jnz2/ALYC/gP4B3k1t6DwNeSSndHxF7kkPxW4H/Is/I/TQ5JP+9gzXfFhHHAZ8lr7+8irxk1CHALW2c8hny8k5nsHYStjbDcvH6P4iIF8nd6T9LbsF+CHhfSumqjtQoSRqcIqXODO2RJEntiYgK4NfA24EzU0ptLoXUlyLiYuAjwPSU0jN9XY8kSf2VYVmSpG4UEcPIXYffBJyWUvp+H5e0RkSMIXe/np1SenNf1yNJUn9mWJYkaZCLiN2APcnLRh1O7iJ+e99WJUlS/+Zs2JIkDX7vBH5KnhjsNIOyJEkbZ8uyJEmSJEklbFmWJEmSJKmEYVmSJEmSpBKGZUmSJEmSShiWJUmSJEkqYViWJEmSJKmEYVmSJEmSpBKGZUmSJEmSShiWJUmSJEkqYViWJEmSJKmEYVmSJEmSpBKGZUmSJEmSSvx/tIVLSbbQpbQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1105x1040 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(8.5, 8), dpi=130)\n",
    "ax.plot(median_climate1,label=\"Hunman selection\")\n",
    "ax.fill_between(range(31),min_climate1,max_climate1,color='blue', alpha=0.1)\n",
    "ax.plot(median_climate2,label=\"Random selection\")\n",
    "ax.fill_between(range(31),min_climate2,max_climate2,color='orange', alpha=0.1)\n",
    "\n",
    "ax.scatter(range(31), median_climate1, s=8,marker = \"v\")\n",
    "ax.scatter(range(31), median_climate2, s=8,marker=\"^\")\n",
    "\n",
    "ax.xaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=5, integer=True))\n",
    "ax.yaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=10))\n",
    "ax.yaxis.set_major_formatter(mpl.ticker.PercentFormatter(xmax=1))\n",
    "\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "ax.set_title('Different initial data set in climate target')\n",
    "ax.set_xlabel('Query iteration')\n",
    "ax.set_ylabel('Performance(median)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf3e3af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dd8c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d5e330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7aa68ed3",
   "metadata": {},
   "source": [
    "# Feminist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77eb5f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_feminist\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset with 597 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_feminist\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset with 67 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_feminist\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset with 285 instances loaded\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "cache_dir = \"./data_cache\"\n",
    "\n",
    "train_dataset_feminist = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_feminist\",\n",
    "    split=\"train\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Training dataset with {len(train_dataset_feminist)} instances loaded\")\n",
    "\n",
    "val_dataset_feminist = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_feminist\",\n",
    "    split=\"validation\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Validation dataset with {len(val_dataset_feminist)} instances loaded\")\n",
    "\n",
    "test_dataset_feminist = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_feminist\",\n",
    "    split=\"test\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Test dataset with {len(test_dataset_feminist)} instances loaded\")\n",
    "\n",
    "num_classes = np.unique(train_dataset_feminist['label']).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a047c7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/config.json from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\3cf34679007e9fe5d0acd644dcc1f4b26bec5cbc9612364f6da7262aed4ef7a4.a5a11219cf90aae61ff30e1658ccf2cb4aa84d6b6e947336556f887c9828dc6d\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-tiny\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/pytorch_model.bin from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\1ee037c9e1a220d5c814779ffe697080d1e6f5b1602e16cf6061aaae41a082c5.038e1aed90492a59d2283f9c44c9fe3ee2380495ff1e7fefb3f1f04af3b685b5\n",
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_original = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\", num_labels=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2141011f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1116' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 03:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:32:20.691804Z [info     ] Start Predict                  dataset=588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:02<00:00, 33.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:32:25.115084Z [info     ] Start Predict                  dataset=568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:02<00:00, 32.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:32:29.746085Z [info     ] Start Predict                  dataset=548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [00:02<00:00, 32.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:32:34.516085Z [info     ] Start Predict                  dataset=528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:02<00:00, 32.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:32:39.638083Z [info     ] Start Predict                  dataset=508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:01<00:00, 33.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:32:44.797111Z [info     ] Start Predict                  dataset=488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 33.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:32:50.089081Z [info     ] Start Predict                  dataset=468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:01<00:00, 32.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:32:55.667082Z [info     ] Start Predict                  dataset=448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 32.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:33:01.525017Z [info     ] Start Predict                  dataset=428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 32.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:33:07.607534Z [info     ] Start Predict                  dataset=408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 32.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:33:14.372562Z [info     ] Start Predict                  dataset=388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 33.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:33:20.665611Z [info     ] Start Predict                  dataset=368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 32.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:33:27.210580Z [info     ] Start Predict                  dataset=348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 33.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:33:34.559104Z [info     ] Start Predict                  dataset=328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 32.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:33:41.468098Z [info     ] Start Predict                  dataset=308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 33.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:33:48.409097Z [info     ] Start Predict                  dataset=288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 33.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:33:55.486132Z [info     ] Start Predict                  dataset=268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 32.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:34:03.022683Z [info     ] Start Predict                  dataset=248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 32.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:34:11.029008Z [info     ] Start Predict                  dataset=228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:34:18.658824Z [info     ] Start Predict                  dataset=208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 32.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:34:26.473823Z [info     ] Start Predict                  dataset=188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 32.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:34:34.565822Z [info     ] Start Predict                  dataset=168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:34:42.798849Z [info     ] Start Predict                  dataset=148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 33.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:34:51.154699Z [info     ] Start Predict                  dataset=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 32.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:35:00.162697Z [info     ] Start Predict                  dataset=108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 33.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:35:08.941114Z [info     ] Start Predict                  dataset=88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 33.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:35:17.950114Z [info     ] Start Predict                  dataset=68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 35.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:35:27.120112Z [info     ] Start Predict                  dataset=48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 33.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:35:36.512116Z [info     ] Start Predict                  dataset=28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 37.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 589\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:35:45.967172Z [info     ] Start Predict                  dataset=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 28.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4, 0.40350877192982454, 0.40350877192982454, 0.4982456140350877, 0.4982456140350877, 0.5543859649122806, 0.5754385964912281, 0.6, 0.6210526315789474, 0.6175438596491228, 0.6175438596491228, 0.631578947368421, 0.6385964912280702, 0.6070175438596491, 0.6350877192982456, 0.624561403508772, 0.6421052631578947, 0.6175438596491228, 0.6175438596491228, 0.6385964912280702, 0.6350877192982456, 0.631578947368421, 0.624561403508772, 0.6350877192982456, 0.6421052631578947, 0.6280701754385964, 0.631578947368421, 0.6421052631578947, 0.6350877192982456, 0.6421052631578947, 0.6491228070175439]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1116' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 03:27]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:35:49.767171Z [info     ] Start Predict                  dataset=588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:02<00:00, 33.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:35:54.188256Z [info     ] Start Predict                  dataset=568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:02<00:00, 32.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:35:59.481223Z [info     ] Start Predict                  dataset=548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [00:02<00:00, 32.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:36:04.337951Z [info     ] Start Predict                  dataset=528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:02<00:00, 32.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:36:09.354241Z [info     ] Start Predict                  dataset=508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:01<00:00, 33.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:36:14.712241Z [info     ] Start Predict                  dataset=488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 32.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:36:20.081934Z [info     ] Start Predict                  dataset=468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:01<00:00, 33.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:36:25.575979Z [info     ] Start Predict                  dataset=448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 33.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:36:31.477979Z [info     ] Start Predict                  dataset=428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 32.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:36:37.335980Z [info     ] Start Predict                  dataset=408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 33.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:36:43.541010Z [info     ] Start Predict                  dataset=388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 32.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:36:50.102621Z [info     ] Start Predict                  dataset=368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 32.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:36:56.638623Z [info     ] Start Predict                  dataset=348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 32.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:37:03.193566Z [info     ] Start Predict                  dataset=328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 32.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:37:09.988567Z [info     ] Start Predict                  dataset=308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 33.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:37:17.027596Z [info     ] Start Predict                  dataset=288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 33.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:37:24.442125Z [info     ] Start Predict                  dataset=268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 33.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:37:31.855123Z [info     ] Start Predict                  dataset=248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 32.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:37:39.313122Z [info     ] Start Predict                  dataset=228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:37:47.315876Z [info     ] Start Predict                  dataset=208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 32.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:37:55.248418Z [info     ] Start Predict                  dataset=188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 34.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:38:03.544418Z [info     ] Start Predict                  dataset=168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 32.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:38:11.825966Z [info     ] Start Predict                  dataset=148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 34.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:38:20.114967Z [info     ] Start Predict                  dataset=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 32.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:38:28.629965Z [info     ] Start Predict                  dataset=108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 33.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:38:37.396966Z [info     ] Start Predict                  dataset=88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 33.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:38:46.502510Z [info     ] Start Predict                  dataset=68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 35.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:38:55.672513Z [info     ] Start Predict                  dataset=48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 32.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:39:04.990147Z [info     ] Start Predict                  dataset=28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 36.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 589\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:39:14.368149Z [info     ] Start Predict                  dataset=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 27.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4, 0.40350877192982454, 0.40350877192982454, 0.4982456140350877, 0.4982456140350877, 0.5543859649122806, 0.5754385964912281, 0.6, 0.6210526315789474, 0.6175438596491228, 0.6175438596491228, 0.631578947368421, 0.6385964912280702, 0.6070175438596491, 0.6350877192982456, 0.624561403508772, 0.6421052631578947, 0.6175438596491228, 0.6175438596491228, 0.6385964912280702, 0.6350877192982456, 0.631578947368421, 0.624561403508772, 0.6350877192982456, 0.6421052631578947, 0.6280701754385964, 0.631578947368421, 0.6421052631578947, 0.6350877192982456, 0.6421052631578947, 0.6491228070175439]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1116' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 03:25]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:39:18.128149Z [info     ] Start Predict                  dataset=588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:02<00:00, 33.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:39:22.614149Z [info     ] Start Predict                  dataset=568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:02<00:00, 32.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:39:27.300150Z [info     ] Start Predict                  dataset=548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [00:02<00:00, 33.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:39:32.043179Z [info     ] Start Predict                  dataset=528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:02<00:00, 32.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:39:37.051601Z [info     ] Start Predict                  dataset=508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:01<00:00, 33.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:39:42.244603Z [info     ] Start Predict                  dataset=488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 32.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:39:47.669053Z [info     ] Start Predict                  dataset=468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:01<00:00, 33.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:39:53.114054Z [info     ] Start Predict                  dataset=448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 33.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:39:58.770055Z [info     ] Start Predict                  dataset=428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 32.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:40:04.708983Z [info     ] Start Predict                  dataset=408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 32.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:40:10.848744Z [info     ] Start Predict                  dataset=388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 33.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:40:17.056006Z [info     ] Start Predict                  dataset=368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 33.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:40:23.517007Z [info     ] Start Predict                  dataset=348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 33.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:40:30.464038Z [info     ] Start Predict                  dataset=328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 33.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:40:37.119013Z [info     ] Start Predict                  dataset=308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 33.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:40:44.050310Z [info     ] Start Predict                  dataset=288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 33.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:40:51.161279Z [info     ] Start Predict                  dataset=268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 33.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:40:58.630838Z [info     ] Start Predict                  dataset=248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 32.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:41:06.383836Z [info     ] Start Predict                  dataset=228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:41:14.073836Z [info     ] Start Predict                  dataset=208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 33.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:41:21.950095Z [info     ] Start Predict                  dataset=188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 33.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:41:29.925098Z [info     ] Start Predict                  dataset=168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 32.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:41:38.092787Z [info     ] Start Predict                  dataset=148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 33.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:41:46.462787Z [info     ] Start Predict                  dataset=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 33.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:41:55.055789Z [info     ] Start Predict                  dataset=108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 33.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:42:03.699355Z [info     ] Start Predict                  dataset=88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 33.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:42:12.609354Z [info     ] Start Predict                  dataset=68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 34.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:42:21.651355Z [info     ] Start Predict                  dataset=48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 32.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:42:30.875353Z [info     ] Start Predict                  dataset=28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 37.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 589\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:42:40.213389Z [info     ] Start Predict                  dataset=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 31.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4, 0.40350877192982454, 0.40350877192982454, 0.4982456140350877, 0.4982456140350877, 0.5543859649122806, 0.5754385964912281, 0.6, 0.6210526315789474, 0.6175438596491228, 0.6175438596491228, 0.631578947368421, 0.6385964912280702, 0.6070175438596491, 0.6350877192982456, 0.624561403508772, 0.6421052631578947, 0.6175438596491228, 0.6175438596491228, 0.6385964912280702, 0.6350877192982456, 0.631578947368421, 0.624561403508772, 0.6350877192982456, 0.6421052631578947, 0.6280701754385964, 0.631578947368421, 0.6421052631578947, 0.6350877192982456, 0.6421052631578947, 0.6491228070175439]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1116' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 03:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:42:43.958390Z [info     ] Start Predict                  dataset=588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:02<00:00, 33.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:42:48.315390Z [info     ] Start Predict                  dataset=568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:02<00:00, 32.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:42:52.958534Z [info     ] Start Predict                  dataset=548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [00:02<00:00, 33.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:42:57.739564Z [info     ] Start Predict                  dataset=528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:02<00:00, 31.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:43:02.883534Z [info     ] Start Predict                  dataset=508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:01<00:00, 32.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:43:08.110552Z [info     ] Start Predict                  dataset=488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 33.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:43:13.235555Z [info     ] Start Predict                  dataset=468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:01<00:00, 33.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:43:18.735554Z [info     ] Start Predict                  dataset=448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 33.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:43:24.368552Z [info     ] Start Predict                  dataset=428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 33.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:43:30.098554Z [info     ] Start Predict                  dataset=408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 33.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:43:36.248020Z [info     ] Start Predict                  dataset=388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 33.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:43:42.491990Z [info     ] Start Predict                  dataset=368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 33.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:43:48.861991Z [info     ] Start Predict                  dataset=348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 33.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:43:55.373984Z [info     ] Start Predict                  dataset=328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 33.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:44:02.194485Z [info     ] Start Predict                  dataset=308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 33.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:44:09.169485Z [info     ] Start Predict                  dataset=288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 32.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:44:16.194065Z [info     ] Start Predict                  dataset=268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 33.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:44:23.445037Z [info     ] Start Predict                  dataset=248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 32.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:44:30.892034Z [info     ] Start Predict                  dataset=228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:44:38.568207Z [info     ] Start Predict                  dataset=208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 32.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:44:46.258210Z [info     ] Start Predict                  dataset=188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 34.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:44:54.232207Z [info     ] Start Predict                  dataset=168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 31.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:45:02.369725Z [info     ] Start Predict                  dataset=148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 34.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:45:10.661728Z [info     ] Start Predict                  dataset=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 33.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:45:18.945725Z [info     ] Start Predict                  dataset=108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 33.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:45:27.646727Z [info     ] Start Predict                  dataset=88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 33.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:45:36.539729Z [info     ] Start Predict                  dataset=68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 35.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:45:45.615021Z [info     ] Start Predict                  dataset=48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 33.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:45:54.834023Z [info     ] Start Predict                  dataset=28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 36.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 589\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:46:04.245022Z [info     ] Start Predict                  dataset=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 27.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4, 0.40350877192982454, 0.40350877192982454, 0.4982456140350877, 0.4982456140350877, 0.5543859649122806, 0.5754385964912281, 0.6, 0.6210526315789474, 0.6175438596491228, 0.6175438596491228, 0.631578947368421, 0.6385964912280702, 0.6070175438596491, 0.6350877192982456, 0.624561403508772, 0.6421052631578947, 0.6175438596491228, 0.6175438596491228, 0.6385964912280702, 0.6350877192982456, 0.631578947368421, 0.624561403508772, 0.6350877192982456, 0.6421052631578947, 0.6280701754385964, 0.631578947368421, 0.6421052631578947, 0.6350877192982456, 0.6421052631578947, 0.6491228070175439]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1116' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 03:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:46:08.058509Z [info     ] Start Predict                  dataset=588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:02<00:00, 33.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:46:12.273507Z [info     ] Start Predict                  dataset=568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:02<00:00, 32.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:46:17.350509Z [info     ] Start Predict                  dataset=548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [00:02<00:00, 33.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:46:21.917509Z [info     ] Start Predict                  dataset=528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:02<00:00, 32.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:46:26.939507Z [info     ] Start Predict                  dataset=508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:01<00:00, 33.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:46:32.086509Z [info     ] Start Predict                  dataset=488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 32.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:46:37.505509Z [info     ] Start Predict                  dataset=468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:01<00:00, 33.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:46:43.066511Z [info     ] Start Predict                  dataset=448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 32.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:46:48.733533Z [info     ] Start Predict                  dataset=428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 33.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:46:54.612530Z [info     ] Start Predict                  dataset=408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 33.03it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:47:00.779562Z [info     ] Start Predict                  dataset=388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 33.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:47:07.049576Z [info     ] Start Predict                  dataset=368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 33.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:47:13.683645Z [info     ] Start Predict                  dataset=348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 33.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:47:20.096646Z [info     ] Start Predict                  dataset=328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 32.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:47:27.283645Z [info     ] Start Predict                  dataset=308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 33.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:47:34.323645Z [info     ] Start Predict                  dataset=288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 32.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:47:41.592646Z [info     ] Start Predict                  dataset=268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 33.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:47:48.924645Z [info     ] Start Predict                  dataset=248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 32.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:47:56.383157Z [info     ] Start Predict                  dataset=228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:48:04.006178Z [info     ] Start Predict                  dataset=208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 33.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:48:11.932237Z [info     ] Start Predict                  dataset=188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 33.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:48:19.963236Z [info     ] Start Predict                  dataset=168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 32.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:48:28.223237Z [info     ] Start Predict                  dataset=148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 33.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:48:36.594237Z [info     ] Start Predict                  dataset=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 32.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:48:45.173757Z [info     ] Start Predict                  dataset=108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 34.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:48:53.814760Z [info     ] Start Predict                  dataset=88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 33.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:49:02.786758Z [info     ] Start Predict                  dataset=68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 35.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:49:12.981789Z [info     ] Start Predict                  dataset=48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 32.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:49:22.217786Z [info     ] Start Predict                  dataset=28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 35.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 589\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:49:31.687994Z [info     ] Start Predict                  dataset=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 31.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4, 0.40350877192982454, 0.40350877192982454, 0.4982456140350877, 0.4982456140350877, 0.5543859649122806, 0.5754385964912281, 0.6, 0.6210526315789474, 0.6175438596491228, 0.6175438596491228, 0.631578947368421, 0.6385964912280702, 0.6070175438596491, 0.6350877192982456, 0.624561403508772, 0.6421052631578947, 0.6175438596491228, 0.6175438596491228, 0.6385964912280702, 0.6350877192982456, 0.631578947368421, 0.624561403508772, 0.6350877192982456, 0.6421052631578947, 0.6280701754385964, 0.631578947368421, 0.6421052631578947, 0.6350877192982456, 0.6421052631578947, 0.6491228070175439]\n"
     ]
    }
   ],
   "source": [
    "active_mc_feminist1 = []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "while mcrun != 5:\n",
    "#     n_labeled_examples = np.unique(train_dataset_feminist['text']).size\n",
    "#     training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "#     print(training_indices0)\n",
    "    active_set_feminist =active_huggingface_dataset(train_dataset_feminist,tokenizer,'label','text')\n",
    "    valid_set_feminist = HuggingFaceDatasets(test_dataset_feminist,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_feminist.can_label = False\n",
    "    active_set_feminist.label([0,1,2,3,4,5,6,7,10])\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_feminist,\n",
    "            eval_dataset=valid_set_feminist,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_feminist = ActiveLearningLoop(active_set_feminist,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_feminist=[unqueried_score]\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_feminist.step()\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_feminist.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_feminist),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_feminist.append(eval_metrics['eval_accuracy'])\n",
    "    print(performance_history_feminist)\n",
    "    active_mc_feminist1.append(performance_history_feminist)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "614f3f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1116' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 03:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:49:35.526994Z [info     ] Start Predict                  dataset=588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:02<00:00, 33.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:49:39.969994Z [info     ] Start Predict                  dataset=568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:02<00:00, 32.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:49:44.623994Z [info     ] Start Predict                  dataset=548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [00:02<00:00, 32.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:49:49.333441Z [info     ] Start Predict                  dataset=528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 33.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:49:54.282441Z [info     ] Start Predict                  dataset=508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:01<00:00, 33.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:49:59.372441Z [info     ] Start Predict                  dataset=488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 32.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:50:04.674472Z [info     ] Start Predict                  dataset=468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:01<00:00, 32.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:50:10.274308Z [info     ] Start Predict                  dataset=448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 33.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:50:15.978598Z [info     ] Start Predict                  dataset=428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 32.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:50:21.919629Z [info     ] Start Predict                  dataset=408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 33.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:50:27.924599Z [info     ] Start Predict                  dataset=388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 33.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:50:34.150595Z [info     ] Start Predict                  dataset=368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 33.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:50:42.649906Z [info     ] Start Predict                  dataset=348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 33.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:50:50.275389Z [info     ] Start Predict                  dataset=328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 32.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:50:57.645391Z [info     ] Start Predict                  dataset=308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 31.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:51:04.509943Z [info     ] Start Predict                  dataset=288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 33.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:51:11.736940Z [info     ] Start Predict                  dataset=268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 33.66it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:51:19.079942Z [info     ] Start Predict                  dataset=248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 32.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:51:26.624993Z [info     ] Start Predict                  dataset=228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:51:34.282992Z [info     ] Start Predict                  dataset=208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 32.66it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:51:42.157031Z [info     ] Start Predict                  dataset=188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 33.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:51:50.079035Z [info     ] Start Predict                  dataset=168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 30.66it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:51:58.316549Z [info     ] Start Predict                  dataset=148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 33.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:52:06.781549Z [info     ] Start Predict                  dataset=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 33.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:52:15.383548Z [info     ] Start Predict                  dataset=108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 32.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:52:24.205129Z [info     ] Start Predict                  dataset=88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 33.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:52:33.132544Z [info     ] Start Predict                  dataset=68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 31.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:52:42.355057Z [info     ] Start Predict                  dataset=48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 32.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:52:51.535059Z [info     ] Start Predict                  dataset=28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 35.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 589\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:53:00.882609Z [info     ] Start Predict                  dataset=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 29.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4105263157894737, 0.38596491228070173, 0.40350877192982454, 0.49473684210526314, 0.5228070175438596, 0.543859649122807, 0.5754385964912281, 0.5964912280701754, 0.5824561403508772, 0.6280701754385964, 0.6175438596491228, 0.6350877192982456, 0.6421052631578947, 0.6105263157894737, 0.6280701754385964, 0.6385964912280702, 0.6385964912280702, 0.6421052631578947, 0.6385964912280702, 0.6385964912280702, 0.6350877192982456, 0.631578947368421, 0.6385964912280702, 0.6456140350877193, 0.6456140350877193, 0.631578947368421, 0.631578947368421, 0.6385964912280702, 0.631578947368421, 0.6421052631578947, 0.6421052631578947]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1116' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 03:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:53:04.585613Z [info     ] Start Predict                  dataset=588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:02<00:00, 32.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:53:08.988610Z [info     ] Start Predict                  dataset=568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:02<00:00, 33.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:53:13.586639Z [info     ] Start Predict                  dataset=548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [00:02<00:00, 33.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:53:18.266611Z [info     ] Start Predict                  dataset=528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:02<00:00, 32.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:53:23.301608Z [info     ] Start Predict                  dataset=508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:01<00:00, 33.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:53:28.406610Z [info     ] Start Predict                  dataset=488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 32.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:53:33.928689Z [info     ] Start Predict                  dataset=468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:01<00:00, 33.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:53:39.631685Z [info     ] Start Predict                  dataset=448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 33.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:53:45.417689Z [info     ] Start Predict                  dataset=428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 33.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:53:51.206198Z [info     ] Start Predict                  dataset=408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 32.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:53:57.236684Z [info     ] Start Predict                  dataset=388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 33.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:54:03.472406Z [info     ] Start Predict                  dataset=368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 33.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:54:09.908406Z [info     ] Start Predict                  dataset=348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 33.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:54:16.574407Z [info     ] Start Predict                  dataset=328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 33.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:54:23.428407Z [info     ] Start Predict                  dataset=308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 33.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:54:30.446404Z [info     ] Start Predict                  dataset=288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 32.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:54:37.602407Z [info     ] Start Predict                  dataset=268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 33.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:54:44.946410Z [info     ] Start Predict                  dataset=248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 33.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:54:52.503404Z [info     ] Start Predict                  dataset=228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:55:00.147406Z [info     ] Start Predict                  dataset=208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 32.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:55:08.025407Z [info     ] Start Predict                  dataset=188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 32.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:55:17.450561Z [info     ] Start Predict                  dataset=168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:55:25.532560Z [info     ] Start Predict                  dataset=148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 34.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:55:33.923562Z [info     ] Start Predict                  dataset=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 32.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:55:42.423562Z [info     ] Start Predict                  dataset=108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 34.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:55:51.135767Z [info     ] Start Predict                  dataset=88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 31.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:56:01.569069Z [info     ] Start Predict                  dataset=68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 34.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:56:11.720247Z [info     ] Start Predict                  dataset=48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 34.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:56:20.960702Z [info     ] Start Predict                  dataset=28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 37.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 589\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:56:30.389221Z [info     ] Start Predict                  dataset=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 27.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36140350877192984, 0.37543859649122807, 0.41754385964912283, 0.47719298245614034, 0.5017543859649123, 0.5017543859649123, 0.5298245614035088, 0.5859649122807018, 0.6175438596491228, 0.631578947368421, 0.631578947368421, 0.6350877192982456, 0.6210526315789474, 0.5929824561403508, 0.5543859649122806, 0.6385964912280702, 0.5824561403508772, 0.6035087719298246, 0.6175438596491228, 0.6280701754385964, 0.6421052631578947, 0.631578947368421, 0.6385964912280702, 0.6385964912280702, 0.6385964912280702, 0.631578947368421, 0.6210526315789474, 0.6421052631578947, 0.6350877192982456, 0.6350877192982456, 0.6456140350877193]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1116' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 03:32]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:56:34.290221Z [info     ] Start Predict                  dataset=588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:02<00:00, 33.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:56:38.677223Z [info     ] Start Predict                  dataset=568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:02<00:00, 33.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:56:43.175739Z [info     ] Start Predict                  dataset=548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [00:02<00:00, 32.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:56:50.457489Z [info     ] Start Predict                  dataset=528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 33.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:56:56.911343Z [info     ] Start Predict                  dataset=508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:01<00:00, 32.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:57:02.017313Z [info     ] Start Predict                  dataset=488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 32.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:57:07.363315Z [info     ] Start Predict                  dataset=468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:01<00:00, 32.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:57:13.027316Z [info     ] Start Predict                  dataset=448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 33.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:57:18.704316Z [info     ] Start Predict                  dataset=428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 33.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:57:26.469313Z [info     ] Start Predict                  dataset=408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 33.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:57:33.390375Z [info     ] Start Predict                  dataset=388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 30.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:57:40.033877Z [info     ] Start Predict                  dataset=368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 31.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:57:46.594428Z [info     ] Start Predict                  dataset=348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 33.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:57:53.172510Z [info     ] Start Predict                  dataset=328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 33.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:58:00.713590Z [info     ] Start Predict                  dataset=308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 33.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:58:07.731621Z [info     ] Start Predict                  dataset=288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 33.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:58:14.875619Z [info     ] Start Predict                  dataset=268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 32.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:58:22.313622Z [info     ] Start Predict                  dataset=248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 32.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:58:29.688621Z [info     ] Start Predict                  dataset=228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:58:37.311621Z [info     ] Start Predict                  dataset=208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 33.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:58:45.074691Z [info     ] Start Predict                  dataset=188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 33.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:58:52.958690Z [info     ] Start Predict                  dataset=168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 32.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:59:01.222495Z [info     ] Start Predict                  dataset=148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 33.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:59:09.510826Z [info     ] Start Predict                  dataset=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 30.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:59:18.013829Z [info     ] Start Predict                  dataset=108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 34.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:59:26.769827Z [info     ] Start Predict                  dataset=88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 32.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:59:35.663369Z [info     ] Start Predict                  dataset=68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 35.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:59:44.622338Z [info     ] Start Predict                  dataset=48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 32.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T12:59:54.175243Z [info     ] Start Predict                  dataset=28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 36.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 589\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:00:03.674240Z [info     ] Start Predict                  dataset=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 31.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36140350877192984, 0.37543859649122807, 0.41754385964912283, 0.47719298245614034, 0.5017543859649123, 0.5017543859649123, 0.5298245614035088, 0.5859649122807018, 0.6175438596491228, 0.631578947368421, 0.631578947368421, 0.6350877192982456, 0.6210526315789474, 0.5929824561403508, 0.5543859649122806, 0.6385964912280702, 0.5824561403508772, 0.6035087719298246, 0.6175438596491228, 0.6280701754385964, 0.6421052631578947, 0.631578947368421, 0.6385964912280702, 0.6385964912280702, 0.6385964912280702, 0.631578947368421, 0.6210526315789474, 0.6421052631578947, 0.6350877192982456, 0.6350877192982456, 0.6456140350877193]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1116' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 03:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:00:07.651755Z [info     ] Start Predict                  dataset=588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:02<00:00, 33.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:00:11.997756Z [info     ] Start Predict                  dataset=568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:02<00:00, 33.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:00:16.575757Z [info     ] Start Predict                  dataset=548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [00:02<00:00, 32.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:00:21.300757Z [info     ] Start Predict                  dataset=528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:02<00:00, 33.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:00:26.350760Z [info     ] Start Predict                  dataset=508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:01<00:00, 33.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:00:32.226754Z [info     ] Start Predict                  dataset=488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 32.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:00:38.242756Z [info     ] Start Predict                  dataset=468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:01<00:00, 33.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:00:43.776202Z [info     ] Start Predict                  dataset=448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 32.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:00:49.596712Z [info     ] Start Predict                  dataset=428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 32.89it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:00:55.575169Z [info     ] Start Predict                  dataset=408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 33.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:01:01.848166Z [info     ] Start Predict                  dataset=388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 33.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:01:08.002167Z [info     ] Start Predict                  dataset=368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 33.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:01:14.536170Z [info     ] Start Predict                  dataset=348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 33.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:01:21.104170Z [info     ] Start Predict                  dataset=328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 32.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:01:27.865010Z [info     ] Start Predict                  dataset=308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 33.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:01:35.036041Z [info     ] Start Predict                  dataset=288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 32.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:01:42.285010Z [info     ] Start Predict                  dataset=268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 31.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:01:49.557011Z [info     ] Start Predict                  dataset=248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 33.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:01:57.014040Z [info     ] Start Predict                  dataset=228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:02:04.692551Z [info     ] Start Predict                  dataset=208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 32.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:02:12.622551Z [info     ] Start Predict                  dataset=188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 33.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:02:20.522117Z [info     ] Start Predict                  dataset=168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:02:29.044575Z [info     ] Start Predict                  dataset=148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 34.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:02:37.373561Z [info     ] Start Predict                  dataset=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 33.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:02:45.875560Z [info     ] Start Predict                  dataset=108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 33.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:02:54.654559Z [info     ] Start Predict                  dataset=88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 33.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:03:03.632563Z [info     ] Start Predict                  dataset=68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 32.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:03:12.738838Z [info     ] Start Predict                  dataset=48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 32.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:03:21.943839Z [info     ] Start Predict                  dataset=28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 31.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 589\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:03:31.371198Z [info     ] Start Predict                  dataset=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 28.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36140350877192984, 0.37543859649122807, 0.41754385964912283, 0.47719298245614034, 0.5017543859649123, 0.5017543859649123, 0.5298245614035088, 0.5859649122807018, 0.6175438596491228, 0.631578947368421, 0.631578947368421, 0.6350877192982456, 0.6210526315789474, 0.5929824561403508, 0.5543859649122806, 0.6385964912280702, 0.5824561403508772, 0.6035087719298246, 0.6175438596491228, 0.6280701754385964, 0.6421052631578947, 0.631578947368421, 0.6385964912280702, 0.6385964912280702, 0.6385964912280702, 0.631578947368421, 0.6210526315789474, 0.6421052631578947, 0.6350877192982456, 0.6350877192982456, 0.6456140350877193]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1116' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 03:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:03:35.235198Z [info     ] Start Predict                  dataset=588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:02<00:00, 33.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:03:39.604196Z [info     ] Start Predict                  dataset=568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:02<00:00, 32.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:03:44.125227Z [info     ] Start Predict                  dataset=548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [00:02<00:00, 33.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:03:48.802260Z [info     ] Start Predict                  dataset=528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:02<00:00, 32.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:03:53.797260Z [info     ] Start Predict                  dataset=508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:01<00:00, 33.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:03:58.900290Z [info     ] Start Predict                  dataset=488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 33.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:04:04.346262Z [info     ] Start Predict                  dataset=468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:01<00:00, 33.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:04:09.856822Z [info     ] Start Predict                  dataset=448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 32.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:04:15.738791Z [info     ] Start Predict                  dataset=428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 33.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:04:21.657792Z [info     ] Start Predict                  dataset=408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 33.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:04:27.636791Z [info     ] Start Predict                  dataset=388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 31.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:04:34.469313Z [info     ] Start Predict                  dataset=368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 31.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:04:41.288311Z [info     ] Start Predict                  dataset=348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 31.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:04:48.043312Z [info     ] Start Predict                  dataset=328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 32.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:04:54.930803Z [info     ] Start Predict                  dataset=308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 33.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:05:01.971379Z [info     ] Start Predict                  dataset=288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 32.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:05:09.076896Z [info     ] Start Predict                  dataset=268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 33.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:05:16.452446Z [info     ] Start Predict                  dataset=248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 32.73it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:05:23.940447Z [info     ] Start Predict                  dataset=228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:05:31.672445Z [info     ] Start Predict                  dataset=208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 30.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:05:39.582236Z [info     ] Start Predict                  dataset=188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 33.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:05:47.534210Z [info     ] Start Predict                  dataset=168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 32.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:05:55.839207Z [info     ] Start Predict                  dataset=148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 32.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:06:04.210723Z [info     ] Start Predict                  dataset=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 32.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:06:12.846604Z [info     ] Start Predict                  dataset=108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 32.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:06:21.955602Z [info     ] Start Predict                  dataset=88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 32.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:06:30.937118Z [info     ] Start Predict                  dataset=68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 34.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:06:39.924118Z [info     ] Start Predict                  dataset=48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 31.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:06:49.284632Z [info     ] Start Predict                  dataset=28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 35.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 589\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:06:59.925708Z [info     ] Start Predict                  dataset=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 33.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36140350877192984, 0.37543859649122807, 0.41754385964912283, 0.47719298245614034, 0.5017543859649123, 0.5017543859649123, 0.5298245614035088, 0.5859649122807018, 0.6175438596491228, 0.631578947368421, 0.631578947368421, 0.6350877192982456, 0.6210526315789474, 0.5929824561403508, 0.5543859649122806, 0.6385964912280702, 0.5824561403508772, 0.6035087719298246, 0.6175438596491228, 0.6280701754385964, 0.6421052631578947, 0.631578947368421, 0.6385964912280702, 0.6385964912280702, 0.6385964912280702, 0.631578947368421, 0.6210526315789474, 0.6421052631578947, 0.6350877192982456, 0.6350877192982456, 0.6456140350877193]\n"
     ]
    }
   ],
   "source": [
    "active_mc_feminist2 = []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "while mcrun != 5:\n",
    "#     n_labeled_examples = np.unique(train_dataset_feminist['text']).size\n",
    "#     training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "#     print(training_indices0)\n",
    "    active_set_feminist =active_huggingface_dataset(train_dataset_feminist,tokenizer,'label','text')\n",
    "    valid_set_feminist = HuggingFaceDatasets(test_dataset_feminist,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_feminist.can_label = False\n",
    "    active_set_feminist.label_randomly(9)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_feminist,\n",
    "            eval_dataset=valid_set_feminist,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_feminist = ActiveLearningLoop(active_set_feminist,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_feminist=[unqueried_score]\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_feminist.step()\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_feminist.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_feminist),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_feminist.append(eval_metrics['eval_accuracy'])\n",
    "    print(performance_history_feminist)\n",
    "    active_mc_feminist2.append(performance_history_feminist)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "256c0a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_feminist1, min_feminist1,max_feminist1= calculate(active_mc_feminist1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9bbe6bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_feminist2, min_feminist2,max_feminist2= calculate(active_mc_feminist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12010cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1105x1040 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(8.5, 8), dpi=130)\n",
    "ax.plot(median_feminist1,label=\"Hunman selection\")\n",
    "ax.fill_between(range(31),min_feminist1,max_feminist1,color='blue', alpha=0.1)\n",
    "ax.plot(median_feminist2,label=\"Random selection\")\n",
    "ax.fill_between(range(31),min_feminist2,max_feminist2,color='orange', alpha=0.1)\n",
    "\n",
    "ax.scatter(range(31), median_feminist1, s=8,marker = \"v\")\n",
    "ax.scatter(range(31), median_feminist2, s=8,marker=\"^\")\n",
    "\n",
    "ax.xaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=5, integer=True))\n",
    "ax.yaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=10))\n",
    "ax.yaxis.set_major_formatter(mpl.ticker.PercentFormatter(xmax=1))\n",
    "\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "ax.set_title('Different initial data set in feminist target')\n",
    "ax.set_xlabel('Query iteration')\n",
    "ax.set_ylabel('Performance(median)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4473388d",
   "metadata": {},
   "source": [
    "# Hillary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef68d9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_hillary\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset with 620 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_hillary\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset with 69 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_hillary\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset with 295 instances loaded\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "cache_dir = \"./data_cache\"\n",
    "\n",
    "train_dataset_hillary = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_hillary\",\n",
    "    split=\"train\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Training dataset with {len(train_dataset_hillary)} instances loaded\")\n",
    "\n",
    "val_dataset_hillary = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_hillary\",\n",
    "    split=\"validation\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Validation dataset with {len(val_dataset_hillary)} instances loaded\")\n",
    "\n",
    "test_dataset_hillary = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_hillary\",\n",
    "    split=\"test\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Test dataset with {len(test_dataset_hillary)} instances loaded\")\n",
    "\n",
    "num_classes = np.unique(train_dataset_hillary['label']).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1e275f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/config.json from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\3cf34679007e9fe5d0acd644dcc1f4b26bec5cbc9612364f6da7262aed4ef7a4.a5a11219cf90aae61ff30e1658ccf2cb4aa84d6b6e947336556f887c9828dc6d\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-tiny\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/pytorch_model.bin from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\1ee037c9e1a220d5c814779ffe697080d1e6f5b1602e16cf6061aaae41a082c5.038e1aed90492a59d2283f9c44c9fe3ee2380495ff1e7fefb3f1f04af3b685b5\n",
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_original = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\", num_labels=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a11a7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1147' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 03:32]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:07:08.866129Z [info     ] Start Predict                  dataset=611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 77/77 [00:02<00:00, 33.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:07:13.388130Z [info     ] Start Predict                  dataset=591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:02<00:00, 32.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:07:18.140129Z [info     ] Start Predict                  dataset=571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 72/72 [00:02<00:00, 33.03it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:07:23.091152Z [info     ] Start Predict                  dataset=551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [00:02<00:00, 31.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:07:28.403899Z [info     ] Start Predict                  dataset=531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 33.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:07:33.860900Z [info     ] Start Predict                  dataset=511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:01<00:00, 33.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:07:39.471898Z [info     ] Start Predict                  dataset=491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [00:01<00:00, 33.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:07:45.093929Z [info     ] Start Predict                  dataset=471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:01<00:00, 32.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:07:50.935959Z [info     ] Start Predict                  dataset=451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 32.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:07:56.972928Z [info     ] Start Predict                  dataset=431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 32.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:08:03.245414Z [info     ] Start Predict                  dataset=411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 32.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:08:09.757414Z [info     ] Start Predict                  dataset=391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 32.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:08:16.418415Z [info     ] Start Predict                  dataset=371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 32.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:08:23.980008Z [info     ] Start Predict                  dataset=351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 32.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:08:31.031006Z [info     ] Start Predict                  dataset=331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 32.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:08:38.318115Z [info     ] Start Predict                  dataset=311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 33.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:08:45.722083Z [info     ] Start Predict                  dataset=291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 32.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:08:53.351055Z [info     ] Start Predict                  dataset=271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 32.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:09:01.530056Z [info     ] Start Predict                  dataset=251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 32.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:09:09.208055Z [info     ] Start Predict                  dataset=231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:09:17.326059Z [info     ] Start Predict                  dataset=211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 33.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:09:25.488055Z [info     ] Start Predict                  dataset=191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 32.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:09:33.924058Z [info     ] Start Predict                  dataset=171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 30.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:09:42.882057Z [info     ] Start Predict                  dataset=151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 33.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:09:51.549212Z [info     ] Start Predict                  dataset=131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 31.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:10:00.536241Z [info     ] Start Predict                  dataset=111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 33.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:10:09.611211Z [info     ] Start Predict                  dataset=91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 34.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:10:18.724211Z [info     ] Start Predict                  dataset=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 33.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:10:28.206212Z [info     ] Start Predict                  dataset=51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 32.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 589\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:10:37.962085Z [info     ] Start Predict                  dataset=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 32.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2542372881355932, 0.27796610169491526, 0.2576271186440678, 0.2576271186440678, 0.28135593220338984, 0.2983050847457627, 0.2983050847457627, 0.2745762711864407, 0.31186440677966104, 0.376271186440678, 0.3389830508474576, 0.49830508474576274, 0.488135593220339, 0.5423728813559322, 0.5389830508474577, 0.5694915254237288, 0.5830508474576271, 0.5898305084745763, 0.5898305084745763, 0.6033898305084746, 0.5694915254237288, 0.5966101694915255, 0.5898305084745763, 0.5898305084745763, 0.5627118644067797, 0.5932203389830508, 0.5694915254237288, 0.5830508474576271, 0.5898305084745763, 0.5830508474576271, 0.5796610169491525]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1147' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 03:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:10:41.799087Z [info     ] Start Predict                  dataset=611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 77/77 [00:02<00:00, 32.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:10:46.343142Z [info     ] Start Predict                  dataset=591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:02<00:00, 32.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:10:51.031141Z [info     ] Start Predict                  dataset=571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 72/72 [00:02<00:00, 33.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:10:55.938142Z [info     ] Start Predict                  dataset=551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [00:02<00:00, 30.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:11:01.385142Z [info     ] Start Predict                  dataset=531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 33.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:11:06.763905Z [info     ] Start Predict                  dataset=511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:01<00:00, 33.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:11:13.114694Z [info     ] Start Predict                  dataset=491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [00:01<00:00, 31.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:11:19.044694Z [info     ] Start Predict                  dataset=471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:01<00:00, 32.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:11:25.105697Z [info     ] Start Predict                  dataset=451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 33.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:11:31.189725Z [info     ] Start Predict                  dataset=431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 32.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:11:37.420113Z [info     ] Start Predict                  dataset=411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 33.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:11:43.811110Z [info     ] Start Predict                  dataset=391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 33.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:11:50.588113Z [info     ] Start Predict                  dataset=371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 33.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:11:57.426110Z [info     ] Start Predict                  dataset=351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 31.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:12:04.596630Z [info     ] Start Predict                  dataset=331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 31.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:12:11.713632Z [info     ] Start Predict                  dataset=311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 31.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:12:20.712629Z [info     ] Start Predict                  dataset=291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 33.51it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:12:28.202820Z [info     ] Start Predict                  dataset=271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 33.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:12:36.001849Z [info     ] Start Predict                  dataset=251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 33.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:12:43.774819Z [info     ] Start Predict                  dataset=231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:12:52.698824Z [info     ] Start Predict                  dataset=211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 33.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:13:01.111731Z [info     ] Start Predict                  dataset=191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 32.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:13:09.693246Z [info     ] Start Predict                  dataset=171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 33.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:13:18.210218Z [info     ] Start Predict                  dataset=151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 33.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:13:26.864220Z [info     ] Start Predict                  dataset=131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 34.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:13:35.795225Z [info     ] Start Predict                  dataset=111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 32.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:13:44.914227Z [info     ] Start Predict                  dataset=91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 34.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:13:54.161225Z [info     ] Start Predict                  dataset=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 33.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:14:03.629239Z [info     ] Start Predict                  dataset=51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 36.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 589\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:14:13.318239Z [info     ] Start Predict                  dataset=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 30.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2542372881355932, 0.27796610169491526, 0.2576271186440678, 0.2576271186440678, 0.28135593220338984, 0.2983050847457627, 0.2983050847457627, 0.2745762711864407, 0.31186440677966104, 0.376271186440678, 0.3389830508474576, 0.49830508474576274, 0.488135593220339, 0.5423728813559322, 0.5389830508474577, 0.5694915254237288, 0.5830508474576271, 0.5898305084745763, 0.5898305084745763, 0.6033898305084746, 0.5694915254237288, 0.5966101694915255, 0.5898305084745763, 0.5898305084745763, 0.5627118644067797, 0.5932203389830508, 0.5694915254237288, 0.5830508474576271, 0.5898305084745763, 0.5830508474576271, 0.5796610169491525]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1147' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 03:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:14:17.852237Z [info     ] Start Predict                  dataset=611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 77/77 [00:02<00:00, 32.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:14:22.379237Z [info     ] Start Predict                  dataset=591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:02<00:00, 32.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:14:27.111239Z [info     ] Start Predict                  dataset=571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 72/72 [00:02<00:00, 33.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:14:31.969237Z [info     ] Start Predict                  dataset=551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [00:02<00:00, 32.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:14:37.072267Z [info     ] Start Predict                  dataset=531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 32.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:14:42.430237Z [info     ] Start Predict                  dataset=511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:01<00:00, 32.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:14:48.926237Z [info     ] Start Predict                  dataset=491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [00:01<00:00, 33.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:14:54.612241Z [info     ] Start Predict                  dataset=471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:01<00:00, 33.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:15:00.533239Z [info     ] Start Predict                  dataset=451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 32.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:15:06.610241Z [info     ] Start Predict                  dataset=431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 32.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:15:12.880237Z [info     ] Start Predict                  dataset=411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 32.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:15:19.305238Z [info     ] Start Predict                  dataset=391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 33.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:15:25.938237Z [info     ] Start Predict                  dataset=371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 33.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:15:32.782236Z [info     ] Start Predict                  dataset=351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 32.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:15:39.622238Z [info     ] Start Predict                  dataset=331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 33.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:15:46.827236Z [info     ] Start Predict                  dataset=311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 33.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:15:54.183240Z [info     ] Start Predict                  dataset=291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 32.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:16:01.805045Z [info     ] Start Predict                  dataset=271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 32.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:16:09.816591Z [info     ] Start Predict                  dataset=251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 33.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:16:17.767593Z [info     ] Start Predict                  dataset=231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:16:25.821610Z [info     ] Start Predict                  dataset=211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 33.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:16:34.043611Z [info     ] Start Predict                  dataset=191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 33.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:16:42.754610Z [info     ] Start Predict                  dataset=171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 33.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:16:51.461611Z [info     ] Start Predict                  dataset=151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 32.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:17:00.477589Z [info     ] Start Predict                  dataset=131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 33.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:17:09.473592Z [info     ] Start Predict                  dataset=111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 33.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:17:18.614132Z [info     ] Start Predict                  dataset=91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 34.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:17:28.058102Z [info     ] Start Predict                  dataset=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 33.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:17:37.594646Z [info     ] Start Predict                  dataset=51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 35.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 589\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:17:47.169646Z [info     ] Start Predict                  dataset=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 33.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2542372881355932, 0.27796610169491526, 0.2576271186440678, 0.2576271186440678, 0.28135593220338984, 0.2983050847457627, 0.2983050847457627, 0.2745762711864407, 0.31186440677966104, 0.376271186440678, 0.3389830508474576, 0.49830508474576274, 0.488135593220339, 0.5423728813559322, 0.5389830508474577, 0.5694915254237288, 0.5830508474576271, 0.5898305084745763, 0.5898305084745763, 0.6033898305084746, 0.5694915254237288, 0.5966101694915255, 0.5898305084745763, 0.5898305084745763, 0.5627118644067797, 0.5932203389830508, 0.5694915254237288, 0.5830508474576271, 0.5898305084745763, 0.5830508474576271, 0.5796610169491525]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1147' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 03:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:17:50.954159Z [info     ] Start Predict                  dataset=611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 77/77 [00:02<00:00, 32.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:17:55.548187Z [info     ] Start Predict                  dataset=591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:02<00:00, 32.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:18:00.259158Z [info     ] Start Predict                  dataset=571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 72/72 [00:02<00:00, 32.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:18:05.187158Z [info     ] Start Predict                  dataset=551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [00:02<00:00, 32.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:18:10.351157Z [info     ] Start Predict                  dataset=531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 33.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:18:15.725156Z [info     ] Start Predict                  dataset=511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:01<00:00, 32.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:18:21.894677Z [info     ] Start Predict                  dataset=491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [00:02<00:00, 29.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:18:27.925234Z [info     ] Start Predict                  dataset=471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:01<00:00, 32.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:18:33.949262Z [info     ] Start Predict                  dataset=451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 31.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:18:40.020233Z [info     ] Start Predict                  dataset=431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 31.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:18:46.347460Z [info     ] Start Predict                  dataset=411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 31.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:18:52.789459Z [info     ] Start Predict                  dataset=391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 32.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:18:59.347462Z [info     ] Start Predict                  dataset=371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 32.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:19:06.168461Z [info     ] Start Predict                  dataset=351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 32.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:19:13.087460Z [info     ] Start Predict                  dataset=331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 32.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:19:20.295644Z [info     ] Start Predict                  dataset=311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 32.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:19:27.642645Z [info     ] Start Predict                  dataset=291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 33.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:19:35.502156Z [info     ] Start Predict                  dataset=271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 32.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:19:43.392094Z [info     ] Start Predict                  dataset=251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 32.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:19:51.380574Z [info     ] Start Predict                  dataset=231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:19:59.274575Z [info     ] Start Predict                  dataset=211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 34.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:20:07.446088Z [info     ] Start Predict                  dataset=191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 32.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:20:15.925087Z [info     ] Start Predict                  dataset=171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 33.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:20:24.481665Z [info     ] Start Predict                  dataset=151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 33.51it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:20:33.193636Z [info     ] Start Predict                  dataset=131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 33.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:20:42.084636Z [info     ] Start Predict                  dataset=111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 33.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:20:51.203636Z [info     ] Start Predict                  dataset=91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 33.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:21:00.440557Z [info     ] Start Predict                  dataset=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 32.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:21:09.891554Z [info     ] Start Predict                  dataset=51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 35.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 589\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:21:19.543555Z [info     ] Start Predict                  dataset=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 33.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2542372881355932, 0.27796610169491526, 0.2576271186440678, 0.2576271186440678, 0.28135593220338984, 0.2983050847457627, 0.2983050847457627, 0.2745762711864407, 0.31186440677966104, 0.376271186440678, 0.3389830508474576, 0.49830508474576274, 0.488135593220339, 0.5423728813559322, 0.5389830508474577, 0.5694915254237288, 0.5830508474576271, 0.5898305084745763, 0.5898305084745763, 0.6033898305084746, 0.5694915254237288, 0.5966101694915255, 0.5898305084745763, 0.5898305084745763, 0.5627118644067797, 0.5932203389830508, 0.5694915254237288, 0.5830508474576271, 0.5898305084745763, 0.5830508474576271, 0.5796610169491525]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1147' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 03:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:21:23.318555Z [info     ] Start Predict                  dataset=611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 77/77 [00:02<00:00, 32.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:21:27.823557Z [info     ] Start Predict                  dataset=591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:02<00:00, 32.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:21:32.568556Z [info     ] Start Predict                  dataset=571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 72/72 [00:02<00:00, 32.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:21:37.522557Z [info     ] Start Predict                  dataset=551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [00:02<00:00, 31.89it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:21:42.835555Z [info     ] Start Predict                  dataset=531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 32.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:21:48.192555Z [info     ] Start Predict                  dataset=511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:01<00:00, 32.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:21:53.697573Z [info     ] Start Predict                  dataset=491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [00:01<00:00, 31.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:21:59.350907Z [info     ] Start Predict                  dataset=471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:01<00:00, 32.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:22:05.338449Z [info     ] Start Predict                  dataset=451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 32.73it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:22:11.351100Z [info     ] Start Predict                  dataset=431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 32.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:22:17.521126Z [info     ] Start Predict                  dataset=411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 32.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:22:23.873156Z [info     ] Start Predict                  dataset=391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 31.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:22:30.709156Z [info     ] Start Predict                  dataset=371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 32.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:22:37.533125Z [info     ] Start Predict                  dataset=351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 32.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:22:44.585127Z [info     ] Start Predict                  dataset=331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 30.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:22:52.027157Z [info     ] Start Predict                  dataset=311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 31.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:22:59.390126Z [info     ] Start Predict                  dataset=291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 31.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:23:07.279547Z [info     ] Start Predict                  dataset=271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 30.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:23:15.652548Z [info     ] Start Predict                  dataset=251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 28.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:23:24.359549Z [info     ] Start Predict                  dataset=231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:23:32.456617Z [info     ] Start Predict                  dataset=211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 33.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:23:41.127779Z [info     ] Start Predict                  dataset=191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 34.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:23:49.487807Z [info     ] Start Predict                  dataset=171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 33.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:23:58.101803Z [info     ] Start Predict                  dataset=151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 33.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:24:06.736028Z [info     ] Start Predict                  dataset=131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 34.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:24:15.492041Z [info     ] Start Predict                  dataset=111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 33.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:24:25.071590Z [info     ] Start Predict                  dataset=91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 33.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:24:34.401208Z [info     ] Start Predict                  dataset=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 33.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:24:43.947855Z [info     ] Start Predict                  dataset=51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 36.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 589\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:24:53.606839Z [info     ] Start Predict                  dataset=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 31.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2542372881355932, 0.27796610169491526, 0.2576271186440678, 0.2576271186440678, 0.28135593220338984, 0.2983050847457627, 0.2983050847457627, 0.2745762711864407, 0.31186440677966104, 0.376271186440678, 0.3389830508474576, 0.49830508474576274, 0.488135593220339, 0.5423728813559322, 0.5389830508474577, 0.5694915254237288, 0.5830508474576271, 0.5898305084745763, 0.5898305084745763, 0.6033898305084746, 0.5694915254237288, 0.5966101694915255, 0.5898305084745763, 0.5898305084745763, 0.5627118644067797, 0.5932203389830508, 0.5694915254237288, 0.5830508474576271, 0.5898305084745763, 0.5830508474576271, 0.5796610169491525]\n"
     ]
    }
   ],
   "source": [
    "active_mc_hillary1 = []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "while mcrun != 5:\n",
    "#     n_labeled_examples = np.unique(train_dataset_hillary['text']).size\n",
    "#     training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "#     print(training_indices0)\n",
    "    active_set_hillary =active_huggingface_dataset(train_dataset_hillary,tokenizer,'label','text')\n",
    "    valid_set_hillary = HuggingFaceDatasets(test_dataset_hillary,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_hillary.can_label = False\n",
    "    active_set_hillary.label([0,1,2,3,4,5,6,8,15])\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_hillary,\n",
    "            eval_dataset=valid_set_hillary,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_hillary = ActiveLearningLoop(active_set_hillary,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_hillary=[unqueried_score]\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_hillary.step()\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_hillary.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_hillary),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_hillary.append(eval_metrics['eval_accuracy'])\n",
    "    print(performance_history_hillary)\n",
    "    active_mc_hillary1.append(performance_history_hillary)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5f55411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1147' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 03:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:24:57.569361Z [info     ] Start Predict                  dataset=611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 77/77 [00:02<00:00, 31.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:25:02.139359Z [info     ] Start Predict                  dataset=591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:02<00:00, 32.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:25:06.925900Z [info     ] Start Predict                  dataset=571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 72/72 [00:02<00:00, 32.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:25:11.936200Z [info     ] Start Predict                  dataset=551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [00:02<00:00, 32.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:25:17.091150Z [info     ] Start Predict                  dataset=531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 26.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:25:23.572632Z [info     ] Start Predict                  dataset=511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:02<00:00, 27.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:25:29.482166Z [info     ] Start Predict                  dataset=491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [00:01<00:00, 32.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:25:35.246165Z [info     ] Start Predict                  dataset=471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:01<00:00, 29.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:25:41.398166Z [info     ] Start Predict                  dataset=451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 32.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:25:47.485682Z [info     ] Start Predict                  dataset=431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 32.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:25:53.898680Z [info     ] Start Predict                  dataset=411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 32.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:26:00.298682Z [info     ] Start Predict                  dataset=391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 32.51it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:26:07.116712Z [info     ] Start Predict                  dataset=371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 32.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:26:14.021425Z [info     ] Start Predict                  dataset=351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 32.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:26:21.088426Z [info     ] Start Predict                  dataset=331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 32.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:26:28.381091Z [info     ] Start Predict                  dataset=311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 31.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:26:35.680089Z [info     ] Start Predict                  dataset=291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 33.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:26:43.996709Z [info     ] Start Predict                  dataset=271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 32.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:26:51.713148Z [info     ] Start Predict                  dataset=251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 32.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:26:59.480149Z [info     ] Start Predict                  dataset=231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.73it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:27:07.353149Z [info     ] Start Predict                  dataset=211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 33.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:27:15.547249Z [info     ] Start Predict                  dataset=191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 32.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:27:23.883247Z [info     ] Start Predict                  dataset=171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 33.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:27:32.376249Z [info     ] Start Predict                  dataset=151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 32.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:27:41.032247Z [info     ] Start Predict                  dataset=131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 34.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:27:49.932250Z [info     ] Start Predict                  dataset=111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 33.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:27:59.262276Z [info     ] Start Predict                  dataset=91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 34.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:28:08.523246Z [info     ] Start Predict                  dataset=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 33.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:28:18.049678Z [info     ] Start Predict                  dataset=51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 35.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 589\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:28:27.608681Z [info     ] Start Predict                  dataset=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 33.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26440677966101694, 0.2745762711864407, 0.26440677966101694, 0.2576271186440678, 0.3016949152542373, 0.3152542372881356, 0.33220338983050846, 0.33559322033898303, 0.39322033898305087, 0.43050847457627117, 0.41694915254237286, 0.3864406779661017, 0.46779661016949153, 0.5491525423728814, 0.5152542372881356, 0.5152542372881356, 0.5559322033898305, 0.5694915254237288, 0.5050847457627119, 0.5830508474576271, 0.5728813559322034, 0.5864406779661017, 0.5830508474576271, 0.5898305084745763, 0.5898305084745763, 0.5898305084745763, 0.5796610169491525, 0.5796610169491525, 0.5898305084745763, 0.5830508474576271, 0.5830508474576271]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1147' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 03:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:28:31.519701Z [info     ] Start Predict                  dataset=611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 77/77 [00:02<00:00, 32.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:28:36.139713Z [info     ] Start Predict                  dataset=591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:02<00:00, 32.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:28:40.936715Z [info     ] Start Predict                  dataset=571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 72/72 [00:02<00:00, 32.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:28:45.886716Z [info     ] Start Predict                  dataset=551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [00:02<00:00, 33.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:28:51.035713Z [info     ] Start Predict                  dataset=531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 32.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:28:56.348713Z [info     ] Start Predict                  dataset=511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:02<00:00, 31.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:29:02.027713Z [info     ] Start Predict                  dataset=491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [00:01<00:00, 33.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:29:07.582234Z [info     ] Start Predict                  dataset=471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:01<00:00, 32.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:29:13.546238Z [info     ] Start Predict                  dataset=451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 33.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:29:19.486234Z [info     ] Start Predict                  dataset=431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 32.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:29:25.844234Z [info     ] Start Predict                  dataset=411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 32.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:29:32.345237Z [info     ] Start Predict                  dataset=391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 32.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:29:39.000233Z [info     ] Start Predict                  dataset=371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 32.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:29:45.673233Z [info     ] Start Predict                  dataset=351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 31.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:29:52.750592Z [info     ] Start Predict                  dataset=331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 33.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:29:59.956563Z [info     ] Start Predict                  dataset=311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 32.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:30:07.314562Z [info     ] Start Predict                  dataset=291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 33.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:30:14.805079Z [info     ] Start Predict                  dataset=271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 32.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:30:22.791593Z [info     ] Start Predict                  dataset=251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 32.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:30:30.563594Z [info     ] Start Predict                  dataset=231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:30:38.616098Z [info     ] Start Predict                  dataset=211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 32.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:30:46.673101Z [info     ] Start Predict                  dataset=191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 33.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:30:55.087127Z [info     ] Start Predict                  dataset=171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 33.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:31:03.646654Z [info     ] Start Predict                  dataset=151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 33.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:31:12.757517Z [info     ] Start Predict                  dataset=131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 33.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:31:21.771622Z [info     ] Start Predict                  dataset=111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 32.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:31:30.875294Z [info     ] Start Predict                  dataset=91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 34.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:31:40.268828Z [info     ] Start Predict                  dataset=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 33.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:31:49.657798Z [info     ] Start Predict                  dataset=51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 36.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 589\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:31:59.174810Z [info     ] Start Predict                  dataset=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 34.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2576271186440678, 0.2745762711864407, 0.2542372881355932, 0.2576271186440678, 0.2711864406779661, 0.2745762711864407, 0.29491525423728815, 0.29491525423728815, 0.33220338983050846, 0.39661016949152544, 0.36610169491525424, 0.4542372881355932, 0.5186440677966102, 0.5423728813559322, 0.5016949152542373, 0.5830508474576271, 0.576271186440678, 0.5966101694915255, 0.5491525423728814, 0.6067796610169491, 0.5627118644067797, 0.5830508474576271, 0.5491525423728814, 0.5932203389830508, 0.5932203389830508, 0.5932203389830508, 0.5864406779661017, 0.5796610169491525, 0.5864406779661017, 0.5830508474576271, 0.5830508474576271]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1147' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 03:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:32:03.087808Z [info     ] Start Predict                  dataset=611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 77/77 [00:02<00:00, 32.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:32:07.608810Z [info     ] Start Predict                  dataset=591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:02<00:00, 33.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:32:12.263811Z [info     ] Start Predict                  dataset=571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 72/72 [00:02<00:00, 33.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:32:17.201810Z [info     ] Start Predict                  dataset=551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [00:02<00:00, 33.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:32:22.317812Z [info     ] Start Predict                  dataset=531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 33.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:32:27.663810Z [info     ] Start Predict                  dataset=511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:01<00:00, 32.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:32:33.197809Z [info     ] Start Predict                  dataset=491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [00:01<00:00, 31.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:32:38.874490Z [info     ] Start Predict                  dataset=471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:01<00:00, 32.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:32:44.770011Z [info     ] Start Predict                  dataset=451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 31.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:32:50.943015Z [info     ] Start Predict                  dataset=431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 32.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:32:57.178011Z [info     ] Start Predict                  dataset=411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 32.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:33:03.625042Z [info     ] Start Predict                  dataset=391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 32.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:33:10.226013Z [info     ] Start Predict                  dataset=371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 32.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:33:17.034632Z [info     ] Start Predict                  dataset=351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 31.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:33:24.051601Z [info     ] Start Predict                  dataset=331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 33.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:33:31.027601Z [info     ] Start Predict                  dataset=311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 32.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:33:38.736969Z [info     ] Start Predict                  dataset=291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 33.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:33:46.150969Z [info     ] Start Predict                  dataset=271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 33.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:33:53.894969Z [info     ] Start Predict                  dataset=251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 33.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:34:01.552967Z [info     ] Start Predict                  dataset=231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:34:09.582968Z [info     ] Start Predict                  dataset=211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 34.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:34:17.658491Z [info     ] Start Predict                  dataset=191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 30.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:34:26.063486Z [info     ] Start Predict                  dataset=171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 33.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:34:34.620488Z [info     ] Start Predict                  dataset=151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 33.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:34:43.408487Z [info     ] Start Predict                  dataset=131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 30.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:34:52.362487Z [info     ] Start Predict                  dataset=111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 32.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:35:01.467490Z [info     ] Start Predict                  dataset=91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 34.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:35:10.773489Z [info     ] Start Predict                  dataset=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 33.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:35:20.182489Z [info     ] Start Predict                  dataset=51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 34.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 589\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:35:29.842490Z [info     ] Start Predict                  dataset=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 31.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2576271186440678, 0.2745762711864407, 0.2542372881355932, 0.2576271186440678, 0.2711864406779661, 0.2745762711864407, 0.29491525423728815, 0.29491525423728815, 0.33220338983050846, 0.39661016949152544, 0.36610169491525424, 0.4542372881355932, 0.5186440677966102, 0.5423728813559322, 0.5016949152542373, 0.5830508474576271, 0.576271186440678, 0.5966101694915255, 0.5491525423728814, 0.6067796610169491, 0.5627118644067797, 0.5830508474576271, 0.5491525423728814, 0.5932203389830508, 0.5932203389830508, 0.5932203389830508, 0.5864406779661017, 0.5796610169491525, 0.5864406779661017, 0.5830508474576271, 0.5830508474576271]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1147' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 03:32]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:35:33.798924Z [info     ] Start Predict                  dataset=611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 77/77 [00:02<00:00, 32.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:35:38.396989Z [info     ] Start Predict                  dataset=591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:02<00:00, 32.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:35:43.149992Z [info     ] Start Predict                  dataset=571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 72/72 [00:02<00:00, 31.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:35:48.156512Z [info     ] Start Predict                  dataset=551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [00:02<00:00, 31.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:35:53.288525Z [info     ] Start Predict                  dataset=531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 32.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:35:58.702526Z [info     ] Start Predict                  dataset=511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:02<00:00, 31.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:36:04.234524Z [info     ] Start Predict                  dataset=491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [00:01<00:00, 32.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:36:10.055039Z [info     ] Start Predict                  dataset=471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:01<00:00, 31.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:36:16.028040Z [info     ] Start Predict                  dataset=451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 31.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:36:22.253040Z [info     ] Start Predict                  dataset=431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 32.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:36:28.568043Z [info     ] Start Predict                  dataset=411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 33.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:36:34.998039Z [info     ] Start Predict                  dataset=391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 32.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:36:41.703605Z [info     ] Start Predict                  dataset=371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 32.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:36:48.740633Z [info     ] Start Predict                  dataset=351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 32.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:36:56.207605Z [info     ] Start Predict                  dataset=331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 33.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:37:03.449149Z [info     ] Start Predict                  dataset=311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 33.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:37:11.403149Z [info     ] Start Predict                  dataset=291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 31.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:37:19.014607Z [info     ] Start Predict                  dataset=271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 33.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:37:26.968636Z [info     ] Start Predict                  dataset=251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 33.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:37:34.768644Z [info     ] Start Predict                  dataset=231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:37:42.820002Z [info     ] Start Predict                  dataset=211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 33.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:37:51.034971Z [info     ] Start Predict                  dataset=191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 33.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:37:59.296971Z [info     ] Start Predict                  dataset=171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 33.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:38:07.887972Z [info     ] Start Predict                  dataset=151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 33.51it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:38:16.632972Z [info     ] Start Predict                  dataset=131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 34.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:38:25.740485Z [info     ] Start Predict                  dataset=111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 33.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:38:34.836519Z [info     ] Start Predict                  dataset=91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 34.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:38:44.142519Z [info     ] Start Predict                  dataset=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 33.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:38:53.629518Z [info     ] Start Predict                  dataset=51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 35.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 589\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:39:03.322519Z [info     ] Start Predict                  dataset=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 34.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2576271186440678, 0.2745762711864407, 0.2542372881355932, 0.2576271186440678, 0.2711864406779661, 0.2745762711864407, 0.29491525423728815, 0.29491525423728815, 0.33220338983050846, 0.39661016949152544, 0.36610169491525424, 0.4542372881355932, 0.5186440677966102, 0.5423728813559322, 0.5016949152542373, 0.5830508474576271, 0.576271186440678, 0.5966101694915255, 0.5491525423728814, 0.6067796610169491, 0.5627118644067797, 0.5830508474576271, 0.5491525423728814, 0.5932203389830508, 0.5932203389830508, 0.5932203389830508, 0.5864406779661017, 0.5796610169491525, 0.5864406779661017, 0.5830508474576271, 0.5830508474576271]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1147' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 03:32]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:39:07.235517Z [info     ] Start Predict                  dataset=611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 77/77 [00:02<00:00, 32.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 29\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:39:11.780517Z [info     ] Start Predict                  dataset=591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:02<00:00, 32.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 49\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:39:16.566518Z [info     ] Start Predict                  dataset=571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 72/72 [00:02<00:00, 32.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 69\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:39:21.452087Z [info     ] Start Predict                  dataset=551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [00:02<00:00, 32.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 89\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:39:26.556108Z [info     ] Start Predict                  dataset=531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 31.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 109\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:39:31.979114Z [info     ] Start Predict                  dataset=511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:02<00:00, 31.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 129\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:39:38.103137Z [info     ] Start Predict                  dataset=491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [00:01<00:00, 32.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 149\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:39:43.866105Z [info     ] Start Predict                  dataset=471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [00:01<00:00, 31.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 169\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:39:50.199699Z [info     ] Start Predict                  dataset=451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 33.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:39:56.226658Z [info     ] Start Predict                  dataset=431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 33.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 209\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:40:02.569216Z [info     ] Start Predict                  dataset=411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 32.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 229\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:40:09.345247Z [info     ] Start Predict                  dataset=391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:01<00:00, 32.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 249\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:40:15.880740Z [info     ] Start Predict                  dataset=371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 31.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 269\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:40:22.745769Z [info     ] Start Predict                  dataset=351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 31.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 289\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:40:29.851739Z [info     ] Start Predict                  dataset=331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 32.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 309\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:40:36.913741Z [info     ] Start Predict                  dataset=311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 33.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 329\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:40:44.306739Z [info     ] Start Predict                  dataset=291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 31.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 349\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:40:51.864254Z [info     ] Start Predict                  dataset=271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 32.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 369\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:40:59.637006Z [info     ] Start Predict                  dataset=251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 31.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:41:07.602528Z [info     ] Start Predict                  dataset=231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 409\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:41:15.619580Z [info     ] Start Predict                  dataset=211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 33.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 429\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:41:23.793236Z [info     ] Start Predict                  dataset=191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 31.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 449\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57/57 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:41:33.285266Z [info     ] Start Predict                  dataset=171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 32.89it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 469\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:41:41.821265Z [info     ] Start Predict                  dataset=151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 33.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 489\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:41:50.544308Z [info     ] Start Predict                  dataset=131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 33.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 509\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:41:59.377800Z [info     ] Start Predict                  dataset=111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 32.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 529\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:42:08.419801Z [info     ] Start Predict                  dataset=91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 33.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 549\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:42:17.719345Z [info     ] Start Predict                  dataset=71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 33.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 569\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:42:27.080348Z [info     ] Start Predict                  dataset=51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 34.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 589\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [74/74 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3372-MainThread ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-05T13:42:36.728346Z [info     ] Start Predict                  dataset=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 33.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2576271186440678, 0.2745762711864407, 0.2542372881355932, 0.2576271186440678, 0.2711864406779661, 0.2745762711864407, 0.29491525423728815, 0.29491525423728815, 0.33220338983050846, 0.39661016949152544, 0.36610169491525424, 0.4542372881355932, 0.5186440677966102, 0.5423728813559322, 0.5016949152542373, 0.5830508474576271, 0.576271186440678, 0.5966101694915255, 0.5491525423728814, 0.6067796610169491, 0.5627118644067797, 0.5830508474576271, 0.5491525423728814, 0.5932203389830508, 0.5932203389830508, 0.5932203389830508, 0.5864406779661017, 0.5796610169491525, 0.5864406779661017, 0.5830508474576271, 0.5830508474576271]\n"
     ]
    }
   ],
   "source": [
    "active_mc_hillary2 = []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "while mcrun != 5:\n",
    "#     n_labeled_examples = np.unique(train_dataset_hillary['text']).size\n",
    "#     training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "#     print(training_indices0)\n",
    "    active_set_hillary =active_huggingface_dataset(train_dataset_hillary,tokenizer,'label','text')\n",
    "    valid_set_hillary = HuggingFaceDatasets(test_dataset_hillary,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_hillary.can_label = False\n",
    "    active_set_hillary.label_randomly(9)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_hillary,\n",
    "            eval_dataset=valid_set_hillary,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_hillary = ActiveLearningLoop(active_set_hillary,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_hillary=[unqueried_score]\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_hillary.step()\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_hillary.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_hillary),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_hillary.append(eval_metrics['eval_accuracy'])\n",
    "    print(performance_history_hillary)\n",
    "    active_mc_hillary2.append(performance_history_hillary)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "369d299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_hillary1, min_hillary1,max_hillary1 = calculate(active_mc_hillary1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f0cc9f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_hillary2, min_hillary2,max_hillary2= calculate(active_mc_hillary2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0be756a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1105x1040 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(8.5, 8), dpi=130)\n",
    "ax.plot(median_hillary1,label=\"Hunman selection\")\n",
    "ax.fill_between(range(31),min_hillary1,max_hillary1,color='blue', alpha=0.1)\n",
    "ax.plot(median_hillary2,label=\"Random selection\")\n",
    "ax.fill_between(range(31),min_hillary2,max_hillary2,color='orange', alpha=0.1)\n",
    "\n",
    "\n",
    "ax.scatter(range(31), median_hillary1, s=8,marker = \"v\")\n",
    "ax.scatter(range(31), median_hillary2, s=8,marker=\"^\")\n",
    "\n",
    "ax.xaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=5, integer=True))\n",
    "ax.yaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=10))\n",
    "ax.yaxis.set_major_formatter(mpl.ticker.PercentFormatter(xmax=1))\n",
    "\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "ax.set_title('Different initial data set in hillary target')\n",
    "ax.set_xlabel('Query iteration')\n",
    "ax.set_ylabel('Performance(median)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0f0ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f259bb98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analytics_course0",
   "language": "python",
   "name": "data_analytics_course0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
