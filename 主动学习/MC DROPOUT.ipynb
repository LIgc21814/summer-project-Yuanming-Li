{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29b8e7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import pdb\n",
    "import logging\n",
    "import re\n",
    "from gensim import parsing\n",
    "import gensim\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b0e300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baal.active import get_heuristic\n",
    "from baal.active.active_loop import ActiveLearningLoop\n",
    "from baal.active.dataset.nlp_datasets import active_huggingface_dataset, HuggingFaceDatasets\n",
    "from baal.bayesian.dropout import patch_module\n",
    "from baal.transformers_trainer_wrapper import BaalTransformersTrainer\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d534823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "895fa954",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baal.bayesian.dropout import unpatch_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14077bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-tiny\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d032279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"transformer_checkpoints\",  # specify the directory where models weights will be saved a certain points during training (checkpoints)\n",
    "    num_train_epochs=1,  # change this if it is taking too long on your computer\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dd2b487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(a):\n",
    "    rotated = list(zip(*a[::-1]))\n",
    "    median0 = []\n",
    "    min0 = []\n",
    "    max0 = []\n",
    "    for i in range(len(rotated)):\n",
    "        median0.append(np.median(rotated[i]))\n",
    "        min0.append(np.min(rotated[i]))\n",
    "        max0.append(np.max(rotated[i]))\n",
    "    return median0,min0,max0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecc5b5a",
   "metadata": {},
   "source": [
    "# Abortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8b10da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_abortion\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset with 587 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_abortion\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset with 66 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_abortion\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset with 280 instances loaded\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "cache_dir = \"./data_cache\"\n",
    "\n",
    "train_dataset_abortion = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_abortion\",\n",
    "    split=\"train\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Training dataset with {len(train_dataset_abortion)} instances loaded\")\n",
    "\n",
    "val_dataset_abortion = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_abortion\",\n",
    "    split=\"validation\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Validation dataset with {len(val_dataset_abortion)} instances loaded\")\n",
    "\n",
    "test_dataset_abortion = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_abortion\",\n",
    "    split=\"test\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Test dataset with {len(test_dataset_abortion)} instances loaded\")\n",
    "\n",
    "num_classes = np.unique(train_dataset_abortion['label']).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cdf17b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/config.json from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\3cf34679007e9fe5d0acd644dcc1f4b26bec5cbc9612364f6da7262aed4ef7a4.a5a11219cf90aae61ff30e1658ccf2cb4aa84d6b6e947336556f887c9828dc6d\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-tiny\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/pytorch_model.bin from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\1ee037c9e1a220d5c814779ffe697080d1e6f5b1602e16cf6061aaae41a082c5.038e1aed90492a59d2283f9c44c9fe3ee2380495ff1e7fefb3f1f04af3b685b5\n",
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_original = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\", num_labels=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16a141c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[123 365 578]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:49:20.195236Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 34.03it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:49:24.315489Z [info     ] Start Predict                  dataset=564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:01<00:00, 36.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:49:28.434816Z [info     ] Start Predict                  dataset=544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:01<00:00, 36.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:49:32.702922Z [info     ] Start Predict                  dataset=524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 37.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:49:37.241147Z [info     ] Start Predict                  dataset=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 36.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:49:41.928883Z [info     ] Start Predict                  dataset=484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 37.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:49:46.794195Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 37.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:49:51.722017Z [info     ] Start Predict                  dataset=444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 37.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:49:56.825844Z [info     ] Start Predict                  dataset=424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 37.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:50:02.210814Z [info     ] Start Predict                  dataset=404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 37.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:50:07.756120Z [info     ] Start Predict                  dataset=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 37.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:50:13.503755Z [info     ] Start Predict                  dataset=364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 38.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:50:19.531024Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 36.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:50:25.674656Z [info     ] Start Predict                  dataset=324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 38.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:50:32.065943Z [info     ] Start Predict                  dataset=304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 37.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:50:38.304932Z [info     ] Start Predict                  dataset=284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 38.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:50:44.793310Z [info     ] Start Predict                  dataset=264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 37.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:50:52.580842Z [info     ] Start Predict                  dataset=244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 37.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:50:59.588071Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 36.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:51:06.815696Z [info     ] Start Predict                  dataset=204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 38.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:51:14.146321Z [info     ] Start Predict                  dataset=184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 38.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:51:21.549114Z [info     ] Start Predict                  dataset=164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 38.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:51:29.260383Z [info     ] Start Predict                  dataset=144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 37.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:51:37.279139Z [info     ] Start Predict                  dataset=124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 35.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:51:45.364035Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 37.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:51:53.656890Z [info     ] Start Predict                  dataset=84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 39.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:52:01.908200Z [info     ] Start Predict                  dataset=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 37.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:52:10.410171Z [info     ] Start Predict                  dataset=44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 40.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:52:19.363591Z [info     ] Start Predict                  dataset=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 37.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:52:28.798370Z [info     ] Start Predict                  dataset=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 55.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17142857142857143, 0.17142857142857143, 0.16785714285714284, 0.16785714285714284, 0.16071428571428573, 0.16785714285714284, 0.16785714285714284, 0.18928571428571428, 0.26071428571428573, 0.32857142857142857, 0.34285714285714286, 0.5678571428571428, 0.5285714285714286, 0.6714285714285714, 0.6392857142857142, 0.6714285714285714, 0.6464285714285715, 0.675, 0.6714285714285714, 0.675, 0.6642857142857143, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675]\n",
      "[535  69 215]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:52:32.108741Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:01<00:00, 36.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:52:35.993236Z [info     ] Start Predict                  dataset=564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:02<00:00, 34.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:52:40.422329Z [info     ] Start Predict                  dataset=544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:01<00:00, 37.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:52:44.744660Z [info     ] Start Predict                  dataset=524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 37.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:52:49.145391Z [info     ] Start Predict                  dataset=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 38.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:52:53.624516Z [info     ] Start Predict                  dataset=484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 37.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:52:58.431139Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 37.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:53:03.446755Z [info     ] Start Predict                  dataset=444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 38.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:53:08.501666Z [info     ] Start Predict                  dataset=424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 38.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:53:13.926779Z [info     ] Start Predict                  dataset=404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 38.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:53:19.414424Z [info     ] Start Predict                  dataset=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 38.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:53:25.168528Z [info     ] Start Predict                  dataset=364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 35.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:53:31.208949Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 37.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:53:37.333670Z [info     ] Start Predict                  dataset=324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 36.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:53:43.460902Z [info     ] Start Predict                  dataset=304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 36.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:53:49.784332Z [info     ] Start Predict                  dataset=284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 38.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:53:56.395907Z [info     ] Start Predict                  dataset=264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 38.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:54:03.231229Z [info     ] Start Predict                  dataset=244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 38.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:54:10.393402Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 38.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:54:17.472709Z [info     ] Start Predict                  dataset=204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 39.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:54:24.671724Z [info     ] Start Predict                  dataset=184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 38.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:54:32.161494Z [info     ] Start Predict                  dataset=164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 39.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:54:39.949748Z [info     ] Start Predict                  dataset=144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 36.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:54:47.865963Z [info     ] Start Predict                  dataset=124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 39.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:54:56.037718Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 37.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:55:04.059262Z [info     ] Start Predict                  dataset=84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 36.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:55:12.505602Z [info     ] Start Predict                  dataset=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 37.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:55:21.063361Z [info     ] Start Predict                  dataset=44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 42.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:55:30.199096Z [info     ] Start Predict                  dataset=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 37.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:55:39.104906Z [info     ] Start Predict                  dataset=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 62.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16785714285714284, 0.16785714285714284, 0.17857142857142858, 0.175, 0.18928571428571428, 0.20357142857142857, 0.23214285714285715, 0.3535714285714286, 0.35, 0.45714285714285713, 0.43214285714285716, 0.6107142857142858, 0.6035714285714285, 0.6107142857142858, 0.6678571428571428, 0.6714285714285714, 0.675, 0.675, 0.6642857142857143, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675]\n",
      "[535  69 215]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:55:42.315912Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 36.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:55:46.764106Z [info     ] Start Predict                  dataset=564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:01<00:00, 36.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:55:50.835194Z [info     ] Start Predict                  dataset=544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:01<00:00, 37.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:55:55.005433Z [info     ] Start Predict                  dataset=524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 37.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:55:59.593430Z [info     ] Start Predict                  dataset=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 35.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:56:04.356602Z [info     ] Start Predict                  dataset=484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 36.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:56:09.697595Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 37.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:56:14.670059Z [info     ] Start Predict                  dataset=444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 37.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:56:19.852397Z [info     ] Start Predict                  dataset=424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 37.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:56:25.210621Z [info     ] Start Predict                  dataset=404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 37.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:56:30.802879Z [info     ] Start Predict                  dataset=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 36.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:56:36.529520Z [info     ] Start Predict                  dataset=364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 37.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:56:42.444281Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 37.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:56:48.724983Z [info     ] Start Predict                  dataset=324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 37.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:56:55.116146Z [info     ] Start Predict                  dataset=304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 36.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:57:01.650560Z [info     ] Start Predict                  dataset=284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 37.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:57:08.306093Z [info     ] Start Predict                  dataset=264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 36.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:57:15.076838Z [info     ] Start Predict                  dataset=244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 38.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:57:22.136972Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 36.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:57:29.156065Z [info     ] Start Predict                  dataset=204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 35.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:57:36.647554Z [info     ] Start Predict                  dataset=184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 36.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:57:44.770528Z [info     ] Start Predict                  dataset=164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 36.51it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:57:52.601930Z [info     ] Start Predict                  dataset=144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 38.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:58:00.542982Z [info     ] Start Predict                  dataset=124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 38.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:58:08.744014Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 37.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:58:17.290217Z [info     ] Start Predict                  dataset=84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 37.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:58:25.968570Z [info     ] Start Predict                  dataset=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 36.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:58:34.900513Z [info     ] Start Predict                  dataset=44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 38.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:58:43.875558Z [info     ] Start Predict                  dataset=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 29.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:58:52.912734Z [info     ] Start Predict                  dataset=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 58.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16785714285714284, 0.16785714285714284, 0.17857142857142858, 0.175, 0.18928571428571428, 0.20357142857142857, 0.23214285714285715, 0.3535714285714286, 0.35, 0.45714285714285713, 0.43214285714285716, 0.6107142857142858, 0.6035714285714285, 0.6107142857142858, 0.6678571428571428, 0.6714285714285714, 0.675, 0.675, 0.6642857142857143, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675]\n",
      "[535  69 215]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:58:56.378405Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:01<00:00, 36.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:59:00.317397Z [info     ] Start Predict                  dataset=564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:01<00:00, 36.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:59:04.455921Z [info     ] Start Predict                  dataset=544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:01<00:00, 35.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:59:08.801393Z [info     ] Start Predict                  dataset=524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 37.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:59:13.300862Z [info     ] Start Predict                  dataset=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 37.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:59:17.898397Z [info     ] Start Predict                  dataset=484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 36.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:59:22.892335Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 36.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:59:27.948220Z [info     ] Start Predict                  dataset=444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 37.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:59:33.250969Z [info     ] Start Predict                  dataset=424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 37.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:59:38.805967Z [info     ] Start Predict                  dataset=404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 37.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:59:44.424300Z [info     ] Start Predict                  dataset=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 36.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:59:50.242227Z [info     ] Start Predict                  dataset=364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 36.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T16:59:57.886670Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 37.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:00:04.080105Z [info     ] Start Predict                  dataset=324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 38.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:00:10.535962Z [info     ] Start Predict                  dataset=304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 37.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:00:18.324691Z [info     ] Start Predict                  dataset=284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 37.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:00:25.069006Z [info     ] Start Predict                  dataset=264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 37.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:00:31.783014Z [info     ] Start Predict                  dataset=244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 36.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:00:38.911264Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 37.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:00:46.182374Z [info     ] Start Predict                  dataset=204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 38.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:00:53.619806Z [info     ] Start Predict                  dataset=184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 36.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:01:01.188826Z [info     ] Start Predict                  dataset=164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 37.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:01:09.083524Z [info     ] Start Predict                  dataset=144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 35.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:01:16.926950Z [info     ] Start Predict                  dataset=124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 36.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:01:25.243842Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 36.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:01:33.582016Z [info     ] Start Predict                  dataset=84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 39.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:01:42.214658Z [info     ] Start Predict                  dataset=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 32.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:01:51.054807Z [info     ] Start Predict                  dataset=44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 39.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:02:00.068423Z [info     ] Start Predict                  dataset=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 36.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:02:09.034667Z [info     ] Start Predict                  dataset=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 45.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16785714285714284, 0.16785714285714284, 0.17857142857142858, 0.175, 0.18928571428571428, 0.20357142857142857, 0.23214285714285715, 0.3535714285714286, 0.35, 0.45714285714285713, 0.43214285714285716, 0.6107142857142858, 0.6035714285714285, 0.6107142857142858, 0.6678571428571428, 0.6714285714285714, 0.675, 0.675, 0.6642857142857143, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675]\n",
      "[535  69 215]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:02:12.468393Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:01<00:00, 36.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:02:16.417225Z [info     ] Start Predict                  dataset=564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:01<00:00, 37.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:02:20.819780Z [info     ] Start Predict                  dataset=544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 30.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:02:25.599183Z [info     ] Start Predict                  dataset=524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 36.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:02:30.119632Z [info     ] Start Predict                  dataset=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 37.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:02:34.729604Z [info     ] Start Predict                  dataset=484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 37.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:02:39.680768Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 35.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:02:44.773139Z [info     ] Start Predict                  dataset=444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 37.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:02:50.037912Z [info     ] Start Predict                  dataset=424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 36.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:02:56.372841Z [info     ] Start Predict                  dataset=404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 37.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:03:02.048632Z [info     ] Start Predict                  dataset=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 36.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:03:09.790242Z [info     ] Start Predict                  dataset=364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 37.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:03:15.775776Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 37.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:03:21.961133Z [info     ] Start Predict                  dataset=324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 38.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:03:28.324438Z [info     ] Start Predict                  dataset=304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 36.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:03:34.857001Z [info     ] Start Predict                  dataset=284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 38.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:03:41.549246Z [info     ] Start Predict                  dataset=264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 38.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:03:48.466287Z [info     ] Start Predict                  dataset=244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 37.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:03:55.572763Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 36.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:04:02.838297Z [info     ] Start Predict                  dataset=204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 37.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:04:10.346485Z [info     ] Start Predict                  dataset=184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 38.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:04:17.963490Z [info     ] Start Predict                  dataset=164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 38.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:04:25.545652Z [info     ] Start Predict                  dataset=144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 34.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:04:33.481733Z [info     ] Start Predict                  dataset=124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 39.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:04:41.723203Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 37.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:04:50.093426Z [info     ] Start Predict                  dataset=84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 37.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:04:58.657256Z [info     ] Start Predict                  dataset=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 35.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:05:07.415457Z [info     ] Start Predict                  dataset=44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 39.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:05:16.204110Z [info     ] Start Predict                  dataset=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 37.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:05:25.365554Z [info     ] Start Predict                  dataset=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 58.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16785714285714284, 0.16785714285714284, 0.17857142857142858, 0.175, 0.18928571428571428, 0.20357142857142857, 0.23214285714285715, 0.3535714285714286, 0.35, 0.45714285714285713, 0.43214285714285716, 0.6107142857142858, 0.6035714285714285, 0.6107142857142858, 0.6678571428571428, 0.6714285714285714, 0.675, 0.675, 0.6642857142857143, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675]\n"
     ]
    }
   ],
   "source": [
    "active_mc_abortion1= []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "while mcrun != 5:\n",
    "    n_labeled_examples = np.unique(train_dataset_abortion['text']).size\n",
    "    training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "    print(training_indices0)\n",
    "    active_set_abortion =active_huggingface_dataset(train_dataset_abortion,tokenizer,'label','text')\n",
    "    valid_set_abortion = HuggingFaceDatasets(test_dataset_abortion,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_abortion.can_label = False\n",
    "    active_set_abortion.label(training_indices0)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = model_original\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_abortion,\n",
    "            eval_dataset=valid_set_abortion,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_abortion = ActiveLearningLoop(active_set_abortion,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_abortion=[unqueried_score]\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_abortion.step()\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_abortion.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_abortion),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_abortion.append(eval_metrics['eval_accuracy'])\n",
    "    print(performance_history_abortion)\n",
    "    active_mc_abortion1.append(performance_history_abortion)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14dc06e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_abortion1, min_abortion1,max_abortion1 = calculate(active_mc_abortion1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aaed6594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9 541 129]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:05:28.782760Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 33.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:05:33.196050Z [info     ] Start Predict                  dataset=564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:02<00:00, 27.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:05:38.214179Z [info     ] Start Predict                  dataset=544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 32.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:05:44.017307Z [info     ] Start Predict                  dataset=524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 33.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:05:48.841579Z [info     ] Start Predict                  dataset=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 32.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:05:53.847223Z [info     ] Start Predict                  dataset=484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 33.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:05:58.935536Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 34.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:06:04.078237Z [info     ] Start Predict                  dataset=444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 33.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:06:09.538183Z [info     ] Start Predict                  dataset=424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 34.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:06:15.037122Z [info     ] Start Predict                  dataset=404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 35.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:06:20.797505Z [info     ] Start Predict                  dataset=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 34.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:06:26.647007Z [info     ] Start Predict                  dataset=364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 34.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:06:32.709215Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 33.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:06:39.131123Z [info     ] Start Predict                  dataset=324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 34.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:06:45.746601Z [info     ] Start Predict                  dataset=304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 33.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:06:52.611309Z [info     ] Start Predict                  dataset=284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 33.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:06:59.591258Z [info     ] Start Predict                  dataset=264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 33.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:07:06.656582Z [info     ] Start Predict                  dataset=244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 33.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:07:13.878588Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 33.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:07:21.257564Z [info     ] Start Predict                  dataset=204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 34.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:07:28.728094Z [info     ] Start Predict                  dataset=184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 33.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:07:36.394071Z [info     ] Start Predict                  dataset=164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 32.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:07:44.249291Z [info     ] Start Predict                  dataset=144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 32.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:07:52.537030Z [info     ] Start Predict                  dataset=124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 32.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:08:00.918474Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 33.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:08:09.247637Z [info     ] Start Predict                  dataset=84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 31.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:08:18.221584Z [info     ] Start Predict                  dataset=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 27.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:08:27.723257Z [info     ] Start Predict                  dataset=44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 35.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:08:38.664486Z [info     ] Start Predict                  dataset=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 25.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:08:49.027757Z [info     ] Start Predict                  dataset=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 47.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21785714285714286, 0.19285714285714287, 0.21071428571428572, 0.26785714285714285, 0.30714285714285716, 0.3464285714285714, 0.3964285714285714, 0.4107142857142857, 0.4392857142857143, 0.5357142857142857, 0.5, 0.6142857142857143, 0.55, 0.6285714285714286, 0.6714285714285714, 0.6678571428571428, 0.6785714285714286, 0.6642857142857143, 0.6714285714285714, 0.675, 0.6678571428571428, 0.6714285714285714, 0.675, 0.675, 0.6785714285714286, 0.675, 0.6714285714285714, 0.675, 0.675, 0.6714285714285714, 0.675]\n",
      "[535  69 215]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:08:52.489467Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 33.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:08:56.733971Z [info     ] Start Predict                  dataset=564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:02<00:00, 32.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:09:01.062155Z [info     ] Start Predict                  dataset=544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 33.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:09:05.599444Z [info     ] Start Predict                  dataset=524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 33.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:09:10.544533Z [info     ] Start Predict                  dataset=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:09:16.229870Z [info     ] Start Predict                  dataset=484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 32.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:09:21.521399Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 32.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:09:26.894026Z [info     ] Start Predict                  dataset=444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 34.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:09:32.679038Z [info     ] Start Predict                  dataset=424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 33.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:09:38.402811Z [info     ] Start Predict                  dataset=404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 32.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:09:44.328154Z [info     ] Start Predict                  dataset=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 33.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:09:50.962335Z [info     ] Start Predict                  dataset=364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 32.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:09:57.410112Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 33.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:10:03.800337Z [info     ] Start Predict                  dataset=324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 33.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:10:10.376550Z [info     ] Start Predict                  dataset=304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 32.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:10:17.233479Z [info     ] Start Predict                  dataset=284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 32.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:10:24.349636Z [info     ] Start Predict                  dataset=264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 32.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:10:31.494093Z [info     ] Start Predict                  dataset=244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 33.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:10:38.978349Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 34.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:10:46.755213Z [info     ] Start Predict                  dataset=204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 34.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:10:54.354117Z [info     ] Start Predict                  dataset=184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 33.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:11:02.036380Z [info     ] Start Predict                  dataset=164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 34.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:11:10.004600Z [info     ] Start Predict                  dataset=144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 33.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:11:18.112902Z [info     ] Start Predict                  dataset=124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 31.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:11:26.491491Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 32.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:11:34.953894Z [info     ] Start Predict                  dataset=84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 36.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:11:45.155873Z [info     ] Start Predict                  dataset=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 27.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:11:54.213688Z [info     ] Start Predict                  dataset=44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 37.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:12:03.171191Z [info     ] Start Predict                  dataset=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 34.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:12:12.221867Z [info     ] Start Predict                  dataset=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 47.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.225, 0.19285714285714287, 0.23214285714285715, 0.325, 0.375, 0.3535714285714286, 0.32857142857142857, 0.4392857142857143, 0.4714285714285714, 0.475, 0.5107142857142857, 0.5607142857142857, 0.55, 0.6357142857142857, 0.6321428571428571, 0.6678571428571428, 0.6678571428571428, 0.6642857142857143, 0.675, 0.675, 0.675, 0.6642857142857143, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.6714285714285714, 0.675]\n",
      "[535  69 215]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:12:15.617124Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 33.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:12:19.791658Z [info     ] Start Predict                  dataset=564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:02<00:00, 33.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:12:24.201997Z [info     ] Start Predict                  dataset=544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 33.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:12:28.994427Z [info     ] Start Predict                  dataset=524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 33.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:12:33.658506Z [info     ] Start Predict                  dataset=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 32.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:12:38.714132Z [info     ] Start Predict                  dataset=484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 33.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:12:43.876407Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 33.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:12:49.119014Z [info     ] Start Predict                  dataset=444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 33.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:12:54.563436Z [info     ] Start Predict                  dataset=424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 33.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:13:00.220971Z [info     ] Start Predict                  dataset=404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 33.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:13:06.099870Z [info     ] Start Predict                  dataset=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 33.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:13:12.088877Z [info     ] Start Predict                  dataset=364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 34.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:13:18.093919Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 33.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:13:24.489158Z [info     ] Start Predict                  dataset=324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 34.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:13:31.110618Z [info     ] Start Predict                  dataset=304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 33.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:13:37.753987Z [info     ] Start Predict                  dataset=284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 32.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:13:44.618510Z [info     ] Start Predict                  dataset=264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 33.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:13:51.560421Z [info     ] Start Predict                  dataset=244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 34.66it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:14:00.226843Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 32.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:14:07.535728Z [info     ] Start Predict                  dataset=204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 34.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:14:15.130217Z [info     ] Start Predict                  dataset=184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 31.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:14:22.756553Z [info     ] Start Predict                  dataset=164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 32.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:14:30.560678Z [info     ] Start Predict                  dataset=144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 31.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:14:38.649394Z [info     ] Start Predict                  dataset=124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 34.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:14:46.903951Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 32.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:14:55.355491Z [info     ] Start Predict                  dataset=84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 34.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:15:04.040091Z [info     ] Start Predict                  dataset=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 33.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:15:12.722390Z [info     ] Start Predict                  dataset=44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 36.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:15:21.583090Z [info     ] Start Predict                  dataset=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 34.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:15:30.755446Z [info     ] Start Predict                  dataset=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 55.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.225, 0.19285714285714287, 0.23214285714285715, 0.325, 0.375, 0.3535714285714286, 0.32857142857142857, 0.4392857142857143, 0.4714285714285714, 0.475, 0.5107142857142857, 0.5607142857142857, 0.55, 0.6357142857142857, 0.6321428571428571, 0.6678571428571428, 0.6678571428571428, 0.6642857142857143, 0.675, 0.675, 0.675, 0.6642857142857143, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.6714285714285714, 0.675]\n",
      "[535  69 215]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:15:34.206102Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 33.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:15:38.412640Z [info     ] Start Predict                  dataset=564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:02<00:00, 33.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:15:42.833939Z [info     ] Start Predict                  dataset=544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 32.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:15:47.327238Z [info     ] Start Predict                  dataset=524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 33.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:15:52.119139Z [info     ] Start Predict                  dataset=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 33.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:15:57.149804Z [info     ] Start Predict                  dataset=484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 33.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:16:02.338095Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 33.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:16:07.549975Z [info     ] Start Predict                  dataset=444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 33.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:16:13.093408Z [info     ] Start Predict                  dataset=424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 33.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:16:18.652551Z [info     ] Start Predict                  dataset=404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 33.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:16:24.723627Z [info     ] Start Predict                  dataset=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 33.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:16:30.668418Z [info     ] Start Predict                  dataset=364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 33.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:16:36.729768Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 32.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:16:43.113191Z [info     ] Start Predict                  dataset=324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 33.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:16:49.724168Z [info     ] Start Predict                  dataset=304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 33.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:16:56.440067Z [info     ] Start Predict                  dataset=284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 33.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:17:03.368588Z [info     ] Start Predict                  dataset=264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 34.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:17:10.451419Z [info     ] Start Predict                  dataset=244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 33.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:17:17.738548Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 33.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:17:25.217119Z [info     ] Start Predict                  dataset=204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 34.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:17:32.690371Z [info     ] Start Predict                  dataset=184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 32.66it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:17:40.400754Z [info     ] Start Predict                  dataset=164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 34.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:17:48.304559Z [info     ] Start Predict                  dataset=144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 33.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:17:56.440315Z [info     ] Start Predict                  dataset=124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 35.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:18:04.831576Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 33.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:18:13.260509Z [info     ] Start Predict                  dataset=84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 34.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:18:21.955171Z [info     ] Start Predict                  dataset=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 34.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:18:30.732408Z [info     ] Start Predict                  dataset=44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 37.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:18:39.707917Z [info     ] Start Predict                  dataset=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 33.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:18:48.793775Z [info     ] Start Predict                  dataset=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 49.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.225, 0.19285714285714287, 0.23214285714285715, 0.325, 0.375, 0.3535714285714286, 0.32857142857142857, 0.4392857142857143, 0.4714285714285714, 0.475, 0.5107142857142857, 0.5607142857142857, 0.55, 0.6357142857142857, 0.6321428571428571, 0.6678571428571428, 0.6678571428571428, 0.6642857142857143, 0.675, 0.675, 0.675, 0.6642857142857143, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.6714285714285714, 0.675]\n",
      "[535  69 215]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1085' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 03:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:18:52.165323Z [info     ] Start Predict                  dataset=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 33.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:18:56.357664Z [info     ] Start Predict                  dataset=564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [00:02<00:00, 33.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:19:00.750478Z [info     ] Start Predict                  dataset=544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 33.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:19:05.206005Z [info     ] Start Predict                  dataset=524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 33.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:19:10.090986Z [info     ] Start Predict                  dataset=504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 33.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:19:15.034167Z [info     ] Start Predict                  dataset=484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:01<00:00, 34.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:19:20.171300Z [info     ] Start Predict                  dataset=464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 33.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:19:25.542912Z [info     ] Start Predict                  dataset=444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 33.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:19:31.097758Z [info     ] Start Predict                  dataset=424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 34.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:19:36.653417Z [info     ] Start Predict                  dataset=404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [00:01<00:00, 34.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:19:42.521225Z [info     ] Start Predict                  dataset=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 31.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:19:48.743037Z [info     ] Start Predict                  dataset=364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 32.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:19:54.808906Z [info     ] Start Predict                  dataset=344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 32.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:20:01.166343Z [info     ] Start Predict                  dataset=324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:01<00:00, 33.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:20:07.750993Z [info     ] Start Predict                  dataset=304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 32.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:20:14.349020Z [info     ] Start Predict                  dataset=284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:01<00:00, 34.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:20:21.371164Z [info     ] Start Predict                  dataset=264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 33.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:20:28.213385Z [info     ] Start Predict                  dataset=244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 35.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:20:35.421899Z [info     ] Start Predict                  dataset=224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 33.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:20:42.675118Z [info     ] Start Predict                  dataset=204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 33.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:20:50.225630Z [info     ] Start Predict                  dataset=184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 34.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:20:57.837330Z [info     ] Start Predict                  dataset=164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 35.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:21:05.673018Z [info     ] Start Predict                  dataset=144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 34.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:21:13.762675Z [info     ] Start Predict                  dataset=124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 34.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:21:22.137947Z [info     ] Start Predict                  dataset=104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 34.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:21:30.640735Z [info     ] Start Predict                  dataset=84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 36.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:21:39.121595Z [info     ] Start Predict                  dataset=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 33.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:21:47.685737Z [info     ] Start Predict                  dataset=44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 36.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:21:56.549457Z [info     ] Start Predict                  dataset=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 33.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 280\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T17:22:05.552779Z [info     ] Start Predict                  dataset=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 58.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.225, 0.19285714285714287, 0.23214285714285715, 0.325, 0.375, 0.3535714285714286, 0.32857142857142857, 0.4392857142857143, 0.4714285714285714, 0.475, 0.5107142857142857, 0.5607142857142857, 0.55, 0.6357142857142857, 0.6321428571428571, 0.6678571428571428, 0.6678571428571428, 0.6642857142857143, 0.675, 0.675, 0.675, 0.6642857142857143, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.675, 0.6714285714285714, 0.675]\n"
     ]
    }
   ],
   "source": [
    "active_mc_abortion2= []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "while mcrun != 5:\n",
    "    n_labeled_examples = np.unique(train_dataset_abortion['text']).size\n",
    "    training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "    print(training_indices0)\n",
    "    active_set_abortion =active_huggingface_dataset(train_dataset_abortion,tokenizer,'label','text')\n",
    "    valid_set_abortion = HuggingFaceDatasets(test_dataset_abortion,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_abortion.can_label = False\n",
    "    active_set_abortion.label(training_indices0)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_abortion,\n",
    "            eval_dataset=valid_set_abortion,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_abortion = ActiveLearningLoop(active_set_abortion,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_abortion=[unqueried_score]\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_abortion.step()\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_abortion.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_abortion),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_abortion.append(eval_metrics['eval_accuracy'])\n",
    "    print(performance_history_abortion)\n",
    "    active_mc_abortion2.append(performance_history_abortion)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b23266d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_abortion2, min_abortion2,max_abortion2 = calculate(active_mc_abortion2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2d801e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1105x1040 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(8.5, 8), dpi=130)\n",
    "ax.plot(median_abortion1,label=\"No Monte Carlo\")\n",
    "ax.fill_between(range(31),min_abortion1,max_abortion1,color='blue', alpha=0.1)\n",
    "ax.plot(median_abortion2,label=\"Monte Carlo\")\n",
    "ax.fill_between(range(31),min_abortion2,max_abortion2,color='orange', alpha=0.1)\n",
    "\n",
    "ax.scatter(range(31), median_abortion1, s=8,marker = \"v\")\n",
    "ax.scatter(range(31), median_abortion2, s=8,marker=\"^\")\n",
    "\n",
    "ax.xaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=8, integer=True))\n",
    "ax.yaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=10))\n",
    "ax.yaxis.set_major_formatter(mpl.ticker.PercentFormatter(xmax=1))\n",
    "\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "ax.set_title('Different query queue sizes in abortion target')\n",
    "ax.set_xlabel('Query iteration')\n",
    "ax.set_ylabel('Performance(median)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eac1ad8",
   "metadata": {},
   "source": [
    "# Atheism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2332cc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_atheism\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset with 461 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_atheism\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset with 52 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_atheism\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset with 220 instances loaded\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "cache_dir = \"./data_cache\"\n",
    "\n",
    "train_dataset_atheism = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_atheism\",\n",
    "    split=\"train\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Training dataset with {len(train_dataset_atheism)} instances loaded\")\n",
    "\n",
    "val_dataset_atheism = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_atheism\",\n",
    "    split=\"validation\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Validation dataset with {len(val_dataset_atheism)} instances loaded\")\n",
    "\n",
    "test_dataset_atheism = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_atheism\",\n",
    "    split=\"test\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Test dataset with {len(test_dataset_atheism)} instances loaded\")\n",
    "\n",
    "num_classes = np.unique(train_dataset_atheism['label']).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4a71e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/config.json from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\3cf34679007e9fe5d0acd644dcc1f4b26bec5cbc9612364f6da7262aed4ef7a4.a5a11219cf90aae61ff30e1658ccf2cb4aa84d6b6e947336556f887c9828dc6d\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-tiny\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/pytorch_model.bin from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\1ee037c9e1a220d5c814779ffe697080d1e6f5b1602e16cf6061aaae41a082c5.038e1aed90492a59d2283f9c44c9fe3ee2380495ff1e7fefb3f1f04af3b685b5\n",
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_original = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\", num_labels=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6ad1c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 93  25 239]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 02:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:55:24.144238Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 37.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:55:27.290733Z [info     ] Start Predict                  dataset=438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 36.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:55:31.000679Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 30.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:55:34.993274Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 36.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:55:38.832356Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 38.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:55:43.519412Z [info     ] Start Predict                  dataset=358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 36.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:55:49.323950Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 38.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:55:53.559958Z [info     ] Start Predict                  dataset=318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 37.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:55:57.979804Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 30.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:56:03.501139Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 34.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:56:08.528069Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 37.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:56:13.549518Z [info     ] Start Predict                  dataset=238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 37.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:56:18.661156Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 37.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:56:23.986590Z [info     ] Start Predict                  dataset=198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 31.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:56:30.151315Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 38.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:56:36.565062Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 31.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:56:42.692176Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 39.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:56:48.671760Z [info     ] Start Predict                  dataset=118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 35.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:56:56.097504Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 29.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:57:02.852985Z [info     ] Start Predict                  dataset=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 38.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:57:09.474647Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 41.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:57:16.295096Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 34.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:57:24.214851Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 46.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16363636363636364, 0.16363636363636364, 0.20454545454545456, 0.2636363636363636, 0.33181818181818185, 0.4636363636363636, 0.5772727272727273, 0.6772727272727272, 0.7136363636363636, 0.7181818181818181, 0.7272727272727273, 0.7181818181818181, 0.7227272727272728, 0.7227272727272728, 0.7227272727272728, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n",
      "[248  76 179]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 02:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:57:34.550312Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 32.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:57:37.810746Z [info     ] Start Predict                  dataset=438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 34.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:57:41.587190Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 30.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:57:45.820583Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 36.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:57:49.682079Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 36.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:57:54.171390Z [info     ] Start Predict                  dataset=358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 29.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:57:58.969293Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 37.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:58:03.295546Z [info     ] Start Predict                  dataset=318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 37.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:58:08.198579Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 35.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:58:13.390589Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:00<00:00, 37.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:58:18.165614Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 37.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:58:23.138617Z [info     ] Start Predict                  dataset=238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 31.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:58:29.631232Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 36.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:58:34.978720Z [info     ] Start Predict                  dataset=198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 37.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:58:41.221010Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 38.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:58:46.874099Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 36.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:58:53.385794Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 35.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:58:59.321306Z [info     ] Start Predict                  dataset=118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 38.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:59:05.558919Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 33.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:59:13.297499Z [info     ] Start Predict                  dataset=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 32.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:59:20.174315Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 33.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:59:28.028084Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 39.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:59:34.978901Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 48.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14545454545454545, 0.14545454545454545, 0.15454545454545454, 0.19545454545454546, 0.2727272727272727, 0.4, 0.4590909090909091, 0.6318181818181818, 0.6227272727272727, 0.6909090909090909, 0.7227272727272728, 0.7181818181818181, 0.7227272727272728, 0.7227272727272728, 0.7227272727272728, 0.7272727272727273, 0.7272727272727273, 0.7227272727272728, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n",
      "[248  76 179]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 02:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:59:45.548602Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 36.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:59:48.906004Z [info     ] Start Predict                  dataset=438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 30.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:59:52.977944Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 34.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T14:59:56.557662Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 35.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:00:00.772097Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 34.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:00:04.870790Z [info     ] Start Predict                  dataset=358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 37.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:00:09.563685Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 32.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:00:13.965337Z [info     ] Start Predict                  dataset=318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 37.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:00:18.419743Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 38.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:00:23.904376Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 30.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:00:29.003472Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 38.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:00:33.988219Z [info     ] Start Predict                  dataset=238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 37.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:00:39.663715Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 31.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:00:45.726108Z [info     ] Start Predict                  dataset=198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 38.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:00:51.242336Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 37.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:00:57.036231Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 30.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:01:04.155120Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 33.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:01:10.452188Z [info     ] Start Predict                  dataset=118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 38.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:01:17.271476Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 37.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:01:23.799920Z [info     ] Start Predict                  dataset=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 38.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:01:30.849868Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 39.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:01:37.753522Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 31.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:01:45.805027Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 44.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14545454545454545, 0.14545454545454545, 0.15454545454545454, 0.19545454545454546, 0.2727272727272727, 0.4, 0.4590909090909091, 0.6318181818181818, 0.6227272727272727, 0.6909090909090909, 0.7227272727272728, 0.7181818181818181, 0.7227272727272728, 0.7227272727272728, 0.7227272727272728, 0.7272727272727273, 0.7272727272727273, 0.7227272727272728, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n",
      "[248  76 179]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 02:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:01:55.353556Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 30.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:01:59.120005Z [info     ] Start Predict                  dataset=438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 29.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:02:03.227716Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 30.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:02:07.401556Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 36.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:02:11.268862Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 37.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:02:15.673424Z [info     ] Start Predict                  dataset=358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 30.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:02:20.385920Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 36.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:02:24.626055Z [info     ] Start Predict                  dataset=318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 36.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:02:29.872499Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 35.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:02:35.146265Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 31.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:02:40.442184Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 37.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:02:45.396227Z [info     ] Start Predict                  dataset=238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 37.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:02:51.447733Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 31.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:02:57.105527Z [info     ] Start Predict                  dataset=198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 37.51it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:03:02.649960Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 35.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:03:08.346946Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 35.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:03:15.228325Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 29.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:03:21.852607Z [info     ] Start Predict                  dataset=118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 38.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:03:28.206016Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 32.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:03:35.635212Z [info     ] Start Predict                  dataset=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 38.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:03:42.162144Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 34.03it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:03:50.021077Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 37.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:03:56.988725Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 45.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14545454545454545, 0.14545454545454545, 0.15454545454545454, 0.19545454545454546, 0.2727272727272727, 0.4, 0.4590909090909091, 0.6318181818181818, 0.6227272727272727, 0.6909090909090909, 0.7227272727272728, 0.7181818181818181, 0.7227272727272728, 0.7227272727272728, 0.7227272727272728, 0.7272727272727273, 0.7272727272727273, 0.7227272727272728, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n",
      "[248  76 179]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 02:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:04:07.611433Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 38.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:04:10.621308Z [info     ] Start Predict                  dataset=438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 30.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:04:14.568245Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 30.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:04:18.434906Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 37.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:04:22.421675Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 30.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:04:27.206915Z [info     ] Start Predict                  dataset=358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 29.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:04:31.838195Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 37.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:04:36.088713Z [info     ] Start Predict                  dataset=318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 36.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:04:41.071757Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:04:46.131719Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:00<00:00, 37.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:04:51.652249Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 33.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:04:56.898884Z [info     ] Start Predict                  dataset=238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 37.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:05:02.140105Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 38.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:05:08.327272Z [info     ] Start Predict                  dataset=198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 30.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:05:14.151269Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 37.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:05:20.515216Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 37.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:05:26.458592Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 37.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:05:32.655727Z [info     ] Start Predict                  dataset=118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 38.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:05:39.010116Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 32.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:05:46.586838Z [info     ] Start Predict                  dataset=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 37.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:05:53.234924Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 41.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:06:00.672333Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 31.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:06:08.546811Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 45.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14545454545454545, 0.14545454545454545, 0.15454545454545454, 0.19545454545454546, 0.2727272727272727, 0.4, 0.4590909090909091, 0.6318181818181818, 0.6227272727272727, 0.6909090909090909, 0.7227272727272728, 0.7181818181818181, 0.7227272727272728, 0.7227272727272728, 0.7227272727272728, 0.7272727272727273, 0.7272727272727273, 0.7227272727272728, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273]\n"
     ]
    }
   ],
   "source": [
    "active_mc_atheism1 = []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "while mcrun != 5:\n",
    "    n_labeled_examples = np.unique(train_dataset_atheism['text']).size\n",
    "    training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "    print(training_indices0)\n",
    "    active_set_atheism =active_huggingface_dataset(train_dataset_atheism,tokenizer,'label','text')\n",
    "    valid_set_atheism = HuggingFaceDatasets(test_dataset_atheism,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_atheism.can_label = False\n",
    "    active_set_atheism.label(training_indices0)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = model_original\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_atheism,\n",
    "            eval_dataset=valid_set_atheism,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_atheism = ActiveLearningLoop(active_set_atheism,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_atheism=[unqueried_score]\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_atheism.step()\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_atheism.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_atheism),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_atheism.append(eval_metrics['eval_accuracy'])\n",
    "    print(performance_history_atheism)\n",
    "    active_mc_atheism1.append(performance_history_atheism)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edb53ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_atheism1, min_atheism1,max_atheism1 = calculate(active_mc_atheism1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acf113a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[332  15 230]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 02:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:06:18.701381Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 34.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:06:22.238284Z [info     ] Start Predict                  dataset=438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:02<00:00, 26.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:06:26.610538Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 27.51it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:06:31.202154Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 31.03it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:06:35.260482Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 33.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:06:39.826956Z [info     ] Start Predict                  dataset=358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 27.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:06:44.853805Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 33.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:06:49.441069Z [info     ] Start Predict                  dataset=318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 33.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:06:54.036746Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:07:00.206818Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 26.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:07:06.576118Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 27.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:07:12.983647Z [info     ] Start Predict                  dataset=238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 26.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:07:18.909034Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:01<00:00, 26.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:07:25.342800Z [info     ] Start Predict                  dataset=198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 31.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:07:31.030924Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 34.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:07:37.707465Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 27.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:07:44.076473Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 33.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:07:50.495405Z [info     ] Start Predict                  dataset=118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 27.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:07:57.712862Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 32.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:08:04.265588Z [info     ] Start Predict                  dataset=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 34.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:08:12.276319Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 29.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:08:19.248290Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 33.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:08:26.684369Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 36.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21363636363636362, 0.17727272727272728, 0.2409090909090909, 0.2318181818181818, 0.2909090909090909, 0.37272727272727274, 0.45, 0.5454545454545454, 0.6090909090909091, 0.6, 0.6545454545454545, 0.7045454545454546, 0.7136363636363636, 0.7227272727272728, 0.7181818181818181, 0.7136363636363636, 0.7227272727272728, 0.7227272727272728, 0.7181818181818181, 0.7227272727272728, 0.7272727272727273, 0.7272727272727273, 0.7227272727272728, 0.7318181818181818]\n",
      "[248  76 179]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 02:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:08:37.920658Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 33.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:08:41.573092Z [info     ] Start Predict                  dataset=438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:02<00:00, 27.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:08:45.902130Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 32.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:08:49.765542Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 27.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:08:54.582373Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 34.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:08:58.643245Z [info     ] Start Predict                  dataset=358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 32.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:09:04.035685Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 33.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:09:08.777963Z [info     ] Start Predict                  dataset=318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 27.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:09:13.993398Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 33.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:09:18.828534Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 33.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:09:24.041236Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 27.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:09:30.323274Z [info     ] Start Predict                  dataset=238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 31.51it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:09:35.652638Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 33.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:09:41.185853Z [info     ] Start Predict                  dataset=198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 33.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:09:46.874370Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 27.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:09:53.855530Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 26.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:10:00.207614Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 32.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:10:06.411796Z [info     ] Start Predict                  dataset=118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 33.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:10:13.376035Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 28.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:10:21.295957Z [info     ] Start Predict                  dataset=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 26.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:10:28.235421Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 34.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:10:35.144408Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 34.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:10:43.141864Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 33.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16818181818181818, 0.15, 0.18181818181818182, 0.18181818181818182, 0.29545454545454547, 0.33181818181818185, 0.4090909090909091, 0.5181818181818182, 0.5818181818181818, 0.5863636363636363, 0.6363636363636364, 0.6636363636363637, 0.7045454545454546, 0.7227272727272728, 0.6818181818181818, 0.7090909090909091, 0.7090909090909091, 0.7318181818181818, 0.7181818181818181, 0.7227272727272728, 0.7272727272727273, 0.7272727272727273, 0.7227272727272728, 0.7272727272727273]\n",
      "[248  76 179]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 02:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:10:53.766336Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 29.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:10:57.715906Z [info     ] Start Predict                  dataset=438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 30.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:11:01.457589Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 33.66it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:11:05.625762Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 26.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:11:10.390136Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 34.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:11:14.448940Z [info     ] Start Predict                  dataset=358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 32.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:11:18.794994Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 34.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:11:23.872675Z [info     ] Start Predict                  dataset=318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 27.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:11:29.196664Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 34.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:11:34.070987Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 33.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:11:39.582285Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 27.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:11:45.258331Z [info     ] Start Predict                  dataset=238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 32.89it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:11:50.627132Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 33.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:11:57.029663Z [info     ] Start Predict                  dataset=198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 27.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:12:03.461542Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 35.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:12:09.285666Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 34.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:12:15.138177Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 29.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:12:22.547455Z [info     ] Start Predict                  dataset=118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 28.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:12:29.400947Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 34.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:12:36.272357Z [info     ] Start Predict                  dataset=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 27.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:12:43.497787Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 37.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:12:50.660102Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 27.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:12:58.511949Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 44.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16818181818181818, 0.15, 0.18181818181818182, 0.18181818181818182, 0.29545454545454547, 0.33181818181818185, 0.4090909090909091, 0.5181818181818182, 0.5818181818181818, 0.5863636363636363, 0.6363636363636364, 0.6636363636363637, 0.7045454545454546, 0.7227272727272728, 0.6818181818181818, 0.7090909090909091, 0.7090909090909091, 0.7318181818181818, 0.7181818181818181, 0.7227272727272728, 0.7272727272727273, 0.7272727272727273, 0.7227272727272728, 0.7272727272727273]\n",
      "[248  76 179]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 02:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:13:08.329703Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 30.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:13:12.224665Z [info     ] Start Predict                  dataset=438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:02<00:00, 26.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:13:16.593691Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 27.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:13:20.761569Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 32.73it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:13:24.816311Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 33.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:13:29.009442Z [info     ] Start Predict                  dataset=358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 32.89it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:13:33.960275Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 27.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:13:39.415244Z [info     ] Start Predict                  dataset=318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 29.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:13:44.189829Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 32.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:13:49.796428Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 31.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:13:54.988199Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 31.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:14:00.241281Z [info     ] Start Predict                  dataset=238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 32.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:14:06.491475Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:01<00:00, 27.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:14:12.341533Z [info     ] Start Predict                  dataset=198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 32.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:14:18.288022Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 28.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:14:24.855425Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 33.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:14:31.141950Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 34.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:14:37.411796Z [info     ] Start Predict                  dataset=118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 32.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:14:44.913913Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 34.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:14:51.393990Z [info     ] Start Predict                  dataset=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 32.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:14:59.503293Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 31.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:15:06.500657Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 37.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:15:14.420303Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 32.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16818181818181818, 0.15, 0.18181818181818182, 0.18181818181818182, 0.29545454545454547, 0.33181818181818185, 0.4090909090909091, 0.5181818181818182, 0.5818181818181818, 0.5863636363636363, 0.6363636363636364, 0.6636363636363637, 0.7045454545454546, 0.7227272727272728, 0.6818181818181818, 0.7090909090909091, 0.7090909090909091, 0.7318181818181818, 0.7181818181818181, 0.7227272727272728, 0.7272727272727273, 0.7272727272727273, 0.7227272727272728, 0.7272727272727273]\n",
      "[248  76 179]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 02:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:15:24.671155Z [info     ] Start Predict                  dataset=458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:02<00:00, 26.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:15:28.884689Z [info     ] Start Predict                  dataset=438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:02<00:00, 26.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:15:33.307656Z [info     ] Start Predict                  dataset=418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 31.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:15:37.037888Z [info     ] Start Predict                  dataset=398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 33.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:15:41.558585Z [info     ] Start Predict                  dataset=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 32.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:15:45.784094Z [info     ] Start Predict                  dataset=358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 32.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:15:50.723218Z [info     ] Start Predict                  dataset=338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 31.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:15:55.393213Z [info     ] Start Predict                  dataset=318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 25.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:16:00.726033Z [info     ] Start Predict                  dataset=298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 32.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:16:05.599748Z [info     ] Start Predict                  dataset=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 33.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:16:11.397902Z [info     ] Start Predict                  dataset=258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 32.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:16:16.711271Z [info     ] Start Predict                  dataset=238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 32.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:16:22.893280Z [info     ] Start Predict                  dataset=218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 33.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:16:28.492145Z [info     ] Start Predict                  dataset=198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 33.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:16:34.306203Z [info     ] Start Predict                  dataset=178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 33.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:16:40.418388Z [info     ] Start Predict                  dataset=158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 27.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:16:47.600841Z [info     ] Start Predict                  dataset=138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 33.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:16:53.803574Z [info     ] Start Predict                  dataset=118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 27.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:17:01.108888Z [info     ] Start Predict                  dataset=98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 35.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:17:07.609206Z [info     ] Start Predict                  dataset=78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 31.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:17:15.447009Z [info     ] Start Predict                  dataset=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 38.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:17:23.060225Z [info     ] Start Predict                  dataset=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 26.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17944-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-06T15:17:30.561887Z [info     ] Start Predict                  dataset=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 38.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 220\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16818181818181818, 0.15, 0.18181818181818182, 0.18181818181818182, 0.29545454545454547, 0.33181818181818185, 0.4090909090909091, 0.5181818181818182, 0.5818181818181818, 0.5863636363636363, 0.6363636363636364, 0.6636363636363637, 0.7045454545454546, 0.7227272727272728, 0.6818181818181818, 0.7090909090909091, 0.7090909090909091, 0.7318181818181818, 0.7181818181818181, 0.7227272727272728, 0.7272727272727273, 0.7272727272727273, 0.7227272727272728, 0.7272727272727273]\n"
     ]
    }
   ],
   "source": [
    "active_mc_atheism2 = []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "while mcrun != 5:\n",
    "    n_labeled_examples = np.unique(train_dataset_atheism['text']).size\n",
    "    training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "    print(training_indices0)\n",
    "    active_set_atheism =active_huggingface_dataset(train_dataset_atheism,tokenizer,'label','text')\n",
    "    valid_set_atheism = HuggingFaceDatasets(test_dataset_atheism,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_atheism.can_label = False\n",
    "    active_set_atheism.label(training_indices0)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_atheism,\n",
    "            eval_dataset=valid_set_atheism,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_atheism = ActiveLearningLoop(active_set_atheism,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_atheism=[unqueried_score]\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_atheism.step()\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_atheism.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_atheism),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_atheism.append(eval_metrics['eval_accuracy'])\n",
    "    print(performance_history_atheism)\n",
    "    active_mc_atheism2.append(performance_history_atheism)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92283df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_atheism2, min_atheism2,max_atheism2 = calculate(active_mc_atheism2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b23ffe16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1105x1040 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(8.5, 8), dpi=130)\n",
    "ax.plot(median_atheism1,label=\"no Monte Carlo\")\n",
    "ax.fill_between(range(24),min_atheism1,max_atheism1,color='blue', alpha=0.1)\n",
    "ax.plot(median_atheism2,label=\"Monte Carlo\")\n",
    "ax.fill_between(range(24),min_atheism2,max_atheism2,color='orange', alpha=0.1)\n",
    "\n",
    "ax.scatter(range(24), median_atheism1, s=8,marker = \"v\")\n",
    "ax.scatter(range(24), median_atheism2, s=8,marker=\"^\")\n",
    "\n",
    "ax.xaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=5, integer=True))\n",
    "ax.yaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=10))\n",
    "ax.yaxis.set_major_formatter(mpl.ticker.PercentFormatter(xmax=1))\n",
    "\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "ax.set_title('Different query queue sizes in atheism target')\n",
    "ax.set_xlabel('Query iteration')\n",
    "ax.set_ylabel('Performance(median)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a365ea1",
   "metadata": {},
   "source": [
    "# Climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8c559ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_climate\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset with 355 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_climate\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset with 40 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_climate\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset with 169 instances loaded\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "cache_dir = \"./data_cache\"\n",
    "\n",
    "train_dataset_climate = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_climate\",\n",
    "    split=\"train\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Training dataset with {len(train_dataset_climate)} instances loaded\")\n",
    "\n",
    "val_dataset_climate = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_climate\",\n",
    "    split=\"validation\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Validation dataset with {len(val_dataset_climate)} instances loaded\")\n",
    "\n",
    "test_dataset_climate = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_climate\",\n",
    "    split=\"test\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Test dataset with {len(test_dataset_climate)} instances loaded\")\n",
    "\n",
    "num_classes = np.unique(train_dataset_climate['label']).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0de329dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/config.json from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\3cf34679007e9fe5d0acd644dcc1f4b26bec5cbc9612364f6da7262aed4ef7a4.a5a11219cf90aae61ff30e1658ccf2cb4aa84d6b6e947336556f887c9828dc6d\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-tiny\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/pytorch_model.bin from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\1ee037c9e1a220d5c814779ffe697080d1e6f5b1602e16cf6061aaae41a082c5.038e1aed90492a59d2283f9c44c9fe3ee2380495ff1e7fefb3f1f04af3b685b5\n",
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_original = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\", num_labels=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff45e1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[137 302 161]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='440' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 01:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:27:42.154050Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 39.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:27:44.624863Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 37.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:27:47.467880Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 37.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:27:50.325514Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:00<00:00, 40.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:27:53.406252Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 38.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:27:56.797230Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 35.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:28:01.285229Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:28:05.530968Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 41.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:28:09.172992Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 39.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:28:14.442633Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 39.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:28:18.479638Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 41.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:28:22.650660Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 40.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:28:26.863707Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 36.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:28:31.260091Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 42.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:28:35.837213Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 36.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:28:41.029216Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 40.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:28:45.953141Z [info     ] Start Predict                  dataset=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 43.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:28:51.983176Z [info     ] Start Predict                  dataset=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 38.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 355\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0650887573964497, 0.0650887573964497, 0.0650887573964497, 0.05917159763313609, 0.05917159763313609, 0.10059171597633136, 0.14792899408284024, 0.35502958579881655, 0.4970414201183432, 0.6745562130177515, 0.5384615384615384, 0.6745562130177515, 0.5562130177514792, 0.7337278106508875, 0.6331360946745562, 0.6153846153846154, 0.727810650887574, 0.6863905325443787, 0.727810650887574]\n",
      "[335 117 232]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='440' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 01:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:28:59.999086Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 38.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:29:02.433084Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 40.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:29:04.952149Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 39.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:29:07.626193Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:00<00:00, 40.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:29:10.487320Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 36.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:29:13.568319Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 39.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:29:16.799321Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:29:21.134455Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 37.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:29:25.131277Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 38.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:29:29.037274Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 36.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:29:33.250274Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 41.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:29:37.348240Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 35.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:29:42.040786Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 37.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:29:46.563805Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 41.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:29:51.261999Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 36.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:29:56.509987Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 35.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:30:02.318985Z [info     ] Start Predict                  dataset=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 28.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:30:08.212807Z [info     ] Start Predict                  dataset=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 31.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 355\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0650887573964497, 0.0650887573964497, 0.05917159763313609, 0.07100591715976332, 0.08284023668639054, 0.11834319526627218, 0.24260355029585798, 0.3727810650887574, 0.5443786982248521, 0.650887573964497, 0.591715976331361, 0.6272189349112426, 0.727810650887574, 0.6272189349112426, 0.727810650887574, 0.6331360946745562, 0.6982248520710059, 0.6272189349112426, 0.7159763313609467]\n",
      "[335 117 232]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='440' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 01:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:30:16.017938Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 38.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:30:18.427753Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 39.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:30:21.085754Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 39.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:30:23.737847Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:00<00:00, 39.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:30:26.686848Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 40.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:30:29.895878Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 38.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:30:33.329850Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:30:36.894849Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 37.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:30:41.119577Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 35.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:30:45.288603Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 42.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:30:49.436614Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 39.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:30:53.561613Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 39.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:30:58.063131Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 35.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:31:02.611857Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 40.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:31:07.398889Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 38.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:31:12.469333Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 43.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:31:17.531370Z [info     ] Start Predict                  dataset=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 35.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:31:22.986375Z [info     ] Start Predict                  dataset=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 41.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 355\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0650887573964497, 0.0650887573964497, 0.05917159763313609, 0.07100591715976332, 0.08284023668639054, 0.11834319526627218, 0.24260355029585798, 0.3727810650887574, 0.5443786982248521, 0.650887573964497, 0.591715976331361, 0.6272189349112426, 0.727810650887574, 0.6272189349112426, 0.727810650887574, 0.6331360946745562, 0.6982248520710059, 0.6272189349112426, 0.7159763313609467]\n",
      "[335 117 232]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='440' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 01:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:31:30.313518Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 40.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:31:32.692552Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 40.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:31:35.327595Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 40.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:31:37.925593Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:00<00:00, 41.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:31:40.714595Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 40.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:31:43.784870Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 42.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:31:47.031870Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 40.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:31:50.393873Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 37.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:31:54.025875Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 39.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:31:57.787869Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 36.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:32:01.803039Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 39.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:32:06.474416Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 37.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:32:12.579608Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 32.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:32:17.347892Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 37.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:32:22.094796Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 38.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:32:26.990989Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 42.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:32:32.068510Z [info     ] Start Predict                  dataset=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 40.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:32:37.331566Z [info     ] Start Predict                  dataset=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 51.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 355\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0650887573964497, 0.0650887573964497, 0.05917159763313609, 0.07100591715976332, 0.08284023668639054, 0.11834319526627218, 0.24260355029585798, 0.3727810650887574, 0.5443786982248521, 0.650887573964497, 0.591715976331361, 0.6272189349112426, 0.727810650887574, 0.6272189349112426, 0.727810650887574, 0.6331360946745562, 0.6982248520710059, 0.6272189349112426, 0.7159763313609467]\n",
      "[335 117 232]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='440' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 01:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:32:48.653694Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 36.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:32:52.494578Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 39.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:32:56.365727Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 41.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:32:59.947839Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:00<00:00, 39.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:33:07.016191Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 36.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:33:11.958849Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 39.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:33:15.769597Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:33:20.603127Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 39.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:33:25.607994Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 40.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:33:31.679711Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 40.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:33:37.332441Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 40.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:33:41.596987Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 37.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:33:46.458038Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 36.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:33:51.622037Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 36.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:33:57.138037Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 38.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:34:05.838075Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 40.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:34:11.493866Z [info     ] Start Predict                  dataset=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 44.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:34:19.477632Z [info     ] Start Predict                  dataset=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 48.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 355\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0650887573964497, 0.0650887573964497, 0.05917159763313609, 0.07100591715976332, 0.08284023668639054, 0.11834319526627218, 0.24260355029585798, 0.3727810650887574, 0.5443786982248521, 0.650887573964497, 0.591715976331361, 0.6272189349112426, 0.727810650887574, 0.6272189349112426, 0.727810650887574, 0.6331360946745562, 0.6982248520710059, 0.6272189349112426, 0.7159763313609467]\n"
     ]
    }
   ],
   "source": [
    "active_mc_climate1= []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "while mcrun != 5:\n",
    "    n_labeled_examples = np.unique(train_dataset_climate['text']).size\n",
    "    training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "    print(training_indices0)\n",
    "    active_set_climate =active_huggingface_dataset(train_dataset_climate,tokenizer,'label','text')\n",
    "    valid_set_climate = HuggingFaceDatasets(test_dataset_climate,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_climate.can_label = False\n",
    "    active_set_climate.label(training_indices0)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = model_original\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_climate,\n",
    "            eval_dataset=valid_set_climate,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_climate = ActiveLearningLoop(active_set_climate,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_climate=[unqueried_score]\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_climate.step()\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_climate.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_climate),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_climate.append(eval_metrics['eval_accuracy'])\n",
    "    print(performance_history_climate)\n",
    "    active_mc_climate1.append(performance_history_climate)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51790d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_climate1, min_climate1,max_climate1 = calculate(active_mc_climate1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7a8e049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[203  82  64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='440' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 01:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:34:27.125170Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 32.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:34:29.909736Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 34.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:34:32.973737Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 29.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:34:37.642659Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 32.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:34:41.532653Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 30.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:34:45.445650Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 36.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:34:48.948771Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:34:52.749918Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 36.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:34:56.445470Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 31.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:35:00.521468Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 36.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:35:04.706268Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 36.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:35:09.066804Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 35.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:35:13.803790Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 28.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:35:19.143791Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 35.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:35:23.913072Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 36.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:35:28.909556Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 27.89it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:35:34.525054Z [info     ] Start Predict                  dataset=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 33.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:35:39.656615Z [info     ] Start Predict                  dataset=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 45.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 355\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05917159763313609, 0.0650887573964497, 0.07100591715976332, 0.08284023668639054, 0.07100591715976332, 0.21893491124260356, 0.24260355029585798, 0.3431952662721893, 0.5088757396449705, 0.5562130177514792, 0.5976331360946746, 0.5502958579881657, 0.5798816568047337, 0.5562130177514792, 0.650887573964497, 0.7218934911242604, 0.6627218934911243, 0.650887573964497, 0.7337278106508875]\n",
      "[335 117 232]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='440' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 01:25]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:35:48.158732Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 33.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:35:52.083802Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 35.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:35:56.592032Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 33.51it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:35:59.574033Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 34.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:36:02.864030Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 30.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:36:07.652511Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 34.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:36:11.655503Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:36:15.615498Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 33.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:36:20.204552Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 36.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:36:25.743375Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 35.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:36:32.062514Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 37.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:36:36.375212Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 37.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:36:41.071454Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 33.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:36:45.819754Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 33.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:36:50.755904Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 34.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:36:55.673845Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 37.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:37:00.866607Z [info     ] Start Predict                  dataset=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 36.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:37:06.143621Z [info     ] Start Predict                  dataset=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 36.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 355\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05917159763313609, 0.07100591715976332, 0.07100591715976332, 0.07100591715976332, 0.07692307692307693, 0.1952662721893491, 0.2485207100591716, 0.3609467455621302, 0.4260355029585799, 0.5680473372781065, 0.5621301775147929, 0.4970414201183432, 0.5088757396449705, 0.5798816568047337, 0.6863905325443787, 0.7218934911242604, 0.6982248520710059, 0.6153846153846154, 0.727810650887574]\n",
      "[335 117 232]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='440' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 01:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:37:13.781105Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 34.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:37:16.444105Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 32.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:37:19.338503Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 37.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:37:22.200941Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 36.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:37:25.335639Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 34.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:37:32.619062Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 35.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:37:36.078212Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:37:40.979899Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 37.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:37:44.874495Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 36.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:37:48.709082Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 35.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:37:52.681623Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 38.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:37:56.801876Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 38.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:38:01.186533Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 36.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:38:05.653069Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 32.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:38:10.813068Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 35.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:38:15.565190Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 35.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:38:20.824685Z [info     ] Start Predict                  dataset=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 34.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:38:26.500451Z [info     ] Start Predict                  dataset=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 44.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 355\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05917159763313609, 0.07100591715976332, 0.07100591715976332, 0.07100591715976332, 0.07692307692307693, 0.1952662721893491, 0.2485207100591716, 0.3609467455621302, 0.4260355029585799, 0.5680473372781065, 0.5621301775147929, 0.4970414201183432, 0.5088757396449705, 0.5798816568047337, 0.6863905325443787, 0.7218934911242604, 0.6982248520710059, 0.6153846153846154, 0.727810650887574]\n",
      "[335 117 232]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='440' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 01:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:38:34.304726Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 34.89it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:38:36.891259Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 34.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:38:39.723788Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 34.03it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:38:42.954057Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 35.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:38:46.156426Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 36.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:38:49.228923Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 34.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:38:52.768408Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:38:56.630999Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 37.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:39:00.406028Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 34.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:39:04.542127Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 35.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:39:08.783754Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 32.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:39:13.681218Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 22.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:39:19.586046Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 34.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:39:24.752288Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 31.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:39:29.966249Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 29.51it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:39:35.401722Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 33.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:39:40.923588Z [info     ] Start Predict                  dataset=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 33.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:39:48.088093Z [info     ] Start Predict                  dataset=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 21.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 355\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05917159763313609, 0.07100591715976332, 0.07100591715976332, 0.07100591715976332, 0.07692307692307693, 0.1952662721893491, 0.2485207100591716, 0.3609467455621302, 0.4260355029585799, 0.5680473372781065, 0.5621301775147929, 0.4970414201183432, 0.5088757396449705, 0.5798816568047337, 0.6863905325443787, 0.7218934911242604, 0.6982248520710059, 0.6153846153846154, 0.727810650887574]\n",
      "[335 117 232]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='440' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 01:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:39:56.220779Z [info     ] Start Predict                  dataset=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:01<00:00, 32.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:39:59.178774Z [info     ] Start Predict                  dataset=332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 27.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:40:03.096995Z [info     ] Start Predict                  dataset=312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 23.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:40:07.134996Z [info     ] Start Predict                  dataset=292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 30.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:40:10.533721Z [info     ] Start Predict                  dataset=272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:01<00:00, 31.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:40:13.917095Z [info     ] Start Predict                  dataset=252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 36.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:40:17.762786Z [info     ] Start Predict                  dataset=232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:40:22.231784Z [info     ] Start Predict                  dataset=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 37.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:40:25.878044Z [info     ] Start Predict                  dataset=192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 36.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:40:29.651155Z [info     ] Start Predict                  dataset=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 36.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:40:33.837479Z [info     ] Start Predict                  dataset=152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 31.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:40:38.328915Z [info     ] Start Predict                  dataset=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 36.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:40:42.895067Z [info     ] Start Predict                  dataset=112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 33.73it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:40:47.985225Z [info     ] Start Predict                  dataset=92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 29.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:40:53.121255Z [info     ] Start Predict                  dataset=72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 34.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:40:58.940447Z [info     ] Start Predict                  dataset=52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 37.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:41:05.032435Z [info     ] Start Predict                  dataset=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 28.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T00:41:11.522558Z [info     ] Start Predict                  dataset=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 40.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 355\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05917159763313609, 0.07100591715976332, 0.07100591715976332, 0.07100591715976332, 0.07692307692307693, 0.1952662721893491, 0.2485207100591716, 0.3609467455621302, 0.4260355029585799, 0.5680473372781065, 0.5621301775147929, 0.4970414201183432, 0.5088757396449705, 0.5798816568047337, 0.6863905325443787, 0.7218934911242604, 0.6982248520710059, 0.6153846153846154, 0.727810650887574]\n"
     ]
    }
   ],
   "source": [
    "active_mc_climate2 = []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "while mcrun != 5:\n",
    "    n_labeled_examples = np.unique(train_dataset_climate['text']).size\n",
    "    training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "    print(training_indices0)\n",
    "    active_set_climate =active_huggingface_dataset(train_dataset_climate,tokenizer,'label','text')\n",
    "    valid_set_climate = HuggingFaceDatasets(test_dataset_climate,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_climate.can_label = False\n",
    "    active_set_climate.label(training_indices0)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_climate,\n",
    "            eval_dataset=valid_set_climate,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_climate = ActiveLearningLoop(active_set_climate,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_climate=[unqueried_score]\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_climate.step()\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_climate.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_climate),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_climate.append(eval_metrics['eval_accuracy'])\n",
    "    print(performance_history_climate)\n",
    "    active_mc_climate2.append(performance_history_climate)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1aeb28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_climate2, min_climate2,max_climate2 = calculate(active_mc_climate2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5a305bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1105x1040 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(8.5, 8), dpi=130)\n",
    "ax.plot(median_climate1,label=\"Queue size 20\")\n",
    "ax.fill_between(range(19),min_climate1,max_climate1,color='blue', alpha=0.1)\n",
    "ax.plot(median_climate2,label=\"Queue size 40\")\n",
    "ax.fill_between(range(19),min_climate2,max_climate2,color='orange', alpha=0.1)\n",
    "\n",
    "ax.scatter(range(19), median_climate1, s=8,marker = \"v\")\n",
    "ax.scatter(range(19), median_climate2, s=8,marker=\"^\")\n",
    "\n",
    "ax.xaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=5, integer=True))\n",
    "ax.yaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=10))\n",
    "ax.yaxis.set_major_formatter(mpl.ticker.PercentFormatter(xmax=1))\n",
    "\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "ax.set_title('Different query queue sizes in climate target')\n",
    "ax.set_xlabel('Query iteration')\n",
    "ax.set_ylabel('Performance(median)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dbe152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430dd787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639a7c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "082e0b9e",
   "metadata": {},
   "source": [
    "# Feminist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2a60b1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_feminist\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset with 597 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_feminist\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset with 67 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_feminist\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset with 285 instances loaded\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "cache_dir = \"./data_cache\"\n",
    "\n",
    "train_dataset_feminist = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_feminist\",\n",
    "    split=\"train\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Training dataset with {len(train_dataset_feminist)} instances loaded\")\n",
    "\n",
    "val_dataset_feminist = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_feminist\",\n",
    "    split=\"validation\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Validation dataset with {len(val_dataset_feminist)} instances loaded\")\n",
    "\n",
    "test_dataset_feminist = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_feminist\",\n",
    "    split=\"test\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Test dataset with {len(test_dataset_feminist)} instances loaded\")\n",
    "\n",
    "num_classes = np.unique(train_dataset_feminist['label']).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "51e4b2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/config.json from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\3cf34679007e9fe5d0acd644dcc1f4b26bec5cbc9612364f6da7262aed4ef7a4.a5a11219cf90aae61ff30e1658ccf2cb4aa84d6b6e947336556f887c9828dc6d\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-tiny\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/pytorch_model.bin from cache at C:\\Users\\LYM/.cache\\huggingface\\transformers\\1ee037c9e1a220d5c814779ffe697080d1e6f5b1602e16cf6061aaae41a082c5.038e1aed90492a59d2283f9c44c9fe3ee2380495ff1e7fefb3f1f04af3b685b5\n",
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_original = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\", num_labels=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d724541f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 40 205 269]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1116' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 03:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:29:44.644492Z [info     ] Start Predict                  dataset=594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 39.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:29:48.561495Z [info     ] Start Predict                  dataset=574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 72/72 [00:01<00:00, 40.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:29:52.505403Z [info     ] Start Predict                  dataset=554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:01<00:00, 40.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:29:56.745404Z [info     ] Start Predict                  dataset=534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 38.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:30:01.146447Z [info     ] Start Predict                  dataset=514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 40.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:30:05.802445Z [info     ] Start Predict                  dataset=494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [00:01<00:00, 36.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:30:10.622444Z [info     ] Start Predict                  dataset=474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 38.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:30:15.596446Z [info     ] Start Predict                  dataset=454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 34.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:30:21.098448Z [info     ] Start Predict                  dataset=434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 37.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:30:26.348448Z [info     ] Start Predict                  dataset=414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 37.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:30:32.150480Z [info     ] Start Predict                  dataset=394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 37.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:30:38.114195Z [info     ] Start Predict                  dataset=374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 39.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:30:44.059318Z [info     ] Start Predict                  dataset=354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 38.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:30:50.064318Z [info     ] Start Predict                  dataset=334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 36.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:30:56.350319Z [info     ] Start Predict                  dataset=314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 36.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:31:02.933321Z [info     ] Start Predict                  dataset=294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:00<00:00, 39.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:31:09.515046Z [info     ] Start Predict                  dataset=274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:00<00:00, 40.51it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:31:16.038046Z [info     ] Start Predict                  dataset=254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 39.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:31:22.858131Z [info     ] Start Predict                  dataset=234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 36.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:31:30.024131Z [info     ] Start Predict                  dataset=214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 37.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:31:37.260132Z [info     ] Start Predict                  dataset=194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 38.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:31:44.832130Z [info     ] Start Predict                  dataset=174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 40.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:31:52.413131Z [info     ] Start Predict                  dataset=154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 36.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:32:00.319165Z [info     ] Start Predict                  dataset=134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 39.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:32:08.244945Z [info     ] Start Predict                  dataset=114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 41.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:32:15.970752Z [info     ] Start Predict                  dataset=94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 42.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:32:24.664754Z [info     ] Start Predict                  dataset=74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 36.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:32:33.173789Z [info     ] Start Predict                  dataset=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 27.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:32:43.218937Z [info     ] Start Predict                  dataset=34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 44.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:32:52.315470Z [info     ] Start Predict                  dataset=14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 32.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20350877192982456, 0.20350877192982456, 0.20350877192982456, 0.20350877192982456, 0.20350877192982456, 0.2, 0.20701754385964913, 0.25263157894736843, 0.2807017543859649, 0.37543859649122807, 0.2631578947368421, 0.47017543859649125, 0.4, 0.3543859649122807, 0.36140350877192984, 0.37543859649122807, 0.36140350877192984, 0.45964912280701753, 0.5403508771929825, 0.6035087719298246, 0.5614035087719298, 0.3508771929824561, 0.5017543859649123, 0.4421052631578947, 0.41403508771929826, 0.5578947368421052, 0.6385964912280702, 0.6210526315789474, 0.6210526315789474, 0.6175438596491228, 0.6421052631578947]\n"
     ]
    }
   ],
   "source": [
    "active_mc_feminist1 = []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "n_labeled_examples = np.unique(train_dataset_feminist['text']).size\n",
    "training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "print(training_indices0)\n",
    "active_set_feminist =active_huggingface_dataset(train_dataset_feminist,tokenizer,'label','text')\n",
    "valid_set_feminist = HuggingFaceDatasets(test_dataset_feminist,tokenizer,'label','text')\n",
    "# # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "active_set_feminist.can_label = False\n",
    "active_set_feminist.label(training_indices0)\n",
    "from baal.active import get_heuristic\n",
    "heuristic = get_heuristic('entropy')\n",
    "model = model_original\n",
    "init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "def compute_metrics(p):\n",
    "    label = p.label_ids\n",
    "    preds = np.argmax(p.predictions, axis=-1)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(label, preds),\n",
    "    }\n",
    "model = BaalTransformersTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=active_set_feminist,\n",
    "        eval_dataset=valid_set_feminist,\n",
    "        tokenizer=None,\n",
    "        compute_metrics=compute_metrics)\n",
    "active_loop_feminist = ActiveLearningLoop(active_set_feminist,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n",
    "model.train()\n",
    "unqueried_score=model.evaluate()['eval_accuracy']\n",
    "performance_history_feminist=[unqueried_score]\n",
    "for epoch in range(al_epochs):\n",
    "    model.train()\n",
    "    eval_metrics = model.evaluate()\n",
    "    should_continue = active_loop_feminist.step()\n",
    "    model.load_state_dict(init_weights)\n",
    "    model.lr_scheduler = None\n",
    "    if not should_continue:\n",
    "            break\n",
    "    active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_feminist.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_feminist),\n",
    "    }\n",
    "\n",
    "    logs = {**eval_metrics, **active_logs}\n",
    "    performance_history_feminist.append(eval_metrics['eval_accuracy'])\n",
    "print(performance_history_feminist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "713980ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# median_feminist1, min_feminist1,max_feminist1= calculate(active_mc_feminist1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c2ca83aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 43 543 357]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1116' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 03:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:32:56.613022Z [info     ] Start Predict                  dataset=594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 29.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:33:01.659203Z [info     ] Start Predict                  dataset=574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 72/72 [00:02<00:00, 31.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:33:06.252192Z [info     ] Start Predict                  dataset=554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 32.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:33:10.783868Z [info     ] Start Predict                  dataset=534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 32.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:33:15.550867Z [info     ] Start Predict                  dataset=514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:02<00:00, 30.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:33:21.613391Z [info     ] Start Predict                  dataset=494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [00:01<00:00, 32.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:33:26.884392Z [info     ] Start Predict                  dataset=474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 37.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:33:32.510406Z [info     ] Start Predict                  dataset=454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:02<00:00, 25.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:33:39.144936Z [info     ] Start Predict                  dataset=434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 34.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:33:44.917508Z [info     ] Start Predict                  dataset=414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 36.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:33:51.016561Z [info     ] Start Predict                  dataset=394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 29.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:33:57.567561Z [info     ] Start Predict                  dataset=374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 35.03it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:34:03.615616Z [info     ] Start Predict                  dataset=354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 33.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:34:09.667297Z [info     ] Start Predict                  dataset=334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 31.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:34:16.915792Z [info     ] Start Predict                  dataset=314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 37.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:34:23.282825Z [info     ] Start Predict                  dataset=294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:00<00:00, 37.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:34:29.750683Z [info     ] Start Predict                  dataset=274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:00<00:00, 38.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:34:36.577838Z [info     ] Start Predict                  dataset=254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 35.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:34:43.298372Z [info     ] Start Predict                  dataset=234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 37.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:34:50.272393Z [info     ] Start Predict                  dataset=214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 35.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:34:57.241390Z [info     ] Start Predict                  dataset=194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 32.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:35:04.852714Z [info     ] Start Predict                  dataset=174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 35.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:35:12.343747Z [info     ] Start Predict                  dataset=154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 38.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:35:19.856833Z [info     ] Start Predict                  dataset=134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 38.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:35:28.192657Z [info     ] Start Predict                  dataset=114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 37.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:35:36.298913Z [info     ] Start Predict                  dataset=94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 36.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:35:44.583961Z [info     ] Start Predict                  dataset=74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 33.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:35:52.999953Z [info     ] Start Predict                  dataset=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 38.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:36:02.623013Z [info     ] Start Predict                  dataset=34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 37.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:36:12.292157Z [info     ] Start Predict                  dataset=14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 36.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20350877192982456, 0.19649122807017544, 0.22807017543859648, 0.20701754385964913, 0.22456140350877193, 0.2596491228070175, 0.23859649122807017, 0.28421052631578947, 0.2982456140350877, 0.30526315789473685, 0.3649122807017544, 0.4421052631578947, 0.32280701754385965, 0.4982456140350877, 0.39649122807017545, 0.44912280701754387, 0.5824561403508772, 0.543859649122807, 0.6070175438596491, 0.37894736842105264, 0.519298245614035, 0.5929824561403508, 0.5157894736842106, 0.6105263157894737, 0.6105263157894737, 0.631578947368421, 0.6, 0.5333333333333333, 0.519298245614035, 0.6210526315789474, 0.6421052631578947]\n",
      "[252 477 368]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1116' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 03:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:36:15.864157Z [info     ] Start Predict                  dataset=594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 32.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:36:20.222160Z [info     ] Start Predict                  dataset=574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 72/72 [00:02<00:00, 32.51it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:36:24.815041Z [info     ] Start Predict                  dataset=554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 33.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:36:29.600042Z [info     ] Start Predict                  dataset=534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 33.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:36:34.474042Z [info     ] Start Predict                  dataset=514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 34.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:36:39.457041Z [info     ] Start Predict                  dataset=494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [00:01<00:00, 36.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:36:44.303045Z [info     ] Start Predict                  dataset=474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 35.89it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:36:49.550040Z [info     ] Start Predict                  dataset=454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 35.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:36:54.941128Z [info     ] Start Predict                  dataset=434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 34.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:37:00.529157Z [info     ] Start Predict                  dataset=414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 35.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:37:06.513157Z [info     ] Start Predict                  dataset=394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 31.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:37:12.471158Z [info     ] Start Predict                  dataset=374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 36.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:37:18.510089Z [info     ] Start Predict                  dataset=354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 35.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:37:24.639881Z [info     ] Start Predict                  dataset=334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 35.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:37:30.940774Z [info     ] Start Predict                  dataset=314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 33.03it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:37:37.540776Z [info     ] Start Predict                  dataset=294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 36.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:37:44.345413Z [info     ] Start Predict                  dataset=274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:00<00:00, 36.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:37:51.487644Z [info     ] Start Predict                  dataset=254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 36.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:37:58.519582Z [info     ] Start Predict                  dataset=234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 37.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:38:05.671581Z [info     ] Start Predict                  dataset=214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 33.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:38:13.072659Z [info     ] Start Predict                  dataset=194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 37.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:38:20.475138Z [info     ] Start Predict                  dataset=174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 36.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:38:28.055141Z [info     ] Start Predict                  dataset=154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 36.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:38:35.930645Z [info     ] Start Predict                  dataset=134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 37.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:38:43.929646Z [info     ] Start Predict                  dataset=114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 36.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:38:51.932617Z [info     ] Start Predict                  dataset=94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 37.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:39:00.287614Z [info     ] Start Predict                  dataset=74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 37.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:39:08.658730Z [info     ] Start Predict                  dataset=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 39.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:39:17.281731Z [info     ] Start Predict                  dataset=34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 42.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:39:25.883732Z [info     ] Start Predict                  dataset=14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 39.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21052631578947367, 0.21403508771929824, 0.22456140350877193, 0.20701754385964913, 0.24210526315789474, 0.2771929824561403, 0.2912280701754386, 0.29473684210526313, 0.3368421052631579, 0.3368421052631579, 0.3684210526315789, 0.43508771929824563, 0.312280701754386, 0.4105263157894737, 0.5543859649122806, 0.48771929824561405, 0.4421052631578947, 0.5017543859649123, 0.519298245614035, 0.5684210526315789, 0.3894736842105263, 0.5684210526315789, 0.4105263157894737, 0.512280701754386, 0.624561403508772, 0.5263157894736842, 0.6, 0.5649122807017544, 0.6, 0.5614035087719298, 0.6140350877192983]\n",
      "[252 477 368]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1116' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 03:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:39:29.380731Z [info     ] Start Predict                  dataset=594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 36.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:39:33.518885Z [info     ] Start Predict                  dataset=574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 72/72 [00:01<00:00, 36.73it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:39:37.774887Z [info     ] Start Predict                  dataset=554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:01<00:00, 35.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:39:42.209251Z [info     ] Start Predict                  dataset=534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 34.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:39:46.881331Z [info     ] Start Predict                  dataset=514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 35.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:39:51.677329Z [info     ] Start Predict                  dataset=494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [00:01<00:00, 35.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:39:56.711331Z [info     ] Start Predict                  dataset=474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 34.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:40:01.870332Z [info     ] Start Predict                  dataset=454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 35.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:40:07.249328Z [info     ] Start Predict                  dataset=434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 36.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:40:12.695329Z [info     ] Start Predict                  dataset=414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 34.51it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:40:18.387371Z [info     ] Start Predict                  dataset=394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 35.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:40:24.372372Z [info     ] Start Predict                  dataset=374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 36.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:40:30.389746Z [info     ] Start Predict                  dataset=354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 36.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:40:36.533832Z [info     ] Start Predict                  dataset=334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 34.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:40:42.870836Z [info     ] Start Predict                  dataset=314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 36.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:40:49.447835Z [info     ] Start Predict                  dataset=294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 35.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:40:56.278838Z [info     ] Start Predict                  dataset=274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 34.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:41:03.007837Z [info     ] Start Predict                  dataset=254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 32.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:41:10.391612Z [info     ] Start Predict                  dataset=234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 35.29it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:41:17.503620Z [info     ] Start Predict                  dataset=214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 38.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:41:24.785650Z [info     ] Start Predict                  dataset=194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 39.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:41:32.386623Z [info     ] Start Predict                  dataset=174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 35.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:41:39.965621Z [info     ] Start Predict                  dataset=154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 36.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:41:48.221662Z [info     ] Start Predict                  dataset=134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 35.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:41:56.156033Z [info     ] Start Predict                  dataset=114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 35.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:42:04.207032Z [info     ] Start Predict                  dataset=94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 35.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:42:12.621652Z [info     ] Start Predict                  dataset=74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 37.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:42:21.167653Z [info     ] Start Predict                  dataset=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 38.89it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:42:29.805678Z [info     ] Start Predict                  dataset=34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 32.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:42:38.768677Z [info     ] Start Predict                  dataset=14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 38.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21052631578947367, 0.21403508771929824, 0.22456140350877193, 0.20701754385964913, 0.24210526315789474, 0.2771929824561403, 0.2912280701754386, 0.29473684210526313, 0.3368421052631579, 0.3368421052631579, 0.3684210526315789, 0.43508771929824563, 0.312280701754386, 0.4105263157894737, 0.5543859649122806, 0.48771929824561405, 0.4421052631578947, 0.5017543859649123, 0.519298245614035, 0.5684210526315789, 0.3894736842105263, 0.5684210526315789, 0.4105263157894737, 0.512280701754386, 0.624561403508772, 0.5263157894736842, 0.6, 0.5649122807017544, 0.6, 0.5614035087719298, 0.6140350877192983]\n",
      "[252 477 368]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1116' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 03:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:42:42.178484Z [info     ] Start Predict                  dataset=594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 35.03it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:42:46.292480Z [info     ] Start Predict                  dataset=574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 72/72 [00:01<00:00, 36.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:42:50.594479Z [info     ] Start Predict                  dataset=554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:01<00:00, 36.52it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:42:54.973479Z [info     ] Start Predict                  dataset=534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 35.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:42:59.473479Z [info     ] Start Predict                  dataset=514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 34.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:43:04.335757Z [info     ] Start Predict                  dataset=494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [00:01<00:00, 35.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:43:09.429761Z [info     ] Start Predict                  dataset=474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 35.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:43:14.588757Z [info     ] Start Predict                  dataset=454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 34.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:43:20.076130Z [info     ] Start Predict                  dataset=434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 36.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:43:25.590130Z [info     ] Start Predict                  dataset=414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 34.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:43:31.167161Z [info     ] Start Predict                  dataset=394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 36.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:43:37.129159Z [info     ] Start Predict                  dataset=374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 36.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:43:43.120159Z [info     ] Start Predict                  dataset=354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 34.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:43:49.352157Z [info     ] Start Predict                  dataset=334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 35.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:43:55.721159Z [info     ] Start Predict                  dataset=314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 34.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:44:02.161159Z [info     ] Start Predict                  dataset=294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 34.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:44:09.025200Z [info     ] Start Predict                  dataset=274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:00<00:00, 36.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:44:15.878201Z [info     ] Start Predict                  dataset=254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 36.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:44:23.028986Z [info     ] Start Predict                  dataset=234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 36.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:44:30.222088Z [info     ] Start Predict                  dataset=214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 32.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:44:37.625087Z [info     ] Start Predict                  dataset=194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 38.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:44:45.116087Z [info     ] Start Predict                  dataset=174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 36.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:44:52.674090Z [info     ] Start Predict                  dataset=154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 36.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:45:00.494087Z [info     ] Start Predict                  dataset=134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 36.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:45:08.366087Z [info     ] Start Predict                  dataset=114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 38.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:45:16.497255Z [info     ] Start Predict                  dataset=94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 36.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:45:24.801254Z [info     ] Start Predict                  dataset=74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 37.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:45:33.255253Z [info     ] Start Predict                  dataset=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 35.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:45:41.869255Z [info     ] Start Predict                  dataset=34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 34.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:45:50.554281Z [info     ] Start Predict                  dataset=14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 40.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21052631578947367, 0.21403508771929824, 0.22456140350877193, 0.20701754385964913, 0.24210526315789474, 0.2771929824561403, 0.2912280701754386, 0.29473684210526313, 0.3368421052631579, 0.3368421052631579, 0.3684210526315789, 0.43508771929824563, 0.312280701754386, 0.4105263157894737, 0.5543859649122806, 0.48771929824561405, 0.4421052631578947, 0.5017543859649123, 0.519298245614035, 0.5684210526315789, 0.3894736842105263, 0.5684210526315789, 0.4105263157894737, 0.512280701754386, 0.624561403508772, 0.5263157894736842, 0.6, 0.5649122807017544, 0.6, 0.5614035087719298, 0.6140350877192983]\n",
      "[252 477 368]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1116' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 03:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:45:53.984285Z [info     ] Start Predict                  dataset=594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 34.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:45:58.143348Z [info     ] Start Predict                  dataset=574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 72/72 [00:02<00:00, 34.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:46:02.489379Z [info     ] Start Predict                  dataset=554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:01<00:00, 35.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:46:06.956348Z [info     ] Start Predict                  dataset=534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:46:11.697394Z [info     ] Start Predict                  dataset=514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 35.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:46:16.450397Z [info     ] Start Predict                  dataset=494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [00:01<00:00, 35.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:46:21.488395Z [info     ] Start Predict                  dataset=474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 36.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:46:26.714397Z [info     ] Start Predict                  dataset=454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:01<00:00, 36.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:46:32.071395Z [info     ] Start Predict                  dataset=434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 36.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:46:37.615396Z [info     ] Start Predict                  dataset=414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 35.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:46:43.336395Z [info     ] Start Predict                  dataset=394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 35.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:46:49.122808Z [info     ] Start Predict                  dataset=374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 34.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:46:55.145808Z [info     ] Start Predict                  dataset=354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 36.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:47:01.305808Z [info     ] Start Predict                  dataset=334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 35.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:47:07.685822Z [info     ] Start Predict                  dataset=314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 36.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:47:14.406820Z [info     ] Start Predict                  dataset=294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:01<00:00, 35.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:47:21.028778Z [info     ] Start Predict                  dataset=274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:00<00:00, 37.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:47:27.991779Z [info     ] Start Predict                  dataset=254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 35.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:47:34.937779Z [info     ] Start Predict                  dataset=234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 37.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:47:42.385480Z [info     ] Start Predict                  dataset=214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 33.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:47:49.722449Z [info     ] Start Predict                  dataset=194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 37.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:47:57.307480Z [info     ] Start Predict                  dataset=174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 33.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:48:04.952475Z [info     ] Start Predict                  dataset=154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 37.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:48:12.766480Z [info     ] Start Predict                  dataset=134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 36.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:48:20.759547Z [info     ] Start Predict                  dataset=114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 37.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:48:29.235202Z [info     ] Start Predict                  dataset=94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 36.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:48:37.531201Z [info     ] Start Predict                  dataset=74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 30.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:48:46.154069Z [info     ] Start Predict                  dataset=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 37.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:48:54.844069Z [info     ] Start Predict                  dataset=34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 40.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 285\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10616-MainThread] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-08-28T15:49:03.804100Z [info     ] Start Predict                  dataset=14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 40.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21052631578947367, 0.21403508771929824, 0.22456140350877193, 0.20701754385964913, 0.24210526315789474, 0.2771929824561403, 0.2912280701754386, 0.29473684210526313, 0.3368421052631579, 0.3368421052631579, 0.3684210526315789, 0.43508771929824563, 0.312280701754386, 0.4105263157894737, 0.5543859649122806, 0.48771929824561405, 0.4421052631578947, 0.5017543859649123, 0.519298245614035, 0.5684210526315789, 0.3894736842105263, 0.5684210526315789, 0.4105263157894737, 0.512280701754386, 0.624561403508772, 0.5263157894736842, 0.6, 0.5649122807017544, 0.6, 0.5614035087719298, 0.6140350877192983]\n"
     ]
    }
   ],
   "source": [
    "active_mc_feminist2 = []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "while mcrun != 5:\n",
    "    n_labeled_examples = np.unique(train_dataset_feminist['text']).size\n",
    "    training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "    print(training_indices0)\n",
    "    active_set_feminist =active_huggingface_dataset(train_dataset_feminist,tokenizer,'label','text')\n",
    "    valid_set_feminist = HuggingFaceDatasets(test_dataset_feminist,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_feminist.can_label = False\n",
    "    active_set_feminist.label(training_indices0)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_feminist,\n",
    "            eval_dataset=valid_set_feminist,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_feminist = ActiveLearningLoop(active_set_feminist,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_feminist=[unqueried_score]\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_feminist.step()\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_feminist.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_feminist),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_feminist.append(eval_metrics['eval_accuracy'])\n",
    "    print(performance_history_feminist)\n",
    "    active_mc_feminist2.append(performance_history_feminist)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9de75d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_feminist2, min_feminist2,max_feminist2= calculate(active_mc_feminist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9b1e644c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8sAAAN9CAYAAACkYuvHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAABP+AAAT/gEHlDmEAAEAAElEQVR4nOzdd3xUVfrH8c+TXqihSC/SVERcQQErtrUrWHbXjl3RteD+dF3brq597bqude1lLWBfXQuiIiIqKCqC0hGkBBIgPXN+f5w7yWSYhCRMMkn4vl+vvDJz77n3nrmZO5nnnnOeY845RERERERERKRSUqIrICIiIiIiItLUKFgWERERERERiaJgWURERERERCSKgmURERERERGRKAqWRURERERERKIoWBYRERERERGJomBZREREREREJIqCZREREREREZEoCpZFREREREREoihYFhEREREREYmiYFlEREREREQkioJlERERERERkSgKlkWkUZnZQjNzET8hM8sLlr9pZleZWa8ath8XbPd4jHUZZnarmc03s5Kg3KSI9Tua2RtmtiY4rjOzMQ3yQkWkWmY2Orj+Jie6LvVlZn8NXsNfG+l4Tf7zy8weD+o1Lk77mxzsb3Q89iciUlcKlkUkUd4BngCeBN4FlgKjgeuBBWZ2j5ll1HGffwf+D8gAJgb7/wDAzLKBN4DDgHnA08H6xVv6QpqK8A2IRNdDROJra/j8aihbclPDzPoE2y6Mf82ajsa+8SPSnKQkugIistW62Tk3OXKBmaUDJwO3AX8E+prZUc65UESxicA0IC/GPo8Lfu/lnPs5at1uQG/gU+fcnnGov4jU33Rge6Ag0RXZAvcBzwOrG+FYzeXz6wrgZmB5nPZ3CpCFbgqISIIoWBaRJsM5Vww8Ymaf4wPiw4EzgIcjyuQRO1AG6BmUiQ6UK9YBP8WtwiJSL865AmBOouuxJZxzq2mcQBmayeeXc2458QuUcc4pSBaRhFI3bBFpcpxz3wJ3B08nRK6LNWY5PA4asOB55JjoccG6J4Lip0asmxy1705mdrOZfWdmBWa23symmdmZZmbR9YwcT2dmB5jZu2aWGyzbOaJcbzO738x+MrMiM1tnZh+a2dGxXn/EuO4+ZnZQcJx8M9sQPB4d65xEPI98/bXulm1mrYMx3wuDei4ws9vMLLu6sYORdd3ca4mxLs3MLjCzqcE5KTKzH8zsejNrHaN8RVdBM+tnZk+b2XIzKzezi83s4WD9pTW8xtuDMtfV4bx0NrMHzeyXoI4/mtlfzCylute3uXNf03ozaxXs/6vgPVhgZjPN7E9mlhajfI3jOmtab2ZJZnaSmX0QvHeLzY/5v9vMtqnxxGy6rxQzO83MPjWzFcG+fgn+vn+3iGEVFmPMslV2ed3cT58tPF9ZZnaRmc0ws1XB33SJ+Wvyijq83phdV6Pep12C9+UvwfmYZ2ZXmllyLY8x2hrn82sfM3vPfP6IXDObZGYDgnJJZnZpsN9CM1tmZrdUc25jjlmOXG5mA8zs+YhzP9vMzq3m9Vf3udPezK4xs2/MbG3wehea2dtmdlZEuYXAtcHTa6PeR3/dzLn/K7AgeNo7atuFEeV6B++/j8xsafB3Xm1m75jZ4dXsu+L/mJltY2b/MrPFZlZqZndFlOtqZo+Y/5wrMrM5Zna5mSVbnD5bt+QciWwN1LIsIk3Vs/gufduZWTfn3C81lH0J6AicGjx/ImLdT8Hz/sAewM/AJ8G6ipYtMxsK/BfoAizCj6POAkbiW7b3BU6s5vh/AM4GZgX76AmEgv0eALwCtAZ+BN4EOgT7HW1mNznn/lLNfs8KzsEs/BjvHYB9gHfNbD/nXPh1hF9jrNdfK8EXqI+A3wDrgLeAZOBcYG+gvK773Mzx2gXHGAXk4rvlFgC7AlcBY81sb+dcbozNBwJfAvnAFCA72PY+4EzgXDO7wzlXJRg1H6ydGryWh6kFM+sGTMV3gV0BvIb/W14T1DWuzCe3excYFBxvCuDw75fbgMPM7CDnXEkcjpUKvAgcBWwAZuD/FjsDFwLHBH+D+bXc5RPACfi/xSfAGqAz/u91Jf7vs6KG7TdQ/Xu3E3Bo8LjivVjX82VmSfhrdC/8+/xT/PuoK/76GgXcVMvXuzm98O9Tw5/b7OC4fwd6AOfVYh8raPjPr6Pww16m4z9nhgXLRpjZEOBfwMHA58BC/GfQZfi/yem1eA2RfgPcg39vfBzsYw/gATNr65y7ZXM7MD9+exr+fRX+mxcC3YPX25fK6/sl4ABgKP5zdGbEriIfxzITeBk4BtgY7CssskfByfhcG3OAb/Hvpz7AgcBvzewy59xt1RyjE/AFPs/Gx/j3yrrgdfbCvz97AL8Ar+I/e/5KDZ899fhs3ZJzJNLyOef0ox/96KfRfvBfthwwejPlkoDioOwBEcvHBcsej7GN8x9rMfdX03ZZEfW6BEiKWNcd/4XXAadHbTc5fExgXIz9dgfWAqXA8VHrtos45n7VnKNC4PCI5QY8EKx7vy6vvxZ/l7uC7acDORHLu+GD/PDrHF1NXfts5u/dJ2r5i8HyZ4A2EcszgMeDdU9GbfPXiHo8DKTGON4nwfoDY6w7JVg3qQ7nZVKwzWtAZsTyHYBfI+oT/fpq/FvEWh/8fT8P1v0DSI9Y1w4fDDngumrehzGvqerW44NJB/wP6BJ17d0QrJtSy/PUOyi/COgUY/3uQFbE89FB+cm12HcG8FlQ/s4tOV/4QM8RBK9Rx0km6lrcTL3C78e/1vA+fRTIiFi3Bz7YDwG963CscTTc51c5MCZieTo+MaIDZgPfR76/gSFASfAaot/3jxPj8zBiuQOui6rjH4Ll+ZHvkereu/gbXg54HUiJKp8O7F2bv1Mtz3ufYNuFNZTZFRgUY/lwfOBbCvSs5u/p8DdQs2Ns/2aw/uWo99AAfPBc3WfPlny21vkc6Uc/Lf1H3bBFpElyPqlX+M53hwY+3Gn4L/tPOufudBEJxZxzy/AtvAAXVLP9O865x2Msvxj/pf1G59xzkSucc3Oo7GJe3X7vds69EbGNw7doAuwZtAxuMTPLwrfIAlzgIlpznW/R/1M8jhNxvB2BY/FZfU93zuVHHK8IGI8PRI83s5wYu1gDXOKcK42x7r7gd6xuneFlD9Synr2BI/GBwXjnXGFEPb/HtxDG06H4RE4fAf/n/Bj+8PHW4d+nJcD4WN1q68LMOuDfd2uBPzjnKlp8g/f/1fhWpr3MbKda7LJz8Ptr59yq6JXOuanOj1Ouaz0N37I6En/DIrKLfX3OV7ienzjnNkbVsdw590Fd61iDxfj3TVHEMT7FB/GGv2EQD1v6+fWcc25SxDbFVA6DGQz80Tm3MGL9t/hAzvA3H+ric+fcNVF1fB4fkLemdr01wn/D951zZZErnHPFzrkpdazTFnHOfeGc+zHG8hnA/fhenEdWs3kJcF70e9HM+uLf38XA+VHvoXn4luxNxOGzVUSiKFgWkaYs/BnlGvg4hwS/X4y10jn3Fb6L6FCLPZ3VxPrsF999EHwgEMvbMeqyCn8TIQ3f9TwehuG7iP7knJse45ivE3QNjJODg9+vRQY4EccrwLf8peBbZ6L9zzm3oZp9v4zvmnlk0IUaqOimOgqYj++iWht74wOCKc65pTHWP1XL/dRW+P3yUnBjpArnkyfNw988GrCFx9oX39L0gXNuTYxjhajs7lvd+zPSHPw1cpiZXWE1zJVeRzcCv8O3jp7gqmbGr8/5+hrfknq6mZ1ndRyXXUcfxHp/U9l9uluMdfWxpZ9fsa6HcCKxUnzrbnXr6/oaNvlMC9TlnMwIfl9mfrx9uzrWIe7MLNPMjjazG83soWAs8uNU3hAZWM2mX7nYSczCGc8/iryRFeGZava3pZ+tIhJFwbKINEnmE+C0C57GGrcaT32D369bNUmFgFb4z8xYrdzVZWwN7/fbavYZboHrVM32S6pZvj74nV79S6qT7sHvhTWUWRSnY0Hlebm0hvN9WFAm1rmpNkNu0Nr8EP7L4FkRq8LjQ/8VK7CqRo3nJWi9rC4ze32Ez8u9NZyXwUGZ6t4zdT3WMTUc6/zaHss5tx7ftXQDPsBdZGaLzOxZM/u9mdU5R4qZnQ78GX8dHBHd+kY9zpdz7ifgIiAV+CewwszmmtljZnbYlrbYR2ms63dLP79i3QgKn+sVzrlY+QrC6+v6Grb4nDjnPsSPK++Mv2G1xsy+NZ9Ece861meLmdke+JsHL+NzTJyF7yp+Kn74AUCbajav7rMs/NkT83M3aDFeF2PVln62ikgUJfgSkaZqML71FPy4uYYUvnH4Gr5bak1itRQVxlgWud9n8S00dRXafJG4aogW/Fg3ZcPLpgM/bGb7WF8WqzvfYQ8CfwHONLO/48d0noD/2/17M9vGEtfzEiSZiiW8/AOqDyrCNmkNrkFNf4Pv8QmGavJdbQ7inHvZzN7Hfxk/EJ/M6vjg51sz28v5qd82y8z2wyeWWo8ftx9rOqJ6nS/n3P1m9jJ+arr9g3qeFvy8b2aHVNPFv64a6/rd0s+vmuoZ79cQl/055/5iZg8BRwD74Vtix+O73D/pnDs1HsfZnCDZ2Cv4wP1h/BCPn4ENzrmQmZ2N/zyq7ibM5j7Lajx8jGVb+tkqIlEULItIU3VC8Pu7arqhxdMSfMKte5xz78d5vwOAa1zsuZ+bimXB7z41lOldzfJwVuZYUz2l4rMMRwsHNu86566uTQXrwjn3i5lNBI7Df5nuGtTvaefnxq2tGs+LmbUF2lazbSmQamatg1bXSNWdy/B5edY592gd6lnt36CG44WP9ZVzblwdjlWjoLX9meAHM9sBP+Z4OL6VeLNTM5nZ9vhWuiTgd865b6opWt/zRfCZ8kjwg5mNAJ7DB8+n4wOc5qKhPr+atGAc9b34ngWGv0HzPHCKmT3rnHunEaqxFz5Q/tI5d3aM9f3rud/wZ0/Mzwoza0Psz54G/WwV2RqpG7aINDnBdCUXBk9vb4RD/jf4fWwz2W91SsHPd1vH7b7Ed6scYGabjGMzs8Oo7BIfLfylblCMdQcQ+6Zs+LyMraGVdUvdH/w+lzom9orwMb5VeR8z6x5j/Uk1bFvTeTk4xjKo//ul2mOZ2WD8VGbRPsC/Xw42s1Z1PF6tBYnQ7gqebjZRmJl1xiePaodPNvffGorH7fpyzn2Oz1wNtahnE9PYnzNNjvPexd9kgap/w/DNpPo0EG1u23CSrE16Npifh/roehwTKvMF7F3NuPrjq9muvp+tW3KORFo0Bcsi0mSYWbqZnYFPfJWJn1eyznMG18PD+HF755jZn81sk3FzZrabmR1Xx/3eju9G+lczOyMYhx25zyQz29fMDqp3zasKB03b12WjIOnLY8HT+8ysfUQdu+Kn5alOOHvwZebnag5vtz2+1SfW8b7CdxkdDDwT68ugmfUxs/M32biWnHMf4bvvH4T/4jzLOTe1jvtYCLyBHw5wv5llRtRvO3zG6OqEz8s1wZfm8Haj8FPnxDIJn4DqYDO7M2g9qsLMBpvZuGqOdb6ZdYko2x3f7XyT7ppBy+oD+CRxE81s2xjH6mJmF9Xm5ouZ/cbMfmdRCaSCFr9wAqpqx5oHZTPw13xf4Hbn3L82c9hJ1PF8mdl+ZnZI9GsK/kYH1KaeTVBDfX41SWY21sz2jB5fHvT0CCfGivwb1utzMbAKH0huE/m5GCGcmGy/4DMhXJdU/E2ifvU4Js65Bfi5kjPwLecVf1Mz60/lrAjR29X3s3VLzpFIi6Y7SCKSKH+O+BKbBXQBdsFnZQ7hv2hcEZX9tkE459ab2eH4wOgmYIKZfQOsxnfh7YdPuPIC1We2jrXfRWZ2dLDNI/ig+Tt8Uqju+AypnYBbgHh0GZyIn2f1fTP7AJ9sCefcmTVu5V2Jz/48AvjZzD4kmHcW/4XwM3w26Wj3A+fgp3z50cw+w7+m3fCtPCnE7kp4Kn6e1D/gM1fPxLfOtA/KDwRWUtlCXB/3U9maXNdW5bDxwFDgKPx5+Rjf3Xk/fCvOb4BYmZ9vorIb+A9m9hXQA3+ebsGPqa4iGOM4Bp8x+GLgNDObhZ9TtTM+iOyLn1v48YhNX8BPqTQU+M7MPsFfR7vhew1MpTLRUKT/C+p0NDDHzL7GJzNrjW+N3h7/HngQKIuxfaTeQT02mtmX+C/fGfju1z3x09Xcupl9HIfPvF0CdDafTTiWPznnVtfzfO0E3AmsC+r5Kz751Sj8+3YuzasLdoN9fjVh++CTtK0Mrqs1+M+NPfGJtD7FjyMOewcoAI42syn4McXl+IzRr9V0IOdcqZm9CYwFvjazT/HjjFc75/7snPvKzN7CT/M0M/jcXY9/P3XA3zD8Yz1f53n4a/c4YPfg2K3wnz1v42cx6EVlq3BYfT5b632ORFo6Bcsikijh1lSHD+py8fOlTsXPF7q5hD1x5ZybZX4+2fPxgdFu+BbFX/FfHO4H/lOP/b4XdIW9CN/Ctie+V88KYCa+y2m8vsBeiT+fY/EBUHge5s0Gy8EX7r3xLRa/wyc/Co/rvAb/RTzWdrlmtidwM75l7jD8+fozcA9+qqZY260zs33xXZlPAnbGn/M1+FayO6nsUllf/wt+r6f6qVZq5JxbGoxnvR4f+I7BJ8a5ER+YzKtmu5/MbK+g3J748/I9cJpz7ikz2yRYDrZbHHSFPxv/JXkn/BfvVfjWsmeIer8450rM7IDgWEfgu3kvwZ/DG6nmRoxzrgSfDXssfpzurvjgPw8fcD4MTIqc47UG0/A3APbBj5/dDR9ULMYHqvc551ZuZh/hnhdpwMk1lPsrPhCsz/l6Ax807I3vtr4nkI//m94KPBQ5N21z0VCfX03U4/hEZXvhbxB1wP//+BZ4EngiMkGbc25FcDPhGvz7e098b4ul+FbYzTkr2P9B+M/GFPz75c/B+qOBy/Bdo/fFv58m49+nI+r7IoP39m74z57D8J89C/Hzu/8Df52GiJotoj6frXE4RyItltV+Bg0REdlamdlkfCC0r3NucmJrUztBQHoD8E/nXL27dG/mGAvxrTV9g27bIiINyvx0VZ/gE2DumOj6iLRkGrMsIiItTjC+8EJ8y8s9Ca6OiEidmFmKme0cY/kg/Fzy0Dg5PUS2auqGLSIiLYaZ/R8wBBgNbAM87Jz7MaGVEhGpuwz8OOmF+LwR+fheLMPw39+nUJlpXkQaiIJlERFpSQ7Ddxf/FT9O8/8SWx0RkXopwueC2B+fKK8dPgnXl/j5pP8ZOTZbRBqGxiyLiIiIiIiIRGnyY5bN7Aoze9HM5puZC7qj1FR+GzN7zMx+NbMiM/vGzM6qofzxZvalmRWa2Woze87MNpnmxMz2MbMvzGyDmc0OsodGl0kO9lXfKUpERERERESkCWjywTJ+2ov98FMfrK2poJm1w2cH/APwKH5uu8XAQ2Z2bYzyFwDP4qe3uAQ/9uNAYKqZdYso1xM/vUs+fi7LH4AXzWyXqF1eDHSjcjoBERERERERaYaafDdsM9vWOTc/eDwbaOWc61NN2ZvwgeoxzrlXIpa/hp93cpBzbkGwrAN+vrq5wAjnXFmwfDgwHXjMOXdmsOxs4G6go3Nuo5kl4ecOfcY5d2VQpjfwHX4OzXjNmSoiIiIiIiIJ0ORblsOBci2dCCyIDJQDdwCpwO8jlh0FtALuCQfKwfFm4DMM/s7M0oLF2UChc25jUCaEb+XOjtjfA8BkBcoiIiIiIiLNX4vJhm1mXYCe+G7V0T4DHLBbxLLw46kxyk/FZ1PdDvgG+BRob2Z/AZ7Gd9Ueiu8ijpkdD+wNDK5HvXsCPaIWdwB2wGc8LKjrPkVERERERKSKLGBb4A3n3PLabNBigmWge/B7afQK51yxma2malBabfmIZT2Ab5xz083sr8B1wA3Bukeccy+aWXvgTuAa59yietT7DGCT8dQiIiIiIiISd2cDD9emYEsKlrOC38XVrC+KKLO58kVRZXDO/c3M/gn0BxY755YFq24DfgHuNrNewD34VuvFwOXOuY82U+9HgXeilg0D7r3jjjvYYYcdNrN549q4cSPz5s1jwIABZGdnb34DEamg60ek/nT9iNSPrh0R7/vvv2fChAngc0/VSksKlsPdldOrWZ8JrKimfGGMspFlAHDOrQJWhZ+b2d7AqcCoYNGbwCLgCGAs8F8zG+ScW1xdpZ1zS4AlkcvMDICRI0cyatSoWJslTG5uLsnJyey1117k5OQkujoizYquH5H60/UjUj+6dkS8Nm3ahB/Wephrk0/wVQfhlt7o8b+YWQZ+HPDS2pSn5i7a4X2mAw8B9wVJwUYAOwIXO+e+BK4GVuOTjomIiIiIiEgz0mKCZefcCnxwG6spdiRgwBcRy8KPd49RfndgAzCnhkNeie+mfXXwPBx0Lwnq44L69KxF9UVERERERKQJaTHBcuBZoK+ZHR21fAJQBrwQsexVfBP8hWZW0R09mGd5b+A/zrmSWAcxs+2By4ELnHMbgsW/BL+HBGXSgQERy0VERERERKSZaPJjls3sZKB38LQTkGZmVwXP1znn7osofjNwLPCUmQ0DFuDnUz4cuD5yzmbn3OpgKqi7gMlm9hTQEbgE+BW4ppr6GD572uvOudciVn0OzAOeNLP7gEOANlQN0EVERERERKQZaPLBMn5qpX2ill0f/F4EVATLzrm1ZrYnfv7js/DB6k/Aec65f0Xv2Dl3dzCl1KX4oLkA+B9wRUS262hn41uPfxe1r1IzOwJ4ALglqNvRzrl5tX+pIiIiIiIi0hQ0+WDZOTe6juWXA6fVofwzwDN1KP8g8GA1634E9qvtvkREREREtpRzjry8PNavX09xcTE+dY5XWlpKx44dWbFiBWvWrElgLUXiy8xIT0+ndevWtG3btmJGoXhq8sGyiIiIiIjE5pzjl19+IT8/H4CkpCSSkirTEiUnJ9O+fXuSk5MTVUWRBlFeXs6GDRvYsGEDGzdupFu3bnEPmBUsi4iIiIg0U3l5eeTn55Oenk7Xrl3JyMioEjCUlZWxYcMGWrVqRUqKvvpLy+Gco6ioiOXLl5Ofn0+rVq1o27ZtXI/R0rJhi4iIiIhsNdavXw9A165dyczMbJCuqCJNkZmRmZlJ165dASp6V8STgmURERERkWaquLiYpKQkMjIyEl0VkYTIyMggKSmJ4uLiuO9bwbKIiIiISDPlnCMpKUktyrLVMjPMrEpiu3hRsCwiIiIiIiLNVkPdLFKwLCIiIiIiIhJFwbKIiIiIiIhIFAXLIiIiIiIiLYyZMW7cuERXo1lTsCwiIiIiIs1Kfn4+119/PbvssgutW7cmKyuLHXbYgcsuu4yVK1cmunpbvY8++ojzzz+fIUOG0Lp1azp16sQee+zBc889V20iri+//JKDDz6Ytm3b0rp1a0aPHs2UKVMaueZVaWZyERERERFpNubOnctBBx3EokWLOProoznjjDNITU1l2rRp3HXXXfz73//mjTfeYMSIEYmuakIVFhaSnJyckGNffvnlLF68mLFjx/LHP/6RjRs38sILL3DCCSfwwQcf8PDDD1cp/8UXX7DPPvvQuXNnrr76atLT03nooYfYf//9efvttznggAMS8joULIuIiIiISLNQUFDAEUccwbJly3j99dc57LDDKtadffbZjB8/ngMOOIAjjzySb7/9ls6dOyewtomVyLm3b775Zvbcc09SUirDzYsuuojRo0fzyCOPcPHFFzN48OCKdRdeeCFJSUlMmTKFXr16AXDKKacwePBgxo8fz48//piQ6dHUDVtERERERJqFRx99lLlz53LJJZdUCZTDhg8fzo033sjKlSu57bbbKpY//vjjmBmTJ0/eZJvRo0fTp0+fTZbPmDGDsWPH0rFjR9LT0xk0aBA33HADZWVlVcr16dOH0aNHb7L95MmTMTMef/zxKsuLi4u58cYbGTx4MBkZGbRr144jjjiCr7/+ulbnIDc3lwkTJtCvXz8yMjJo3749O+20EzfccEOVctFjlseNG1cxJ3Gsn4ULF1aUzcvL4/LLL6d///6kp6fTqVMnjj/+eObPn1+rOo4ePbpKoAyQlJTEscceC8C3335bsXz+/PlMmzaN4447riJQBmjbti1nnnkm8+bN4/PPP6/VceNNLcsiIiIiItIsvPTSSwCcddZZ1ZYZN24cF198MS+//HKVgLku3nrrLcaOHUv//v259NJLycnJ4bPPPuOaa65h5syZvPjii/Xab2lpKQcffDBTp07l5JNP5oILLiAvL49HHnmEPfbYgylTpjB8+PAa93HccccxZcoUzjnnHIYOHUphYSFz585l8uTJXHnlldVud84552zSnbmwsJBLL72U8vJyWrduDfhAeffdd2fx4sWcfvrpDB48mOXLl/PAAw8wYsQIZsyYQe/evev1+pctWwZQpcV/+vTpAOy+++6blA8vmz59OiNHjqzXMbeEgmURERERkRboxEemsXRtIaFQiKSkJBq/E2ts3dtn8syZ9Qt8Zs+eTevWrenfv3+1ZbKyshg0aBCzZ89mw4YNtGrVqk7HKCoq4rTTTmPEiBF88MEHFS2k4eB0woQJTJ48OWZr8ubce++9TJ48mbfffpuDDz64Yvn48ePZcccd+dOf/hSz9TssLy+PDz74gPHjx3PffffV6dijRo1i1KhRFc9DoRDHHHMMGzdu5JVXXqFDhw4AXH311RWtvUOHDq0oP27cOIYMGcK11167SWt5bSxbtowHH3yQbbfdlr322qvKcoAePXpssk142dKlS+t8vHhQsCwiIiIi0gItW1vIojUFia5GXOXn59OlS5fNlmvbti0A69evr3Ow/L///Y+VK1dyww03sG7duirrDj30UCZMmMC7775br2D5mWeeYcCAAQwfPpzVq1dXWXfggQfyxBNPUFhYSGZmZsztMzMzycjIYNq0aSxcuDBm9/HauuSSS5g0aRJ33303Rx11FADOOZ599ln22GMPunfvXqWO2dnZjBw5knfffbfOxyooKGDs2LFs2LCBV199ldTU1CrrANLT0zfZLjzuOlymsSlYFhERERFpgbq3z8RBk2xZrq82bdqQl5e32XJ5eXkkJSXRsWPHOh/jhx9+AHxX7+q6e//666913m9434WFhXTq1KnaMqtXr6Znz54x16WlpXH33Xdz4YUX0rdvX7bffnv2228/jjrqKA488MBa1+Ouu+7innvu4cILL+TCCy+sWL5q1SrWrFnD+++/X20dk5LqlvaqqKiIo446ihkzZvD444+zzz77VFmflZUF+LHc0QoLC6uUaWwKlkVEREREWqBnzhxJWVlZRVfk6IRLzdGOO+7IlClT+Omnn6rtir1x40Z+/PFHevfuXdGCWVMm5eiEXeF5gG+++WaGDRsWc5tu3bpVPK5u39H7De97hx124O677662PjUF0uCzfh955JG8+eabTJkyhYkTJ3L//fczZswYXn755c0Gs5MmTeLSSy/lyCOP5M4779ykfgD77rsvf/nLX2rcT20UFRUxZswY3n//fR588EFOOeWUTcp0794diN3VuqYu2o2h+V8xIiIiIiKyVTjmmGOYMmUKDz30ELfeemvMMo8//jilpaWcdNJJFctycnIAn0k62oIFC6p0Cx44cCDgWzNrM79vTk5OzP3Gyhw9cOBAli9fzn777VfnFtpIXbp04YwzzuCMM84gFApx1lln8dhjj/HRRx+x7777Vrvd9OnTOeGEE9hll1147rnnNqlDp06daNeuHXl5eVs8t3FxcTFjx47l3Xff5YEHHqi2lX7XXXcFYOrUqZuUmTp1apUyjU1TR4mIiIiISLNw5plnMnDgQO666y7eeuutTdbPmDGDK6+8kq5du3L++edXLA8HwO+9916V8s899xy//PJLlWUHHXQQnTt35tZbb91kXDH4rsHr16+vsu85c+ZUtIKCDxTvv//+TbY9+eSTWbVqVbVZujfXvbugoGCT8btJSUnsvPPOQOybAWHz58/niCOOoHPnzrz++usxuzYnJSVx4okn8tVXX/H888/H3M/KlStrrCP41z9mzBjeeecd/vnPf3LOOedUW7Zfv37stttuvPjiiyxZsqRieX5+Po8++ij9+vVLSCZsUMuyiIiIiIg0E1lZWbz22mscfPDBHH744RxzzDHsu+++pKSk8Pnnn/P000/Trl07Xn31VbbZZpuK7QYNGsQBBxzAgw8+iHOOnXfemZkzZzJx4kT69+9PaWlplWM8+eSTjBkzhu22247TTz+dAQMGsG7dOubMmcMrr7zCxIkTKxJ8XXDBBTz//PMccMABnHvuuZSUlPDUU0/FDEYvuugi/ve///HnP/+ZyZMns//++9OmTRsWL17M+++/T0ZGBh9++GG1r3/u3Lnss88+jB07lsGDB9OhQwfmzJnDAw88QLdu3WpsDT7++ONZuXIlV1xxxSY3DQDGjh1LdnY2N9xwA59++iknnHACEydOZNSoUaSlpbFo0SLeeusthg0bttls2CeeeCL//e9/OeCAA2jVqhVPP/10lfU77bQTO+20U8Xze+65h9GjR7PXXntx4YUXkpaWxoMPPsjy5ct56623auxG36Ccc/ppYj/AKMBNnTrVNTVr1qxxkyZNcmvWrEl0VUSaHV0/IvWn60cktrlz57q5c+dWu760tNStXbvWlZaWNmKtGl5eXp677rrr3M477+yys7Md4AA3ePBgt3bt2pjbLF++3B177LGudevWLjs72x188MHu+++/d/vss4/r3bv3JuW//fZbd+KJJ7pu3bq51NRU17lzZzdq1Ch33XXXbfJZ9Pjjj7uBAwe61NRU16dPH3fLLbe4999/3wHu3//+d5WypaWl7u6773bDhw93WVlZLisry/Xv39+dcMIJ7p133qnxda9evdpdfPHFbujQoa5du3YuIyPDbbvttm78+PFu8eLFVcoC7tRTT6143rt374rzFOtnwYIFFWU3btzorrvuOrfjjju6jIwM16pVK7fddtu5M888002bNq3GOtbmWNdee+0m20yfPt0deOCBrnXr1i4rK8vtvffe7sMPP9zssZzb/HXgnHNTp04NH3+Uq2VcZi4YxC1Nh5mNAqZOnTq1ylxoTUFubi4ff/wxe+21V8XYDxGpHV0/IvWn60cktnnz5gEwYMCAmOtbWoKv6pSVlXHccccxadIkbr/9diZMmJDoKkkj2tx1APDZZ5+x++67A+zunPusNvvVmGUREREREWnWUlJSeOGFFzj00EO59NJLeeCBBxJdJWkBWu7tJRERERER2WqkpaXx5ptvJroa0oKoZVlEREREREQkioJlERERERERkSgKlkVERERERESiKFgWERERERERiaJgWURERERERCSKgmURERERERGRKAqWRURERERERKIoWBYRERERERGJomBZREREREREJIqCZREREREREZEoCpZFRERERERaGDNj3Lhxia5Gs6ZgWUREREREmpX8/Hyuv/56dtllF1q3bk1WVhY77LADl112GStXrkx09STKN998Q2pqKmbG888/H7PMl19+ycEHH0zbtm1p3bo1o0ePZsqUKY1c06pSEnp0ERERERGROpg7dy4HHXQQixYt4uijj+aMM84gNTWVadOmcdddd/Hvf/+bN954gxEjRiS6qglVWFhIcnJyoqtBKBTirLPOIiMjgw0bNsQs88UXX7DPPvvQuXNnrr76atLT03nooYfYf//9efvttznggAMaudaegmUREREREWkWCgoKOOKII1i2bBmvv/46hx12WMW6s88+m/Hjx3PAAQdw5JFH8u2339K5c+cE1jaxMjIyEl0FAO677z6+++47LrvsMq699tqYZS688EKSkpKYMmUKvXr1AuCUU05h8ODBjB8/nh9//BEza8xqA+qGLSIiIiIizcSjjz7K3LlzueSSS6oEymHDhw/nxhtvZOXKldx2220Vyx9//HHMjMmTJ2+yzejRo+nTp88my2fMmMHYsWPp2LEj6enpDBo0iBtuuIGysrIq5fr06cPo0aM32X7y5MmYGY8//niV5cXFxdx4440MHjyYjIwM2rVrxxFHHMHXX39dq3OQm5vLhAkT6NevHxkZGbRv356ddtqJG264oUq56DHL48aNw8yq/Vm4cGFF2by8PC6//HL69+9Peno6nTp14vjjj2f+/Pm1qmPYkiVLuOqqq7j22msrguBo8+fPZ9q0aRx33HFVyrRt25YzzzyTefPm8fnnn9fpuPGilmUREREREWkWXnrpJQDOOuusasuMGzeOiy++mJdffrlKwFwXb731FmPHjqV///5ceuml5OTk8Nlnn3HNNdcwc+ZMXnzxxXrtt7S0lIMPPpipU6dy8sknc8EFF5CXl8cjjzzCHnvswZQpUxg+fHiN+zjuuOOYMmUK55xzDkOHDqWwsJC5c+cyefJkrrzyymq3O+ecczbpzlxYWMill15KeXk5rVu3BnygvPvuu7N48WJOP/10Bg8ezPLly3nggQcYMWIEM2bMoHfv3rV6veeffz59+vThkksu4emnn45ZZvr06QDsvvvum6wLL5s+fTojR46s1THjScGyiIiIiEhL9MSRJK9bQmsXIsmSoPF7scbWtiec+lq9Np09ezatW7emf//+1ZbJyspi0KBBzJ49mw0bNtCqVas6HaOoqIjTTjuNESNG8MEHH5CS4kOmcHA6YcIEJk+eHLM1eXPuvfdeJk+ezNtvv83BBx9csXz8+PHsuOOO/OlPf4rZ+h2Wl5fHBx98wPjx47nvvvvqdOxRo0YxatSoiuehUIhjjjmGjRs38sorr9ChQwcArr766orW3qFDh1aUHzduHEOGDOHaa6/dpLU8lhdffJE33niDTz75pOIcxrJs2TIAevToscm68LKlS5fW6jXGm4JlEREREZGWKG8JtnY+iU/xFD/5+fl06dJls+Xatm0LwPr16+scLP/vf/9j5cqV3HDDDaxbt67KukMPPZQJEybw7rvv1itYfuaZZxgwYADDhw9n9erVVdYdeOCBPPHEExQWFpKZmRlz+8zMTDIyMpg2bRoLFy6M2X28ti655BImTZrE3XffzVFHHQWAc45nn32WPfbYg+7du1epY3Z2NiNHjuTdd9/d7L7XrVvHRRddxBlnnBGzxThSQUEBAOnp6ZusC4+7DpdpbAqWRURERERaorY9cQ5CQctyAvIjxda2Z703bdOmDXl5eZstl5eXR1JSEh07dqzzMX744QfAd/Wurrv3r7/+Wuf9hvddWFhIp06dqi2zevVqevaMfY7S0tK4++67ufDCC+nbty/bb789++23H0cddRQHHnhgretx1113cc8993DhhRdy4YUXVixftWoVa9as4f3336+2jklJm097ddlll1FWVsYtt9yy2bJZWVmAH8sdrbCwsEqZxqZgWURERESkJTr1NcrLyiq6ItfUFba52HHHHZkyZQo//fRTtV2xN27cyI8//kjv3r1JTU0FqDGTcnTCLuccADfffDPDhg2LuU23bt0qHle37+j9hve9ww47cPfdd1dbn5oCafBZv4888kjefPNNpkyZwsSJE7n//vsZM2YML7/88maD2UmTJnHppZdy5JFHcuedd25SP4B9992Xv/zlLzXupzpff/01jzzyCNdffz35+fnk5+cDVLRSr1q1ioULF9K1a1fS09Pp3r07ELurdU1dtBtD879iRERERERkq3DMMccwZcoUHnroIW699daYZR5//HFKS0s56aSTKpbl5OQAPpN0tAULFlQE1QADBw4EfGtmbeb3zcnJibnfWJmjBw4cyPLly9lvv/1q1UJbnS5dunDGGWdwxhlnVMxj/Nhjj/HRRx+x7777Vrvd9OnTOeGEE9hll1147rnnNqlDp06daNeuHXl5efWe23jRokU457jqqqu46qqrNlkfbs3+7LPPGDlyJLvuuisAU6dO3aQlf+rUqQAVZRqbpo4SEREREZFm4cwzz2TgwIHcddddvPXWW5usnzFjBldeeSVdu3bl/PPPr1geDoDfe++9KuWfe+45fvnllyrLDjroIDp37sytt966ybhi8F2D169fX2Xfc+bMqWgFBd+l+P77799k25NPPplVq1ZVm6V7c927CwoKNhm/m5SUxM477wzEvhkQNn/+fI444gg6d+7M66+/HrNrc1JSEieeeCJfffUVzz//fMz9rFy5ssY6jhgxgokTJ27y88c//hGASy+9lIkTJzJo0CAA+vXrx2677caLL77IkiVLKvaTn5/Po48+Sr9+/RKSCRvUsiwiIiIiIs1EVlYWr732GgcffDCHH344xxxzDPvuuy8pKSl8/vnnPP3007Rr145XX32VbbbZpmK7QYMGccABB/Dggw/inGPnnXdm5syZTJw4kf79+1NaWlrlGE8++SRjxoxhu+224/TTT2fAgAGsW7eOOXPm8MorrzBx4sSKBF8XXHABzz//PAcccADnnnsuJSUlPPXUUzGD0Ysuuoj//e9//PnPf2by5Mnsv//+tGnThsWLF/P++++TkZHBhx9+WO3rnzt3Lvvssw9jx45l8ODBdOjQgTlz5vDAAw/QrVu3GluDjz/+eFauXMkVV1yxyU0DgLFjx5Kdnc0NN9zAp59+ygknnMDEiRMZNWoUaWlpLFq0iLfeeothw4bVmA27a9eujBkzZpPl4WRpw4cP32T9Pffcw+jRo9lrr7248MILSUtL48EHH2T58uW89dZbNXajb0gKlkVEREREpNkYNGgQs2bN4u677+aVV17h7bffZuPGjQAMHjyYTz75hHbt2m2y3VNPPcUf//hHnnnmGZ566in22msvPvzwQ8477zwWLlxYpexBBx3EF198wc0338wzzzzDqlWraN++Pf369WPChAnstNNOFWX32GMPHn/8cW688Ub+7//+j+7du3PeeecxfPhw9t9//yr7TU1N5c033+Sf//wnTz31FNdeey3gx0DvtttunHrqqTW+9p49e3L66afz4Ycf8uqrr1JUVES3bt045ZRT+POf/1yRBTyWcKv1TTfdFHP9ggULyM7Opm3btnz66afcfvvt/Oc//+G1114jJSWFHj16sOeee3LmmWfWWMf6GDFiBFOmTOHKK6/kr3/9K+Xl5QwfPpz33nuvXlnH48XCg7il6TCzUcDUqVOnVpkLrSnIzc3l448/Zq+99qoY+yEitaPrR6T+dP2IxDZv3jwABgwYEHN9WQtL8FWdsrIyjjvuOCZNmsTtt9/OhAkTEl0laUSbuw4APvvss/A0Vrs75z6rzX41ZllERERERJq1lJQUXnjhBQ499FAuvfRSHnjggURXSVqAlnt7SUREREREthppaWm8+eabia6GtCBqWRYRERERERGJomBZREREREREJIqCZREREREREZEoCpZFRERERESk2WqoGZ4ULIuIiIiINFNmRnl5OaFQKNFVEUmIUChEKBTCzOK+bwXLIiIiIiLNVKtWrXDOsWzZMkpKShqshU2kqXHOUVJSwrJly3DO0apVq7gfQ1NHiYiIiIg0Ux06dKCgoIANGzawYcMGzIykpKSKVrZQKER5eTnJyckkJamdTFoG5xyhUKji5lB6ejodOnSI+3EULIuIiIiINFOpqan07duXtWvXsn79esrKyqp0yS4vL2ft2rW0b99ewbK0GGZGamoqKSkptG7dmvbt2zdIN2wFyyIiIiIizZiZkZOTQ05OzibrcnNzmTdvHttvv33M9SJSPd1eEhEREREREYmiYFlEREREREQkioJlERERERERkSgtLlg2s23M7F9mtsTMSsxssZndbWbtqin7mJn9amZFZvaNmZ0Vo1yWmd1rZsvNbLWZPWlmmwz6MLMxZrbRzPo20MsTERERERGRRtCiEnyZWWfgc6Ab8CAwG9gROA/Y28z2cM4VBGXbAZ8A3YG7gAXAUcBDZtbNOfe3iF3fBJwG3AIUAJcDjwBHRxy7DXAf8Dfn3IKGe5UiIiIiIiLS0FpUsAxcAfQGTnDOPRdeaGZTgWeBCcDfg8WXA/2BY5xzrwTLHjaz14ArzezJiKD3OOAO59z1wf7W4oPqDOdcUVDmJmANcEfDvTwRERERERFpDC2tG/a+QCHwfNTyF4AifOtw2InAgohAOewOIBX4fcSybGB1xPM1QDKQAWBmI4GzgbOdc2Vb+BpEREREREQkwVpay3IGUOScc5ELnXMhMysEtjWzjvjX3RPf2hztM8ABu0Us+xQ4z8w+xQfjlwPfO+fWmVkq8DDwL+fc53WtsJn1BHpELd4RID8/n9zc3LruskHl5+dX+S0itafrR6T+dP2I1I+uHRGvPtdASwuWvwcGmdnOzrmZ4YVmtjPQPnjaC7Dg8dLoHTjnis1sNVUD2IuA14AZwfNlwDHB48uCfV9ZzzqfAVwba8XMmTMpKiqKtSrhZs2alegqiDRbun5E6k/Xj0j96NqRrd2cOXPqvE1LC5bvxifp+o+ZXYxP8DUYn8CrFN+9OovKYLm4mv0UBeUAcM7NM7MhwHbBPr4Pgur+wFX4MdL5ZjYeGA+0xgfXlznnCjdT50eBd6KW7Qg8tPPOO7Prrrtu9kU3pvz8fGbNmsXQoUNp06ZNoqsj0qzo+hGpP10/IvWja0fEy8jIqPM2LSpYds59ZGYn4oPjN4PFIeAx4DtgLJCPD3gB0qvZVSawImrfZfjgO9KDwDvOuYlm9nvgdnxL8RLgcfy45vGbqfOSoHwFMx/Lt2nThpycTWaoahKact1EmjpdPyL1p+tHpH507cjWrj43i1pUsAzgnHvezF7Ct862BuY65341s+lAGfATED5T0WOFMbMMoAPwcU3HMbNx+HHN2weLzgBeds49G6y/CbjXzC5wzoW2+IWJiIiIiIhIo2lxwTJUtALPDD83sy7Ab4CPgnmWC8xsKTAqxuYj8d20v6hu/2bWCfgHcKVzLjzuuQfwZUSxJfiEYx2BlfV+MSIiIiIiItLoWtrUUZswsyTgHnyX6BsiVj0L9DWzo6M2mYBvgX6hht3eCSwA7otY9gswJOL5EKCEqlNOiYiIiIiISDPQolqWzawVMB2YiA9m2wLHA8PwrcAfRhS/GTgWeMrMhgXljwIOB653zs2v5hgH4udg3i2qe/XTwGNmdhc+y/bVwLPqgi0iIiIiItL8tKhgGd+S+w1wAtAVKMB3pz7YOVcl47Rzbq2Z7QncCJyFH8f8E3Cec+5fsXZuZpnAv4C7nXNfR61+IjjmeUA2MAk/5ZSIiIiIiIg0My0qWHbOlQB/qEP55cBpdShfCPSrZp0Dbgp+REREREREpBlr8WOWRUREREREROpKwbKIiIiIiIhIFAXLIiIiIiIiIlEULIuIiIiIiIhEUbAsIiIiIiIiEkXBsoiIiIiIiEgUBcsiIiIiIiIiURQsi4iIiIiIiERRsCwiIiIiIiISRcGyiIiIiIiISBQFyyIiIiIiIiJRFCyLiIiIiIiIRFGwLCIiIiIiIhJFwbKIiIiIiIhIFAXLIiIiIiIiIlEULIuIiIiIiIhEUbAsIiIiIiIiEkXBsoiIiIiIiEgUBcsiIiIiIiIiURQsi4iIiIiIiERRsCwiIiIiIiISRcGyiIiIiIiISBQFyyIiIiIiIiJRFCyLiIiIiIiIRFGwLCIiIiIiIhJFwbKIiIiIiIhIFAXLIiIiIiIiIlEULIuIiIiIiIhEUbAsIiIiIiIiEkXBsoiIiIiIiEgUBcsiIiIiIiIiURQsi4iIiIiIiERRsCwiIiIiIiISRcGyiIiIiIiISBQFyyIiIiIiIiJRFCyLiIiIiIiIRFGwLCIiIiIiIhJFwbKIiIiIiIhIFAXLIiIiIiIiIlEULIuIiIiIiIhEUbAsIiIiIiIiEkXBsoiIiIiIiEgUBcsiIiIiIiIiURQsi4iIiIiIiERRsCwiIiIiIiISRcGyiIiIiIiISBQFyyIiIiIiIiJRFCyLiIiIiIiIRFGwLCIiIiIiIhJFwbKIiIiIiIhIFAXLIiIiIiIiIlEULIuIiIiIiIhEUbAsIiIiIiIiEkXBsoiIiIiIiEgUBcsiIiIiIiIiURQsi4iIiIiIiERRsCwiIiIiIiISRcGyiIiIiIiISBQFyyIiIiIiIiJRFCyLiIiIiIiIRFGwLCIiIiIiIhJFwbKIiIiIiIhIFAXLIiIiIiIiIlEULIuIiIiIiIhEUbAsIiIiIiIiEqXFBctm1srMrjaz2Wa2wcxWmdknZnZSjLLbmNljZvarmRWZ2TdmdlaMcllmdq+ZLTez1Wb2pJnlxCg3xsw2mlnfhnp9IiIiIiIi0vBSEl2BeDKzJOAdYCTwOHAPkA2cDDxlZgOdc9cEZdsBnwDdgbuABcBRwENm1s0597eIXd8EnAbcAhQAlwOPAEdHHLsNcB/wN+fcggZ7kSIiIiIiItLgWlSwDIwAdgfucs5dEl5oZv8C5gNnA9cEiy8H+gPHOOdeCZY9bGavAVea2ZMRQe9xwB3OueuD/a3FB9UZzrmioMxNwBrgjoZ7eSIiIiIiItIYWlo37LbB718iFzrnCoG1+FbhsBOBBRGBctgdQCrw+4hl2cDqiOdrgGQgA8DMRuID8bOdc2Vb+BpEREREREQkwVpay/J0IB+4zMwWAtOAVvhAdhC+KzVm1gXoCTwbYx+fAQ7YLWLZp8B5ZvYpUIhvlf7eObfOzFKBh4F/Oec+r2uFzawn0CNq8Y4A+fn55Obm1nWXDSo/P7/KbxGpPV0/IvWn60ekfnTtiHj1uQZaVLDsnMs1szH44PU/EavWAUc5594InncPfi+NsY9iM1tN1QD2IuA1YEbwfBlwTPD4MqA9cGU9q30GcG2sFTNnzqSoqCjWqoSbNWtWoqsg0mzp+hGpP10/IvWja0e2dnPmzKnzNi0qWA6sBb4GJgJTgXbAecB/zOwY59zbQFZQtriafRRFlME5N8/MhgDb4btofx8E1f2Bq4ATnHP5ZjYeGA+0xgfXlwVdwGvyKD4pWaQdgYd23nlndt1119q85kaTn5/PrFmzGDp0KG3atEl0dUSaFV0/IvWn60ekfnTtiHgZGRl13qZFBctBQPsZcLFz7sGI5c8CM4HHzKwPlWOX06vZVSawInJBMBZ5dlS5B4F3nHMTzez3wO34luIl+GzcyfjguVrOuSVB+cjXAUCbNm3IydlkhqomoSnXTaSp0/UjUn+6fkTqR9eObO3qc7OopSX4ugSfdOvFyIXOuWJgEtAF3zq8LFgVPVYYM8sAOhCji3ZUuXH4cc0XBIvOAF52zj3rnPuYYLqpYDorERERERERaUZaWiAXHoucGmNdeFmKc24FPhgeFaPcSMCAL6o7iJl1Av4BXOmcCwfVPajaQrwEH7h3rHXtRUREREREpEloacHy98HvcZELzaw1fq7kjcB3weJngb5mdnTUPiYAZcALNRznTmABcF/Esl+AIRHPhwAlVJ1ySkRERERERJqBFjVmGbgLOAW4KRi//Ak+U/UZQC/gT865cHrpm4FjgafMbBg++D0KOBy43jk3P9YBzOxA/BzMuznnQhGrnsaPib4L32p9NfBsVBkRERERERFpBlpUsOycW2RmQ4ErgP2Bo4FyfHKvK51zL0SUXWtmewI3AmcBbYCfgPOcc/+KtX8zywT+BdztnPs6avUTQFd85u1s/Bjpi+L24kRERERERKTRtKhgGSAYQ3x+LcsuB06rw74LgX7VrHP4pF431XZ/IiIiIiIi0jS1tDHLIiIiIiIiIltMwbKIiIiIiIhIFAXLIiIiIiIiIlEULIuIiIiIiIhEUbAsIiIiIiIiEkXBsoiIiIiIiEgUBcsiIiIiIiIiURQsi4iIiIiIiERRsCwiIiIiIiISRcGyiIiIiIiISBQFyyIiIiIiIiJRFCyLiIiIiIiIRFGwLCIiIiIiIhJFwbKIiIiIiIhIFAXLIiIiIiIiIlEULIuIiIiIiIhEUbAsIiIiIiIiEkXBsoiIiIiIiEgUBcsiIiIiIiIiURQsi4iIiIiIiERRsCwiIiIiIiISRcGyiIiIiIiISBQFyyIiIiIiIiJRFCyLiIiIiIiIRFGwLCIiIiIiIhJFwbKIiIiIiIhIFAXLIiIiIiIiIlEULIuIiIiIiIhEUbAsIiIiIiIiEkXBsoiIiIiIiEgUBcsiIiIiIiIiURQsi4iIiIiIiERRsCwiIiIiIiISRcGyiIiIiIiISBQFyyIiIiIiIiJRFCyLiIiIiIiIRFGwLCIiIiIiIhJFwbKIiIiIiIhIFAXLIiIiIiIiIlEULIuIiIiIiIhEUbAsIiIiIiIiEkXBsoiIiIiIiEgUBcsiIiIiIiIiUVISXQERERGRRHPO8Z8ZS3j+iyUM7dGOk0b2on/n1omuloiIJJCCZREREdmqrcwv4s+vfMsHc1YC8PXidTw+dSEjt83h5JF9+O3gbUhNVmc8EZGtjYJlERER2Wq9+c1yrpz0LesKSjdZN21+LtPm59KpdTrH79qT40f0omvbzATUUkREEkHBsoiIiGx18gpKufa12Uya+UvFsj4dsrjp6J1YkV/IU58t4qvF6wBYtb6Yez74ifsn/8wB23fmpJG92aNfR5KSLEG1bzqKSstZuraAFXnFOFyDHy85yejRLotu7TJIacat/QUlZSxaU8CiNQX0aJ/Jjt3bJrpKIhKDgmURERHZqnw8bxX/9+I3rMgvqlh28sjeXHHodmSl+a9GY3/Tg+9+yePpaYuZ9PUyCkvLKQ853vnuV9757lf6dszmxBG9OHZYD9plpSXqpTSK/KJSFgeB3cI1G/3jXP97eX4RruFj5E2kJBk92mfSq0M2vXOy6N0hi145WfTpmE2vnCwyUpMbv1IRnHOsLShl0ZqNFUFx+Jwtyi1g1friirLjdu+jYFmkiVKwLCIiIluFgpIybn57Dk9+tqhi2TZt0rn12KHsM7DTJuUHd2vLTUcP4YpDt+OVL5fy9OeL+WnlBgAWrN7I39/8gdve+ZEjh3bjpJG9GdqzXWO9lLhyzrFqQ3FFULd4zUYW5RawMHi8NkYX9UQrCzkWrvF1jGWbNun0zsmmV4cs+nTIqhJUx+vmRijkWJ5fxKLgBsLCNQUszt0YnMMC1heX1Wo/i3NjvwYRSTwFyyIiItLifbV4LZf+ZxYLVm+sWHbUzt247sgdaZuVWuO2bTJSGbdHX07dvQ/T5ufy9OeLeGf2CspCjuKyEC9+uZQXv1zKTj3actLI3hyxUzcy0xLbshmtrDzEL+uKWJQbbukMgrpc/1NQUl6n/aUkGT1zfGtu7w5ZdG+X2SjdootKy1mSW1BR91/yCmO2bP+aX8yv+cVMX5i7ybo2GSkVLdC9O2RFBNXZdG6dXqV7fXFZOUtyCyuC4PBxF67ZyNLcQkrKQ3Wqf1pKUkRLeDa9O2Sxfdc2dT4PItI4FCyLiIg0km+X5vH8F4vZqUdbfr9rr0RXZ6tQUhbinvfn8c/JPxEKgqp2Wan8fcyOHL5Ttzrty8wY1a8Do/p1YGV+Ec9/sYTnpi9meZ7vzv3N0jwue+kb/v7G9xw3vCcnjujFtp1axfslVauotNwHcqs3sjg33PXXtw4vXVtIWahu/aWz0pIrAso+HXxA2TsI8Lq2bRpjhmMFs4uClvHqgtn8ojK+WZrHN0vzNlmXnpJEr5ws2melsWxdYbXBeE3aZKTQu0Nlq3Y4GO/dIYttWmdorLtIM6JgWUREpIEtyS3gH+/+yKtBMqlnPgfn4A+7KWBuSD+uWM8lL8zk++X5Fcv2HdSJW47Zic5tMrZo353bZHDh/gMYP7of789ZydPTFvHxvNWAD8Ye/WQBj36ygD37d+Skkb05YPvOcQku1xWUVAmCFwZdfhflbuTX/OLN7yBKTnZa0Lpataty7w7ZdGyVhlnTDuzSU5Lp37kV/TtvelOiPORYkV/EotU+eF4U0U160ZoCNsToJl1cFmJe0NW+Jp1bp0fcQMgKguFs+sSxm7eIJJ6CZRERkQaSV1DK/ZN/4vFPF27SwnX1q7MZsE0rhvXOSVDtWq7ykOPRT+bzj3fmVpz3rLRkrj58B/6wa8+4BoApyUkcNLgLBw3uwoLVG3lm2iJe/HIpeYV+nO8nP63mk59W06VNBsfv1ovjd+tZY6AeCjlWri+uTAyVW9ldetGagor91pYZdGubWdFCHO5uHH7eOqPmLujNWXKS0b1dJt3bZbJ71DrnHLkbS4KbDpGJy/x5XldQQvf2mVVb1nN8QNwrJ6vJdbMXkYahYFlERCTOisvKeeqzRdz7wU9Vgpse7TPZtU8OE79eRmm549ynv+L1C/akS9sta+WUSktyC7j0P7OqjFUd3rs9t/9uKL07ZDfosft2zOaqw3fgTwcN4vVZv/D0tEXMCrr6rsgv4s735nLvB/P47eBt+P2uvXDOVXaXjhhDXFxWx3GwyUn0yMmsEgSHx8T2zMkkPUWBXTQzo0OrdDq0SmeXXu0TXR0RaaIULIuIiMRJKOR449vl3PbOHJbkFlYsb5uZyh/368/Jo3qTlpxEUWk5b89ewar1xZzz9Je8cPbIhE9109w553jhiyVc/8b3bAySVaUlJzHhtwM5a69tSW7EcaIZqckcN7wnxw3vyTdL1/H0tEW8NusXikpDlIUcb327gre+XVGnfbZOT6kY99orJzvI8OxbOru0yWjU1ycisrVQsCwiIhIH0+av4aa3fqhoSQQfrJ26e2/O37d/lXGM/zhuKAtWb2TOivXMWrKOqybN5rZjd2ry40ObqpXri7ji5W95f87KimXbd23Dnb8fynZdEptpeKce7bj12HZceegOvPTVUp6Ztoj5ERm5I3VqnV45/jVIpBUeP9w+K1XvDxGRRqZgWUREZAv8tHI9N789h/d+WFll+ZFDu/F/Bw2iZ07WJttkp6fw0MnDOfL+T1hXUMpLXy5lcLc2nLZH38aqdovx1rfLuXLitxVzAScZnLtPPy46YECT6n7cNiuVM/bsy+l79GHqz2v45KfVtM9KrZg+qFdOFtnp+lomItKU6FNZRESkHlauL+Ku9+bxwhdLKI+YkmdE3xyuPGx7durRrsbte3XI4r7jd+GUxz4n5ODvb/7AoG1as3v/jg1c85Yhr6CUa1+bzaQgwzhA7w5Z3PG7oU06aZqZsUf/juyhv7OISJOnYFlERKQONhaX8fDH83loynwKgrGxAP07t+KKQ7Zjv+0617q77J4DOvKXQ7fn72/+QHnIcf6zX/HaBXvGbI2WSh/PW8X/vfgNK/KLKpadNLIXfzl0e7LS9NVGRETiQ/9RREREaqGsPMSLXy7ljv/NZdX6yvlsO7ZKZ8KBA/nd8B71mkf3jD378t0v+Uz8ehlrC0o5+6kvefm8UQr6Yigph1veW8ALX1Umx9qmTTq3HjuUfQZ2SmDNRESkJdJ/YhERkRo45/hgzkpufnsO81ZuqFiemZrM2Xtvy9l7b7tFY03NjJuOHsLPqzbwzdI8fliez2UvfcO9x/9GCZ0ifPvLem77JpmVRZWB8pFDu3HdUYOrJE8TERGJFwXLIiIi1fh2aR43vPU90+ZXztmbZPD7XXtyyQED6dwmPvMjZ6Qm86+ThnHkfZ+wekMJb3yznB26tWH86P5x2X9DcM7x5GeLuOf9eeQWlDTC8QD8zYN2Walcf9SOHDG0W4MfV0REtl4KlkVERKIsyS3gH+/+yKsRyaMA9t+uM38+ZDsGbNM67sfs1i6TB04axgkPT6O03HHbOz+yfZc27Ltd57gfa0uVlIW45tXZPP/FkkY/9h7btuOOPwxjmzjdqBAREamOgmUREZFAXkEp9304jyemLqKkPFSxfEj3tvzl0O0Z1a9Dgx5/1z45/PXIwVw5cTbOwYXPf82r5+/Btp1aNehx62LNhmLOe/orpi/0re1JBnv070hSA3cZd+Vl9GA1lx69HR0UKIuISCNoUcGymf0VuLaGImXOudSI8tsANwGHAW2BucC9zrmHo/abBdwCHAukAm8BFzvncqPKjQGeAXZ0zi3Y0tcjIiKNozzk+PenC7j3g5/IKyytWN69XSaXHTyII3bqRlJS44wfPnFEb777JZ9nP1/M+qIyznpyBpPO34PWGamb37iB/bA8nzOfmMGydYUAtM5I4f4TdmHvRkiulZuby8cff6xx3CIi0mhaVLAMvAL8FGP5TsD/Aa+HF5hZO+AToDtwF7AAOAp4yMy6Oef+FrH9TcBp+IC5ALgceAQ4OmJ/bYD7gL8pUBYRaV6ue/07nvhsUcXzNhkp/HG/AZw8qjcZqcmNXp+/HjGYuSvWM2PRWn5etZFLXpjJQycPb7SAPZZ3v1vBxS/MrJgua9uO2Tx86nD6NaFWbxERkXhqUcGyc+4b4Jvo5Wb2YPDw0YjFlwP9gWOcc68Eyx42s9eAK83syYig9zjgDufc9cH+1uKD6gznXHiSx5uANcAdcX1RIiLSoP7zxZKKQDktOYlTRvXmgv36JzTDclpKEv88aReOvPdTVuQX8d4PK7nrvblM+O2gRq+Lc477P/yJf7w7t2LZXgM6ct/xu9A2K/Gt3SIiIg2l7hNCNjNBF+o/AMuA/0asOhFYEBEoh92B72r9+4hl2cDqiOdrgGQgIzjGSOBs4GznXFlcX4CIiDSYrxav5apJswEwg3+euAtXHb5Dk5iKqHPrDB46ZRhpKf5f9T0f/MR/Zy9v1DoUlZZz4fMzqwTKp+/Rl3+P21WBsoiItHgtqmW5Gr8D2gD3OOfKAcysC9ATeDZG+c8AB+wWsexT4Dwz+xQoxLdKf++cW2dmqcDDwL+cc5/XtXJm1hPoEbV4R4D8/Hxyc3M33SiB8vPzq/wWkdrT9dO0rFpfwtlPflORyOu8PXqyS5fUJvW52yMLrjpoW655048wuuSFmbRPLWNAp+wGP/bK9cVMmPgj36/YCEBKkvGX327LmJ06k5+3rsGPH03Xj0j96NoR8epzDWwNwfIZ+OD3sYhl3YPfS6MLO+eKzWw1VQPYi4DXgBnB82XAMcHjy4D2wJVbUL+YSclmzpxJUVFRrFUJN2vWrERXQaTZ0vWTeKUhuPe7ZFZv9GOAh+aEGFi2gI8/bnopJ9oCo7smMXl5EoWlIcY/O4tLh5ST3YANu4vWwyM/JpNf6s9PqxTH6YPK6JD3Ix9//GPDHbgWdP2I1I+uHdnazZkzp87btOhg2cwGAXsC70cl3coKfhdXs2lRRBmcc/PMbAiwHb6L9vdBUN0fuAo4wTmXb2bjgfFAa3xwfZlzrnAz1XwUeCdq2Y7AQzvvvDO77rrrZl9nY8rPz2fWrFkMHTqUNm3aJLo6Is2Krp+mwTnHdf/9mUUbVgHQv2Mm9580hKy0xk/kVVuj9nBc8OIPTF+Ux5pi47XVHbjn2O1JaYCEX299t4r7pv9MSbkDYECnLO48eju6tU2P+7HqQtePSP3o2hHxMjLqPu1giw6W8a224DNXRyoIflf3nz8TWBG5IBiLPDuq3IPAO865iWb2e+D24JhLgMfx45rH11RB59ySoHyF8LQYbdq0IScnp6bNE6Yp102kqdP1k1hPTF3Iq9/6QLltZiqPnjaCHh0avlvzlnrwlN048v5PWJJbyLSFeTz8+a9cedgOcdt/KOS47d0feWDyzxXLDhq8DXf8bmey05vO1wVdPyL1o2tHtnb1uVnUYhN8mVkKcAqQC0yMWr0s+B09VhgzywA6EKOLdlS5cfhxzRcEi84AXnbOPeuc+5hguikza7HnWESkufns5zVc98b3ACQZ3H/CLvRuBoEyQPvsNB46eTiZwVRWD3+8gElfL9vMVrWzobiMs5+aUSVQvnC//jxw4rAmFSiLiIg0ppYcyB0BbAM85Zyr0t3aObcCHwyPirHdSMCAL6rbsZl1Av4BXOmcCwfVPajaQrwEny27Y31fgIiIxM/StQWc/+xXlId89+K/HLo9ew5oXh/R23dtw+2/G1rx/PKXv+HbpXlbtM/Fawo4+p+f8t4PKwFIT0ni3uN/w4TfDkrovM4iIiKJ1pKD5XAX7EerWf8s0NfMjo5aPgEoA16oYd93AguA+yKW/QIMiXg+BCih6pRTIiKSAIUl5Zz95JfkbiwBYOxvunPGnn0TXKv6OXRIVy7Ytz8AxWUhzn5qBqvWV5eCo2af/byGo+7/hLm/bgCgS5sMXjp3d44Y2i1u9RUREWmuWmSwbGbdgIOB6c65b6spdjMwH3jKzG4wszPN7HV8i/RNzrn51ez7QPwczGc750IRq54GDjWzu8zsT8DVwLNRZUREpJE55/i/l2bx/XI/ZcSQ7m256eghFfkhmqMJBw5k/+06A7A8r4jxz3xJSVnd/t088/kiTn70c9YWlAIwtGc7XrtgD4b0aBv3+oqIiDRHLTJYBsbhk2tFJ/aq4Jxbi8+U/R/gLHwrcV/gPOfcNbG2MbNM4F/A3c65r6NWP4GfPupo4ApgEn7KKRERSaAHp8znjW+WA9CxVRoPnjyMjNSmm/m6NpKSjDv/sDPbBvMtf7FwLde98V2tti0tD3HNq7O5cuJsyoIu6WN/050Xzh5J5zZ1zxQqIiLSUrXIrB3OuRuBG2tRbjlwWh32Wwj0q2adwyf1uqm2+xMRkYY1+ceV3PJfP69iSpLxzxOH0a1dZoJrFR9tMlJ5+JThjLnvU9YXl/H0tMUM7taW43frVe026wpKOP/Zr/j0pzUAmMHlB2/HOXtv26xb2kVERBpCS21ZFhGRrdyC1Rv543Nf43zjKX89cjC79W1Z06b069SKu4/fmXCce82rs5mxMDdm2Z9WrmfM/Z9WBMrZack8cspwzt2nnwJlERGRGBQsi4hIi7O+qJSznpzB+qIyAI7frRcnjeyd4Fo1jP2224Y//XYQAKXljnOf/orleYVVynw4ZyVj75/KwjUFAPTKyWLi+Xuw//bbNHp9RUREmgsFyyIi0qKEQo5LXpjFTyt9hudhvdvztyMHJ7hWDWv86H4cNqQrAKs3FHPuU19SVFqOc46HpvzM6U98wfpif+Ng5LY5TDp/DwZu0zqRVRYREWnyWuSYZRER2Xrd9f483vvhV8BPhfTASbuQltKy7w2bGbcdtxM/r9rAnBXrmbU0jyte+ZYkM17+amlFuRNH9OKvRw4mNbllnw8REZF40H9LERFpMf47ewX3vD8PgLSUJB48eRidW28dGZ6z0lJ4+JThtMtKBWDi18sqAuXkJOP6owZzw9ghCpRFRERqSf8xRUSkRZj763ou/c/Miuc3jR3C0J7tElafROiZk8X9J+xCclJlwq62mak8dfpunDyqT+IqJiIi0gwpWBYRkWZvXUEJZz05g40l5QCcvkdfjhnWI8G1Sow9+nfk+qN2JC0liR27t+HV8/dg9/4dE10tERGRZkdjlkVEpFkrKw/xx+e+ZlGQ6Xn3fh34y6HbJbhWiXXCiF6M/U13MtOSE10VERGRZkstyyIi0qzd+s6PfDxvNQA92mdy3wm7kKJxuQqURUREtpC+TYiISLM16etlPDRlPgCZqck8fMpwcrLTElwrERERaQkULIuISLM0e1kel7/8TcXzfxw3lO27tklgjURERKQlUbAsIiLNzuoNxZz95AyKy0IAnL9vPw7bqWuCayUiIiItiYJlERFpVkrLQ4x/5it+ySsCYN9BnZhw4KAE10pERERaGgXLIiLSrFz3+vdMX5ALwLYds7n7+N9UmVdYREREJB4ULIuISLPx/PTFPDVtEQCt01N46JThtMlITXCtREREpCVSsCwiIs3Cl4tyufrV2QCYwV1/2Jn+nVsluFYiIiLSUilYFhGRJm9FXhHnPv0VpeUOgEsPHMj+22+T4FqJiIhIS6ZgWUREmrSi0nLOefpLVq0vBuCQHbtw/r79E1wrERERaekULIuISJPlnOOqSbOZtWQdANt1ac0/jhuKmRJ6iYiISMNKSXQFREREYiktD3H9G9/z0pdLAWiXlcpDJw8nO13/ukRERKTh6RuHiIg0OesKShj/zFdM/XkNAEkG9x2/C706ZCW4ZiIiIrK1ULAsIiJNyk8r13PGEzNYtKYAgOy0ZO7+w2/Yc0DHBNdMREREtiYKlkVEpMn4cM5KLnzua9YXlwHQKyeLR04dzsBtWie4ZiIiIrK1UbAsIiIJ55zj4Y/nc9Pbc3B+dihGbpvDP08cRk52WmIrJyIiIlslBcsiIpJQRaXlXDlxNi9/tbRi2YkjevHXIweTmqxJG0RERCQxFCyLiEjCrFxfxDlPfcnXi9cBkJxk/PWIHTh5VJ+E1ktEREREwbKIiCTE7GV5nPXkDJbnFQHQNjOVB07chd37K5GXiIiIJJ6CZRERaXRvfrOcS1+cSVFpCID+nVvxyCnD6dMxO8E1ExEREfEULIuISKMJhRx3vz+Pu9+fV7Fs30GduPv439AmIzWBNRMRERGpSsGyiIg0ioKSMi79zyzenr2iYtk5e2/LZQdvR3KSJbBmIiIiIptSsCwiIg1u2bpCznpiBt8vzwcgLTmJm44ewjHDeiS4ZiIiIiKxKVgWEZEG9eWiXM556ktWbygBoGOrdB48eRjDerdPcM1EREREqqdgWUREGsyLM5Zw5cTZlJT7RF6Du7Xh4VOG061dZoJrJiIiIlIzBcsiIhJ35SHHzW//wMMfL6hYdtiQrtx23E5kpelfj4iIiDR9+sYiIiJxlV9Uyh+f/ZqP5q6qWDbhwIH8cb/+mCmRl4iIiDQPCpZFRCRuFqzeyJlPfMHPqzYCkJmazB2/G8ohQ7omuGYiIiIidaNgWURE4uKTeas5/9mvyCssBaBb2wwePnU4g7u1TXDNREREpFG4EJQXQ3IGtIDeZAqWRURkizjnePKzRVz3xveUhxwAw3q3518nDaNT6/QE105EREQaRVkBlOSBK4GMbXzA3MwpWBYRkXorKQtx7Wvf8dz0xRXLjhvWg7+P3ZH0lOQE1kxEREQaRagMSvP8T8l6SM0G5xJdq7hQsCwiIvWSu7GE857+ks8X5AKQZPCXQ7fnjD37KpGXiIhIS+cclG2EknU+UHYOktISXau4UrAsIiJ19su6Qn7/0GcsyS0EoHV6Cvee8BtGD+qc4JqJiIhIgysvqWxNLiuA5GxIyfTBcwuiYFlEROrEOcflL39TESj37ZjNw6cMp3/nVgmumYiIiDQo56A0P+hynQ+WBGntwVrm0CsFyyIiUicvfLGEj+etBqB/51a8fO7utM1KTXCtREREpEGVF0HxOijL949TWrWIJF41UbAsIiK19su6Qv7+5g+AH6P8j+OGKlAWERFpyVwoaEnO863KSWmQ1qFFTA21OQqWRUSkVpxzXPHKt2woLgPgrL22Zeee7RJbKRERaTpC5ZDUMrvjbrXC00GV5kGoBFLbtLgkXjVRsCwiIrXy0pdL+WjuKgC27ZTNJQcOTHCNREQkYULl4Ep9ABUqhfJi/zylFaTlbBWtji1a5HRQpRsgKWOraU2OpGBZREQ269f8Iq5/43vA/5+87didyEhV64GIyFbBucqguOJ3kQ+oQiX+twv5fxDlxb58+tYXWLUI4emgwoFyKASp7SBp6wwbt85XLSIiteac4y+vfEt+ke9+ffoefRnWOyfBtRIRkQbhHLiyqsFxebH/7cqgvBQoA0sBS4WkdN+abMlBpuS1ULLG7ys9x2dLluYhVBrMmZwPZRv8dFDpWYmuVUIpWBYRkRpNmrmM9+esBKBPhyz+9NtBCa6RiIjU1ve/5Ff83jMnxo3OUHkQCJf6uXNDxRGBcvBjyZCU6oPj1MzqWxnNILU9lK6D4tVAuIVZAXOT5hyUrfeBckm+/zum5bTY6aDqQsGyiIhUa+X6Iv76WmX361uPHUpmmv55iog0B845Zr7/PL9Nm829K1LYY4eeWGSrcXkxuKjA2DkfGCelQkq2D5Dr0p3azHfbLc2rDJjTOijxV1NVXgzFa7eq6aDqQsGyiIjE5Jzj6kmzySssBeDUUX3Yra+6X4uINBefffUN5669lRTK2cdKmPxtH/bdNiMIjMuAct96aGlBd+rW8WkFNoO0dj6LcvHqYAxzRwXMTUnM6aDUbT6azoaIiMT0xjfLeee7XwHomZPJZQer+7WISLPgHK50I7Pef5YUygHYz33GPR8uwZWX+Fbj1DaQ3skHSKlBa2K8A6W0tkCSD5iLVgUBuiRcWQEU/up/SvP9eyG1jQLlGHRGRERkE6s3FHPta99VPL/lmJ3ISlNnJBGRJi1U7oOfwhVMnv0Tg9ZPq1iVQz4ZK79h8iIguYZxx/GW2sYnAysJB8yljXNc2VSoDIrXQNEKKF4FJAVd5LeeeZPrSsGyiIhs4tpXvyN3YwkAJ47oxe79Oia4RiIiUq3yYijOhcJfoHA5FK/k4U+WsXvSd1WKHZY0jfs/+bXx65fa2nf1Ll4DRasVMCdC6QYo+tX/lBb4ceWprTS912aomUBERKp4+9vlvPntcgC6t8vkikO3T3CNRERkE85BeYGfE7dso+9a68ohOQvSOjAi6X0yrGpQekjyF0zJSFBwlNrK17N4NRDyXcCT1aLZ4DQd1BZRsCwiIhVyN5Zw9auzK57ffMwQWqXrX4WISJMRKqsMjsuD35bsg+Tk9IpiF3WfA6v847yMnrQtWkIHy+eh3VcDAxJT95RswHwrOPikXxF1ljiKnA6qNB/QdFD1Ebdu2Ga2vZmNN7P7zexFM/tP8Pg8M9shXscREZGG87fXv2P1Bt/9+g+79mSvAZ0SXCMREQFidLX+1QfOqe0grX3VoNM5+HkKAKH0NnzX/feV6+b8t3HrHS0lywf2xWv8GObyosTWpyUqL65M4FWyLuht0L5RAuXpiwvY6/75TF+4rsGP1Ri2qLnAzNKB04HzgMFAdf06nJl9D/wT+LdzTleFiEgT8+53K3h15i8AdG2bwV8OU/drEZGEciEoLwxakjcEXa1DQfDTqfrxpqvnwXo/nKa0xyhWtx5MKKM9SUVrYe67cMBVkJzaiC8kSkqmjxqK1wDBtFIpmYmrT0tRZTqo9T7reSNOB+VCIda89ne6b9iNG/6byaTzu2DNfEx0vc+cmR0P/AjcB6wD/gKMBnoCWUB28Hhf4EpgbVD2x2BbERFpItYVlHDlpMru1zcePYQ2GQn8IiUisjULlfmAp3A5FPwCBcuhrDAYb9rRt87WFIT8PLniYWmvPXCWTEnf/fyCwnWweHqDVr9WkjN94q+StT4zc1lBomvUvJUVRk0H1brRp4P6YfKLHFLyLs+n/Z29lz/O5LmrGu3YDWVLzt5jwKtAP+fc3s65W5xzU5xzy5xzRc65wuDxR865m51zewP9gEnAI3Gou4iIxMl1b3zPqvXFABw7rAf7Duqc4BqJiGyFyot8a2vhMt/duni1by1Mz9m0q3VNfv7I/7YkSnuOAqCk3wGV6+e8HeeK11NyBqREBswbE12j5idUHnRpX57Q6aBcwVq6fXlnxfNPQzty13vzcM41aj3ibUuC5X7OuYuccwtru4FzbqFz7iKg/xYcV0RE4uiDOb/yylfLAOjcOp2rD1OaCRGRRuNCflqfwl+hYJlvRS7J91MtpXUMpl2qw1jTwrXwy0z/uNvOuIx2AJR1+Q1kB9MAznsPypvI9E3J6ZDa1o+tLVrlz4XUTukGP2dyE5gOavnrN9HO5QHwdNn+fOUGMmvJumbfulzvYNk598sWbLu8vtuKiEj85BWW8pdXIrpfjx1C2yx1vxYRaRSl+b6rdeFyKFzhEzOltoL0DsG43noEPfM/8QE4QL99Kpebg4G/9Y+L8mDRtC2vf7wkpflArzTPt6aXrk90jZq2UKm/sVD0qz9fluZ7HyQlaPaKJV/QbdHrAKx07bi17A8Vq+7/4KfE1ClOGq8Tu4iINDk3vPk9K/J9zsUxO3fjgB22SXCNRES2EuXFvvts8WqfvTo9B9LabXn32fkfVT7edh8I+SE2lG2E7Q6uXPdjgrNiR0tKhdT2EQFzfqJr1PQ4V3mDpehX320/LcePYU+UshJ459qKpzeGxlGa2prM1CQyU5Nol9W859KO6+0HM+sFnIOfvK0Dm2bHds65/eN5TBERqZ+P5q7iPzOWAtCxVTrXHjE4wTUSEdmKlBf6n5TWfuxuPITKYP7H/nHrrtBpIKxeEaw06DoEsjvBxlUw9z347bWQ3ISCmaSUIGBeBzgfHKa1TXStmoby4so5k8sLIKWVT5KWaJ8/DLkL/ONt9+Guk66BpJYzl3PcgmUzOwSYCKQB64HceO1bRETia31RKVe8/E3F87+P2ZH22U3oC5NIS1eSB4R819NmPrWK1INzPntxqBRS4hgMLpsJxUGLbL+9g4Vl/ldyOrgSGHQQfPW0L7fws6pdtZuCpBSfzKxkrT9PON/ivrVyIR8gl+YFY9lTfAKvRsxyXa01C2Dag/5xSgYceluLCpQhvt2wbwJWA7s559o65/rG+onj8aplZm3N7CYz+9HMisws18ymmtnYqHLbmNljZvZrUO4bMzsrxv6yzOxeM1tuZqvN7Ekzy4lRboyZbTSzRnmdIiL1ddPbc/glz3e/Pnynrhy8Y5cE10hkK1Je7AOBotVBC5psdULFvnXQ0uJ7syRWF2wL2saS0v3zQQdVlmlqXbHDLNkHzGUbfVf1isB5K1MxHdQKf4MttbVvaW8KgbJz8O5fKxPF7T0BOg5KaJUaQjy7YW8HXOWcmxHHfdaZmfUEPgRygH8D3+Pnfd4O6BVRrh3wCdAduAtYABwFPGRm3Zxzf4vY7U3AacAtQAFwOX76q6Mj9tcGP4/035xzCxrm1YmIbLlPf1rNs58vBqBDdhp/O1Ldr0UaVel6n8XWlfsgwFL8l2DZepQX+vGmyXEeaxqeXzklHXqPDI4R9BpKzoCkcuiyPbTqDBtWwrz3/ZjTlCbYs8iS/XjckrVUdsluv3X0xAiV+xtppfm+NTk5M2hNbkKvffZEWBLM1915O9j9osTWp4HEM1heDZTEcX/19RSQDQx1zi2podzl+CmsjnHOvRIse9jMXgOuNLMnI4Le44A7nHPXA5jZWnxQneGcKwrK3ASsAe6I8+sREYmbjcVlXB7R/fq6o3akQ6taztspIluuvAjK1vusLmk5UJLrgwJL8dmPpeVzDsoK/M2S2s6bXBt5y2B1kHm41wjfLbZkA1jwvkrOgORgmqpBB8GXT0Hxelj4KfTfN371iCdLCrpkrwO3BnBMXwaXvjSL24/bmd36btLRs9mZviCXS1+cWfl6Sjf4LteleRAK+defqCzX1SnIhQ9v9Y8tCQ673b/fWqB4tuE/S0RLayKY2V7APsAtzrklZpZiZtnVFD8RWBARKIfdAaQCv49Ylo2/GRC2BkgGMoLjjgTOBs52zpVt+SsREWkYt/x3DkvXFgJwyI5dOGynrgmukchWJtyqnNLKB8mpbX33yuI1UN4U2hykwZUX+Z+kON+ojOyC3S/ogp2UVpk8LCkFUrIBB4N+W1l2ztvxrUe8hQPmUDGuaDUPv/oebdZ+zw1v/YBr5l2znXM8+ep/yV77Ize8+R2ucGXTmQ6qJh/e4qcfA9jlJOi1R2Lr04DiefYfBfY2s1eBu/HdmsujCznnFsfxmNEODX7PN7NXgCOAFDNbBPzDOXcfgJl1AXriA/xonwEO2C1i2afAeWb2KVCIb5X+3jm3zsxSgYeBfznnPq9rhYNu4z2iFu8IkJ+fT25u08qTlp+fX+W3iNReoq+fLxfn8eRniwBol5nChH26N7nPGJHqJPr6iYvyYihZDWXFkJpORYe8kEH+ckgtCFqRWlaCHIlSkg/Fa/10P7YhbrttNed9wp2p13XclVDuWkhJI7/Yv8/y8/OhPA2KHaT3oG32NiRv/BU37wPWrl7ju243ZS6V736YzV15F5KdXsTjq4/mvVldGNarfaJrVm/LPn2Wu9ddRXK64+bcs3nv6zEM657ub2pYCIjf+yNeUpZ+TpvvXgOgPLszecMuhrVrE1upWqrP/494Bss/4INMAw6voVxD/gfYLvj9CD5YPyOo03jgXjNrH3Sl7h6UWxq9A+dcsZmtpmoAexHwGhAej70MOCZ4fBnQHriynnU+A7g21oqZM2dSVFQUa1XCzZo1K9FVEGm2EnH9lJTDLbOSCc/od0T3Yr7/qs7390QSruX8/1kWY9kvjV4LaRmSQ8UcsvQLAPIzevDRnHXAuiploq+dwVm/of/G/2KlG5n34YusaDescSq7BYYseZZs/Hfjce4VZn+RzseLDklwreqnS95X7Dr/HpLwreOXhR7ls/k5fLxqhwTXrHpJoRL2/eG6iuczOh/Pii9mJ7BGdTNnzpw6bxPPYPk6INF9IcLZMTYCezvnigHM7AV8oq8rzOw+fMIvgOJq9lMUUQbn3DwzG4IPxlPxrcrFZtYfuAo4wTmXb2bj8YF5a3xwfZlzrnAzdX4UeCdq2Y7AQzvvvDO77rrrZl90Y8rPz2fWrFkMHTqUNm3aJLo6Is1KIq+ff7y/kNXFywHYp397Lh47CGtKiUJENqPZ//8pL6rsal1dMq/SDT6BT1pb3z1b12jLU17os6A751uW4yR10cckz/JZiVO325+9hm3rp6VK70h+YajqtVO6HopXk9xzLLzms2HvnDyHjbueFLf6NIRZP/9C168/rrJsx2XPkdSpH132PiNBtaqflCWfkv3qP0kiVLEsiXJ2+ukevtnrAbbfvmkGzJlfPEBmyUoASvqMZsDhFzKgKWTmrqWMjLqPq45bsOyc+2u89rUFwoHps+FAGcA5V2JmzwDXACOAVcGq6vqbZAIrIhcEY5Gjb508CLzjnJtoZr8Hbse3FC8BHse3oo+vqcJBErIqicjCX2DbtGlDTk7TTFzQlOsm0tQ19vUzY2Euz33lA+U2GSnc9rtd6NCmZSbikJavWf7/cc5P/5IcgrRO1Y9BdNlQutaXS0/euueWbamKVkNKkr8ZEs+xqJ9X9hTK3OFAMlslQUp7yOwCeb4rb8W1U94KCkPQejC06Qr5y0lf9DHp2SmQ2nT/Nyyb9hKZQTvXV6H+7JLkk5ltN/MGkvptC0OOqWnzpmPJF/DGORDy3eMfKTuEdraRY5On0JoC+n16OTlDX4asJvY5t3oezHrSP07LJu3IO8jJ6ZjYOtVRfW60Np9bAbUT7la9PMa68LIcKvs+RY8VxswygA7E6KIdVW4cflzzBcGiM4CXnXPPOuc+JphuyqwZ3W4RkRanqLScy176pmJ6ymuPGExnBcoijau8AMo3+GRLNQVIZpDazmdKLsn1LYDScoTK/XsB4hsoO1eZ3CujLXTdCVyZn5YqOcaUUMlpEYm+gjmXSwtgwceblm0qyks4rOhNAIpdKhe6P3Fr6EQA34154tkwN7qjZhO0YjY8cwyUbgTgpdC+3G4ncx1nMd1tD0CX0AqYeIHPbdBUuBC8cy2EgjzG+/wJcvoltk6NJO7p1cwsGd9duT0xgnHn3JR4HzPCNOBcfPKuaOE5ln91zq0ws6XAqBjlRuIH9X1R3UHMrBPwD+BK51w4qO4BfBlRbAk+W3ZHYGVdXoSISLzc8b+5zF/t/ynvO6gTR+/SfTNbiEhcOecTOpVt9FNFbU7FVDmaUqrFqZhbOc43LFfNhfVBh8i+ewFlVbNgx5KS7efu7T8avnjcL5vzNgw8ML51i5cf3qJ9uU9ImT50DJ8cfTyUHQnvZcK0R3wQ95+T4cSXg3PQBK3+CZ4aU5lFesB+HHvknRwbvqFR+Bg8fTysXQjLvoa3/gJH3OY/ExJt1ou+TgBdhsCIC2ou34LE9eyb2eX4KZa+AT4CPozx05BeBfKBU8ysbUS9WgOnAmvx2a7BZ8Lua2bR011NAMqAF2o4zp34BGL3RSz7BRgS8XwIPs1l5JRTIiKN5qvFa3nk4/kAtE5P4cajh2icskhjK9vgf5IyfPBbG5pSqnola5tvi3tDBcs/T6583G+fymMk13CTJTnTj5nutC207VG5n9LNpdpJAOcqA3qAUef738lZsNefYGjQ/bqsGJ77PSz9cpNdJNy6JfDkUbAxGAnaewQc/o+qLf+Z7eDYB/1vgDlvwSf3NnZNN7VhFXx0u39syXDYPyAlRo+FFipuwbKZnYnvejwTn/TKgLuA24BcfCbp0+N1vFicc+uAS4AuwHQz+z8z+xMwHegKXOycC/q/cDMwH3jKzG4wszPN7HX8dFM3OefmxzqGmR2In4P5bOdcKGLV08ChZnZXcMyr8WOnQ7H2IyLSkIpKy/m/F2cRCrpfX334DnRtq9YpkUblQlCa77vepmTXbdukoKtsyVofMIe7P27Nyov8+SjJ8+e2OQmVBV2wk2p/06S2wl2wLQn67FFzF+wwS/LBclIKDDzALysthPkN2QG0nhZ9Bqt+9I+33Ru67Owfm0F6G9j/z7BDMHtsyUZ4eiz8+n1CqhrThpU+UM4POqN2Hwpj7oHUGP+T2/eCsfdBcqp//tm/YPakRqtqTB/cBMXBDapdT4OeIxNbn0YWz5blc4Fpzrl9gYeCZW865/4M7AT0oWGnjQLAOfcYcCQ+ide1wN+Cx4c5556MKLcW2BP4D3AWvpW4L3Cec+6aWPs2s0zgX8Ddzrmvo1Y/gZ8+6mjgCmASfsopEZFGd/f78/h5le9+vffAThw3fJMUDSLS0Mo2+O7XSZn160qZnOlbCEty/U9zCxDjrXSDH1tbXuDPa3PSUK3KBWth2Uz/uPtvID0juNFSi5ujyVm+3IB9KpfN+W986xcPMx6vfDxyfNUs8clZkNIG9vsTDAiC/qI8H5yu+blRqxlT4Vp4aizkBnXpvB0c/U8f5FenxzA45MbK5/+9BhZPb9h6Vmf+FN89H6BNN9j3qsTUI4HiGSxvD7wYPA5PIZUC4Jxbjg+gGyV4dM697pzb0znXyjmX7Zzb2zn3doxyy51zpznnOjvnMpxzOzrn/lXDfgudc/2cc3+Ksc45525yzvVyznVwzp3qnKv7zNciIlvom6XreGiK7xzTKj2Fm9T9WqTxhcp9d+Hywi2bIiglG0iC4lzfqhrO1re1KS/xNx9w/pyWbmxe56K8EMoaIFhe8DEVX7u3jeiCnVSL4ySnQ3I2dNgW2gXpfn6eDCUFNW7WqFb/BPODxGOdB0H/31ZdbwZprSG9LRx0jW9ZB9i4Ep48EvJizWfeSIo3wDPHwa/BZDod+sKx/4LMWuQu2OFw2POP/nGoFCZdCGsWNFxdYykpgHf/Vvn84Bshs33j1qEJiGewXA5sCB6Hb/dFvhsWAgPieDwREcF3uZ7763r+9/2vPPLxfC5+YSblQf/rKw7dju7t1P1apNGVbfDBcnLWlifoSW3ju9aWrIXSvPjUr7kJt9KnZIOlQflGHxg2B6FSn+E8KTn+yZp+/qjy8bZ71a4LdqSUbEjNquyKXVZU2a27KYgcqzziHH8OoyVnQXIrSDYYc5dvYQfIWxqME05A+qDSInj+BFga5Atu282PR261Te33Meo8GHyUf1yUBy+f63sSNJap90P+L/7xoENg+zGNd+wmJJ7ZsBcTZJx2zhWb2RJgL+D5YP2u+LHLIiJSR3kFpSzK3cjCNQUsXrORRWsKWJRbwOI1BazIj/2Fcfd+HThht14x14lIAwq3KoeKIS0O85CGp5QqyQULsmSntt7y/TYXoXIfLLty32pqyX4seNnG5pEpPNwFOynOdQ2VwYJP/OM2XSGnlw+W63JOkjODrNh7wfR/+2Vz/gvbHRLfutbHxtXw/Wv+cavOsNPxscuFW5fLN/hzcuyD8Pyp8OsPsGaez0B96huVibMaWnkpvHQ6LAhuOrTq5OvUNtZkPTUwg4Ou863jS2fAusV+SqnfPwYp6fGvd6Rff4AvnvCP01vDIbdU7f6+FYlnsDwFnxzr6uD5i8DFwTjfJOAk4LE4Hk9EpMUIhRwr1xezaM3GiiB44ZqNLM4tYNGaAvIKS+u0vy5tMrjlmJ3U/VokEcrW+5/k7Ph9wdyap5Qq2+BbZpOD7uxJqYD55aG2wfMmrKwwuHES5xscy76G4mDE37b7+GOkZNWcBTtaUrJvXe400CeXWrvYtyyXbIS0Oiali7evnvWBJ8Dwcb4FvDrJWf56K1vlr5PjHoFnT4LcBbDiW3j2ODh5UsO/plAIJo2HH/2c0GS2g2MegA7967e/lDQYe08wpdQiWPYVvH0VHH5rwwWvoXI/p7Ir989HXw7tejfMsZqBeAbLdwOzzCzDOVeET641CD9lE8C7wJ/jeDwRkWalLORYVQifzl/L2h/zfevwmgIW5/qW4uKyuiXvSUtOokdOJr1zsujdIZveHbLo3SGLXjn+cWpyE5ibUWRrEyoLMmCX1JzEpz4ip5QiGaxz7bvbNlcuFATFUcFmSmZloq+0dgmr3maVl/h6Wkr8g5sqXbD3ruyCXdebBylZkJoNA/aD6Y/7KZh+mgw7HBbP2tZNaRHMfM4/Ts2E4WfVXN7M97Yo3+jfE1k58Pt/wzMn+K7ES6b7btEn/KfhWmWdg7cuhW//45+nZcPYe2GbwVu238z2cMy/4Ok/+O7YP7zhb2yExzTH29fP+RsM4Lu073ZuwxynmYhbsOyc+xH4MeL5RuCIYL7jcufchmo3FhFp4ZbnFTL2oa9YkZ8CM+fUertW6Sn0ysmiT8fKILh3Tha9O2bTpU0GyUlqOZatRKiZzDVcmu+Du5RWDdPyEzmllCVDRic//U9LVVYQjPfNrHo+kzJ8UFS6wY/pjvdY4HgpL/Q/dWntra3w/MopGdB956CVuB7HSc6ApCzov48PlgF+fDuxwfJ3r0LhOv94p+N8N+zNScmubF125dB6Gx8wP3ui79I9fzK8dBoc9yQkN8A1895fYUbQiTYlHcbcCT2Gx2ffOX38lFL/Od23tk/9pw+Yw2Oa42X9Cvj4Lv84KQUOu71yGqutVIN/ujrnttJMFCIile54dy4r8mN/2e/YKs23DOdk0StoHQ4/z8lOU1dqEYCSYJ7PsgKq5g9tQkKlvvt1qAzS2zXccZIzfYtrSa4PkNI7Nt1gcUs454Ph8kJIi/qbm/mAOdy63BTHcDvn36+hEkhpG9995y2rnBqp1wg/OWtyRv2D8tRs2GYHH5TlLvQZqIs3QHqrOFW4DlwoIrGXwcjza7dddOtyahsfUP7+MXj2ZN8qO+dNeHU8jPkXJMXxmvn4dvj0Lv84KQUOvwX67BW//QP0HA4H3wBvXuafv321n86p567xO8Z7N/gu+AAjzoJuw+K372aqBd+KFBFpGn5etYGXv1oKQJtUx7jde7NDz470ysmmV4csWqXro1ikRuXF4IJEdqX5fgxoUxyvW5rvg7uURggwUrKhpMxPKWXJPphsaTfWyot84GOpsW8GpGRByRo/jVRDteRviVBx0AU7vQG6YE+ufLzt3v4GTXJm/cdvJ2f589l/tG9dLi+Bnz6EwUfEobJ19PNHsHahfzzwQOg4qPbbVrQur/Sty5YMHQfAcQ/DC6f5QPCbF/wQiUNvi8/fZfrD8P51/rElwSHXwcCDtny/sQw+wif6+vQ+f3Nu4h/hpOcgp++W73ve+zDvPf+4XU8Y/Zct32cLUO9bKmYWMrMyM0uLeF6+mZ+y+FVdRKR5uPN/cwlmcuLgniHGjejOwTt2ZYdubRQoi9RGeaH/8g6+i3PxmsrnTUV5ic+A7ULxn0u3Oi19SqlwYq/q5qm2pKY9jVQ4C3ZDvB8ixyv3GennTN6SG0jhRF8D969c9uN/67+/LfHFvysfjxpft4A23LqcnOVbl8O6DvGJtpKD8cpfPAwfXL/ldZ31PLz1p8rnB1wBO4zZ8v3WZPfxsENwE6MoD16Kw5RSxRvhvb9XPj/0lvjnXGimtuRb2pP4WdDLo56LiEjg+1/yeeOb5QD0aJfOyE4bN7OFiFThnG9JdsH99uTMpjleN3KscmPZZEqpFEhNQLfZhlBe7M+nWc2tpSlZTXMaqXAXbFdWGaDFS0kBLP7cP+40EFq127Iu2GHJWT4ZVU5fn0V6wcdQvN5PHdRYVnwHS4K5ibsNhT771H0fKdn+OiyOaF0G3115zN0w8Xyf8fnj231AuOfF9avrD6/7zNdh+1wMO5/Y8D0czODgv/vEZUu/9C3Nk/4Iv3vMZ8+uj0/u9uOVAXY4EgYcGr/6NnP1/g/jnBtX03MREYE7/leR95Cz9+hJcm7tk3uJCJVdWQkCpqR0SDbf/bapjNctL/JjlR3xD4w2Z5MppeqZ5KmpKQvGnSZvZqqfpjqNVHlRMLdyA7wfFn9e2bNi23184JdSjyzY0ZIzfMA8YDR8vsAnkvrpg/gnkapJxVhlYOR59bu2w63L4Z4JkePZ++0Dh98Gr//J9wJ571ofMO96et2O8fMHfi7l8PRKI8+E3c5uvKEAKWk+03Z4SqmlX8J/r4LD6jEf8vLZ8NUz/nFGWzj4pqY3pCGBWmA2CBGRpuGrxWt574eVAAzo3IpDtu+Y4BqJNEMVXVkjWkxSsoFkP163ZK1vxUuk0vVBVuYEtepGTinVFLuo11WozAc6ztXu5kPkNFJNRUUW7Ibogj258nGfUf4cxSPbtplP9DXot5XL5jRiV+z85TDnbf+4bQ/Y4Zj67yvcuhwq8kFxpO0Ogd/+rfL5mxPgm//Uft+Lp8HzJ1ZeZ7v8wbdON3aAGZ5SKiNIHvf96z5Ldl2EyuCdayrP0f5XQpse8a1nM6dgWUSkgdz+bmWr8oQDB2qaJ5G6iuzKmhTVvbCpjNctK/Stypa0aR0bU+SUUsVrfGtjc1W2IWhVrmascrSkjCDA3rhpYJQILuQD5VB5/N8TzlWOV85oC9v0D1qE4xSUh7tid9jWP1/wKRTlx2ffm/Pl05UttbudUf8uxVD92OWwocfCvpcHTxxMPBfmvLX5/S6fBc/8DkoL/PMdj4D9rvK9XBIhp49vYQ73Kvj0PvjutdpvP+MpWPmDf9xzV9jljLhXsbnb0gRfm0vopQRfIrJVmvrzaj79aQ0AO3Zvw8E7dklwjUSaoZq6sobH65YV+C7IpesbvXqAD5QbKwP25iRn+nNVkuu7qTeFwLGuXMgHN6GS2geA4Wmkwl23E628qOFalVfOgQ2/+sd9g6mJ4tEFOywpxXd9H7Cffx4q9VmSG1rxBpgVtO6mt4bfjNvyfdbUugyw6zifLAt8kP7iOD8Xc3VWzYWnjobi4ObcwP3hoL8nLlAO67krHBKRnOu/V8GSGZvfLm8ZfHqvf5ycCof9o2Hmn27mtqRl+ckYP7MBA+YBrwU/84Jls4GntqSyIiLNgXOOf7xT2ap86W8Haa5kkfrYXFfW8Hjd0vU+QCwrbNz6lRX4Y1tK0xkrm9oKSILiXKbPW8Ret3zA9AW5ia5V7YUD3qTMTbq1Tl+0gb3u+Y7pizZsul1Kln+vlG5MfLf88kIoa6As2PMjsmD33R1S4pDYK1pKFmx/SOXzH9+O7/5j+eYlKAn+rjsfD1lxmEvdzF8P1bUuA+xxAQw72T8uL4bnjq9MMBZp3WJ4agwUrPbP++4Oh91WdXhIIg0+sjLwLy+FiRf4+bKr4xz873ooDT4zR54HXXZu6Fo2S/UOlp1z45xzp4V/gKeBfsCxzrntnHNjg5/tgN8F6xQsi0iL9+GPK/lq8ToAhvduz+iBnRJbIZHmyIV8MLq5rqyJGq/rHJQ04rzKdZHaBhcq5YE3v+DA/Fd48PUpuEQHkLXhnD+f5YWbTBflnOOpt6fy2/UTufed7zd9PU1lGqnw+5ZQw9xACXfBtiTo9Zsg4V2cg+XkTOi0A3Ts758v/AwK18X3GJFCZfBlECIkpfjALV4217psBvtdAUPG+uelBfDMMbBidmWZ9b/Ck0dB/jL/vMcucORdkNrEEuntcQFsf7h/XJQHL58LhdVMKfXjO5U3XnL6wj5/bpw6NkPxHLN8PfCwc+6V6BXOuZeAR4G/b7KViEgLEgo5/vHO3IrnfzpIrcoi9VJe5L/g1qZ1bpPxuo0w6qu8AMo3+GM3lemrwsz4ZF4BN6y7nGtSn+LUVf9g8txVia7V5pUX+mA3KX2TLMiT5+Vxed71XJ36DGPXPMzkn2KMo03JCsaQJ7ArdjghXVIDtCoX5MIvs/zj7r+BtOygC3ac339m/noadIB/Hipr2K7Yc//np0EC2P4waL9t/PZtSUHrcmb17wszOOh6GHSQf16U51uR1/zsz/lTYyB3vl+3zfZw9H2NO51WbZnBITdAj2H++dpFMPFCKIu6gViUD+/fUPn80Fv8e0liimewPBT4sYb1PwRlRERarLdnr+D75f5L3F4DOjJy2w4JrpFIM1XRlbWWrTfJmT6wLsn1Pw05XjfcqlxW0CTnNXbOUfLezXQz3/16RNIc7nk3RmtsUxOe6id501blZz/8hh7mu8DulfQtd01evunrCbfklm3wY20ToSycvb0BguUFH+PnJwP6NFAX7LCULNguYq7dHxsoK7ZzVaeLGnV+/I+Rkg0pratvXQY/7vjwW6Hvnv75xlUUP3ooP/zjQFj5vV/WYdsg+3T7+NcxXlLSYMy90K6Xf750hh/DHHmtTLkTNgbdyXc6Fvr9dtP9SIV4BssbgD1rWL93UEZEpEUqD7kq8ypf+ttBCayNSDMWKg9agUJ1azVLySY8XrdBp5Qq2+gDsqQ03w28ifn247fYv+SDiufpVsr6X35k8o8rE1irzSgv8ufUkjf5m0/+KR9bVTlHfSfLY+XypdW0LidwGqlQeTAnOA3T2+DniPHKfXYLsmA3ULCclOq7Ynca4J8v/Kz6Lr1bYtlXsPwb/7jXSOi+W/yPUZvWZfDjj8fcU9Eym16wgu1DPwHg2naHY/+fvfsOs6uqGj/+3bdNr5mZ9B7SSEiBhF5CU3pTARVBQVT0tYu/90V95bWgoohiFBBpIooFUCzUJBBCQgoklPTek0mZXm45+/fHPnfumcmUe2fObTPr8zz3yb7tnD3JzOSus9de634orHJ/fm7LLzNz7ayl1J63YfVTZpxXBhd8X3oq98DNYPlp4Hql1A+UUqXRB5VSpUqpHwLXAn9z8XxCCJFRnn17D1uqzX/EF0wdzMyRpemdkBDZqq23ci8CgWS3lNKWKeoVacq8vcoAzTWMWP6DYx6eqnYyf8HGTt6QIcKNZr+o79h00PmvH2CK2tnusRM8W5j/+oFjj5PONlJ9+b7t8dgh2Pa6GRcPg7JRdvXzJG4B8OXHUpN1BDa+7P45VjwSG5/y2eQFbr4Cc+tudRnMPuRr7qeudHLbQ3t1Ocvm3gMlI5Mzt2QoH2sCf0dLqa2L/sSWJ/8fbdkJF3wHioambYrZws1g+f8BK4H/Bg4ppfYopXYDh+znVth/CiFEvxMMW9z7ivkgqhR87cKJaZ6REFks0odU1mNaSrmc1BZuMO2iPHnH7KvNCK/8kHLLrACu1WPaHj7Bt4PSXJ26AmiJsELm7xXdaTG30jwv03072j12km8rpXmdBIrpbCMVaTJp2N5OWp311Z63odVujzb2dBPUJWtVOcqbFysYBe6nYh/dAZvsDIjycTDp0u5f3xfKYy6kefPsAmxd04ECbuN/+HdkLm9EpnJD8L/50aqczN/G0NGoufDB/2u7O275nYzX5qKTHn0azLwxXTPLKq79ltda1wKnA58FngfqgHp7fCtwhtY6RV3NhRAitf68che7jpgWDJedMIzJQ4rTPCMhspQVtlNZPb1PcW7XUuqwey2l2laVj63WnBE2vmRSLgEKq5h62yOY7p1wy7jDPHRVOYRq0t9aqaNwgwlsu/g7fei68Zxfur/dY58etZuHruuiEFQ62khZIROEebzJSc13towaneQU7CjlgcopUGWvsu540xS8csvKx2lb5Tz5VtPrN5naVpebu11dXrS5jtf3+7gt9GU+GvoWW/Rw1uxt6jztP9NNuxJObV9dvEX7WXb8t9LfHzpLuHpJVGsd1lo/qLW+VGs9xb5dqrV+SGudgtKUQgiRei2hCPct2ASA16P4ygWyqixEr/VlVdkpGS2lQvUmsPPmZ96qctNRePHO2P0Pfg+KhkCpnTpavdH8nQRrzcp4prAidruoUNfBX2s91O5u/9iB9V0HPOloI9VWBTtJAWx0v7IvF0bOMt+DqajC7s2Hyc5U7JfcOW5zDbz3jBnnl8Gsj7tz3O7EubrcaXp/N49nOn36F3g1cGbb/V+Gr+JHK8i+lfI0ScpveqVUjlJquFIqQzp1CyFE8jyxbAcH6loB+NDsEYytkBYMQvRaWxVsF6oJH9NSKtL7Y1kRe1W55ZhqzRnh5e9B02Eznn4NjDvLjKOrgo2HINhq/n6DNZmTjh1ptPd/d/N3erCTZiuhJji8uev3pLqNVLgZrNbkpGDX7DZtjABGzYGc4uRU2+6MNwBTr4zdX+9SKvbqpyBkZ3zM/gQEUtSKKY7V5dI8L3l+dcyt07T/LLBoSz231t3MveGruTv0ER6IXMaaXTXZ0U4uA7j6r66Umg38FFMV2wtcACxQSlUBfwTu0lonoTqAEEKkR0NrmF8vMh9iAl4PXzz/uDTPSIgs1i6V1aXr+d4886E4eMQcN6eid8cOR1eVCzKveuz652H9f8y4aCic6ygRUzUZNr5oxtWbYNRJZnXZmwueyvR+LVqbVOlIMwQqu35dtSNYHnMGbLcLXe1dAxVdZPK0ayNVErufDJGgCfiVLzkZB+1SsE9OTQq206CJMOR42P8+7FpuLrwUVPT+eOEgvPWEGXsDMPcz7swzHsoD/iJ7T3vnrd8eum586uaTAvNf308rAe4Nf6j94ws2M29SFlT3TjPXfqKVUjOBxcB44HHnc1rrg0AeIDvJhRD9yiOvb+NIo1mh+ejJoxhemsIPMEJ0Y/m2I5z5kwUs3+biHsNkS1Yqa19bSllhCNWBFUxtkBKPxkPwkiP9+qLvQ44jAIiuLAMcXG9WPpXPrC6H0rwHM9Jkt+DK6z5oPxhrG8XsT8TG+97t/vipaiPl1taBrmxZFBuPPSV1KdhRzp7L2up7Kvb6f8f6/E67CoqH9+14ifIVxrV3ub8ozdHk+RR5fk+7W2m+JADHw82ftP8D9gCzgVzgUx2efwX4iIvnE0KItKptCvHg4q0A5Po93Davf12NFtlLh5pZ/refU3B0GD/4dw7P3nYaKtNWQzsTTWUNJKElk78YQkdNsKy8EChNYF4Zuqqstdmn3Fxj7s+8Fsac1v41VY5+79EVWn+xKXwWqrFXKZOQOhyPUINZ3csp7/510TRsfy5Mvszs2w23mJXO7jirYvuLk7fPPNxkLqT4klDYMdgEO5ebccVxUDo69RdslAeOvwIW3W3ur38eZl3fu2Np3b5d1Kmf7/v8EtW2utzQ5epyvxGq56EPD4PcSsgZlO7ZZCU3f2ucCTyktbZr/x9jJzDMxfMJIURaPfDaFupbTO3Cm04bS1VRivaQCdGDHc/cyRcafslfA99l365t2bE3LdmprL1tKWWFzF5lK2xWKjPJun/DJnt3W8lwOPsbx76maKjZ4wpwcJ35UynwFUGwDlp7sdLuhnCzvars7756tBWGQ3Z/6IpJEMiHISeY+4c2mZTerrRrI9V9u6Bei7SaFUrlT86FlB3LYvvLx55qLmykar+yU/lEGDrdjHetgIZe/k7Z8YYpNgcw7mwYfII780uUr9DcrObMqw7vlkiz+f3lLzXdAUSvuPm/US5Q283z0kdFCNFvVNe38siS7QAU5fj47NldtDARIsW01rDh3wAUqhY+5/sH9768KfMrnyY7lRXsFaXSxFpKherNzZdhhfsaDpqiXlEX/RByOpmjUrFU7MPbIGyKEeLNMYFquC496djRALanv9ejO2JzHjzV/Dn8RPNnJAQH1nb/fl+++b4KNSQnKEplCvaYNKRgR3lzHD2XdWwffKJWPBobn3pb+jI1oqvL3ly7VV0/Y4XNxahAKeQOyrzq/VnEzb+5LcCJ3Tx/HtDDbzQhhMgOv160meaQqax7y5njZO+PyBivv7uFUeGdbfev9y5gbzasLoebTAq2J8mrZh5f/C2lIkETSGors/Yqaw0vfBda7DWK2R+HUXO7fn00FVtH4JCjgrSvyA4ka8wKaapEguaDPKrnwlvO/cpDppk/hzs+bu5f0/37lcdkKySjjZTW9taBEHiSkMquday4V24JDJ+d3u/D46+KjXtTFbt6I2yzi7NVTYHxF7gzr96Kri5HmvrX6rK2zM+0v9hscUhmcbsBwM1g+UngBqWU8ztfAyilbgc+APzexfMJIURa7K1p5g/LTDBSlu/nU2eMSe+EhHB4dcG/8KjYB79cFeIzvn8yf0E3bXbSrS2VNZCalaZ4W0qF6kxQ58uwPY3v/x22LDTj0lFw1le6f72zyJezsnS60rHDDWZlubt2UVHOYDmasjt8duyxnop8gfm3TkYbKavV3jqQpO/bg+tMBgGYVWV/QXqD5bIJMGymGe9eBfUHE3v/ysdi41M+a6rTp1N/XV0O1Zrvk0BZfD9joltuBss/BZYBzwNLMIHyL5VS+4G7gJeAX7t4PiGESIv7FmwiGDEVND979niKcuWqrcgcM/S6trGlzQf4j3lfYVROnHt00yEVKdgdefPMamDwiEnJ7lgVN9JqCntp0lcAqzP1B+CVH9p3FFz8Q7OPtzsdK2I7tUvH7m43nUui6aE6Et+/t7PHcnRluXycWWmFnot8QWxlLdJoVoHdkvQUbEfLqDGn2N+zaQwwPV6Yerl9R8PGF+J/b0M1rH3OjAurYPq1rk+vV/rb6nK40Vy4CZSaDBrRZ64Fy1rrIKav8jeABqAF00ZqP3A7cKnWA6A+uxCiX9t+qJE/r9wNQGVRDp84dUx6JySEU6SVy4rtFWTlwXPKzQDkqSD3DFuQxol1Q2s7BTtJqazd8RfSZUupUJ3pAZxJlXK1hue/Da315v5JN8KI7nbA2QZNiO1z7RgsgyMduzb56djRvcreOFe8ovMtHQW5dpEipWCYvbp8ZAe01Pd8HF9erDK2G6LftzqSvIsp0RRs5YVxZ2XGVoDjrwbsVfREUrHfftLsMQeY80nwZ8DXAmZ12VfYP1aXI63mAo6/DALlmVW5P4u5uttbax3WWt+jtT5Ja12gtc7XWs/UWv9Max1281xCCJEO9768kYhlPlD/17kTyAukOY1MiCitoeVQLC21ciKc8hnItetrrnyk9xVsk8myP+B5ctLz4c5fDDpsguXoymqkxawqK0zKdqZ492+wbbEZl42BM78U3/t8ASgfa8YHNxy7gqaU3U6q1k7HTtLahrbMqrLVGl/g13gYGu3v2cFT2n9/tO1b1rD/nZ6P5cm1V7Ub3fn6Ii2x79tkaDoCe+2va9h0KKjKjGC5bGzsAs2et6B+f8/vCTXD6j+ZsT8fTvp08ubXG/1hdVlHTHZIoNTepyyfTdwipdGEECJOG/bX8/c1ewEYXprHdXNGpXlGQjiEG2HvKtN/FmD4LMgphJNusp9vgSU/T9v0uhRuMkFHOtrhQIeWUkdN1eToqrKvKD1z6kzdXljwIzNWHrjkLtN3OF7RVOzWOnOsjjwBE/iFa5NXHTvcZL5PPXnxXRipdu5XPr79c84iX/viCJbdbiMVaTI/U8n6vt36Gm2dWNuqYGdIADT1ith4Qxyp2O89G+sFPuMjUFCZjFn1nsdrgmVPTnauLmsNwRqz/zpQnlnbRvoBV4NlZVyolLpNKfVtpdR3Oty+7eb5hBAile55aUPbRecvnX8cAZ9cbxQZwoqYVdFdy2OPRYsgnfhxyLGDvpUPQ+Oh1M+vK9qye4FG0ruC29ZSqs7sXw7Vm9TXTKkiqzX851sQtFOI53wyVmgpXu32LW/o/DW+QpPKGaxJTuXoUIP594636FC7/crT2z+XaJEvaN9Gqi+0ZQfcVvK+R5z7lcefk76LSZ1JJBVbW7HCXsoDJ38uqVPrtWxeXQ7VgTdgfodl0raRfsK1Rm1KqanAM8AE2n6CjqGB73XxnBBCZKx3dtfwwvsHABhXWcDVs4aneUZCOITrTIC337ESN3yW+TOnyOxtXfIrkw655F648PtpmeYxoqmsmRAIOFtKaW0qyWaKNX+GHUvNeNB4OOO/Ej9GtH0UmBXb48499jXRdOxQnVllyxvsXn/WSLMpsKUC8R+zXduoGe2fKxoCxcOhbk/PvZajnG2kws1mH3NvRAt7JavNWSQUa7FUPBSqpmZGCnZUyQjTqmznm7B3tclUKB7W+Ws3LzK9sgEmfgAqJ3f+unTzeM3KbLjBBMyZ1le9K+EmIAKBQZn1O6sfcXNZ5H5gOPBlYDYwtpPbOBfPJ4QQKfPTFze2jb9y/kR8XllVFhki2gs40hrb41hY1f7D64k3xFaXV/zO7AXNBJHm5KayJsoTMAGzvzhWECvdanbDwp+YsfLCxXeBrxdplpVxrCyDIx3b5erY0eJaiQQh0WA5pwhKxxz7/DD7glD9gfjbGLnRRiqc5CrYe96GoL36PeZUM+dMScGOmnplbLzhxa5ft+KR2PjUDF1Vjsq21WUraOYakIJeyeTmp705wN1a6/u01qu11js6u7l4PiGESInl247w2kZTZGbK0GIumT40zTMSwiFUC8F6aG6ABpP9wPDZ7T845RabgBkg1ARv/CL18+woFamsveHxZ86eP23Bf+4w/2YAp9wCQ6d3/56uFAyK7RXtrCK2U1s6dq076diRVrNipzzxX4QIB+HINjOumtJ5sOjct7x/dXzH7WsbKSsS29earAsq7VKwz+r9CngyHX9NLENg/b87f82+92D3SjMePgtGn5WaufVWdHXZk2Mu5GUybZmLpIESEyhnysW9fsjNYPkwkEEboYQQou+01vz0hdgqzNcumIjHI1dvRYYIN5oPTErBPke/2WgKttNJn4CAvZ9txUOm2m46JTuVtT94+4+xfeiVE+HU2/p2vOi+5Zqd0NrNyqpSZoU9VOdOdexwg/le9Sawqnx4s6leDccW94pyBst749y3DH1rI5WKnuBbFpk/fbkw5ozM/BkpGgyjTjHjfe9C7Z5jX+NcVT7lc9mx8pktq8uhGpNxECjLzIsp/YibwfKfgCt6fJUQQmSRxZsOsXy7CSpmjizlvClVaZ6REDZtQbDOTm0tMm1copzFj6JyS0yxLzCFot64LzXz7EqyU1mz3dEd8OrPzNjjs9Ov+1gEzblv+dDGrl8HZgXWk2syF/qSjm2FTbCsdWIr9u2Ke03r/DXOImf7EwiWPblmVbk3baSSHSzX7IIjW8145ImQU5Z5KdhR066JjTsW+qrbG6uUXToSplyVunn1RdvqciBzV5ejBQgDpWbLiEgqN4PlO4AWpdTflFLnKKXGKqVGdby5eD4hhEgqrTU/fTH2ge0bH5iEyoYr42JgCNWbfaWeHBNM7VltHvfntQ+KnE66EQL26t6KB6H5aEqmeoxUpLJmMytip1/bH9ZP/SwMntr347bbt9xDKjaYlSsrZKpjh3sZOIQbTLq9N84K2FEH18XGg7tIPc8tgYqJZnxgXfwrgUqZ9lWJtpGywvb3rccEK8mQDSnYUVOvdKRi/6f9c6ueML1/Aebe0vcLPamUyavLkWazV9lfJgW9UsTNYDkErAOuBF4BNgPbOrkJIURWeHHtAd7ZbVZUTh03iNMnVKR5RkLYrJBZ7Yu0mg91rY1QbV/YGTIdvF3sAc4rhdn26nJrQ/pWl1ORyprNVv0edq8y46opcMqt7hx3cILBcrQ6drDOBMyJrsJqy7RpskKJ/1tHV5aVt+s0bIBhdhZFS12s6nI8etNGKpUp2AATzs3MFOyoggqTJg5w4H2zKg7md8uav5hxbjHMvikt0+s1j9e0YMq01eVolkagDHLK3atUL7rl5t/yT4CvA28B9wH/18VNCCEyXsTS3OOogP31D3SxUidEOgRrzcqyr8Der7w6FsiM6GS/stOcG8Fvr/ItfxCaa5I5085JsNy1w9tg8b1m7PGb9OuuLn4kqmx0rJJ2PMFydA7ePLuQXE1i5ws3mkJa3rzE9qtqHbv4M2hcbK99Z5z7lvetif8czjZS8RYxS3b19mBjbI96xQQoHZe5KdhRx3eSiv3OX2PVvGd+FHJLUz6tPvMVmd+vmbK6rLXZp+wvNqn53ixaqc9ybgbLNwBPa63naK2/rLW+s7Obi+cTQoik+ec7e9lwoB6AcydXceJoSXcSGSLcbNKvtY71Xt39duz5zvYrO+WVweyPmXFrPSydn5x5diUVqazZyorAf/4bwq3m/um3dZ1S3xseH1QcZ8aHNpnzxSOajh2qjT8dW2uzahtpSbxHcP0+aLH3SfeUfu78ft/3TmLn8eWbryee1WUrZFK2Pd7krejtWGZ6LAOMOzOzU7CjplwW+zle/2/z873qcXPf4zOFvbKRc+9y8Kg7VeH7IlRjfo4CZdnTA7qfcPOnPR94ycXjCSFEWoQiFj9/Kbaq/LULJ6ZxNkI4aG2vKjeYD3JRbcW9VPuiR12Z80mztxlg+f2xwCQVZFW5aysegb326uiQaXDyLe6fI1oRO9QMR3fG955oOnao3qwuxxNkR5rMqq0nJ/Hg0lncq7sUbIDB02LtoPa/l9h5PPbqXDxtpNqqtycxgG2Xgn1e4hcZ0qFgEIy1W0IdXA9vPgR1+8z9qZd13h87W/iKIGcQ+AvMv39Lde+KwvVVtGp7oNRUqRcp5WawvAyY4uLxhBAiLf62ajfbD5uiL5dMH8rxw+Q/J5EhwvXm5gnEAgQrEguwKiaYPYI9yS+DWR8145Y6WPrr5My3M+Gm5KayZqtDm+H1X5qx106/TkbxsyrHvuXqOFOxwZGOXRNfdexo8axEC3tB+xTxwV1Uwo7y58aqZR/cEGs3FS9fnv092UMbqXAzWK3J+77VOlbcK68URp6cPXtSp10dGy/+ZWzc11Zn6ebxQm4l5A2H/GFmnzAWBA+bi5a96dOdqEirCdQD5eYmRUZTzs2fwq8D1yulpH2UECJrtYYj/PKVTQB4FHzlAllVFhnCCptCS5EmU9QrqnojhOyKvj2lYDvN+aTp4wrw5m9M0JxskaCZv8eXPYFAKlhh+Pd/x1Jwz/iiufCRDJWOtG7nCm48fAVmrqHa7qtIR1pMISLl7V3AX+1sGzWj59dHi3yFW9u/Nx6eXFNduLsVw+j3rfInL1g5sBYaq814zGlmNTNbTL7U8e9s7+8dfRoMm5O2KbnKGzDpz3nDzC2nyjwWqoPWIyaYTca+Zh0xW24CpSZQz/T96/2Um/9T/RyoB55WSu1QSr2qlFrQ4faKi+cTQgjXPfnmTvbWmr1JV80awYSqbgrLCJFKoTrzwclb2D7QbNdfeWb8xysYBLOuN+OWWliWgtVlScHu3Ju/i6UQD5thLmQki3MPdLxFvpz8JXY69tGu07FDDeYCTm/3Vh6w20YVVEDx8J5f7yzytTeBIl8QXxupSLO5JfP7dqujZdSEedmRgh2VX44ed067h/Qpn+1/q6DRfcx5Q+zAeaipmm21mtXmUIN7Kdpamy0PvkKzopxIj3LhKjeD5XGAD9gJWMAoYGyH2zgXzyeEEK5qCoaZv3AzAH6v4svnH5fmGQlhi7SYYNmKHFv0Z08Cxb06mvup2Oryst+Ygl/JFG4yq3iZ3A4n1Q5ugCV2kTVfDlx0V3JXkHKKoGSEfe5eBMsen52OXWdSsjuyQmZVGWJ7ghMRbIy1IKqaEl/A1a7I17uJnzPaRqqzVGytHd+3SQxYoinYygsTLsi6zIv15ee3jTdaw1nEyWmcTZIpZX4P51bEguZAOSjsFO2avqdoh+piK9p+uWifTq79JGqtx2itx/Z0c+t8Qgjhtkff2M6hhiAA184ZycjyXuy1E8JtWtuBSX37ol5R0ZXlggooHZnYsQsqYOa1ZtxSA2/e36epdivSClZzclNZs00kZNKvox+sz/wyDErBR6Xo6nLDAWg+mvj7fQXmwk1n6djhBnurQC9XRqs30pbKO6SH4l5RFRNj7aUSLfIFsTZS4YZjqx5brXYKdk7yvm8bD8eC/OEzoGBwcs6TJFpr7tw8nm3WYMLaw4/D13Hvgi3oTGi5lGzRgDbfDppzBptV4FB971O0w81AxBw3UJqMWYsEZNdlKyGESJLa5hAPvLoVgByfh/86V1aVRYYIN5pgWXmPXamr3x+rPDt8Vu8+zM+9OdZ7d+l8aI2jjU5vSAr2sZY9CAftlOMRJ8KJN6TmvJWOIl+J7luO8hebtFNnOrYVsdtFhXqfRpxIca8ojxeG2f3FD28zlb4T1VUbqVR8325bTNsFgvHnZN3PyKIN1SzbG+LS4A85tfU+XrFOZM2uGhZtrE731FJHeewU7cH2avMQCBSZjITgITtFO44q8lbIVGcPlNmr1RKqpZv8CwghBPC7xVupbTarO584dTSDi7Prw4rop9pW7xq7WFXuQwp2VGElzPiIGTcfheUP9O443dHariYcSm4qaxZ5b/Uqwkt+Y+748+CiH6SugM9gZ7Dci1RscKRj18bSsSON9qpyH4pTOYP3ISfE/75osKwjvVtd7qyNVDQFW4eTu2d0i2O/8sQPZF2AFN2+1Ege1ZTFHl+wOV1TSp/OUrRzKszjrUfsFO1g5+/Vlvl58hebQDkZ1fBFwnr906iUel0pdW4v3neuUur13p5XCCHcdrihld+9vg2AgoCXz52TpCq0QiQqbKdfe/PNynJH7YLlmb0/z9xbTDohmNXlYA9tdBLVlsoakBRsQIdaKXzlDnyYlSZ91lehbHTqJlDpQrAMdjq2/QE/1GC+VyMtfStOFW1n5Q1AxeTuX+vkLPK1L8EiX1Ed20hFWuzeykkMlCMh2GZ/LC4ZDlXTk3euJCnN95Pn9xxzK83vxZ71/sTjN2nUeUPt2xBTIyLcAK2HzQVEZ4p2qMZkOOSU934bg3BdXy5Z7AFeVkq9BzwG/EdrvbazFyqlpgIXAzcA04Cn+nBeIYRw1f2vbqExaD603nzGWMoLBvh/8CIzRIJ2Ua8gBAZ1/prd9n5lXw4Mntr7cxVVmdXlt56ApsOw/EE44yu9P15HbamsUgeA+v1U/+P7jInsAGBpZCotRZcwL5VzKBlu9vgGGxJvtdSRvxhCR82FkEizKd7W2wsiVgSqTes+KifGtgfEo69FvsDMPdxgZ3IUx6pg+5JYYGn3W+bfAWDc2VkZJD10Yz9pEZUsymOKdPkLY4XkotXXgw12wUNtLoj6S833nsgYvV5Z1lpfC5wO7AV+AryrlKpVSq2220QttMe1wLvAj4DdwOla64+6MXkhhOirg/UtPL7UfGgtyfNzy1lStF9kiFAtBOvBV9R58BFsjK0KDpkWWxnurZNvAa/fjN+4D4Ld9NFNRKpSWTNd81FY+BP0gx+gao/ppNmoc/hG+Fbufe1gaoshKRUr8nVoi7kw01seH3gLYsW+fH24IFKzM9YzPNGLPyUjoaDSjPe/37vzt2sj1WACZSvSu6re8XK2jDou+6pgiwR5cyFnUIcUbY/ZPuAvM6vKIqP06SdSa71Ua/1BYALwP8DrQClwMjAHKAFeA24HJmitL9FaL+vTjIUQwkXPv7ef1rDpi3jrWeMozvWneUZC4CjqpboOMPe9FysY09v9yk5Fg+GED5tx02FY8du+HxNSk8qayYKN8MZv4IELYcUjKDsw3a/L+HzoS+zWVazZ28SizXWpnVeVneJsheDw1r4dy2dvE/B1sV0gXs79ylVxVsKOUgqG2T8HtXugqRdVvsGs7EZa7EJlSe6tDLBlkX3eXOjQq1j0Yx4fBEpMwJxvFwTLHSQXSzKQK/8iWuttWusf28HwGK11gda60G4XdZnW+mda6+1unEsIIdz00toDbeOrZw9P40yEsGkLgnWxVNCuRFtGgamE7YaTb4kVlXnjl+6sLkdTWbOswm+fRYLw1h/gwQ/A679sS7VtUAXcFbqec1rvYZE1s+3l818/0MWBkqRyUmzcl33LUf7ivhX2gth+ZYChCRT3imq3b3l17+agvKaNVKQZwkmugn10Jxwx9TIYcyrklCbvXCIzKY/5uckZZPY4i4wjly+EEANWfUuIZVsPA3D8sGKGlmTfXjHRD4XqTWEvT273q3RuFfdyKh4KJ1xjxo2HYOXv+nY8bZmgP9mprJnEisD7/4CHLoaXv29W6cGsHJ76Of5nxOM87rkC5c8jz6fMza8ozUtx5dsqR/Gs3raPctsBR7A8ZEbi728XLPdy3zLYbaQaASupAcyOlS/G7kw4X1YVhchArv9mVkqNBc4DBgN/0FpvV0oFgCHAfq11HzbGCCGEexZvOkQoYvYJnj9lcJpnIwQmJTZUC5HWrot6gQlC96424/JxkFfW9WsTdcqt8M7fwArDkl/AnFtMa6PeiLSYStgDYVVZa5NSu/heqN4Ye9zjg5nXwlnfhNLR/LLt9RY07TGtZHK6+bdOlorj7L2SVvsV3XSKFhsrGQ55vdi7OcyRYbG/D8GyJ2BW+1TyLmBorTny7stEa6Dr4z6I1IkXIvO4eglLKfVjYCPwIPB/QLRSTi6wFrjNzfMJIURfvOxIwZZgWWSEYK3Zq+wr6L6i8KHN0Fpvxm6lYEcVD4PpV5txYzWseqT3x4o0m/YofWkllA12rYQnPw5P39Y+UJ5yKXx2MVz+ayjt0BpKecxFBG21bx+TKv5cKB9rxgfXp2cOTs01UL/fjKum9K6idsEgKBtjxvvX9u1r8uYldVV58bp9TA2ZQmTvW6NZVN1JH3UhRNq5FiwrpT4DfAOYD1wIsQtkWus64B/AZW6dTwgh+iIcsVi44SAAg4tzmDZcWjWINAs3m/Rr6Dm43O3YrzzCheJeHZ1ya2zv8uv3Qqgl8WNYETuVVceO1d8cXA9//Qz88Yb2e8jHnQ23vAgfeQKquqnq7AmYCuRWmpLuovuWm2ug4WB65hDlTAUfnGBxL6doka+mI1C3t29zShKtNcsX/pscFQbgZWs2976yObUV0YUQcXFzZfk24Gmt9ZeBtzt5/h1gUiePCyFEyr21s4ajTSEAzpsyGNXbvqBCuEFre1W5AXxxXLjZ69yv7PLKMpg02GlXmnHDAXjr0cSP0dZbuR+uKh/dCc99Ax69Gra+Fnt8+Cy44a9ww99hxMk9r456AuZmhZI7364Mdu5bTnMq9sF1sfHg6b0/jnPfcnSrQoZZtLmOqXWL2+4/H5nLml01LNpYncZZCSE642awPBF4qZvnq4EKF88nhBC99sq6WAr2BZKCLdItXG9unkB8q7DR4l55ZbG0U7ed8pn2q8vh1sTe3xYs96P9yg0H4aX/g99dAuv+CdgrgRXHwYcfhptfgfEXxJ9C7AmYVN90lXOpzKBgudqxstybSthRzmC5L/uWk+i3i3dyjmcNANutwazTowCYv2BzOqclhOiEm3lRLUBhN8+PBmpcPJ8QQvTaS3awnOf3cur4NBTXESLKCptWUZGm7ot6RTVUQ80uMx4+q3d7O+NROgKOvxzefRrq98Fbj8HcW+N7rxU2Xw+evvXdzRQtdbD8YVj1OISaY4+XDIezvw4nfBx8vaj27fGaque6xmQXpDrDpcrl9lF9EU3DDhRC+fjeH2foCbHCZX2piJ1EZ7CafGUuPr3MXPL85mekNH+AVIwXIou4ubK8HLiqsyeUUnnAJ4AlLp6vU0op3c2ttMNrByulHlZKHVBKtSil3lFKfbqTY+Yrpe5TSu1TSh1SSj2ulDqmTKNS6kqlVKNdEVwIkaG2VjewtboRgDOPqyDX3w8+zIvsFao1e5W9hfG1jtmT5BRsp1M/Gwt2X/95/KvL/WVVOdQCb/4OHrwQlj0QC5Tzy+GC78LnV8DsT/UuUI7yBszfsU5DKnZBpflaoP3KbqpFgqZoHZgAvi973AMFsX3iB9aboDnD3Fb5Ttv4lltuY933LmLd9y7ioRtPSuOshBCdcXNl+W7gBaXUE8Cj9mPDlVKXAN8FhgPXu3i+7izGVOTuqDE6sAPn1zHzuhfYBlwBPKiUGqa1vtPxvruATwI/BpqAbwIPAVc7jlcM/Aq4U2u9zcWvRQjhslfWxQrZnD9VUrBFGkVaTF9lKwI5ce7tdRaSGp6E4l5OpSPN6vJ7z5hiSW//3rSS6kmkGcIt6WmJ1EfLdzRw+7NbeWT6Gsauf6h94atAoSl+dup/9a61UWc8AfDkmH3Lqe5FrZTpt7z9DTiyHYJNEMhP7RwADm+L7dvuriBavIbNggPvQagJDm+Giol9P6ZbwkHTYgxMX/MRJ6d1OkKI7rkWLGutX1ZKfQ74BbGg+FH7zyDwaa31UrfO14OtWusnenjNN4EJwDVa66ftx36rlPoHcIdS6nFH0Pth4B6t9fcAlFJHMUF1rtY6WiL0LuAwcI+rX4kQwnXRFGyl4NzJVWmejRiwtDZtokL14E+gbUx0ZdnrhyF9qBocr1M/A+//3azQLb4HZn2i+5VUKwThJpNiHM9KeQbRlsXCf/2Z3zU/wdiV+2JPeANw4g1w5tehaJi7J/XkmH3L4UagwN1jx6PSDpbRcGgTDJuR+jk4+zwPmdb34w0/0VzYAVPkK5OC5R1vQLDBjCd90PycCCEylqv/i2mtHwTGAl8GfgM8AHwNmKC1ftTNc/VEKRVQSnX36eNjwDZHoBx1D+AHrnU8VgAcctw/DHgx/aNRSp0C3ArcqrUO93XuQojkOdoYZNWOowDMGllKRWFOmmckBqxwowmWlS/+FcVQCxywqwYPmQa+FHz/lo2GqZeacd0eWN3DtehoCrYn+6pg73r2+3yz4W7Ge0ygrPHACR+G25bCxfe4HyiDSTn25EC6Pj6027ecplRs53mH9KG4V5SzyNe+9/p+PDdtdNTCnXJ5+uYhhIiL65d8tdb7tdb3aa0/r7W+TWt9r9Z6j9vn6cGHMOnSdUqpw0qph5RSQ6JP2uORQGcr3Usx5S3nOh5bAnxOKXWiUmoqZlV6rda6RinlB34L3K+1fjNJX48QwiWLNh4kYpkKtudJFWyRLlbE3qvcmNiq8v53Y+mqw5K8X9np1M/GVokX/wwi3eyvDTeD1Qre7LoQpQ+sZ8TmP7Xd/3dkLp8v/RX6qt/CoAnJPbk3B/CawmipVuWoiF2dpiJf0bZRytO3tlFRVVPAZ++X359BwXIkBJteMeOCChh9ZnrnI4TokWtp2HZRq2la6+e6eP4y4F2t9Xa3ztmFFcBfgU1APjAPs9/4QqXUyVrrfZh9ygC7O75Za92qlDoEjHA8/CXgH8BK+/4e4Bp7fDtQBtzRm8kqpUZ2OBfANIC6ujqOHDnSm8MmTV1dXbs/hcg2/14d+7GfOzw3pT9j8vMj2oTqofWwKezkbYr7bbmblxHdUVpfNoVQTUNy5teRp5KC8ReSs/l5qN1Nw5LfEpx23bGvs0LQWg3hEPjj/7riUdfQ1O5Pt1n/+iEVdiuon3k+xXO+86ABXl6zlRNHlSXlnG3CzdAaBmpTf5HBW0WZx4+yQoT2vk99qr6norSm9MB6PECkZBS1jSFo7Pvv5aLK4/HvW4Wu3szRw0dMKn2a+Xa/SXFLLQAto+fRVFufkvPK/z1CGL35GXCzwNcPMKu1nQbLmHTsXcANLp7zGFrruR0e+oNS6lXgceBOTLp09LNGV2U9WxyvQWu9SSk1HZiMSdFeawfVE4BvAR/VWtcppW4DbgOKMMH17Vrr5mMP387NwP929sTq1atpaWnp7Km0W7NmTbqnIETCwha8ttkLKAblaPasXcXeFHdqAfn5Eb138pYlbf85vb43j2D1upSdu9B/DufyAgqNev3nvH5kMFp19zEiOUlla9btcP2YlXXvctqhFQDU5o5kwuSz+IqKANC04z0Wu3/KjHJ2zjBKm3egqjeyePn7Kd1rnhs6ygdaagDYxxBWLV7synGnhQcxHlBWiHcXv0RNwThXjtsXJ+z8G8X2eFVwHIdc+lrjJf/3iIFu/frEs2fcDJbPoPMK1FEvYgLVlNNa/14p9X/AJfZD0cvSXV2+zQP2dzhGGOiYy/MA8ILW+hml1LXAzzDB7y5McTMvJnjuzu+AFzo8Ng14cObMmcyZM6eHt6dWXV0da9asYcaMGRQXF/f8BiEyyJvba2h90wQXF04byllnpbbLm/z8CMCsKrdUm7ZKiVQ/1hala7cDZgXu5NNSXUV3CsHgBeRseZGC4EHOHVRN8PiPOOanzWp56Cj4Sl3vGVzX0MSadTuYMWU0xYUuVmy2IhQ//b22uz+KfIy31sf+XU4YUcp/XzzFvfN1RmtoPQTBGggkeRW7E3mN02HjDnxWC2dPLsEq7pjwljz+nUvaPl2VTzqZM092JzU5sOEIvPAiACdV1NI6Lcn/hj2xIpSuN8GqlVPClAv72HIsAfJ/jxBGbm7i7QzdDJar6BBgdnAQSOcGwe3A6fY4ern7mP8NlFK5wCBM+6kuKaVuwuxrjv72vRn4m9b6Sfv5u4D7lFJf0LrrJn9a612Y4Np5bACKi4spL3epNYXLMnluQnTlzddj1W0vmzU6bd/D8vMzwLWEIeA3QVEiAeXhLdBqUji9I0+kvLQwSRPsxjlfhC0vAZrCt34Np90CXvujRKQVmmshXASBBPZhJ6i4MN/dr/3dp+HIJjMeewZ3feKb6ani3aKhuRUCebHe1qkyYjps/CcApS07YdTkHt7govWxZfv8sXPId+t348Sz2pYiCmo2UpCOnxenXSug2aSXeyZdSHnVkB7e4D75v0cMdL25WOTm/wY1wPhunp8ApGZzRgfKRJ8TsIN5rfV+zH7lUzt5+SmAwux97up4lcBPgTu01tENkCNoH/TuwlTLrujr/IUQfae15qW1pmVUUa6POWPlA4NIA61NUIkn8ZXX3c7+yjPdnFX8Bo2HyR8046M74J1YQSzTW7nZrJhni2ATLP6FGSsPXHBn+tpdeQMm08AKpv7cziJfB1Jc5Ougs22Ui22rysdBbokZ73/fveP2llTBFiIrufk/wmLgFqXUMU1L7erTtwCvu3i+Yyilulq5/i9MMPsPx2NPAmOVUld3eO1XgTDwVDen+jmwDfiV47G9gLOE43RMf2lnyykhRJpsOFDPnhpTQuCcSVX4vdnV/1X0E1YIdMi0i0pUtL8ywPDZ7s0pUad9DnNNGVj8U4iEzUWAcJNpf+TJoirYKx+FhoNmPP0aGHpity9Pqmi/ZaubSuPJ4mwfVZ3i9lHRtlH55eBm+rdSsRZSR3ZAS1rWawxtxYLlnCKYcH765iKESIjbBb4uA9Yope4B3rEfnwl8BSgEfuji+Trz30qp84F/Ajswe4/Psee1Cfiu47U/wrSY+r1S6kRM8HsFcCnwPa311s5OoJS6ANODeW6H9OongIeVUvdiVq2/DTzZXQq2ECJ1XrZXlQHOn3LMNT0hUkOHTHsgjz/x9+6xV5ZzS2BQGosVVRwHky6EDS/AkW3w7l9g2pVmZdmT4/pe5aRpqIY3f2fGvlw491vpnbvHb1aWw8mp9t2t3BIoHgp1+9qv9CZbqBmObjfjysngcfki5rDZsGUBoGH/OzDm9B7fkhT73oV6e6fihHPB7+KeeyFEUrkWLGutVyulPgQ8AvwY7P4L5vLzIeDDWuuVXb3fJQswFas/jkl/1sAWTCB/t9a61jHfo0qpMzAB/KeBYmAz8Dmt9f2dHVwplQfcD/xCa/12h6cfA4YCnwMKgGcxLaeEEBng5XVm9cjrUZwzUYJlkSZWyNx8BYm9r+mISXsGGDYzfanCUafdZoJloHnBj/jg8+Xcfckg5o7Nop1HS+ZDyA5MT74VSsekdTooj0lh15a5pfrfuHKyCZbr9kJLHeSmoBDUoU3mawUYPNX94w93ZArsS2OwvOHF2HjKZemZgxCiV9xcWUZr/U+l1CjgA8BxmEB5A/BiHC2U3Dj/P2ifat3T6/dhejDH+/pmutiXrbXWwF32TQiRQQ7Wt7B6Vw0Ac8aUUZLfi1U9Idxg2SvLKsHvQWcK9og0pmBHVU6EiRfCxhfJq9vOjOCr/GDBOTx7y1CyYl350GZ45y9mXFABZ3wlvfOJ8gTAa6dip7rfctUk2LLQjA+uh1EdO3EmQbv9ytO7fl1vObcr7HvX/ePHQ2vYaAfL/jw47oPpmYcQoldcv2yptW7WWj+rtb5ba/0TrfXfUxEoCyFEVxauP9g2Pn9KOovyiwHPCppU30TTffc4insNm+nqlHrttM+1Db/ke5r1+xpZtLkujRNKwKKfxlY0z/oa5GVIwT9PtMhXOvYtO4p8pWrfcrtg+QT3j180BIqHm3G6inwdXAe1di3Y8fPMnmUhRNaQCjdCiH7vpbUSLIsMYIXtYLkPxb08PhiahBW4XtCVk1jqPwWA8Z59/LfvSe59dT8m0SqD7VgKW18144oJcOLN6Z2PkydgF/lKc0XsVO1bjhb38vqhMglp2BBbXW44CPUHu39tMmx0pmBfmvrzCyH6xNVgWSl1nVJqiVLqoFIq0skt7Ob5hBCiJy2hCK9vrgZgQlUhYyoS3CsqhFusEOhI4sW9wq2w/z0zHjzVpHJmgEWb6/ha/Uep1aZY0U2+F6nYvzizV5e1BQvvjt0/7zvgy6Dq3R4veHKBiEnfTaXSkbHCU6kIlrUVW8EeNAH8SWo5NsyRir1/dXLO0Z0NdhVsXw5Mujj15xdC9IlrwbJS6hvAHzB7lZcBj3dy+71b5xNCiHgs2XyIlpBJt5RVZZFW2i7upbyJve/AWojYabnDZ7k/r16a//oB9lLBN0O3tj12t/8B/vjq2jTOqgfv/8OkxQKMPg0mZeBKnzdgsg90ilOxlcfsRQezp9tK8vpG7R4INppxMop7RTmLfO1N8b7lQ5vhiN1cZewZkFuW2vMLIfrMzQJfnwfeBM6TPcpCiEzx8jppGSUyRLS4l68wsfftduxXTmd/5Q5K87zk+RWvcjJPWedxrecVylUDX2m8F6y5ZpU0k4RaYPEv7DsKLvhu5s0R2u9b9gRSe+6qybB3NUSCpi1YxXHJO1f0ogXA4OOTdx7nHv/9KQ6WN0oVbCGynZvB8hDgJxIoCyEyhWVpXrFbRpUXBJg1Sq7qizSKBAEr8ZVlZyXs4TPdnFGfPHSdozlE6G54/MNweAtTWt+B5b+DU27t+s3psOrxWK/baVfC8BRUe+4NT45J1Q83YjpRplC7fcsbkhwsO4qIJaO4V1RuCVRMhEMb4cA6k96eqn7a0ZZRHl9mZjEIIXrk5p7lLUCJi8cTQog+eXdPLQfrWwGYN6kKrycrmtqI/siKgA4mHihrDXvtYLlkBBRmaHaEPw8u+5lJIQZY/EuzQpkpGg/DsgfN2JcD5347dQFTojw+EzDrNJR5qZoUGztXfpPBGSwPnZHcc0X3LbfUxfqVJ9vRHbE92WNOg4LK1JxXCOEqN4PlnwO3KKWkJr4QIiO84kjBvmBqhgYZYmDQveyvfHQ7NB0x4wzar9ypqkkw73Yz1hF47hvQWp/eOUW9MT+2P3buzVA+vvvXp5s3B/Amf99wRxUTIdop+2CS20dFg/GiIZCf5ECy3b7l1ck9V5QzBXuyrCoLka3cTMMOAtXAOqXUw8A2INLxRVrrx108pxBCdOklOwU74PVw5nFyVV+kkWUX90q0Evae1bFxBu1X7tKsj8K2JbBloekt++KdcOnd6V3FPbwVVv/ZjPPL4YxvpG8u8fIETDslK2RWmlMlkA9lo81FmmT2Wm6pg7q9Zlw1JfnfH85gef+7Jg0/2aJVsJVX9isLkcXc/A38qGP8rS5eozFVsYUQIqn21DSzbp9pYXPq+EEU5KTwA6cQHUWLe3nzE3vfHkdxrxFZECwrBRf9AB65AhqrYd2/TBXgVAQnXXn1Z2alG+Csr5qAOdNF+y2HW4AUtwqrmmyC5cZD0FANhUm40OgMxJNZ3CtqyDS7f3Uo1oYtmer2xoqJjZwDRcOSf04hRFK4+elxnovHEkKIPnlFqmCLTGKFgHDiq4TR4l6BQqiY4Pq0kiK/DC79CTz1KUDDS9+DYTOgfGzq57JzOWxeYMbl4+CkT6d+Dr3h8Zt9y1Ya0tirJsGG5824ekNyguV2xb2mu3/8jnw5JmDe+7Y5t9WLn8VEbHwpNp5ySfLOI4RIOtd+U2itX3XrWEII0VcvrY0Fy+dJf2WRTtoCK0jC/+U218DhLWY8fKbpg5stRp8Cp3zaFNUKNZn9yx9/MlYALBW0BYvujt0/71vgy03d+ftCKRMsK2VWxRMtDNcX7SpirzeZAW5zFg8bkuTiXlHDZptgOdxqLgIkc0W7LVhWMOXK5J1HCJF0WfQ/rxBCxKe+JcSyrYcBOH5YMcNKU5zGKISTFTYFvnq7qgyZX9yrM6d/AYbaLYEOvA+v/aL717tt3b9jKbcj52Zf0OKN9lsOpva8HdtHJUP0uP685LanckpVka+Gg7He6CNmQ8nI5J1LCJF0ruegKKVOAk4Gyjg2GNda6++5fU4hhHBavOkQoYgGZFVZZIC2Sth9CZazYL9yR14/XPZTePQqU4l6xcMw5tTkrFR2FG6F1+6J3b/gTvCkcHXWDdF+y1YIvCm84Fc42PQmbqlNTvsoKwyHNplx5aTUFTBzBsv73oNkXX/a9DKmRA8w+ZLMbVEmhIiLa7+hlFJ5wNPAhZi+A5q2/gNtYw1IsCyESKqXnS2jJFgW6RathO0rSOx90WBZeWMrtNmmdCRc+F34p12B+t//DTc9AwUVyT3vqt9D3T4zPv5yGHlqcs+XDB6/WVkON6X2vEqZ1eWdb8KR7ebCgy/HveMf2QYRe7V88FT3jtuTiuPM3v9gQ3KLfG1w7FeeekXyziOESAk307C/gwmUf4Ap9qWAG4GLgMXACiCFvxWFEANRxNIsXG9aRg0uzmHa8OI0z0gMeFYveixHgrFqulWTTUufbDX1UjjeDhoaD8G//8fsJ06WpqOw9AEz9gbg3O9k5+qe8oA31/xdJfPvqzPRVGwdgUOb3T22M7V78DR3j90djxeG2cvJh7dBqNn9czQdhV0rzHjIdCjL8H7eQogeuRksfwj4i9b6O0D0kt0erfULwPlAALjJxfMJIcQx3tp5lKNNIcCkYKts/JAs+g+tzZ5TpRIL2A6sMyt6kJ37lTs6/9tQOsqMty2GlUnsIrn0N2b1EGDOp2BQivbEJoOz33IqdSzy5Sbn8YakOGMiGizrSHJWlze/EmtTNuXi7LxII4Rox81geSQQrYht/6YgAKC1DgN/BK5z8XxCCHGMl9dKyyiRQXTYDpYHWHGvjnIK4LKfmdRigFfvgf3vu3+eI9vh7T+acV4ZnPkN98+RSp5oka8UB8uVk2Jjt4Plth7LKjVto5ySXeRr44uxcbYVlBNCdMrNYLke8DrGFuDswl4LDHHxfEIIcYzofuU8v5fTxid5X6QQPYmmYHsSSMEG2PNWbDwiC4t7dWboNDjry2ZsheC5r5vCX2567R7z9w1w5peTvzc62TwBu8hXiitiV4yPfc8ma2W5bBTklLh77J44g2W3V5Zb6mD7MjOunASVU9w9vhAiLdwMlrcAEwC01hHgfUxqNsrkQV4N7HLxfEII0c7W6ga2VJsP32ccV0GuP8uq34r+xwqZatiJrCxrHVtZLh4KRf3oOvOcm2DM6WZ8dDu88kP3jr17Vay/bdkYmPMZ946dLh4veHKBiPm+SBVvAAaNM+PqDe6du/GQuQFUTUl9mnLJCCioNGO3Mxu2LIxlAEyWFGwh+gs3g+WXgQ8rpaLHfAD4oFJqC7AJs2/5dy6eTwgh2nll3cG2sVTBFhmhNyvLtbtjAUU2tozqjvLAxXdBfrm5/+7TsO5ffT+u1rDwJ7H7595hevj2B96AudiiU71v2U7Fbq2Hur3uHLNdca/j3TlmIpSKrS7X7jEFudzSrgr2le4dVwiRVm4Gyz8Czo0eU2v9a+AbmPTro8D/AD/p8t1CCNFH0RRspWDeZNmvLDKAFTKBnErgv1tnCnZ/2K/cUWGlCZijXvgu1Ozu2zHX/wf2vWPGI06E46/p2/EyiScnTfuWk1Dky9m3OV3t0IY5LkDtW+3OMYONsP11My4fB0NmuHNcIUTauRYsa60btNYb7GJe0cd+prWerbWeo7X+sdapzCESQgwkNU1BVu4wqwQzR5ZSWeRiX1AhesOKgA6aVNpE7O5nxb06M+4sOOlGMw42wD+/DpFeBoPhILz289j98+9M/O88k6Vr3/LgZATLzpXlNAXLzn3L0QssfbX1tVj1+skXSQq2EP2ImyvLQgiRNos2VBOxzPW48yUFW2QC3Yv+yhBbWfbnQ+VE9+eVKc76qtm3CrB3Dbwxv3fHeftJk7oOMOVSGH2GO/PLFB6fWV2OrUWkhnNluXpD169LRLUddOcWQ+lod46ZqGGOC1BuFfna4KiCPfUKd44phMgICfay6J5dyOsCTKGvQUDHS2taa/09N88phBAAL61ztoySYFlkACtkbonsV26pg0ObzXjYDBMo9Ve+gGkn9fg1EGqGpQ/C6NNg1Nz4j9FcA2/8xoy9fjjvO/1zVc+bA3jt/e8p+p7IL4PCKmg46M7KcrgVDm8z46qp6Vv9LxhkCsAd3Q7719rbJPrwPRNqMSvLYAqIDTvJjVkKITKEa79xlVJTgWcwgXJXv3U0IMGyEMJVwbDFaxuqARhZnsfEwYVpnpEQxIp7efPjf8/eNZj/Kul/xb06M2gsnHcHPP8tQMM/b4dPPmN6JMdj6f3QWmfGJ90EFZO6fXnW8gTMxQArmNoLKFWTTbBcswtaGyCnD79bD20GHTHjwVPdmV9vDT/RBMtNR0zxspLhvT/W9iUQajLjyRf1ry0AQghX07DvB4YDXwZmA2M7uY1z8XxCCAHA8m1HqG81KYrnTR6M6o8rSyL7WCEgwZXAdv2V++l+5Y6mX22CDICGA/Cfb8fXqujoTnjrSTPOLYGzbk/eHNMtXfuWq5yp2Bv7dizn6vTgaX07Vl85i3ztXd23Y214ITaWFGwh+h03g+U5wN1a6/u01qu11js6u7l4PiGEAGJVsAEumCop2CIDaAusVhJO4Ir2V1YeGDpAKuoqBRd+F4qHmfubX4HVf+z5fa/9PFYh+owvQUE/roDv8Zt9yymviO1YqXdWsu4N577nIWkq7hXlVpGvSBC2LDLjosEw8tQ+TUsIkXncDJYPA4dcPJ4QQvRIa90WLBfl+JgzpjzNMxICx37lBILlSCj2wb1yYt9SXrNNbjFc9lNQdgrrgh93v5K5523Y8LwZl46Ekz+X/Dmmk1ImWFaeWCpzKjhXlg/2scjXATvY9vjMnuV0GnpCrJ1bX4p87Vhm+lADTPxg/64xIMQA5Waw/CdA8k+EECm14UA9u482A3D2pEoCPinyLzKAFTLVixOphF290RS6gv7bMqo7w2fB6Z8340gQnvuaKZ7Ukdaw6O7Y/XPvMJXD+ztvTupTsctGgy/XjPtSEVvr2PsHjYNAQd/n1heBgljAfmC9yQTpDamCLUS/5+anyjuAFqXU35RS5yilxiqlRnW8uXg+IYTglXUH28ZSBVtkDN2LlWXnfuWBUNyrM6fcCiPnmPGhzbDwx8e8xL9tYSxdffgsmPaRFE4wjdr2LacwFdvjjbUvq95oeof3Rt3e2ApsuleVo6I/Y6EmOLw58fdbYbNlACC/HEaf6d7chBAZw81gOQSsA64EXgE2A9s6uQkhhGteWmtSsL0exTmTKtM8GyFs0UrYKoFgebczWM6ileVQA7QegmANhBvNymc8Bbo64/HCpT8xBbsAVv8JNr7U9rSywuQvvy/2+gvuHDjVhz0Bc0vXvuVwCxztZekZZwr3kDQX94rqa5GvXStN6zKAiR8wrdCEEP2Om5srfgJ8BXgLWAIcdfHYQghxjIP1LazZXQPAnDFllObLhxWRAbQ2acTKE3//Vq1jq6WFVbFiV5nOCoLVAoHy2Gp6uNH8qbxmJVT57QJVcX7kKBoCF30fnvkvc//5b9sBVhFjD72Ct263eXzSRTD6rKR8WRlJKfDmmpRhbcX23CbbYOe+5fUmjTpRzuJg6a6EHdWuyNd7cEKCGQobnSnYl7szJyFExnEzWL4BeFpr/WEXjymEEF1auP5g2wKWpGCLjKHDJnBMZFW5bq9pmwQmPTQb2p9pDaE68BdDboUJjq2gvaoehEirvcoctvdi2yvtbcGzP1bQq6PjzoeZ15mV5ZZa+Nc3UfN+yKT9z5rnPT44/3+z4+/JTW39lkNmD3MqVDrbR22AKRcnfox2lbAzpMp71RSzHzvckniRL23FMh5yS2Dsue7PTwiREdwMlvOBl3p8lRBCuORlx37l8yRYFpkimoLtSaC4157VsXG2pGBHmkzwFigxK57Q/mvWun3wbIXMKrQVNm21wo0m6PD4zHFU9E87AJ73Tdi90uxd3rWC3L/dRCDSaJ478QaonJLarzcTtKViB1MYLDvbR63v+nXdiaZhF1RC0dC+z8kNXr9pz7brTajeBOFg/KnUe96GRrsBzHEXgD83efMUQqSVmzk8y4AB+D+XECIdWkIRFm+qBmB8ZQFjK9JcXVWIKCuU+MpythX3ssImWPYXg7+k89coZQI6fyHklEPeYMgbAfnD7dswyK0En/2zazWbvc+thyBYC8qCS34MPhMU5jXuAaBRFaDP+mYqvsrMk459yzkFpj0X9C5Ybm2Amp1mPHhqZmUDRPctW2E4sDb+9zmrYE+5zN05CSEyipvB8teB65VSUjtfCJF0SzYfoiVk2n2cP1VWlfs1rSHSSQuhTNWrlWV7v7I/D6omdf/aTBCuA1+hWVVOZO+sx2tWof3FkDPIBMz5dgCdZwfQgXI7QLagbAiccVu7QzyqrmTR3gFS1Ksjj9f0WybS+yJqvRHtt9xwEJoSLEnj7Jc9OEMqYUe127e8Or73aA2b7ETKQCFMuMD1aQkhMoebadg/B+qBp5VSu4HtQMceA1prfZ6L5xRCDFAvS8uogSNUayou51bE0n0zWbQadLxBZGtjbE/nkOkmPTSTRZoBZVaUfS5kdHh87Yt/aR1L3dYh9JzPsHTJMk4LLaU+dxjPhi7gxZc3cc7ESlQmrVKmitdOWdchUCkqalg5KbZHt3o9jD41/vdWO1ajB093d1595cziiHff8v73oG6fGU+Yl/6e0UKIpHIzWB4HaMDOtUF6KgshksKyNK+sM8WQyvL9zB5VluYZiaSxIiZQDtdDpCjzg2UrbIK8RPor71tt9u4CjMjw/cragnCDWf0NlCbnHEqZgNBrAsFFWw9yc/3nuTL/HM4/biShdX7W7Kph0cZq5k2qSs4cMpknJ5aK7UlRsFzlKPJ1IMFg2dk2augJ7s3JDeXjILcUWmpg//vxvWejpGALMZC4loattR6jtR7b082t8wkhBq739tZysL4VgHmTq/B6BuDq0kARabRvrdmRim2FTPVnlcDq8O63Y+NM368cqgdvvkm/TuSCQB/MX7gZCw9veaYR8hXGHl+wOSXnzziegEnxt4KpO6czWK5OcN9ydJ+zLxcGZdgWA6ViP3NHdkBLffev1zq2X9mXCxM/mNz5CSHSzpVgWSlVoJRaoJS62Y3jCSFEd15ee6BtfIGkYPdfWkOokeXbaznzgf0s337YrNxmsmiv4UQCyb3RYFnBsJnJmJU7om2gAiXgK0rZaUvz/eT5PeT4zEWxHJ8iz+8ZuH3VPT6zuqxT+LNQPAxyis3YuVLcEysS27NccVz81aZTKVrkCw373+n+tdUbY8XKxp8DOV0UtxNC9BuuXBbWWjcqpeYAf3DjeEII0Z3ofuWA18OZEyvTPBuRNJEmdN1OrOe+xSeaK/jBizfz7IRRKE9hz+9NFytsAgRfnCvLVgT2rjHjigmQW5y8ufVFtKdyoMTsVU7hXuGHbpwDwJEjR1i8eDF/vPVUysvLU3b+jOTNAbx2IbkUrPArBZUTTSuvw1shEmxLk+/W0Z2mjzFkXnGvKGeRr73vwJjTu37thhdi4ymXJm9OQoiM4WY17NVI6yghRJLtqWlm7b46AE4ZP4jCnNSkgoo0CDdy4B8/4pTQcj7t+zeFB1ayaMOBnt+XTlYICIOKs1pz9UYI2r2DMzkFO9xo0n/9xanr7yu65gmYQnDpSMW2QnBoS3zvObguNh4yzf05uaFdka93u39tdL+yNwCTLknenIQQGcPNYPl/gVuUUme7eEwhhGhnwTpnCvYALO4zUERa0Afeo3LvoraHzvK8w70LdqItK33z6o62wGoloaStdv2VZ7o9I3dYYbBazIpyVz2VRWqlfd9ynKnYztdlWiXsqKIhUDzcjLsr8nV4Kxy2LxKMPQPyBnh2gxADhJtLMh8HdgELlFKrgU1AU4fXaK217GsWQvTaS46WUefKfuX+K9TAgRfnM4RYYHyG5z3u2tvEovX7mDd1eBon1wWrF/uV92RBca9QHfh70VNZJI/Hb/YtWz0UpHKTM1g+GGeRL+frhs5wdz5uGj4b6vaYPtL1B6GokwuxzirYk2VVWYiBws1g+SbHeJZ960gDEiwLIXqloTXMsi2HAZg6tJjhpXlpnpFIikgQqt+ncs+Cdg8f79nBIGqZv2hr5gbLiVbCjgbLBRVQOjI58+qLcLPZr+orBl9+umcjopQybdSUB3Qk/rT/vqiYYM6jIwkEy/bKculIyM3gFn/DZsO658x4/2oouvDY10SrYHt8MPnylE1NCJFebraO8sRxS8FvcyFEf7V4YzXBiFlpPF9SsPuvSCMsvR+vvaq8UceCyHP871Oal6Grm4lWwq4/AHV7zXj4rJQWzYqLtiDSYFKvk9VTWfReqlOxfTkwyO4AenC9KfrWnaaj0GBvm6maknnf304di3x1VLMrtv969ClQKP//CDFQZOgnDiGEONZLjv3K50+VFOx+yYrAwbWwzq46WzSEiTc/2Pb0z6Zt5qGPjDSBXKaxQvYqX5zBcrv9yhmYgh2qA19BSnsqiwS0Bcuh1J2z0k7FbqmNBcJdcfZjztRK2FHDZgJ2ML//vWOf3/hSbDxZqmALMZAkJVhWSk1VSl1q36RCthCizyKWZuF6s1+5qiiHacOk0FC/FG6Apb82QSfAqbfBiFMgf5C5v2sVRFrNLZNobc/JE/8KWrv9yjOTMavei7SafwN/MfgyuFXXQOYJmFsqg+WqSbFxT6nYB7OguFdUbonpAw1wYN2xq+bRllHKA1MkBVuIgcTVYFkpdbZSai3wLvB3+/aeUup9pdRZbp5LCDGwvLXzKEebzIfC86YMxuPJ4JQ+0TvagkPrYO1/zP2iwXDiTeDxwFi70UJDNRzaaKozZxIrZNKw411VBthtryz7cjJr5U1rCNdDoBj8pZmdPjuQRfctayt1mRaJFPlyto3K5OJeUdFU7JY6OLoj9nj9fthnp2aPOClWOVsIMSC4FiwrpU4CXgDGAI8AXwW+Zo/HAC8opU7s6v1CCNGdl50to6bKfrF+KdwEbzhWlU/5LOTYGQTj58Vet2MZhDMsWNYh02LJE2dxr2BTLNgYMs30bc0U4QbTS9lfklnzEsdKdb/ldsFyD+2jos/nFEHZuOTNyS3DHFsh9q6OjZ0p2FOkCrYQA43bfZZrgWla61u01r/QWt+rtb4FmAbU2a8RQoiEvbzWBMu5fg+nja9I82yE67SGQ+th7T/N/cJKs6ocNc4RLO9cafoZpzL9tCdWOLHiXvvejV0UyKT9ylYYIi2m+rW/ON2zET1JdSp2QYW5Qfcry5Gg6UsMUDkJPFlQ39VZ5Gufo8jXBkfLqClXpmw6QojM4GawfDrwa6311o5PaK23Ab8BznDxfEKIAWLboUa2VDcCcOZxleT6s+CDl0hMpAWWzjcFvgBO+QzkOFrNlI6EQRPMePdqCDVm1r7lPhX36qzTYpqE6iBQZKpfS0/lzJeOfcuV9r7loztMhkRnDm+NzSmTthh0Z8i0WGbIgffNn42HYPcqMx4+C0pHp2duQoi0cfN/wjzgcDfPH7JfI4QQCXnFWQVbWkb1T4c3wnv/MOOCCjjpU8fulY2uLoeaTJqklUnBctCsjscbYGZica9wk9kf7i8Bn/x3nRU8XvDkAJGeWzm5pS0VW5v6AZ1xrjoPyfDiXlG+HBMwg0kht8Kw6RXA/nudfIns3xdiAHIzWN4MdFci8Ar7NUIIkZCX7BRspeDcydIyqt+JtMIb95kPpwAn3wo55ce+rt2+5TfNanSqAoTuWGETLMebgq2t2J7I8nGQV9bty1NCRyDSZAJlv1SazyreHJPRoFO0uhzPvmVnsJzplbCdoqnY4Vao3gAbHSnYU69Iz5yEEGnlZrD8GHC+UurPSqkZSqmAfZuplHoKOBdT7EsIIeJW0xRk5Y6jAMwYUUplUU6aZyRcd2QTvPuMGeeXw0mf7HwFZ8wZoOwU/F0rTbCcCavLVgh0GFScxb0ObYbWejPOlBTsUD348k2gLD2Vs0uqU7HjaR8VDaKVBwZPS/6c3OIs8rXlVXNRDmDw8VB+XHrmJIRIKzf/R7wHmAVcD1xjP6YxXd4V8Efg5y6eTwgxACzaUE3EMquHF0yVVeV+xwrDkl86VpVvgbwuCrjllpjWLbvehP3roPkw5FSY9jnppEN2ca84L+Q4U7BHZEBxr0iLWe32F4OvIN2zEYnyBMxe23AjkIJ/v/Kxpkp6JNh5sKw1VK+PvTanKPlzcouzyNfKx2JF+KZcLCnYQgxQrq0sa60trfXHgAsxxbxeAF6yxxdorT+mdSbkywkhsomzZdR5sl+5/zmyGd592ozzy2HOLd3v+43uW9YW7FieOSvLibSNyqTiXlqbVlHSUzl7eXzmQo0Op+58FfYqa/XGY3s8NxyA5hozzpbiXlEVx0Gg0Ixb6mKPSxVsIQasXgfLSql7lFKzHPdHKaXytNYva62/oLW+WGt9kT1+xZ3pCiEGkmDY4tUN1QCMKMtj0uAsWqEQPdMWvPELiNjpo3M+Bbk9tAVz7lveuQIizbEK2ulihQArliLek+jKcl4ZlI1J1qziIz2V+wdvDuCNZWgkWzQVO9QENbvaP9duv/LxqZmPWzxeGNbhAlblRKjKsq9DCOGavqwsfxmY4ri/DbiqT7MRQgiHFduPUN9qPvydP2UwSla9+pejW2DNX804rwzm3NxzP9bhJ8ZWfnatMqmgVkty59kdK2JWt+MNlBuq24KLo2XT07uSa4XM3H3F4JcLUVnNEwCv3xSaS4Xuinw572dLJWynjn3PJ0kKthADWV+C5aOAs4Sn/CYRQrgqWgUbTLAs+hGtYckvTLALMOcmyI8jzd7rhzFnmnHNLqjZkd5+yzpsVvPiLO6lHfuV/350DGndnRSqM0Gy9FTOfm1FvtIRLK9r/1y7tlEzUjMfF+lh7YNlPUWqYAsxkPWlwNcq4BtKKS9QYz92plKq22NqrR/vwzmFEAOE1ppX1ptguSjHx9yxnbQSEtmrZjus+bMZ55XC3Fvir8I8fh5s/I8Z71gGFVPtHsdpuGYbrYQd59z3vPs6I+zxczVjGb25jnnHpaFVU7jJrOJLT+X+weO3g+W6nl/rhkpnReyOK8t2sJxfDsUjyDZLW8Zwmj3eYg1lZ90w5g1P65SEEGnUl2D5K8AzwL32fQ18xr51RQMSLAshevT+3jp2HWkG4KxJlQR8svLVr7zxC9PLFGDOjZCfQObAOOe+5VUw66MmaE3HnttoJew4Ak5tRcjdtgCAOp3Pu3oc9y7azTljA6hUBqw6ApFGU0lceir3D0qZqvDKY/59490W0Fu5xVA8DOr2xipfAwSb4OgOM66aknXpy1prfvxGPV+JzOAc7xoejFzK+gVbOGeybAMSYqDqdbCstX5fKTUFGAcMBRYBPwBedmdqQoiB7IllO9rGF00bksaZCNfV7oK3/2jGucVw0s3xV5IGU7E2+kF91yoI2/2W0xEsW6G4g5O3ly9htj4MwIvWSQTxs2ZfkEWbjzJvTIPpc+zNS35KdKgOfIV2T+UkB1UidaItpKyg+T5Ktqop5mewbp+pfp1XCoc2YdZFyL7iXphWhWv21HETt1McaqKOAthVw6KN1cybJN0YhBiI+vQ/stY6orXepLV+DXgVWKS1frW7mzvTFkL0Z0cbgzy7eg8Ag4tz+MDxEiz3K0vuNQEuwEk3QsHQxN6vFIw714xbauHAWtMrONW0tvdLe+JaQdu34rm28T8jJ7eN5y9rgpxBgIbgYQjW2hW2kyDSYubtLwZ/YXLOIdKjLVhO0vdOR1WOVOzqjebPdvuVp6VmHi6av3CzPVImUI4+vmBz528QQvR7rly+VkpFf6OMceN4blJK5SultiqltFLq/k6eH6yUelgpdUAp1aKUekcp9ekujnOfUmqfUuqQUupxpdQxmyiVUlcqpRqVUmOT9TUJ0d89tXIXLSHTu/NjJ4/G75UU7H6jfi+89YQZ5xSZCti9WRF2tpDa8aYdBFpdvz4ZrJBJw+6+VIehLU4PvgFArS7gLe8M8vwe8vweSgvyIX8Y5A2FnMHm7yNUD61HTGsst4qAOXsqB0rdOabIHG1FvtIQLEeD5HbB8gmpmYeLSvP9bT+XzltpvrRVE2Kg6sue5TZa60al1EnAE24cz2X/B1R29oRSqhR4HRiO2Xu9DbgCeFApNUxrfafj5XcBnwR+DDQB3wQeAq52HK8Y+BVwp9Z6m9tfiBADQThi8fulJgU74PVw/dxRaZ6RcFW7VeWPQ2GCq8pRY8+OjXetMmnYkdbUFqvSIVMJO54U8t2rKI0cAaDkhIt455rLjn2Nv8ikR0daINxoAttIk/nTk2e+tr7sRQ3Xm32t/pLE0t5FdojuW9aWuSU7nb/SURG7ekP7P71+qJhy7Hsy3EM3zkn3FIQQGcaVYNm2mvZ9l9NOKTUL0w/6m8BPO3nJN4EJwDVa66ftx36rlPoHcIdS6nFH0Pth4B6t9ffsYx/FBNW5Wuto/t9dwGHgnqR8QUIMAC+vO8ieGlPY69IThlJZlJPmGQnX1B+AVXaNx5xCmPNp8+G+NworTQ/X/e/C3negtc4UrCKFwbIVLe5V0PNr1z8fGx9/VdevU8oExb48sErsoNm+BY+aVWxfvllBTHiuQcipMinYon9y9lvu7c9WvEpHQKAAgo1wYJ0J0KOVsSuOA3+Szy+EECng5mXH/wVuUUqd3eMrU8BuafVb4AXgb1287GPANkegHHUP4AeudTxWABxy3D8MeIFc+3ynALcCt2qtw33+AoQYoB57Y3vb+MbTxqRtHiIJ3rgXQuZCCLM/BoXD+na8aFXsSAh2r0p9v2UrFF+PZSsCG18049wSGH9efMf3+E26dN5QyBsGuYPBmwOhBmg9DOEEUrRDdSZIzinNugrFIgGpTMVWnlgLqcOb4ch2CDWZ+1VTk39+IYRIATdXlj8O7AIWKKVWA5sw6cpOWmt9s4vn7M6XgamYFeFjKKWGACOBJzt5eimmnONcx2NLgM8ppZYAzZhV6bVa6xqllB8TmN+vtX4zkUkqpUYCHRsRTgOoq6vjyJEjiRwu6erq6tr9KYSbNlU3snSrqRY8fVghIwusjPsZ6IuB/POjmg5TuuIRFGD5C6iddD26tglUc6+P6as8kegaafOmZTRXngY5ntRVeG45AqFWaGns9mW+vasobjTXWlvGnEtTfTPmv5FE+cEqgLDH7GWO1II+BCrHBNFdpWhHmk3F7gCmtc8x/zVnh4H88xM3y4LWkMlE8Cf/okh+yThy97wFkRBNq/9Ovv14Y/F4WvvR7+5sJz87Qhi9+RlwM1i+yTGeZd860kDSg2Wl1GjgTuB7WuttSqkxnbws2mJ+d8cntNatSqlDtA9ivwT8A1hp398DXGOPbwfKgDt6Md2bMavyx1i9ejUtLWmo8BqHNWvWpHsKoh96aouHaMLLrIJaFi9enN4JJclA/PmZsvcvlIVNgLhx0AVsWLMT2NmnY3qsEBcrP14donXrchYHNgPpqFq7r9tnT9j157ag/q3QcVSn7ft6V5rO666B+PPTO3uSfobR9UXMtMf63WfbHn/7gJfD/fT3dzaTnx0x0K1fv77nF3XgWrCstc6kcrW/AXbQ+T7lqOgF0K7y9locr0FrvUkpNR2YjEnRXmsH1ROAbwEf1VrXKaVuA24DijDB9e1a6+6WEH6HSRV3mgY8OHPmTObMyaxiE3V1daxZs4YZM2ZQXCz73oR7aptDfHPFW4BFRYGfz19+cr+rgj1Qf35U81FKH/0sAJY/n8Ef+C+qise6kg5sHZmLd9cSSpt3ctbkAnTJeAiU9Pm4PYq0Qmu1SYPurqetFaZ0/WozzClh8gduZrLPxcq62rKLm7XYxcBaAQ2eXJOOG643q8455anpvZtEA/XnJ2GhemiptgvCJbeQm/egBbseAaAgeLDt8ePPuRqdPyip5xbxk58dIYzc3MRrKbi5spwRlFIfBS4CztZad7dpJ5qH1lX1oDxgv/MBey/yex1e9wDwgtb6GaXUtcDPMKvFu4BHMfuab+tqElrrXXS43K/sD5DFxcWUlx/TnSojZPLcRHb662tbaAmb1j83nDqWwZUVaZ5R8gy4n5+Xf9G2l9Ez+3rKRkx2r8fvpAtg1xIAyo6shpFTIK8s+ftyQ3XQVAOenO4LKe1YBs0mHdUz5SLKq5LYM7ytinYjhJvAagaVa/Y653baFCIrDbifn0SFc6EpaMbxFJ/ri4ITzN5lZ9u24qGUDZ8ge+MzkPzsiIGuNxeLXF+2UUoVKKXOV0p9TCk12O3j93DuAPBz4J/ATqXUGDsFO5pOXWQ/VkIsP6njfmGUUrnAIDpJ0e7wupsw+5q/YD90M/A3rfWTWuvF2O2mlEp2/wYhslvE0jxut4vyexXXnzwyzTMSrmk+CssfMmN/Psy92VRzdss4R7/lXStNwGgF3Tt+V6w420Y5q2BPvTKpU8KbCzmDTDGwvKGm8nWgTHoqDzSegPm+TMXPgT8Pyka3f6xqigTKQoh+w9UgTin1OUwQ+iLwOHC8/XilUqpFKXWrm+frRD5QBVyK6ZkcvUU3znzUvv85rfV+TDB8aifHOQVQwIquTqSUqsSked+htY4G1SNov0q8C1Mtu/8ukQnhglfWHWD30Wi7qGFUFUnLkX7jjV9BsMGMZ30Eike62/91yAkQTffcaVfEjqSg1kMkCFjd9z22wrEq2PnlMO7c5M8LwOMzqeh5QyF3iPRUHmg8PpPxkKrGHFWT298fPC015xVCiBRw7ROLUuoaYD6wELgFE2wCoLWuBp4HrnDrfF1oBK7q5PYZ+/kX7PvRVlJPAmOVUld3OM5XgTDwVDfn+jkm8P6V47G9wHTH/elAkPYtp4QQHTwq7aL6p+YaWP6AGftzYe6nwetyWqjHA2PtjoUNB+HwFrOHN5msCOhg94EywM43zco6wKQPgi/FPcOVSl1lcJFZvDmANzUtpDoGy0MkWBZC9B9u7ln+BrBAa32VUmoQ8FCH51cCn3bxfMew9yg/2/FxRzXs7Vpr5/M/Aj4E/F4pdSIm+L0CszL9Pa311s7Oo5S6ANODea7Wzo06PAE8rJS6F7Nq/W3gyQ6vEUI4bDxQzxtbTLuomSNLmTmyNL0TEu5Z9mtorTfjGfaqcjKCt/Hz4P2nzXjHchgywwS0yQoUdZz9lZ0p2MdflZy5CNEZTwC8fhMsJzmzQFdOxJl0rQefgCRhCyH6CzfTsKcDz3Tz/D5MinTG0FofBc4A/owJ5H8FjMWkaX+ns/copfKA+4FfaK3f7vD0Y5j2UVcD/40J3L+UlMkL0U84V5VvklXl/qOlFt78jRn7cuHkW5JXbOiYfcutyV1dtkJ2ENLN9eZICDa+ZMb5g2DMOcmbjxAdeQLmloJ9y280xkq/NOhcFh0uTfo5hRAiVdxcWY5gKj93ZRgmTTrltNbbofMLnVrrfcAnEzhWMzC+i+c0pqjXXYnPUoiBp7YpxDNvmVp7lUU5XDx9aJpnJFyz7H5oqTPjGddAyajug8u+KB0JgybA4c2wezWEGu1g2cVCYk7R4l7ebo6/801zwQBg8sXgZrsoIXri8Zt9y1ZdUk+jrQg/WRZkvq5ghDrEams89y7YyjmTh7R19hBCiGzm5sryGuADnT2hlPICH6GbgllCiIHnzyt30RyKAPDRuaMI+KRwfL/QUmdSsMGxquxSq6iujDvH/Blqgv3vQjiJRb6sEBDuPvhf/5/YWFKwRaopZfYtKw/oiLvH1haEmyF4hEXr97BmfytfDt7G78Pn893wjazZVcOijdXunlMIIdLEzU+mvwIuUkp9n1j1Z59S6njgaWAq8EsXzyeEyGIRS/P4su2AaRf1sZNHpXdCwj1vPgAtNWZ8wlVQMib5FZmdqdg7VoLVYlesdpm27NTW7lKwg7DpFTMuqITRZ7o/DyF64mYLKR0x/btbj0DrYSAMvkLmv2m2O6zUk/l2+FNs1iYle/6CzX0/pxBCZADXcuK01k8ppaYD/4PZrwsQvbSugP/VWv+n0zcLIQacBesPsuuIaRd18fShVBVLu6h+obUels03Y18OnPzp5K8qA4w901Sn1pH2+5a9Lqc/W2FT4Ku7VeUdyxwp2BdJCrZIj7ZgOQTevMTfb4XtvuWtgDZ9vANFZvuBNxe8uZQWVpPnbzrmraX58j0vhOgfXAmW7Z7D44BHMKvIHwMmY4LkjcATWuuVbpxLCNE/PCaFvfqn5Q/G2iVNvxJKRrsfsHYmtwSGnwi7l8P+tWYOORXgL3L3PG2VsCUFW2S4aJGvcALlYqygo0Cex6RyB0raBcjOC0UP3TjH/XkLIUQG6VOwrJTyAL+mfV/l5cBVWuv9fZybEKKf2nSgntc3m/bjM0aUMGtUWZpnJFzR2gBv2K3nvQE45Rbwp2BVOWr8PBMsa8usLheNMGPl4o6jaCXsrip7hx0p2IVVkoIt0kcpE9xq3f3PQTQ4jrSadmveXPCVgc8OkD250q9bCDFg9fUTxBeAW4H9mBXld4GTgd/28bhCiH7ssaXb28Y3nT4mbfMQLlvxEDQfMePpV5i9yt4Upte3ayG1KrZK5iarhx7L25fEektPvsT0uhUiXdr6LTv2LWtt0quDtdBaDZEmk66dWwF5wyBvOOQPh5xB5qKQBMpCiAGsr2nYnwDWAadoresBlFK/BT6plCqz+xgLIUSb2uYQf1tl2kVVFAakXVR/EWyEN+4zY6/froDtcgp0T0acBIFCCDbAzpVmtcxqBXqxX7MzWpugQylz68yG52PjaZKCLdLME7BbSAUBbS4e6ZAJjr054C01Feu9eeZ10u5JCCHa6evK8iTg0WigbLvPPu7EPh5bCNEP/cXZLurk0eT4ZNWiX1jxO2gyqfUcfxmUjgWfS0FqvLx+GGOnPdfsgprd7q4s67AdLHdxnTncCpsWmHHREBh1unvnFqI3vDkmMI60mO9dXx7kVNmrxyMgbwgEykwGiATKQghxjL4GywXA3g6PRe/n9/HYQoh+JmJpHl+6AwCfR9pF9RvBJnjD7gzo8ad+r7LTeEcq9s7lEGk2adNuiKZgd9UGa9sSs6oNMOWS7itmC5EKymOq0ecPM6nVecMhf6hdtEtWkoUQoiduVD3RXdyX38BCiHYWbTjIziOmzcjF04cyWNpF9Q8rH4bGajM+/hIoHWeq56ZDZ/uWLZdWl62QSWHtamXZmYItVbBFpsgph9wq8BenpjK9EEL0I25c9r5UKTXCcT8fEzBfp5Q6qcNrtdb6bhfOKYTIQo862kXdKO2i+odgEyz5hRl7fPaqclH6VqwqjoOiYVC/F3a9BeEWk4LaVfXqRERXln2drCyHWmJVsIuHwsjT+n4+IYQQQqSVG8Hydfato1s6eUwDEiwLMQBtPljP4k1mT+sJI0qYPao0vRMS7lj1KDQeNOPjL4aycablTLooZVKxV/8Bmmugej3kDjLFufoawFsh+zidJGVtWwwhkzXBlEulgrAQQgjRD/Q1WJ7X80uEEAIee2NH2/jGU8egZK9c9gs1w5J7zdjjMxWw/UXu9jXujXF2sAywcxUMO9GkY3tzen9MKwI62HUQvN6Zgn11788jhBBCiIzRp2BZa/2qWxMRQvRfdS0h/vbWbsC0i7p0hrSL6g92vPRrRjccMHemXgTlE0wxoXQbd05svHMlzL3J7FvuS7Csu+mvHGqGLYvMuGQEjDi59+cRQgghRMZI8+V/IcRA8JeVu2kKmnZR188dJe2i+gEdaqZw5XwAwnjRcz5pAuV0ryoDFFbC4GlmvPcdaK3vewspK2RunVW43upMwb5EUrCFEEKIfiIDPtUIIfozy9I8vnQ7EG0XNTq9ExJ9Fwlx8Pc3M8g6DMBfwmexqGZIZqwqR0VbSEWCJmCONJtU6t6yullZXv+f2FhSsIUQQoh+Q4JlIURSLdp4kB2HzarbB6cNYUiJtIvKaqEW9FMfZ/DOfwHQoHOZH7mSe187hM6EVeWodi2kVva9hZQVAsLHriwHm2CrvSOpdCQMn9P7cwghhBAio2TQJxshRH/0qKOw1ydPH5O+iYi+CzbCH69DbTTFrOp0Pp8I/j9260rW7Glg0cbqNE/QYfRpsT3KO1ea9lG9DZa1Zb+3sxTs18yeZZAq2EIIIUQ/I8GyECJptlQ38JodQE0bXszsUWVpnpHotZY6eOIa2LoQgMO6iOuD3+ItPbHtJfMXbE7X7I7lz4NRp5hx9SZoOmR6LvdGd/uVN0gVbCGEEKK/kmBZCJE0j7+xvW1802ljpV1Utmo6Ao9fDjuXAlDjKePGyHfY6h1Lnl+R5/eQ5/dQmh9I80Q7GO9Ixd75Flgtdjp1gqwQ6E72KwcbYYudgl022rSoEkIIIUS/0dc+y0II0an6lhB/XWXaRZUXBLj0BGkXlZUaDsLjV8LB9839osGUfugB/lk2CnQr5A6BnPK0TrFL4+YB3zXjnSth6iUmHdvTSZGu7mh7ZdnXYb/9lkWx1WpJwRZCCCH6HVlZFkIkxV9X7abRbhf10bmjyPVLIJF1avfAIxfFAuWSEXDdw1AxESKN4CsCf3F659idISdAnh3I71oJ4dbetZBqq4Td4fryeknBFkIIIfozCZaFEK6zLM1jdgq216P42Cmj0jshkbgj2+CRD8Jhex/yoLEmUC4bB+FGUzzLX9z5Pt5M4fHAuLPNuP4AHN1pWkhpK/5jaG3aTykPOLcRtDaa4l4A5WNh6Cz35i2EEEKIjCDBshDCda9uqma7o13U0JK8NM9IJKR6IzxyMdTsNPerJsJHHoaSkXZl6GbTU9lflN55xsPZQmrnCruFVDD+9+uwScPuuKq8ZaEJogGmXCYp2EIIIUQ/JMGyEMJ1jy7Z3ja+6bQxaZuH6IX975nU6/q95v7QafCR30HREHM/VA++AvCXmNXWTDe+Y7/lBFOxoynYHfc5O1Owp0kKthBCCNEfZcEnHSFENtla3cCrdruo44cVc9JoaReVNXavgkcvMW2WAEbMhg//FvIrzH3LXmX1FpqAORuUjoLy8Wa8+20IN5siX/GyQseuLLc2wDY7BXvQeBgy07XpCiGEECJzSLAshHDV40t3tI1vPG2MtIvKFtuXwONXQEuNuT/mFLjmfsgtjb0mXA/+QgiUtN+/m+miq8vBRti/3m4hFY7vvZ2tLG9eABG7BdWUy7Lr70IIIYQQcZNgWQjhmo7toi6fMSzNMxJx2fwKPHENBOvN/Qlnw1W/hhzHnuRIqyl25SsCX5btQR/XIRU70mrSseNhBc3X7Uw5X/+f2Pj4q9yZoxBCCCEyjgTLQgjX/G3VbhpazYrddXNGSruobLD+X/DH60x6MsDkD8Dl94K/Q0AcbjCrypncKqorY88EZX8v7lxpCnPFs2/ZCptg2Vnxu6UOti0x44rjYMgM9+crhBBCiIwgwbIQwhWWpdtSsL0excdPGZ3mGYkevftXeOqGWFXn6VfApXeDL7f968LNptqzv9i0jMo2uSUw/EQz3v8+tNaZfctad/8+K2SqYasOKdhWNAX7UknBFkIIIfoxCZaFEK54bVM1Ww81AvCB4wczrDTLUnUHmrd+D3+7BXTE3J91LXzg+8dWfdYaIo0m/TobV5WjovuWrQjsWWPvW+6hhZQOmcDYubLsTMGedo378xRCCCFExpBgWQjhisfe2N42vum0sembiOjZmw/AP74A2Curcz8J5327fVAYFWkyq8n+4s6fzxbjzomNo6nYPe1btsImuI5eQGiphe1vmHHVJKialpSpCiGEECIzSLAshOizbYcaWbjBtIuaMrSYOWOkXVTGWnwP/Of22P3Tb4Ozv27SrDvSlgmWfYXgLzr2+WwyYg4E7HZXO1eYPcs97Vu2QkA4tt950yuxKtpTLpcUbCGEEKKfk2BZCNFnjy/d3jb+pLSLykxaw4Lvwyt3xh6b91U47QvtKz07hRvAmw/+kq5fky28fhhzphkf3QEN1RBpNhcEOqMte+XZmYL9fGwsVbCFEEKIfi/LP/0IIdKtoTXMX1aadlFl+X4unyntojKO1vDCHfDa3ea+8sAFd8BJt3S9OmqFzcqrrwh8BambazI5W0jtXGX2LHe1umx12K/cfBR2LDXjqilQOTW5cxVCCCFE2kmwLITok6ffcrSLmjtK2kVlGsuCf34Zls039z1e+OCdMPNj3acRh+tNq6hAcf9JNx7vDJbtVGyrpfPXdqyEvfHlWAr21Mv6z9+JEEIIIbokwbIQotcsS/OoXdjLo5B2UZkmEoZnPwurHjX3vX649C6Y/qHug71Iq1mN9heDLz8lU02JiolQZGc+7Fph0qzDXQTLHSthb3CmYEsVbCGEEGIgkGBZCNFrr28+xNbqaLuoIQyXdlGZIxyEv94E7zxl7vty4IqfweTL4nhvg1lVzuZWUZ1RKra63FwDh3bYLaRCx77WCpm2WsoHTUdgx5vm8cHHQ8WklE1ZCCGEEOkjwbIQotcedbSLuvG0MWmbR7ZYu7eu3Z/JsmLTXpb+8AOw7jnzQCAfrvolTLig5zdHms2eZn+xaRnV34zrkIrd2b5lre3HPCbA3vhyrB+1pGALIYQQA0YWN80UQqTT9kONLNxwEIDJQ4o4eWx5mmeU2XSohfrnv8vJnq0cWOtHrxlEMkIuDVRtXc9oa4e5n1OEuvo+GHlyHG/WEG6EQGn/W1WOatdveQWceL1d9bow9rgVMmnYKpqC/Z/Yc8dfnYpZCiGEECIDSLAshOiVx5fuQGszvknaRfVo71Nf5qKGZwAYArApOedRQHTneLUuZtup9zI3nkAZTE9lT8AEyp5++t9DYSUMngYH3oM9q82e5UiLuVAQ/R7WIVPMy+OHxsOwc7l5fOgJMGhi2qYuhBBCiNSSNGwhRMIaW8P8ZeUuAErz/Vwxc3iaZ5TZ9NtPMHzzH1N6ztXWOK4NfocfvFOOjl7V6I62TLDsL+q/q8pR0dXlSBD2vW+CZcuRim2FY8W9Nr4U68UsKdhCCCHEgNJPlw6EEMn09Fu7qbfbRV07ZyR5AWkX1aW9q7Ge+wrRv6Fl477K/9sxm+2NikeuG8e8Ce4Fpgs31fHJp7ba9+ygbm8TizbXMe+4ku7fHG4Ab74JlFU/v446fh4s/ZUZ71wBo+eaPcreXPOYs7iXswr21KtSP1chhBBCpE0//0QkhHBbxNI8ttTsh/UouEHaRXWt6Qg8dQNeKwjAo+pqDpTMtFcnFfOXHASPx7Xb/DcOYoLk9quf818/0P08rbAJFn1F4Cvs/rX9wajTwBsw450rTHDcbmU5aNKyGw+bFlMAw2ZA+YTUz1UIIYQQaSPBshAiblprvvuP99l8sAGAC6YOZkRZP+rD6yYrAn+7GWp3AvCqNZM/BczKZI4P8vyK0jx3k3tK87zk+dUxtx7PE643raICxQMjzTiQD6NOMeODG6G53lQBtyJ2CnbQTsF+UVKwhRBCiAFM0rCFEHG7b8Fmfr/MrCrn+b186TwpdtSlhT+ELQvMuGQYZ3/8l0wP5bF4xTr++ImJlJe6v4L70HXjE39TdBXVXwy+AXThY9w82PYaoGH3W1A42PRcxgM6DMoP650p2FIFWwghhBhoZGVZCBGXP7y5g3te2giAz6P49cdnM3VYPy8E1Vvr/wWLf2rG3gBcdjcUVKZ3Tl0J2avK/b2oV0fjnf2Wl5s07EirXQk7ZFLod68yzw+fBWXj0jNPIYQQQqSNBMtCiB49/94+vv3se233f/KhE5g3qSqNM8pghzbDM5+N3T//mzBsdvrm051Isynm5S8Cb066Z5NaQ2ZAnt0bfMcKe992i71/OQybF2G6VgNTLpcUbCGEEGIAkmBZCNGtpVsO88U/rsay44Y7Lp7C1bNHpHdSmaq1AZ76OLTWmfsnXA0nXJ/eOXVFawg1DIxWUZ3xeGDc2WZcvx9q95s07EgrYMGGF+0XKjheUrCFEEKIgUiCZSFEl97fW8utj68kGDFFjj5z1jg+fZako3ZKa/jHf0H1OnN/6DQ471uZuyIZaTKryf5i8PjTPZv0GOdMxV5h+i7rEDQ6UrBHnAilUvFdCCGEGIgkWBZCdGrn4SZufHhFWz/la2aP4P9dNDnNs8pgy34D7z9txvnlcPnPwJ+X3jl1RVsmWPYXmXZRA9Ux+5aDJgV702uxx6UKthBCCDFgSbAshDhGdX0rNzz8JocaTO/ZcydX8aNrpqMkaOjc9iXw4rfMWHnhkh9Cyaj0zqk74Qbw5turyt50zyZ9SkdBuZ0psWuVaR0VaYGNL9svUFIFWwghhBjAJFgWQrRT3xLik48uZ8fhJgBmjypl/kdn4/fKr4tO1e2Dv9wEOmLun/l5GHt2WqfUrWgfYV+huQ100VTsYCMc3Ay1u2HfO+axkSdBycj0zU0IIYQQaSWffoUQbVrDET77xCre22MKVE2oKuThm+aQFxjAq4/dCQfhz5+AxoPm/sTzYO6t6Z1TT8IN4CuAQImkF0OHVOyVsH1V7P5UqYIthBBCDGS+dE9ACJEZIpbmq39ew5LNhwEYWpLL45+aS2l+IM0zy2Av/A/sXm7Gg8bBB7+f2WnNVtCsgPuLwJef7tlkhjFnmvZZ2oKdy8AyxexQHph6ZVqnJoQQQoj0kpVlIQRaa+587n3+9c4+AErz/fz+5rkMK83QAlWZYM2fYMVvzThQYAp65ZamdUo9CjWAvxD8JemeSebIK4XhJ5rx3ncdKdhzMnvfuRBCCCGSToJlIQS/WrCZx5fuACDX7+Hhm+YwoWoAV0nuyb534Lkvxe5/8LtQmeGVwiPNJqXYX2xaRomY6L7l6L5zMCnYQgghhBjQJFgWYoB78s2d/OyljQB4PYrffOxEZo8qS/OsMljTEXjq4xBuMffn3giTLknvnHqitb2qXGSCZdGec98yoJUHpl6VpskIIYQQIlNIsCzEAPb8e/v41rPvtt2/+0MnMG9yVRpnlOEsC56+FWrMKjyj58KZX838IlCRZrOa7C8Gjz/ds8k8I+agAwVtd9d4p6OLhqVxQkIIIYTIBBIsCzFALdt6mC/+aTWWNvfvuHgKV88ekd5JZbpXfwSbXzLj4qFwyd3gzfACaNqCSKNd1EtS6zvl9XO4Ym7b3T81z2HRxuo0TkgIIYQQmUCCZSEGoLV76/j0YysJhk3l31vPGsenzxqX5llluA3Pw6s/NmNvAC6/GwqzYBU+3AjePHtVOYMrdaeR1prf1Z8MQLUu5j+Rudz78ia01mmemRBCCCHSSVpHCTHA7DzcxI2PLKe+NQzA1bOH8/8+mOHFqdLt8BaTfh117jdg2Inpm0+8dASsVsipBF9humeTsRZtqOY31dN5Rf2YQ7qEWgpZs6uGRRurmTcpCy6ICCGEECIpZGVZiAHkUEMrn3j4TarrWwGYN6mSH19zAh5Phu+5TadgIzx1A7TWmvvTr4CZH03vnOIVqgdfAQSKM39fdRrNX7gZUGzUIzlCrADa/AWb0zcpIYQQQqSdrCwLMUA0tIb55CMr2H64CYBZo0qZ/7HZ+L1yzaxLWpsWUQffN/eHTIXzvgMqC/7OrKBZWfYXmYBZdKk030+e/9h/09L8DN+PLoQQQoik6lfBslJqEvAdYDYwDPP17QT+Ddyttd7f4fWDgbuAS4ASYCNwn9b6tx1elw/8GPgQ4LeP92Wt9ZEOr7sS+AMwTWu9ze2vT4jeag1H+MzvV/LuHrM6OqGqkIdvnEN+oF/9CnDf8gfh3b+YcV4ZXP4zCOSnd07xCjWAv1BaRcXhoRvnpHsKQgghhMhA/e2T8ghgCPAMsBsIA9OBzwDXK6Vmaa0PACilSoHXgeHAvcA24ArgQaXUMK31nY7j3gV8EhMwNwHfBB4Cro6+QClVDPwKuFMCZZFJLEvz1T+vYcnmwwAMLcnl8U/NpaxAVs26tWMpvPA/Zqy8cMkPoXRMWqfULSsMOgRWyIyVMoGyNzfdMxNCCCGEyEr9KljWWr8CvNLxcaXUYuAp4Gbgh/bD3wQmANdorZ+2H/utUuofwB1KqccdQe+HgXu01t+zj3cUE1Tnaq1b7NfcBRwG7knClyZEr2itufO59/nXO/sAk276+KfmMqw0L80zy3D1++EvN5qgE+CMz8HYs9M7JydtmTRrKwzaTrfGCx6f6aPsyzdBsr8k3TMVQgghhMha/SpY7kY06C1zPPYxYJsjUI66B7gMuBb4kf1YAXDI8ZrDgBfIBVqUUqcAtwJnaK3DLs9diF6bv3Azjy3dAUCu38PvbpzDcYOl1263IiH4y03QcMDcP+5cOPmz6SuQpbW9Yhy2A+SQmYvHB54AqELw5Jh2Vp7ozZ8d+6qFEEIIITJYvwyWlVK5QCEmmJ1MLOj9t/38EGAk8GQnb18KaGCu47ElwOeUUkuAZsyq9FqtdY1Syg/8Frhfa/1mEr4cIXrlj8t38tMXNwLg9Sh+87ETOXF0WQ/vErz4Ldi51IzLx8BFP0htf2IrbALiaEq1jpjg1+MHXx54Skxw7PE7gmPpnyyEEEII4bZ+GSwDtwD3Oe7vAm7UWi+07w+3/9zd8Y1a61al1CHM/ueoLwH/AFba9/cA19jj2zEr1nf0ZqJKqZEdzgUwDaCuro4jR44c+6Y0qqura/enyEwLNh7mjr9vbLv/vx8cz4wqX8Z9P2WawIa/U/jm/QBofz61836A1eKDlgZXjl/X0NTuT3QEdBgs+08c6dTKC8oH3nzzp8cHym8/ruzXNts3Ifo/+f9HiN6Rnx0hjN78DPTXYPlZYD1mdXkWJq3auaQWLWfb2sX7WxyvQWu9SSk1HbNK7cesKrcqpSYA3wI+qrWuU0rdBtwGFGGC69u11j19kr0Z+N/Onli9ejUtLS2dPZV2a9asSfcURBc218Fv1nqxtEkbvmJ0hJKj61m8eH2aZ5bZipt3cuaG/2u7v3zEp9m/NQJb17l+rjXrdrh+TCEGCvn/R4jekZ8dMdCtX5/4Z+F+GSxrrXcTWzV+Vin1N2CFUipfa30XpqI1QE4Xh8gD2rWZsvciv9fhdQ8AL2itn1FKXQv8DBP87gIexexrvq2H6f4OeKHDY9OAB2fOnMmcOZnV0qSuro41a9YwY8YMioulJU2m2XiwkTv++D5hHQHghjlD+cq8MemdVBbYsH03Y/95Oz4dBKD5hOs57uSPcZxb+5R1CMLN1DU0s2bzEWZMHk5xUbGdSm0X5cIHHtlnLERX5P8fIXpHfnaEMHJzE+8Q0i+D5Y601u8opd7GBK53YdKo4dj05+h+50HA4u6OqZS6CbOveYr90M3A37TWT9rP3wXcp5T6gtba6mZuuzDBtfPYABQXF1NeXt7Tl5cWMK6dSQAAPUJJREFUmTy3gaolFOGrD7xNQ6sJlK+eNZw7r5qBx5OmwlSZSGtoqYX6fVC3F+r3oWv3UPb60wyxzPUxPfIk8i74f+R5+9haS2uItECkyaRN+8ohR8PmIxQPGk15RaULX5AQA4/8/yNE78jPjhjoenOxaEAEy7Y8oBxAa71fKbUbOLWT150CKGBFVwdSSlUCPwXusFexwQTeqxwv24UpMFYBHOzz7IXoweubDrG31qTtnzWxkh9/6ISsD5SXbzvC1/6ymp99eCZzx/bwH3wkDI0HTRBsB8Lt/oyOQ03t3qYw+ysAdusKth//v5zRl0BZRyDcBFaLKcQVKAFfgbkF7XNLQS4hhBBCiIzXr4JlpdQQrfX+Th6fh0ltXuR4+EngdqXU1R3aR30VCGP6Mnfl55h2VL9yPLYXmO64Px0I0r7llBBJs2BD7JrMf507Ab83u1N6tdb84F9r2XWkmZ/96y3+dO0oVP2+roPghgOm/3Av7bIq+Wzoy/iWRzh9um7L8IhbpNWsIuuI6XPsrwBfoQmSPdFftU3dHkIIIYQQQmSOfhUsA79RSg0FFgA7MCu7JwLXAfXA1xyv/RHwIeD3SqkTMcHvFcClwPe01ls7O4FS6gJMD+a5HdKrnwAeVkrdi9kv/W3gye5SsIVwi9aaRetNsFyS52fWyNL0TqivImHeX/Ak3zhwPyfkbKP4UBPM78PxPF4oqITCCiisgsJKKBzM+40lfHepYj9l7NODCOODvU0s2lzHvONKej6u1hBptlOtvSZIjq4ie/PT15tZCCGEEEL0WX8Llv8I3AjcAFRi+iXvwBTiultrvTP6Qq31UaXUGcAPgU8DxcBm4HNa6/s7O7hSKg+4H/iF1vrtDk8/BgwFPgcUYCpyf8m1r0yIbmw80NAuBduXravKjYfgrcfQKx5mWt1uUyKvJ4FCOwiutG9VUDgEigbbt6FQUOFY3Y3530c2slI3HvP4/NcPdB8sW2ETIFut4M2FQGlsFdnbVd1AIYQQQgiRTfpVsKy1/jPw5wRevw/4ZAKvbwbGd/GcxhQPuyve4wnhlgXrYynY507OwsJRe9+GNx+E9/4GkVac67HrrZHs0IPZp8s5c/ooxo8eaYLgwiEmEM4p6vUKbmmelzz/se8tzeviV2O0YJe27FTrEvAXgLdA9iELIYQQQvQz/SpYFmKgWmjvV1YKzjouS4LlcBDW/h2WPwC729fTC+LnH5FTeSx8Ie/qcW2Pn3SogL9eNtG1KTx0XafXvtrTlkm1DjeZ1WlfgWMVOU9SrYUQQggh+ikJloXIcrVNIVbtOArAzJGlDCrM8DTg+v2w8hFY9YgpyuVUWAUnXM3t20/nhV0+8Jky9lFdrvgmgxUyAbIOmlTrnHLwF5pV5L62lRJCCCGEEBlPgmUhstzizdVELA3AvElVaZ5NF7SGXcvNKvLav5s9v04jZsHMa2HSB8Gbw71npGeaaG1aPoWbAW1Srb2ldpCcL6nWQgghhBADiATLQmQ5537ljAuWQy1mH/LyB2DfmvbP+XJh8oUw62MwZHp605m1NnuRI80m1dpfGEu39uZKqrUQQgghxAAkwbIQWcyyNK9uqAagsiiH44cVp3lGtppdsPJ3sOoxaD7S/rniYTDzQ3DChyG/Ij3z6yhcD2gIlMcKdkmqtRBCCCHEgCbBshBZ7J09tRxuDAJwzsRKPJ40r85uXwxvPgAb/m0KYzmNngszr4cJ52ZWIBppMfuTcyoht1JSrYUQQgghBCDBshBZbWG7llGpS8Fevu0IX/vLan724ZnMHZ4D7zwFy38LB9e2f2EgH6ZeDLM+ChWTMy+dWUfMqnKgzBTwkkBZCCGEEELYJFgWIostsltG+TyK049LTUqz1pof/Gst6uh29v35MbS1ANVa1/5FZaNNqvX0ayC3LCXz6pVQrdmXHCjLrNVuIYQQQgiRdhIsC5GlqutbWbO7FoA5Y8opzvWn5Lyvrd3NTQd+yBWBN/A0a8czCsadDjOvg3HnZP4qbbgRlAf8JeAvSvdshBBCCCFEhpFgWYgs9erG6rbxvMmVKTmnDgfJ+/unuMq7vO2xelVI4azLUbOvh7LxmZdq3RkraHoo51aZVWUhhBBCCCE6kGBZiCyV8v3KlsWB33+KuUETKB/WRfwkfB1/j5zGb0ZPYV55SfLn4AatIVgLgRLIKcv8FXAhhBBCCJEWnnRPQAiRuFDE4rVNZmV5RFke4ysLk3tCreHfX2PIjucAqNP5fCL43zwVmUcLOcx//UByz++mUC348u19yrnpno0QQgghhMhQsrIsRBZateMo9S1hwKwqq2SmPmsNL/8vrHwYgCadw2cjt7PVN5Y8+yWleVnyqyTcDFhmVdmfIT2phRBCCCFERsqST7hCCKeFG2Ip2PMmJTkFe/HPYMkvzNjrJ/+Kn/DkhAuTe85ksMIQaYDAILOqnA17q4UQQgghRNpIGrYQWSi6XznH5+GUcYOSd6I3H4AF3zNj5YGL/g+yMVDW2qRf+4vsfcqpqRwuhBBCCCGylwTLQmSZ3Ueb2HigAYDTxg8iL5CkAlWrn4T/3B67f8EdMOWK5Jwr2cINJkD2l4KvIN2zEUIIIYQQWUCCZSGyzMINzpZRSUrBXvsP+PvnY/fnfRVmXJ+dqcuRVtMqyl8KgdJ0z0YIIYQQQmQJCZaFyDKL1id5v/LmV+CvnwJtmfun3gon3ZKdgbK2IFwXaxOl5FeeEEIIIYSIj3xyFCKLtIQiLNlyCIAJVYWMLM939wQ7l8GfPgZWyNw/8aNw+hezM1AGCNWYtOtAKXhz0j0bIYQQQgiRRSRYFiKLLNt6mJaQWfE91+0U7H1r4A8fttsrAdOvgHn/A54k7YlOtnAToOx9ykXpno0QQgghhMgyEiwLkUUWOfYrnzOp0r0DV2+E318FrXXm/qQL4APfy95A2QpBpMmsKEubKCGEEEII0QsSLAuRJbTWLLD3Kxfm+JgzptydAx/dAY9fAU2Hzf1xp8PFP87e9kptbaKKIVCevQG/EEIIIYRIKwmWhcgSWw81svNIEwBnHleB3+vCj2/9fhMo1+8190eeCJffC/68nt8bLQCWaUJ14M01q8q+OL4OIYQQQgghOuFL9wSEEPFZ6KyC7cZ+5aYj8PiVcHSbuT/keLjqVxAo7Pm9kWYI1YPymRVcT4b8Kok0g45AYBD4S9I9GyGEEEIIkcVkZVmILLFwQyxY7vN+5dZ6eOIaqF5n7leMh2t+A7mlPb830gKhBsgZBP58U3E61GDSn9NJRyDcKPuUhRBCCCGEKzJkOUgI0Z2G1jDLtx0BYPrwEqqKcnt/sFAzPHkd7H3L3C8dAR96AAriCMAjrRBugJxyyK00qdieWrNHOHjYXmUO9H5ufRGsjbWJytb91kIIIYQQImNIsCxEFnh90yFCEbNyO68vq8rhIPz5RtjxurlfWAUffgCKh/f8XisI4TqzaptTYfYFg/nTl2uC1bbU7CJQKUxcCTWYQl6BUvDHkUYuhBBCCCFEDyRYFiILLHKmYPd2v7IVgWc+A5teMPfzyuDD90PZuDjeGzarx4FSEyg7C2cpjwmgvfngyYVwPQSPgK8wFlAnkxUEqwVyKs08hBBCCCGEcIEEy0JkOK11237l8oIAM0aU9uYg8M8vw/tPm/s5RfCh+VA5pef3WmEIHTUFswKDwJff+eu8OZA3GML5EKwxVakjzSY1WyWpfZO2zHkCJSY1PJWr2UIIIYQQol+TYFmIDLd2Xx0H6loBOHtiJV5PgoWrtIYXvwVvPW7u+/Pgqnth6Kw43hsxBbz8xXZBrx5SnJUyr/XmmVuozqwyewu6DrL7IlRrjhsoM8G6EEIIIYQQLpFgWYgM1+eWUa/dDUt/ZcZeP1x+N4w6ref3aQuCR+2iWeVmH3K8PH57X3MehHJNUNva4m6bqbDpOY2/BHwJzE0IIYQQQog4SLAsRIZbuKEaAI+Cs46rSOzNy34DC39gxsoLF38fxp/X8/ucgXLOIJPmnCilzEq0N9fcQrVmldqTa47bl9ZOVhgijSYglzZRQgghhBAiCWSDnxAZ7GhjkLd3HgXgxNFllOYn0Jbprd/D8//PvqPgA9+CKZf3/D6tzZ5jX57ZBxwoTXTa7Xl8JuDOHWKKcGGZNlNWsHfH0zqWGh4oc2+lWgghhBBCCAf5lClEBnttUzWW6RjFOZMSSMF+/xl47oux++d+DaZf2/P7tDbFvLwBE4j6SxOab7d8+R3aTNWZnsy+wsQKc4Xrzf7kQGly9kELIYQQQgiBBMtCZLQFjv3K58axX3n5tiM89aeHuTv0IzzaMg+efhuc+Kn4UpVDNWa/caDc3NxObz6mzVRdYm2mIi1ghcwKtb8XqeFCCCGEEELESYJlITJUxNK8utHsVx5aksvkId0XsdJa88yzf+b7LT/Go0LmwTk3wGmfjy/oDdbawWy5SZtO5j7gaJupUJ7ZyxyMo82UjphV5UCZtIkSQgghhBBJJ582hchQq3fVUNNkgt5zJlWhegheVy5dyH/XfJc8ZfYC7x5zBZz9zfiCylAdKG2C5GQHylFKmcJheUNN4OzNNUXFolWuj5ljrVmBDpSZNHEhhBBCCCGSSIJlITJUu5ZRkyq7fa0+uI5JL91IsWoG4G+RM/lC7SfQcQXKDWbV1l8OgUGpX7GNtpnKHWwCdR2E1iOm4rVzjspj9ikn0sJKCCGEEEKIXpJgWYgMtXCDCZYDXg+nT+imZdTR7QQfuYJiXQfA85E53B66ldX7Wlm0ua77k4QbTXAaGAS5leDpIgU62aJtpnIHm5s/3+yfDjWYqtlWC/hdLjgmhBBCCCFENyRYFiIDHahr4f29JtA9eVw5BTldlBeo2wuPXU5O8wEAXotM54uhLxDBBL3zXz/Q9UnCTRBptQPlivQFyk6dtpk6atK1c8oyY45CCCGEEGJAkAJfQmSgRRtiKdhdtoxqPAyPXwk1OwB4S0/ky3wVrz9Anv2S0rwufsQjzRBpsgPTiszrVexsMxVqMIW/4qmWLYQQQgghhEsy7BOyEALiaBnVUgtPXA2HNpj7lccx+yMP8VZB93ubAdN+KdxoF/OqNHuGM1G0zZSvWFaUhRBCCCFEykkathAZJhi2eH3TIQDGDMpnbEVBhxc0wZPXwb7V5n7ZKPjQ/RBXoNwK4Qa7PVRFdlSVlkBZCCGEEEKkgQTLQmSYFduP0BiMADCv46pyOAh/vgF2vmHuFw2BDz8ARcN6PrAVhHCdqSidM8j0OhZCCCGEEEJ0SoJlITJM+5ZRjmDZisDTn4bNL5v7+YPMinLpmJ4PaoVML+VAqVlR9uX1+BYhhBBCCCEGMgmWhcgw0ZZReX4vJ48rNw9aFjz3RVj7rLmfUwTXzIfKST0f0AqbNkz+YjtQzk/KvIUQQgghhOhPJFgWIoPsPNzElupGAE6fUEGOzwtaw4t3wNtPmBf58+Hq+2DojJ4PqCOOQHkQ+Ap6fIsQQgghhBBCgmUhIBI0Kc4ZYOGGTqpgL/oRLPu1GXsDcMVPYeTJPR9M2z2K/YUmUPYXJWHGQgghhBBC9E8SLIuBSVsQamD5+s2cefcilm/YbNoppZmzZdQ5kyrhjV/Bqz8yD3i8cMkPYdy8ng8UDZR9Babytb84STMWQgghhBCif5I+y2JgscImKA43oBsO8No/nuXc+hoe/M/JzBnuRQVKTBGsNPQebg5GWLr1MACThxQxbMufTfo1AAo+8B2YfEnPB9IagjWmiFdOufl6hBBCCCGEEAmRYFkMDJEWEyTX7oCNL8Cmheidq/i6DoMfWmv/wO5nLmfkBZ+CkjEQKAFfESiVsim+seUQwbAFwOcq1sBz3449ed7tMO3DPR9ERyBUa9pCBcrBX5qcyQohhBBCCNHPSbAs+i9tQbgJDm+A9f+Eja/A3ncADbTfg5Cjwozc9jT6kedRsz8CJ90ERcPBX5KyfsTR/crzPG9z2Zaft82TM78As2/sPnDXlrkYYLXYqddl5pbCYF8IIYQQQoj+RIJl0f9EgrB/Nax7zqwiH9zQ6cvWWqN5PjKHVvx8xvcc5aoBFWqCNx+Fd56BOTfCiTdAXpXZ86uSt8Vfa83C9dWcrNbxm8C9eHTYPDH3Jjjlc10HvVpDpMncvHmQU2UKefkKJFAWQgghhBCiDyRYFv2DFYFdy2Dd32HD83B0RycvUjB8Fkw4h9vWjOff+8vannkych63+P7Frb7/kEcLNNfCa7+Et5+C0z4D06+F3EFmH3ASbDrYwKDa9/hd4G5yCZkHZ34Izvp650G61hBphkgjeHNN/2R/sR0kS90+IYQQQggh+kqCZZG9ImHYvhjWPQvr/wMNB459jccHo06GiRfAhHMhrxDCjQS31pB3OFb9Okwh93MtO0Z9lHsGPw+rHgcrBPUH4IX/gxWPw5lfhClX2gXAvK5+KW+vfIPHAj+mULWYB6ZcBOd/p/PzRJoh1GDaSAXsllD+IgmShRBCCCGEcJEEyyK7hFpg60JY+6xJsW4+euxrfLkw7kw47nwYfzbkltjvbYBwM+QM4qGbJpoV2U5dCKd9ERZ8H979K6DhyHb4+1fhzd/BOd+ACReaVVw3HNnKhas+Q5lqAKB17FnkXPTDYytyR4uUKQ/klNnp1sX/v737DrOrLPc+/r2TSU+GkARC71Kk93JQynvQ12MBaRZAmuABOR4UBRVBEF84BxFQQOkgJRxFpViOiFKkNyUISJPQCSSEMJA+mfv9Y60JO4uZMDPJzJ7MfD/XNdeaeVbZ9w5ZZH77edbzLPHgLkmSJMmwrF7q/knTOObah/nhPpuxzYoN8PQfi2eQn/4jzJv53hOGNMI6Oxc9yGv8CwyqGS6dWcwQHRTDlYeOff+loZZdA/a6GHb8Kvz5JHjqj0X75Mfgfw6C1beDXb4Jq+24eMtMvfUyLT/bnWVbitD/14bN2GL3s4rA36plbhH0AxjcWMzSPWhUXZa3kiRJkvoLw7J6l5YWcsYUrrnhf9nhrUcZcM2p5PyJxPy57z12xLii93jdf4VVt4GBbYTHbCnWHB44qFhKafCYzvXEjt8QPn8tvHAv3HwivHhf0f78vXD5HrDeR2GXb8P4TTs/odaMqXDlHgx46wUA7m9Zjwc2/T5bDB5e7G+ZB83vFO9h0MgyJDcWw68lSZIkdSvDsnrOvNnw9qvQ9MoitpOJlnmcBTAIqGbkZVaGD+wG630EVtp00c/ptjTDvOlLZiml1baDQ24qerb/dBK8/njR/uRN8NSfYJO9YedvFz3SHTFrOlz5aZj6FAB/b1mDQ+d+gwkbrFiulfw2ZHMlJPfMElaSJEmSDMvqpMdfaVqw3XHMmKIxs3h2+D3h92VoevXdtlnTuvSakwauzhpbf5RY7//C8ut3LPDOnwPNTcU6yYOXhcHLdOm1FxIB634U1tkNHv0l3Pr9YtbtnA8Tfw6PXQ9bHQwfPhaGj23/OnNnwITPwORHAHiWlTlw7jcZMqKRDcfNg7kzi4DfMLac4bp7ZuCWJEmS1D7Dsjosm+fw0h9/xJZDX2XaExeTDzQTrWG4efbiXbxhKIwcx5sDx3Lr66N4LZfl5RzHX1o24YUcz2UrrsUu4zsYeJvLdYcHLwtDxi65ibhaDRgAm+wLG34aHrocbv9vmDEFmufAvefD366GHf4Dtj8KBldeu3kO/Hz/YpkrYM6IFfncG99iGo3sveZgBgxogIbRxbPJA4e7VrIkSZJUJ4ZlddhtT7/J3k0/o6FpftHQ1lLGbRk2GkYuV34tX36Nh1HjYdQKMGpFGDoaBgzgsMue4sF5M95zifPufI1dPtCBsDyvqRi+PGRsMZlXdw5dHjgItjkMNvs83PtTuOtsmPN28XXrqXD/RUUv85YHQcPgYqmrXx0K/7ylOH/EWK5e8xRee6N4RnnX9cfDsBXLtZINyZIkSVI9GZbVIZnJ2X9+hg8ymvG8AcA8GmhoXI6oDcKjxi8chEeuUPQadzD8jR42kGGD3nvs6GHv81c1s3g+OQbA4HEwdFyxxnJPGDwCPvx12OoQuPNMuP/Cogd5xhT432/APefwz42/xlN338DH5t9anDN0GdjjDG74fSMwh4YBwY4brg2DfC5ZkiRJ6g0My+qQ256cwsSX3uKUEV9mr3UGcfYz45g4o5HLPr12x3p8O+jiz67d+ZNyfjnj9dBy6PWYRU/81V2Gj4GPfB+2OxJuO60Yjp3zYfoLrH3H0bS+sxw8nPj0WUxdZnMemVxMFLbVGsvSOMygLEmSJPUWdUgUWhqdd+szADwa69E0fHXeikYgOO/O1+pbWMs8mDsNBo0oepOHjK1PUK7VuBJ86hw46gH44O4L7Zqdg/jbtj+ANXfl9hcGkFm077Le8nUoVJIkSVJ7+lRYjoh1I+J7EXFvREyJiLcj4uGIOD4i3jPLU0SMj4hLI+K1iJgdEY9ExGFtHDc8Is6JiFcjYmpEXBERY9o4bo+ImBERa3bXe6yX0cMHMWzQAIY0FEOkhwyEYYPi/YdHd6f5s2DeWzB4NAxZbvGWhuoOY9cm9/kZR4/+MTfP35KnW1bmsHnHcPI/VicHjebWp95YcOiu6xuWJUmSpN6krw3DPgQ4CvgNMIFild5dgO8D+0bEdpk5CyAiRgN3AisDZwOTgN2BCyNipcw8uea6pwEHA/8NzASOAy4G9mw9ICIagXOBkzNzUve9xfq4+MCtAZg2bRp33HEH13x+PGOWW7l+BTXPgPmzYfCYcsbr3rm80m1PTuH6yeO4nmPebXypiT8/8Tp/eWoKACuPHsY6y4+sU4WSJEmS2tLXwvIvgf/KzOk1bedHxNPA8RRh+ryy/ThgHWCvzPx12XZRRNwIHB8RV9SE3n2AMzPzFICIeJMiVA/NzNY1k04D3gDO7Kb31su0FMOfYxAMKL9iYPe/bGYx4zUtxWzXQ8bCwMHd/7pd1Dp8veoHf3iCptnNQNGrHL2pR1ySJElS3xqGnZkPVoJyq1+U241r2vYDJtUE5VZnAoOAz9S0jQCm1vz8BjAQGAoQEdsBhwOHZ2Zzl9/A0mTwWBg0qphxumVOMcHW7Ckw982y13cOCx7IXVKypbh+BAxdrvjqxUEZ3h2+Xv2a3dyy4Jhd1l+ujhVKkiRJaktf61luT+t44dcBImIFYFWKodpV9wAJbFPTdhdwRETcBcyi6JV+PDOnR8Qg4CLg/My8r7OFRcSqwCqV5o0AmpqamDZtWmcv2a2ampqK7ZwGmDUCaIaWwdDSXEy2lfOgZWax1nFLc/kMcUMRqgc0AAO79lxxzofmt4sZrxuGQPMAmNm0JN9atzj9k2sD753he9/LJgIwpCFYb9kBve6/s7rHgvunqff/3ZV6G+8fqWu8d6RCV+6BPh+WI2IgcCLQDFxdNreG55eqx2fmnIiYysIB9j+BG4EHy59fBvYqvz8WWJZimHdXHAp8t60dDz/8MLNnz25rV91NnDix3iUstabNgWemFLfeWiPn8+C9d9e5IvU07x+p67x/pK7x3lF/98QTT3T6nD4floEfA9sB38nMJ8u24eV2TjvnzK45hsx8OiI2BtanGKL9eBmq1wG+A3w+M5si4kjgSGAURbg+tnVCsUW4BLip0rYRcOFmm23G1ltv3aE32VOampqYOHEim266KY2Nje9/QmbRy9za09wyr+yBLn/OZqCFose57H2OhneXf5o/B1pmQcMoGNTYayfy6oxfPvwa8CwAn9xqLT60xYr1LUg9ptP3j6QFvH+krvHekQpDhw7t9Dl9OixHxPcpwuvFwKk1u2aW2yHtnDoMmFzbUD6L/GjluAuAmzLzuoj4DPBDip7iF4HLKZ5rPnJRNWbmi+XxtXUD0NjYyJgx71mhqldYrNqyBVrmlsF5LsyfWzz3nM1l+9ziuBgAGTBk5XIir87/Be+N7n/xnwu+/8TmazJmzPBFHK2+qDff21Jv5/0jdY33jvq7rnxY1GfDckScRDE0+grgS5kLzTb1crmtPitMRAwFxgJ3vM/1D6J4rnmDsulQ4FeZOaHcfxpwTkQclZktbV+ln4oBRfCtDb8Lep1bQ/Sc4vsBw2Do2GK27T5g9rz53PVMsb7y2suNYLWxBmVJkiSpN+qTYTkivkvxHPBVwMHVsJqZkyPiJWD7Nk7fDgjggUVcfzngDOD4zGx97nkV4KGaw16kmC17HOXEYlqEBROAlcOsW4dvR0PXJgTrpe6fNI1Z8+YDxZJRkiRJknqnPrV0FEBEnAicRDGZ10GL6NWdAKwZEXtW2r9GMRnYzxfxMmcBk4Bza9peYeGlqTYG5rLwklPqqIhy7ea+E5QBbnni3c9NdlnPsCxJkiT1Vn2qZzkivgycDLwA3Ax8LhYOW69l5s3l9/8F7A1cGRFbUoTf3YFPAKdk5rPtvMZuFGswb1MJ4lcBl0bE2RSzbJ8ATHAItmrd9mQRlkcOaWCrNXxuSJIkSeqt+lRYBlqnjl6NYoKtqtspQjSZ+WZE7Egx8ddhQCPwDHBEZp7f1sUjYhhwPvCjzPxbZffPgBWBI4ARwPUUS05JADw75R2ee6OYW27HdcYxuKHPDeyQJEmS+ow+FZYz8yDgoE4c/ypwcCeOnwWs3c6+BE4rv6T3uPXJKQu+93llSZIkqXeza0vqIbfWPK+883rL1bESSZIkSe/HsCz1gBlzmrlvUrFk1EYrN7J8Y99YM1qSJEnqqwzLUg+485mpzJtfLPXtLNiSJElS72dYlnpA6yzYADsbliVJkqRer09N8CV1xux58znh+kf5zSOv0Fz2+naX5pbi+ssOH8Rmq47u1teSJEmStPgMy+qXZs5t5vArHuLOZ6b26Ovusv7yDBwQ73+gJEmSpLoyLKvfeXv2PA69/EHuf24aAKOHD2KjlZbp9tcdN3Iw3/joet3+OpIkSZIWn2FZ/cpbM+fxhcvuZ+KL0wFYftQQrv7itnxg/Kj6FiZJkiSpVzEsq9944505HHDJ/Tz+ahMAK48extVf3JY1xo2oc2WSJEmSehvDsvqF15tms9/F9/H06+8AsNqY4Uw4bFtWWXZ4nSuTJEmS1BsZltXnvTx9FvtddC/PvTETgLWXG8HVX9yOFZYZWufKJEmSJPVWhmX1aS+8MZPPXXQvL0+fBcD6K4ziqi9uy7iRQ+pcmSRJkqTezLCsPuuZ199hv4vv5bWmOQBsssoyXHHINowePrjOlUmSJEnq7QzL6pOemNzE/hffx9R35gKw5erLctnBW9M4dFCdK5MkSZK0NBhQ7wK0dHnwhbe4Y3Iwb35LvUtp199feovPXnjvgqC8/VpjueKQbQzKkiRJkjrMsKwOa2lJfnjLc/xy0kD2vXQif3h0MplZ77IW8tDz0/j8RfcyfeY8AHZadzkuO3hrRgxxEIUkSZKkjjMsq8Meefkt/jm1mCjr+Tdn8+9XPcQ+59/DQ8+/WefKCvf88w0OuOR+3p7TDMBuHxzPhV/YkqGDBta5MkmSJElLG8OyOmyzVUdz7SGbssmYd4dgP/j8m+z107s58uqHeG7qjLrVdvtTUzjosvuZOXc+AJ/YZEV+st8WDGkwKEuSJEnqPMOyOmX1McM4dL0WLv38hmy+2ugF7b//+2R2O+t2TrrxMabNmNujNd38+Gsc9rMHmdNchPi9t1yFH312cwYN9K+3JEmSpK4xTahLNlulkV8fsQM/2W8LVh87HIB585PL736OnU6/lZ/e9k9mz5vf7XX89pFXOOKqh5hbTji2/3arcfpemzBwQHT7a0uSJEnquwzL6rKI4N82XpGbv7oT3/3kB1l2eDHb9NtzmvnvPzzBrmfcxq8eeomWlu6ZBOxXD73EV675G83l9Q/dcU1O2X0jBhiUJUmSJC0mw7IW2+CGARz8L2ty+7G7cMTOazOkofhr9cpbsznm2ol84pw7ufPpqUv0Na++73mOuXYirTn8qF3W4Tsf34AIg7IkSZKkxWdY1hLTOHQQx/3f9bnl6zuz5xYr05pbH3+1if0vuY8DL72fJyY3LfbrXHLnJI6/7tEFP3/9I+vy9Y+uZ1CWJEmStMQYlrXErTx6GGfuuxm//Y8d2XGdcQvab39qCv/2ozs49pcTmfzW7C5d+7xbn+GU3z6+4OfvfHwDjtr1A4tdsyRJkiTVMiyr22y40jJceeg2XH7w1qy/wigAWhJ+8eBL7HzGrZxx05O8PXteh66Vmfzwj0/yg5ueXND2/T024osfWqtbapckSZLUvxmW1a0igp3XW57ffeVDnL73JoxvHALA7HktnHvrM+z8g9u48p7nmDe/pd1rZCan/v4fnHPLMwAMCDhjn03Zf7vVe+Q9SJIkSep/DMvqEQMHBPtutSq3fX0Xvv6RdRk5pAGAN2bM5YQbHuOjZ/2Fmx6bTObCM2e3tCQn3vAYF90xacF1fvTZzdl7y1V6/D1IkiRJ6j8My+pRwwYP5KhdP8Bt39iZA7ZbfcF6yM9OncGXrnyIfS+4h7++8CYA81uS4371CFfe+zwAgwYGP9lvCz656Up1q1+SJElS/9BQ7wLUP40bOYRT9tiIg/5lDU7/wxPc9NhrADzw3Jvs+ZO7+fjGKwLwu7+/CsCQhgFccMCW7Lze8nWrWZIkSVL/YVhWXa293EguOGArHnhuGqf+/h/87YXpwLshGWD44IFc/IWt2KFmZm1JkiRJ6k4Ow1avsPUaY/j1ETtw3ue3YPWxwxe0jxrSwBWHbGNQliRJktSj7FlWrxERfHyTFdntg+P5nwdeYOKLb3HojmvywZUa612aJEmSpH7GsKxeZ3DDAL6w/Rqwfb0rkSRJktRfOQxbkiRJkqQKw7IkSZIkSRWGZUmSJEmSKgzLkiRJkiRVGJYlSZIkSaowLEuSJEmSVGFYliRJkiSpwrAsSZIkSVKFYVmSJEmSpArDsiRJkiRJFYZlSZIkSZIqDMuSJEmSJFUYliVJkiRJqjAsS5IkSZJUYViWJEmSJKnCsCxJkiRJUoVhWZIkSZKkCsOyJEmSJEkVhmVJkiRJkioMy5IkSZIkVRiWJUmSJEmqMCxLkiRJklRhWJYkSZIkqcKwLEmSJElShWFZkiRJkqQKw7IkSZIkSRWGZUmSJEmSKgzLkiRJkiRVGJYlSZIkSaowLEuSJEmSVGFYliRJkiSpwrAsSZIkSVJFnwvLEfGtiLg2Ip6NiIyI597n+PERcWlEvBYRsyPikYg4rI3jhkfEORHxakRMjYgrImJMG8ftEREzImLNJfi2JEmSJEk9qKHeBXSDU4FpwF+B0Ys6MCJGA3cCKwNnA5OA3YELI2KlzDy55vDTgIOB/wZmAscBFwN71lyvETgXODkzJy2RdyNJkiRJ6nF9MSyvnZnPAkTEo8DIRRx7HLAOsFdm/rpsuygibgSOj4grakLvPsCZmXlKee03KUL10MycXR5zGvAGcOaSfUuSJEmSpJ7U54ZhtwblDtoPmFQTlFudCQwCPlPTNgKYWvPzG8BAYChARGwHHA4cnpnNna1bkiRJktR79MWe5Q6JiBWAVYEJbey+B0hgm5q2u4AjIuIuYBZFr/TjmTk9IgYBFwHnZ+Z9naxjVWCVSvNGAE1NTUybNq0zl+t2TU1NC20ldZz3j9R13j9S13jvSIWu3AP9NixTPKcM8FJ1R2bOiYipLBxi/xO4EXiw/PllYK/y+2OBZYHju1DHocB329rx8MMPM3v27LZ21d3EiRPrXYK01PL+kbrO+0fqGu8d9XdPPPFEp8/pz2F5eLmd087+2TXHkJlPR8TGwPoUQ7QfL0P1OsB3gM9nZlNEHAkcCYyiCNfHZuasRdRxCXBTpW0j4MLNNtuMrbfeurPvq1s1NTUxceJENt10UxobG+tdjrRU8f6Rus77R+oa7x2pMHTo0E6f05/D8sxyO6Sd/cOAybUN5bPIj1aOuwC4KTOvi4jPAD+k6C1+Ebic4rnmI9srIjNfLI9dICIAaGxsZMyY96xO1Sv05tqk3s77R+o67x+pa7x31N915cOiPjfBVye8XG6rzwsTEUOBsbQxRLty3EEUzzUfVTYdCvwqMydk5h2Uy01FRH/+c5YkSZKkpU6/DXGZOZkiDG/fxu7tgAAeaO/8iFgOOAM4PjNbQ/UqLNxL/CLFbNnjlkTNkiRJkqSe0W/DcmkCsGZE7Flp/xrQDPx8EeeeBUwCzq1pewXYuObnjYG5LLzklCRJkiSpl+tzzyxHxAHA6uWPywGDI+I75c/TM7M23P4XsDdwZURsSRF+dwc+AZzS3prNEbEbxRrM22RmS82uq4BLI+Jsil7rE4AJlWMkSZIkSb1cnwvLFM8N71RpO6XcPk9NT3BmvhkROwKnAocBjcAzwBGZeX5bF4+IYcD5wI8y82+V3T8DVgSOAEYA11MsOSVJkiRJWor0ubCcmTt38vhXgYM7cfwsYO129iXFpF6ndaYGSZIkSVLv0t+fWZYkSZIk6T0My5IkSZIkVRiWJUmSJEmqMCxLkiRJklRhWJYkSZIkqcKwLEmSJElShWFZkiRJkqQKw7IkSZIkSRWGZUmSJEmSKgzLkiRJkiRVGJYlSZIkSaowLEuSJEmSVGFYliRJkiSpwrAsSZIkSVKFYVmSJEmSpArDsiRJkiRJFYZlSZIkSZIqDMuSJEmSJFUYliVJkiRJqjAsS5IkSZJUYViWJEmSJKnCsCxJkiRJUoVhWZIkSZKkCsOyJEmSJEkVhmVJkiRJkioMy5IkSZIkVRiWJUmSJEmqMCxLkiRJklRhWJYkSZIkqcKwLEmSJElShWFZkiRJkqQKw7IkSZIkSRWGZUmSJEmSKgzLkiRJkiRVGJYlSZIkSaowLEuSJEmSVGFYliRJkiSpwrAsSZIkSVKFYVmSJEmSpArDsiRJkiRJFYZlSZIkSZIqDMuSJEmSJFUYliVJkiRJqjAsS5IkSZJUYViWJEmSJKnCsCxJkiRJUoVhWZIkSZKkCsOyJEmSJEkVhmVJkiRJkioMy5IkSZIkVRiWJUmSJEmqMCxLkiRJklRhWJYkSZIkqcKwLEmSJElShWFZkiRJkqQKw7IkSZIkSRWGZUmSJEmSKgzLkiRJkiRVGJYlSZIkSaowLEuSJEmSVGFYliRJkiSpwrAsSZIkSVKFYVmSJEmSpArDsiRJkiRJFf0+LEfE5yLioYiYFRFTI+KaiFi9csxOEfFARLwTEY9GxKfbuM7A8jo/7bnqJUmSJEndoV+H5Yg4CpgAzAK+CpwN7AbcHRErlcesCvwOaAKOAf4BXBsRW1QudzSwEvDNnqhdkiRJktR9GupdQL1ExFjgNOCvwM6Z2Vy2/wG4H/ge8EXgY8BA4FOZOSMiLgKeBfYqz6XsiT4ZODgz3+rp9yJJkiRJWrL6c8/y7sBI4MetQRkgMx8E/gLsGxGDgRHArMycUe5vAd4s21v9FLgtM6/tqeIlSZIkSd2n3/YsA9uU27vb2Hc3sBOwPnAXsGxEfBu4imKY9qbAqVA88wx8GNiwK0WUw7xXqTRvCXDvvffS1NTUlct2mxkzZvD0008zf/58RowY8f4nSFrA+0fqOu8fqWu8d6TC448/3vrt8I6e05/D8srl9qU29rW2rZKZv4+IkyiGZf+/sv3izLw2IpYFzgJOzMznu1jHocB329rxta99rYuXlCRJkiS1YS3gzx05sD+H5dZPFOa0sW927TGZeXJE/ARYB3ghM18u9/8AeAX4UUSsBvyYosf6BeC4zLy9A3VcAtxUaRsLfBB4CJjZsbfTYzYCLgQOBx6tcy3S0sb7R+o67x+pa7x3pMJwiqD8246e0J/DcmsIHUIxG3atYZVjyMwpwJTWnyPiw8CBwPZl0++A54FPAp8G/hAR62XmC4sqIjNfBF5sY1eH/yP2pIho/fbRzLynnrVISxvvH6nrvH+krvHekRbSoR7lVv15gq/W3uHq88Kw6CHaRMQQik/ozi0nBNuW4lO7ozPzIeAEYCqw3xKtWJIkSZLUI/pzWH6g3O7Qxr4dgHeAJ9o593iKbvwTyp9bA/eLAJmZFEF71SVSqSRJkiSpR/XnsHwDxTDrr0TEguHoEbEVxezWv8jMudWTImID4DjgqMx8p2x+pdxuXB4zBPhATbskSZIkaSnSb59Zzsyp5XJQZwO3RcSVwDjgq8BrwInVc6J46OMi4DeZeWPNrvuAp4ErIuJc4GNAI/Dzbn0T9fEScDLtDFGXtEjeP1LXef9IXeO9I3VRFCOG+6+I2A84BtiAoqf5ZuBbmTmpjWO/BJwObJCZr1T2rQf8FNiaYqKvb2Zmr5ykS5IkSZK0aP0+LEuSJEmSVNWfn1mWJEmSJKlNhmVJkiRJkioMy5IkSZIkVRiWJUmSJEmqMCxLkiRJklRhWJYkSZIkqcKwrA6LiM9FxEMRMSsipkbENRGxer3rknq7iBgZESdExKMR8U5ETImIOyNi/3rXJvUGEfGtiLg2Ip6NiIyI5zpwzm4R8fuIeCMiZkfEpIiYEBGDe6BkqVeIiHUj4nsRcW/5b8vbEfFwRBwfESPe59wjy/stI2KFnqpZWpq4zrI6JCKOAs4B7gKuAsYBRwNzgK0z85X6VSf1XhExALgD2A64HLgPGAEcAGwOnJKZJ9atQKkXiIgEpgF/BbYEmjJzjUUc/y3gVOBW4DdAEzAe+DCwZ2bO7O6apd4gIv4LOIriPrgHmAvsAuwLPAJsl5mz2jhvJeAfFB1nI4EVM3NyT9UtLS0My3pfETEWeA54Ctg2M5vL9q2A+4FLM/OL9atQ6r0iYnvgbuDszPxqTfsw4FmK/w/7ib76tYhYKzOfLb9/FBjZXliOiF2BPwGnZebxPVel1PuUv4s9k5nTK+3fB44HjsrM89o479fAmsCjwP4YlqU2OQxbHbE7xaeOP24NygCZ+SDwF2Bfh71J7Vqm3C40+qL8pP9NwB4w9XutQbmDjgemAifBgsccBnZHXVJvl5kPVoNy6RflduPqjojYg+J3u38H5ndbcVIfYFhWR2xTbu9uY9/dwChg/Z4rR1qq3E8xRPTYiNgnIlaNiA0i4ixgPcpf+CW9v/IZzJ0oHmc4ICKeB94GZkTEDRGxVl0LlHqPlcvt67WNEdEInAtcmJn39XhV0lKmod4FaKnQ+j/cl9rY19q2CsWzMZJqZOa08lP8i3j3k36A6cDumfnbetQlLaXWAQYC2wIfAc4AHqR4/v84YJuI2DQzX2//ElLfVo60OBFoBq6u7D6N4vf/b/V0XdLSyLCsjhhebue0sW925RhJ7/Um8DfgOorRGKOBI4BfRMRemfm/daxNWpqMKrfLAV/KzAvLn68re5kvBr6KQUD9248pJpX8TmY+2dpYzqHx78AX2hm6LanCYdjqiNZnKoe0sW9Y5RhJNSJiY4oZSv+Umd/IzOsy8zLgQ8DzwKUR0da9Jem9Wmf1bQF+Vtl3BcXzl7v0aEVSL1JO7HUkxQdHp9a0D6IY4XRrZlZ7myW1w7Csjni53K7Sxr5FDdGWVPRyDQWurW3MzDnA9cAK+My/1FGt/9a8Wd5DC2TmPIqJv8b0eFVSLxARJ1FMgHcFxciL2iVvvgxsAJweEWu0flFM4AqwakSs3pP1SksDh2GrIx4AvgTsADxd2bcD8A7wRE8XJS0lWj9QGtTGvtY2/18sdUBmvhYRzwGrR8SIzJzRui8ihlIMz67+OyX1eRHxXeC7wFXAwZnZUjlkDYpOspvaucT9FI/bDe2uGqWlkT3L6ogbKIZZfyUiFvxSX67t92HgF5k5t17FSb3c4+X2oNrGiBgF7APMAB7r4ZqkpdkVQFD0lNX6MsXvNb/r8YqkOoqIEylWVrgaOKiNoAxwCfDpNr5uLfcfTPFvkqQasfAIDaltEfGfwNnAXcCVwDiK4aXzgK0y8+X2z5b6r3JY21+BZYEJwJ3l94cCawNfz8wf1q9Cqf4i4gCgdQjofwCDgdb7Ynpmnltz7CiKeQA+CFxKMRv2FhT31GPA9rU9zlJfFhFfplgK6gWKGbCr6ya/lpk3L+L8y4EDgRUzc3J31SktrQzL6rCI2A84huKZl5nAzcC3MnNSXQuTermIWIVidt7/A6xG8cvMw8C5mfnzOpYm9QoRcRvF+slteT4z16gcPwY4maJnbHlgMvBr4CRn+VV/UhN223N7Zu7cgfMNy1IbDMuSJEmSJFX4zLIkSZIkSRWGZUmSJEmSKgzLkiRJkiRVGJYlSZIkSaowLEuSJEmSVGFYliRJkiSpwrAsSZIkSVKFYVmSJEmSpArDsiRJkiRJFYZlSZIkSZIqDMuSJOl9RcRtEfFcvetYHBHxXETcVu86JElLB8OyJEldFBGNEXFCRPw1It6OiJkR8XhEnB4Ry9e7vu4WEXtExEn1rqNWRBwdEQfVuw5J0tIvMrPeNUiStNSJiHWBm4DVgV8DtwLzgO2A/YG3gE9k5n11K3IJiojBFL83zKlpuxw4MDOjboVVlL3fz2Xmzm3sGwJkZs7t6bokSUufhnoXIEnS0iYihgO/AVYGPpmZv6vZfWFE/AT4E3BjRGycma/Xqc6RmfnOkrhWTwfMMtjOz8zmJXXN2qAvSdL7cRi2JEmddyiwLnBWJSgDkJkPAt8Glge+0doeEQdFREbEztVz2nsmOCK2iojrImJqRMyJiCcj4viIaGjr/IhYKyJ+GRHTgLcjYvPyNf9fW28kIm4sh48vs6g3XK2v/P7A8vus+dq55pgPRMSVEfFqRMwt6/tBRIyoXPvy8tzlIuLSiHgNmAWsUu4/MiL+GBEvl9d5NSKuiog1aq6xRkQkRU//TrU11dbc1jPLEfHJiLijHEo/IyLuj4jPtfdnEBGrRMQvIuLN8vibypEGkqQ+xJ5lSZI6b+9ye9EijrkcOBvYi5rA3BkR8W/AdcAzwA+BacD2wPeAzYB9KqeMBG4H7gSOB5bPzL9FxIPAQRFxYmbOr7n+CsDHgAmZ+VYnyzsa+BrwIeCAmvZ/lNfeErgFmA5cALwMbAJ8BfiXiNgpM+dVrnkz8ApwCjACaO0VPwa4u9w/HdgI+CKwa9lz/wYwpazjLGAq0OaHA1URcXhZ39PAacBcimH0EyJizcw8tXLKCIo/43soPhBZE/hP4IaI2Kj2z1eStHQzLEuS1HkbAW9n5jPtHZCZMyPiSWCjrgyHjoihwGXAfcCuNcORL4iIicCZEbFzZt5Wc9pY4HuZ+d3K5S4svz4G/Lam/UCK3wUu7kxtAJl5fUTsAXwoM69q45BLgcnAVpn5ds37uoXiGe/9KD5QqDUxMw9s41qbZOaM2oaIuJFiqPuhwOnl/qsi4vvAa+3UtJCIGA2cCTwHbN36gUE5jP4e4OSIuCozX6g5bRzwg8w8veY6U4DTgX+leI5dktQHOAxbkqTOa6SYwOv9tB4zqguvsRvFMO4rgNERMa71C/h9ecxH2jjvzDbargHepgiWtQ4BnszMO7pQX7siYmOKXuT/AYZUar8TmEHHa6c1KEfEgIhYprzORIo/320Xo9TdKHqKz6ntWc/MmcAZFB8kfKpyTgvw40rbLeX2A4tRiySplzEsS5LUeU3AIp/xLS1DEa6mduE1Nii3F1EMMa79eqLcN75yzpS2hlOXvdoTgE9ExHiAiPgQxXPXl3ShtvfTWvuJvLf21ykCarV2KIZCv0dE7Fo+azyDYhh267WWAZZdjDrXKrePtbHv75VjWr2SmbMrbW+U27GLUYskqZdxGLYkSZ33KPDhiFinvaHY5SRW6wHP1zybu6j1Gqv/Jrcux/RN4KF2znml8vPMRVz/AuBLFEOvT6foZZ4H/GwR53RVa+1nA++ZAK30ZrWh7NFd+EIR2wB/pHhu+5vAJIrJv5Ki53pxPvhf1JJX7e1b1DPJvWYJLUnS4jMsS5LUeb8CPgwcDhzbzjEHAYOA2mdnp5XbMW0cvyZFeG31VLmdmZl/6nKlpXKir4eAQyPifIrJwX6zmMtatRf+W2tvWQK1fw4YCHwsMye1NpYfRrTVq7yoDySq/lluN+S9zxpvWDlGktTPOAxbkqTOu5giEB5dzli9kIjYimI25leB82p2tYbIf60c/zlgpcplbqIYsnxs+Yxu9TWGRURnn4W+kGLo9XnAcLowsVfFO2Ut1dD6MMUw5sMjYp3qSRHREBFtfWDQltae3Gqv7bdp+/eYd+j40OybKYZ2HxURjTX1DaWYgbuZYj1tSVI/ZM+yJEmdVM50/SngD8BvI+JXwK0U4WpbiqWHpgO7Z+ZrNec9GRF/Ar4UEUERKjcDPk0xzHhQ5TW+AFwPPBERl1I80zsaWB/Yszzvtk6UPoFi4qr9gRdZ/Jmb7wOOAs6LiP+l6Bm/JTNfL2u/BXi4rP0xioC+Tln7t3jvbNhtuQ74KvD7iLiQYmmn3SgmEGvrWfD7gEMi4iTgSSAz83/aunBmTo+IY4DzgQci4rLyPexP8d/l+MpM2JKkfsSwLElSF5TBd1OKNXb3pFiWaUS5+zFgx8yc3sapBwDnUCyddABwB7AL8FNgjcpr3BQRW1M8q7sfsBzFs77/pJg5+pFO1vxORFxDMXz8ssxs6cz5bbgG2BL4LPAZip7eXYDXM/PhiNicIhR/Cvh3ihm5n6MIyX/uYM13RcRewAkU6y/PolgyaifgL22c8h2K5Z2O5t1J2NoMy+X1L4iIVymG059A0YP9KLBfZk7oSI2SpL4pMjvzaI8kSWpPRDQA1wJ7AMdkZptLIdVTRJwLHAGslZnP17seSZJ6K8OyJElLUEQMphg6/G/AkZn50zqXtEBELEMx/PqOzPx4veuRJKk3MyxLktTHRcRGwOYUy0btSjFE/O76ViVJUu/mbNiSJPV9ewNXUEwMdqRBWZKk92fPsiRJkiRJFfYsS5IkSZJUYViWJEmSJKnCsCxJkiRJUoVhWZIkSZKkCsOyJEmSJEkVhmVJkiRJkioMy5IkSZIkVRiWJUmSJEmqMCxLkiRJklRhWJYkSZIkqcKwLEmSJElSxf8HraHggJr6l3cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1105x1040 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(8.5, 8), dpi=130)\n",
    "ax.plot(performance_history_atheism,label=\"Queue size 20\")\n",
    "# ax.fill_between(range(31),min_feminist1,max_feminist1,color='blue', alpha=0.1)\n",
    "ax.plot(median_feminist2,label=\"Queue size 40\")\n",
    "ax.fill_between(range(31),min_feminist2,max_feminist2,color='orange', alpha=0.1)\n",
    "\n",
    "# ax.scatter(range(31), median_feminist1, s=8,marker = \"v\")\n",
    "ax.scatter(range(31), median_feminist2, s=8,marker=\"^\")\n",
    "\n",
    "ax.xaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=5, integer=True))\n",
    "ax.yaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=10))\n",
    "ax.yaxis.set_major_formatter(mpl.ticker.PercentFormatter(xmax=1))\n",
    "\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "ax.set_title('Different query queue sizes in feminist target')\n",
    "ax.set_xlabel('Query iteration')\n",
    "ax.set_ylabel('Performance(median)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70074108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74a50582",
   "metadata": {},
   "source": [
    "# Hillary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7a6ce84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_hillary\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset with 620 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_hillary\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset with 69 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache\\tweet_eval\\stance_hillary\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset with 295 instances loaded\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "cache_dir = \"./data_cache\"\n",
    "\n",
    "train_dataset_hillary = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_hillary\",\n",
    "    split=\"train\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Training dataset with {len(train_dataset_hillary)} instances loaded\")\n",
    "\n",
    "val_dataset_hillary = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_hillary\",\n",
    "    split=\"validation\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Validation dataset with {len(val_dataset_hillary)} instances loaded\")\n",
    "\n",
    "test_dataset_hillary = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"stance_hillary\",\n",
    "    split=\"test\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "print(f\"Test dataset with {len(test_dataset_hillary)} instances loaded\")\n",
    "\n",
    "num_classes = np.unique(train_dataset_hillary['label']).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6033da57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_original = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\", num_labels=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd3faae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[332  52  10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1147' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 03:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:44:35.884352Z [info     ] Start Predict                  dataset=617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 78/78 [00:02<00:00, 37.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:44:39.875890Z [info     ] Start Predict                  dataset=597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 41.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:44:46.009162Z [info     ] Start Predict                  dataset=577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:01<00:00, 40.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:44:52.134946Z [info     ] Start Predict                  dataset=557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:01<00:00, 38.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:44:59.508671Z [info     ] Start Predict                  dataset=537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:01<00:00, 40.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:45:04.494484Z [info     ] Start Predict                  dataset=517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 40.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:45:11.243055Z [info     ] Start Predict                  dataset=497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 40.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:45:16.021731Z [info     ] Start Predict                  dataset=477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 41.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:45:21.245937Z [info     ] Start Predict                  dataset=457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 38.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:45:27.333447Z [info     ] Start Predict                  dataset=437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 39.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:45:33.085696Z [info     ] Start Predict                  dataset=417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 39.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:45:39.228546Z [info     ] Start Predict                  dataset=397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 38.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:45:45.568250Z [info     ] Start Predict                  dataset=377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 39.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:45:52.012445Z [info     ] Start Predict                  dataset=357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 41.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:45:58.458939Z [info     ] Start Predict                  dataset=337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 36.66it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:46:05.266672Z [info     ] Start Predict                  dataset=317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 38.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:46:11.811585Z [info     ] Start Predict                  dataset=297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 43.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:46:18.346868Z [info     ] Start Predict                  dataset=277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:00<00:00, 39.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:46:25.150167Z [info     ] Start Predict                  dataset=257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 32.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:46:32.636588Z [info     ] Start Predict                  dataset=237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 38.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:46:40.628379Z [info     ] Start Predict                  dataset=217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 36.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:46:48.415399Z [info     ] Start Predict                  dataset=197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 36.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:46:56.575050Z [info     ] Start Predict                  dataset=177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 33.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:47:04.478543Z [info     ] Start Predict                  dataset=157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 40.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:47:12.090150Z [info     ] Start Predict                  dataset=137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 46.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:47:19.669761Z [info     ] Start Predict                  dataset=117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 44.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:47:27.523527Z [info     ] Start Predict                  dataset=97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 46.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:47:35.497941Z [info     ] Start Predict                  dataset=77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 34.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:47:43.994763Z [info     ] Start Predict                  dataset=57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 43.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:47:52.874732Z [info     ] Start Predict                  dataset=37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 42.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2677966101694915, 0.2677966101694915, 0.31864406779661014, 0.31186440677966104, 0.34576271186440677, 0.38305084745762713, 0.488135593220339, 0.488135593220339, 0.4135593220338983, 0.5254237288135594, 0.4440677966101695, 0.5016949152542373, 0.559322033898305, 0.5728813559322034, 0.5864406779661017, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.576271186440678, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271]\n",
      "[503 141 583]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1147' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 03:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:47:56.057393Z [info     ] Start Predict                  dataset=617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 78/78 [00:01<00:00, 42.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:47:59.819952Z [info     ] Start Predict                  dataset=597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 41.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:48:05.118802Z [info     ] Start Predict                  dataset=577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:01<00:00, 43.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:48:09.479988Z [info     ] Start Predict                  dataset=557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:01<00:00, 43.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:48:13.485021Z [info     ] Start Predict                  dataset=537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:01<00:00, 43.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:48:17.980295Z [info     ] Start Predict                  dataset=517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 43.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:48:22.425504Z [info     ] Start Predict                  dataset=497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 42.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:48:27.321877Z [info     ] Start Predict                  dataset=477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 42.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:48:32.173762Z [info     ] Start Predict                  dataset=457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 43.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:48:37.008675Z [info     ] Start Predict                  dataset=437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 43.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:48:42.289312Z [info     ] Start Predict                  dataset=417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 44.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:48:47.641714Z [info     ] Start Predict                  dataset=397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 44.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:48:53.221096Z [info     ] Start Predict                  dataset=377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 41.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:48:59.109889Z [info     ] Start Predict                  dataset=357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 42.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:49:05.248437Z [info     ] Start Predict                  dataset=337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 41.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:49:11.381682Z [info     ] Start Predict                  dataset=317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:00<00:00, 42.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:49:17.674458Z [info     ] Start Predict                  dataset=297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 42.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:49:23.966185Z [info     ] Start Predict                  dataset=277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:00<00:00, 40.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:49:30.676216Z [info     ] Start Predict                  dataset=257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 39.40it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:49:37.539486Z [info     ] Start Predict                  dataset=237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 42.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:49:44.530313Z [info     ] Start Predict                  dataset=217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 41.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:49:51.911201Z [info     ] Start Predict                  dataset=197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 41.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:49:59.242772Z [info     ] Start Predict                  dataset=177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 47.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:50:06.481577Z [info     ] Start Predict                  dataset=157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 41.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:50:13.927290Z [info     ] Start Predict                  dataset=137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 45.60it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:50:21.540372Z [info     ] Start Predict                  dataset=117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 47.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:50:29.313008Z [info     ] Start Predict                  dataset=97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 45.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:50:37.244941Z [info     ] Start Predict                  dataset=77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 44.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:50:45.914686Z [info     ] Start Predict                  dataset=57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 48.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:50:54.290045Z [info     ] Start Predict                  dataset=37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 41.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28135593220338984, 0.28135593220338984, 0.3050847457627119, 0.3016949152542373, 0.3559322033898305, 0.34576271186440677, 0.3559322033898305, 0.43728813559322033, 0.4440677966101695, 0.4915254237288136, 0.559322033898305, 0.5423728813559322, 0.5728813559322034, 0.5491525423728814, 0.5932203389830508, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5864406779661017, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271]\n",
      "[503 141 583]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1147' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 03:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:50:57.628331Z [info     ] Start Predict                  dataset=617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 78/78 [00:01<00:00, 39.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:51:01.501824Z [info     ] Start Predict                  dataset=597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 39.45it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:51:05.522382Z [info     ] Start Predict                  dataset=577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:01<00:00, 42.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:51:09.555953Z [info     ] Start Predict                  dataset=557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:01<00:00, 41.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:51:14.010352Z [info     ] Start Predict                  dataset=537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:01<00:00, 42.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:51:18.235938Z [info     ] Start Predict                  dataset=517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 41.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:51:22.801077Z [info     ] Start Predict                  dataset=497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 44.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:51:27.476693Z [info     ] Start Predict                  dataset=477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 41.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:51:32.470828Z [info     ] Start Predict                  dataset=457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 43.50it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:51:37.395156Z [info     ] Start Predict                  dataset=437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 42.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:51:42.664576Z [info     ] Start Predict                  dataset=417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 44.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:51:48.445224Z [info     ] Start Predict                  dataset=397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 42.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:51:53.835548Z [info     ] Start Predict                  dataset=377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 43.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:51:59.467082Z [info     ] Start Predict                  dataset=357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 42.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:52:05.430060Z [info     ] Start Predict                  dataset=337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:00<00:00, 44.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:52:11.387205Z [info     ] Start Predict                  dataset=317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:00<00:00, 42.51it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:52:17.834088Z [info     ] Start Predict                  dataset=297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 44.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:52:24.555206Z [info     ] Start Predict                  dataset=277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:00<00:00, 39.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:52:31.624191Z [info     ] Start Predict                  dataset=257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 41.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:52:38.482310Z [info     ] Start Predict                  dataset=237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 39.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:52:45.433006Z [info     ] Start Predict                  dataset=217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 43.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:52:52.429153Z [info     ] Start Predict                  dataset=197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 40.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:53:00.164870Z [info     ] Start Predict                  dataset=177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 42.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:53:07.500758Z [info     ] Start Predict                  dataset=157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 44.70it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:53:15.118548Z [info     ] Start Predict                  dataset=137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 44.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:53:23.177321Z [info     ] Start Predict                  dataset=117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 41.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:53:31.047059Z [info     ] Start Predict                  dataset=97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 49.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:53:39.073099Z [info     ] Start Predict                  dataset=77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 45.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:53:47.323630Z [info     ] Start Predict                  dataset=57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 47.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:53:55.683544Z [info     ] Start Predict                  dataset=37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 46.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28135593220338984, 0.28135593220338984, 0.3050847457627119, 0.3016949152542373, 0.3559322033898305, 0.34576271186440677, 0.3559322033898305, 0.43728813559322033, 0.4440677966101695, 0.4915254237288136, 0.559322033898305, 0.5423728813559322, 0.5728813559322034, 0.5491525423728814, 0.5932203389830508, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5864406779661017, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271]\n",
      "[503 141 583]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1147' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 02:56]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:53:58.751457Z [info     ] Start Predict                  dataset=617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 78/78 [00:02<00:00, 35.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:54:02.766801Z [info     ] Start Predict                  dataset=597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 44.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:54:06.376074Z [info     ] Start Predict                  dataset=577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:01<00:00, 44.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:54:10.304433Z [info     ] Start Predict                  dataset=557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:01<00:00, 43.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:54:14.397060Z [info     ] Start Predict                  dataset=537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:01<00:00, 45.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:54:18.423554Z [info     ] Start Predict                  dataset=517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 44.13it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:54:22.824001Z [info     ] Start Predict                  dataset=497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 43.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:54:27.532676Z [info     ] Start Predict                  dataset=477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 42.31it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:54:32.362652Z [info     ] Start Predict                  dataset=457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 42.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:54:37.240767Z [info     ] Start Predict                  dataset=437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 42.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:54:42.466805Z [info     ] Start Predict                  dataset=417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 45.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:54:47.539828Z [info     ] Start Predict                  dataset=397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 44.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:54:52.923152Z [info     ] Start Predict                  dataset=377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 45.44it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:54:58.591083Z [info     ] Start Predict                  dataset=357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 42.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:55:04.497949Z [info     ] Start Predict                  dataset=337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:00<00:00, 43.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:55:10.350706Z [info     ] Start Predict                  dataset=317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:00<00:00, 45.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:55:16.533732Z [info     ] Start Predict                  dataset=297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 36.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:55:23.265620Z [info     ] Start Predict                  dataset=277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:00<00:00, 42.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:55:29.716787Z [info     ] Start Predict                  dataset=257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 45.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:55:36.592311Z [info     ] Start Predict                  dataset=237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 41.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:55:43.473158Z [info     ] Start Predict                  dataset=217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 44.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:55:50.446272Z [info     ] Start Predict                  dataset=197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 41.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:55:58.174426Z [info     ] Start Predict                  dataset=177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 44.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:56:05.682305Z [info     ] Start Predict                  dataset=157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 42.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:56:13.183318Z [info     ] Start Predict                  dataset=137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 43.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:56:20.758108Z [info     ] Start Predict                  dataset=117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 45.90it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:56:28.431012Z [info     ] Start Predict                  dataset=97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 48.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:56:36.381874Z [info     ] Start Predict                  dataset=77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 44.96it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:56:44.526654Z [info     ] Start Predict                  dataset=57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 40.48it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:56:53.307944Z [info     ] Start Predict                  dataset=37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 46.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28135593220338984, 0.28135593220338984, 0.3050847457627119, 0.3016949152542373, 0.3559322033898305, 0.34576271186440677, 0.3559322033898305, 0.43728813559322033, 0.4440677966101695, 0.4915254237288136, 0.559322033898305, 0.5423728813559322, 0.5728813559322034, 0.5491525423728814, 0.5932203389830508, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5864406779661017, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271]\n",
      "[503 141 583]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1147' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 03:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:56:56.924934Z [info     ] Start Predict                  dataset=617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 78/78 [00:01<00:00, 41.20it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:57:00.539142Z [info     ] Start Predict                  dataset=597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 42.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:57:04.225511Z [info     ] Start Predict                  dataset=577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:01<00:00, 41.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:57:08.296042Z [info     ] Start Predict                  dataset=557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:01<00:00, 43.12it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:57:12.379061Z [info     ] Start Predict                  dataset=537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:01<00:00, 43.59it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:57:16.631183Z [info     ] Start Predict                  dataset=517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 42.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:57:21.141767Z [info     ] Start Predict                  dataset=497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 41.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:57:25.795767Z [info     ] Start Predict                  dataset=477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 43.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:57:30.745214Z [info     ] Start Predict                  dataset=457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 42.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:57:35.806357Z [info     ] Start Predict                  dataset=437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 41.02it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:57:41.064163Z [info     ] Start Predict                  dataset=417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 44.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:57:46.444269Z [info     ] Start Predict                  dataset=397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 42.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:57:52.010209Z [info     ] Start Predict                  dataset=377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 43.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:57:57.653914Z [info     ] Start Predict                  dataset=357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 42.23it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:58:03.385370Z [info     ] Start Predict                  dataset=337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 42.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:58:09.424538Z [info     ] Start Predict                  dataset=317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:00<00:00, 40.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:58:15.793768Z [info     ] Start Predict                  dataset=297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 42.77it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:58:22.179591Z [info     ] Start Predict                  dataset=277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:00<00:00, 41.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:58:29.206910Z [info     ] Start Predict                  dataset=257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 41.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:58:35.962501Z [info     ] Start Predict                  dataset=237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 44.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:58:42.826503Z [info     ] Start Predict                  dataset=217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 45.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:58:49.987237Z [info     ] Start Predict                  dataset=197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 42.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:58:57.586345Z [info     ] Start Predict                  dataset=177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 31.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:59:05.879938Z [info     ] Start Predict                  dataset=157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 41.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:59:14.272352Z [info     ] Start Predict                  dataset=137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 41.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:59:22.465831Z [info     ] Start Predict                  dataset=117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 36.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:59:30.759677Z [info     ] Start Predict                  dataset=97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 43.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:59:39.765904Z [info     ] Start Predict                  dataset=77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 40.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:59:48.620032Z [info     ] Start Predict                  dataset=57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 37.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T15:59:57.651255Z [info     ] Start Predict                  dataset=37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 49.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28135593220338984, 0.28135593220338984, 0.3050847457627119, 0.3016949152542373, 0.3559322033898305, 0.34576271186440677, 0.3559322033898305, 0.43728813559322033, 0.4440677966101695, 0.4915254237288136, 0.559322033898305, 0.5423728813559322, 0.5728813559322034, 0.5491525423728814, 0.5932203389830508, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5864406779661017, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271]\n"
     ]
    }
   ],
   "source": [
    "active_mc_hillary1 = []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "while mcrun != 5:\n",
    "    n_labeled_examples = np.unique(train_dataset_hillary['text']).size\n",
    "    training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "    print(training_indices0)\n",
    "    active_set_hillary =active_huggingface_dataset(train_dataset_hillary,tokenizer,'label','text')\n",
    "    valid_set_hillary = HuggingFaceDatasets(test_dataset_hillary,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_hillary.can_label = False\n",
    "    active_set_hillary.label(training_indices0)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = model_original\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_hillary,\n",
    "            eval_dataset=valid_set_hillary,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_hillary = ActiveLearningLoop(active_set_hillary,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_hillary=[unqueried_score]\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_hillary.step()\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_hillary.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_hillary),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_hillary.append(eval_metrics['eval_accuracy'])\n",
    "    print(performance_history_hillary)\n",
    "    active_mc_hillary1.append(performance_history_hillary)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfd6ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_hillary1, min_hillary1,max_hillary1 = calculate(active_mc_hillary1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d90f408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[476 577  59]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1147' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 03:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:00:01.923396Z [info     ] Start Predict                  dataset=617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 78/78 [00:02<00:00, 35.89it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:00:06.197308Z [info     ] Start Predict                  dataset=597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 33.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:00:10.927265Z [info     ] Start Predict                  dataset=577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 35.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:00:15.515921Z [info     ] Start Predict                  dataset=557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 31.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:00:20.702669Z [info     ] Start Predict                  dataset=537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 29.62it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:00:26.298152Z [info     ] Start Predict                  dataset=517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:02<00:00, 28.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:00:31.754269Z [info     ] Start Predict                  dataset=497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 33.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:00:37.090082Z [info     ] Start Predict                  dataset=477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 35.00it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:00:42.882589Z [info     ] Start Predict                  dataset=457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 34.22it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:00:48.741983Z [info     ] Start Predict                  dataset=437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 33.27it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:00:54.712977Z [info     ] Start Predict                  dataset=417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 34.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:01:00.962295Z [info     ] Start Predict                  dataset=397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 33.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:01:07.285507Z [info     ] Start Predict                  dataset=377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 35.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:01:13.940739Z [info     ] Start Predict                  dataset=357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 33.51it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:01:20.771647Z [info     ] Start Predict                  dataset=337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 34.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:01:27.097362Z [info     ] Start Predict                  dataset=317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 38.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:01:33.927879Z [info     ] Start Predict                  dataset=297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 35.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:01:40.990050Z [info     ] Start Predict                  dataset=277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:00<00:00, 35.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:01:48.040387Z [info     ] Start Predict                  dataset=257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 35.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:01:55.328413Z [info     ] Start Predict                  dataset=237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 35.74it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:02:03.073087Z [info     ] Start Predict                  dataset=217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 32.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:02:10.717274Z [info     ] Start Predict                  dataset=197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 35.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:02:18.571592Z [info     ] Start Predict                  dataset=177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 38.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:02:26.637001Z [info     ] Start Predict                  dataset=157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 34.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:02:34.885095Z [info     ] Start Predict                  dataset=137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 35.19it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:02:42.959294Z [info     ] Start Predict                  dataset=117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 40.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:02:52.056577Z [info     ] Start Predict                  dataset=97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 35.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:03:01.254121Z [info     ] Start Predict                  dataset=77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 33.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:03:10.482546Z [info     ] Start Predict                  dataset=57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 38.10it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:03:19.454236Z [info     ] Start Predict                  dataset=37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 36.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3389830508474576, 0.3254237288135593, 0.39322033898305087, 0.4101694915254237, 0.46440677966101696, 0.4271186440677966, 0.5322033898305085, 0.5254237288135594, 0.5559322033898305, 0.5254237288135594, 0.5728813559322034, 0.5457627118644067, 0.5728813559322034, 0.5423728813559322, 0.576271186440678, 0.5661016949152542, 0.5864406779661017, 0.5627118644067797, 0.5796610169491525, 0.5661016949152542, 0.5728813559322034, 0.5661016949152542, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5694915254237288, 0.5796610169491525, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271]\n",
      "[503 141 583]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1147' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 03:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:03:22.996932Z [info     ] Start Predict                  dataset=617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 78/78 [00:02<00:00, 35.14it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:03:27.145275Z [info     ] Start Predict                  dataset=597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 35.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:03:31.425143Z [info     ] Start Predict                  dataset=577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 33.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:03:36.310015Z [info     ] Start Predict                  dataset=557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 32.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:03:41.524102Z [info     ] Start Predict                  dataset=537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:01<00:00, 36.33it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:03:46.386391Z [info     ] Start Predict                  dataset=517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 35.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:03:51.369841Z [info     ] Start Predict                  dataset=497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 36.47it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:03:56.485204Z [info     ] Start Predict                  dataset=477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 38.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:04:01.854817Z [info     ] Start Predict                  dataset=457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 38.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:04:07.224030Z [info     ] Start Predict                  dataset=437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 32.24it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:04:13.016433Z [info     ] Start Predict                  dataset=417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 37.54it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:04:18.933930Z [info     ] Start Predict                  dataset=397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 32.66it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:04:25.577904Z [info     ] Start Predict                  dataset=377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 36.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:04:31.589905Z [info     ] Start Predict                  dataset=357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 36.57it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:04:37.891985Z [info     ] Start Predict                  dataset=337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 32.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:04:44.896823Z [info     ] Start Predict                  dataset=317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 32.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:04:52.056867Z [info     ] Start Predict                  dataset=297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 37.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:05:00.239473Z [info     ] Start Predict                  dataset=277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 33.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:05:07.761920Z [info     ] Start Predict                  dataset=257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 33.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:05:15.199670Z [info     ] Start Predict                  dataset=237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 33.71it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:05:22.909069Z [info     ] Start Predict                  dataset=217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 36.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:05:30.893782Z [info     ] Start Predict                  dataset=197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 38.26it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:05:38.473300Z [info     ] Start Predict                  dataset=177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 35.93it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:05:47.026106Z [info     ] Start Predict                  dataset=157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 36.04it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:05:55.516809Z [info     ] Start Predict                  dataset=137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 34.75it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:06:04.648803Z [info     ] Start Predict                  dataset=117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 34.72it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:06:13.374097Z [info     ] Start Predict                  dataset=97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 36.61it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:06:21.830117Z [info     ] Start Predict                  dataset=77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 37.84it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:06:30.795980Z [info     ] Start Predict                  dataset=57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 40.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:06:40.528813Z [info     ] Start Predict                  dataset=37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 37.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.30847457627118646, 0.29152542372881357, 0.376271186440678, 0.3864406779661017, 0.38305084745762713, 0.4101694915254237, 0.5016949152542373, 0.5050847457627119, 0.5254237288135594, 0.49491525423728816, 0.5864406779661017, 0.5152542372881356, 0.5796610169491525, 0.5322033898305085, 0.5796610169491525, 0.5627118644067797, 0.5864406779661017, 0.5728813559322034, 0.576271186440678, 0.5796610169491525, 0.576271186440678, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5864406779661017, 0.5830508474576271, 0.5796610169491525, 0.5830508474576271, 0.5796610169491525, 0.5830508474576271, 0.5830508474576271]\n",
      "[503 141 583]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1147' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 03:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:06:44.178897Z [info     ] Start Predict                  dataset=617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 78/78 [00:02<00:00, 32.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:06:48.414721Z [info     ] Start Predict                  dataset=597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 36.42it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:06:52.628700Z [info     ] Start Predict                  dataset=577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:01<00:00, 38.07it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:06:57.004161Z [info     ] Start Predict                  dataset=557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 31.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:07:02.550626Z [info     ] Start Predict                  dataset=537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 25.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:07:09.410156Z [info     ] Start Predict                  dataset=517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:03<00:00, 21.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:07:17.098706Z [info     ] Start Predict                  dataset=497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 24.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:07:23.995384Z [info     ] Start Predict                  dataset=477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 33.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:07:30.031049Z [info     ] Start Predict                  dataset=457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 36.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:07:35.552806Z [info     ] Start Predict                  dataset=437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 35.51it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:07:41.264357Z [info     ] Start Predict                  dataset=417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 37.15it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:07:47.039082Z [info     ] Start Predict                  dataset=397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 36.39it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:07:52.946280Z [info     ] Start Predict                  dataset=377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 37.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:07:59.051428Z [info     ] Start Predict                  dataset=357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 37.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:08:05.195908Z [info     ] Start Predict                  dataset=337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 35.18it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:08:11.702998Z [info     ] Start Predict                  dataset=317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 30.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:08:19.226487Z [info     ] Start Predict                  dataset=297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 30.73it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:08:26.562520Z [info     ] Start Predict                  dataset=277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:01<00:00, 32.11it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:08:34.509987Z [info     ] Start Predict                  dataset=257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:01<00:00, 31.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:08:42.342375Z [info     ] Start Predict                  dataset=237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 35.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:08:49.866773Z [info     ] Start Predict                  dataset=217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 32.06it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:08:57.673008Z [info     ] Start Predict                  dataset=197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 34.05it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:09:05.494241Z [info     ] Start Predict                  dataset=177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 36.68it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:09:13.600472Z [info     ] Start Predict                  dataset=157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 37.87it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:09:22.310971Z [info     ] Start Predict                  dataset=137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 37.99it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:09:30.805948Z [info     ] Start Predict                  dataset=117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 26.46it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:09:40.710848Z [info     ] Start Predict                  dataset=97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 34.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:09:51.060964Z [info     ] Start Predict                  dataset=77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 35.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:10:01.393735Z [info     ] Start Predict                  dataset=57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 39.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:10:10.463796Z [info     ] Start Predict                  dataset=37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 35.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.30847457627118646, 0.29152542372881357, 0.376271186440678, 0.3864406779661017, 0.38305084745762713, 0.4101694915254237, 0.5016949152542373, 0.5050847457627119, 0.5254237288135594, 0.49491525423728816, 0.5864406779661017, 0.5152542372881356, 0.5796610169491525, 0.5322033898305085, 0.5796610169491525, 0.5627118644067797, 0.5864406779661017, 0.5728813559322034, 0.576271186440678, 0.5796610169491525, 0.576271186440678, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5864406779661017, 0.5830508474576271, 0.5796610169491525, 0.5830508474576271, 0.5796610169491525, 0.5830508474576271, 0.5830508474576271]\n",
      "[503 141 583]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1147' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 03:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:10:14.235723Z [info     ] Start Predict                  dataset=617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 78/78 [00:02<00:00, 36.76it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:10:18.284130Z [info     ] Start Predict                  dataset=597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 37.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:10:22.399421Z [info     ] Start Predict                  dataset=577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 32.32it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:10:27.290136Z [info     ] Start Predict                  dataset=557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 33.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:10:31.854941Z [info     ] Start Predict                  dataset=537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:01<00:00, 37.58it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:10:36.431770Z [info     ] Start Predict                  dataset=517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 37.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:10:41.129444Z [info     ] Start Predict                  dataset=497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 37.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:10:45.981297Z [info     ] Start Predict                  dataset=477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 36.86it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:10:51.339031Z [info     ] Start Predict                  dataset=457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 36.94it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:10:56.818151Z [info     ] Start Predict                  dataset=437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 36.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:11:02.924783Z [info     ] Start Predict                  dataset=417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 33.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:11:09.022507Z [info     ] Start Predict                  dataset=397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 35.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:11:15.282030Z [info     ] Start Predict                  dataset=377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 34.83it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:11:21.584806Z [info     ] Start Predict                  dataset=357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 32.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:11:28.283918Z [info     ] Start Predict                  dataset=337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 34.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:11:34.993510Z [info     ] Start Predict                  dataset=317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 33.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:11:41.901662Z [info     ] Start Predict                  dataset=297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 34.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:11:49.080111Z [info     ] Start Predict                  dataset=277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:00<00:00, 35.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:11:56.740909Z [info     ] Start Predict                  dataset=257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 34.64it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:12:04.154579Z [info     ] Start Predict                  dataset=237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 33.78it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:12:11.626284Z [info     ] Start Predict                  dataset=217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 35.35it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:12:19.356945Z [info     ] Start Predict                  dataset=197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 34.16it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:12:27.353590Z [info     ] Start Predict                  dataset=177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 34.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:12:35.471435Z [info     ] Start Predict                  dataset=157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 34.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:12:43.798382Z [info     ] Start Predict                  dataset=137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 36.51it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:12:52.116077Z [info     ] Start Predict                  dataset=117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 35.55it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:13:00.888862Z [info     ] Start Predict                  dataset=97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 34.28it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:13:09.659011Z [info     ] Start Predict                  dataset=77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 36.63it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:13:18.629060Z [info     ] Start Predict                  dataset=57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 38.56it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:13:27.934006Z [info     ] Start Predict                  dataset=37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 34.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.30847457627118646, 0.29152542372881357, 0.376271186440678, 0.3864406779661017, 0.38305084745762713, 0.4101694915254237, 0.5016949152542373, 0.5050847457627119, 0.5254237288135594, 0.49491525423728816, 0.5864406779661017, 0.5152542372881356, 0.5796610169491525, 0.5322033898305085, 0.5796610169491525, 0.5627118644067797, 0.5864406779661017, 0.5728813559322034, 0.576271186440678, 0.5796610169491525, 0.576271186440678, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5864406779661017, 0.5830508474576271, 0.5796610169491525, 0.5830508474576271, 0.5796610169491525, 0.5830508474576271, 0.5830508474576271]\n",
      "[503 141 583]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\LYM\\miniconda3\\envs\\data_analytics_course0\\lib\\site-packages\\baal\\bayesian\\common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1147' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 03:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:13:31.482382Z [info     ] Start Predict                  dataset=617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 78/78 [00:02<00:00, 34.88it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 23\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:13:35.723668Z [info     ] Start Predict                  dataset=597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:02<00:00, 31.95it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:13:40.286697Z [info     ] Start Predict                  dataset=577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:02<00:00, 34.69it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 63\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:13:44.856760Z [info     ] Start Predict                  dataset=557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:02<00:00, 34.09it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:13:49.669921Z [info     ] Start Predict                  dataset=537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:02<00:00, 33.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 103\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:13:54.741516Z [info     ] Start Predict                  dataset=517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:02<00:00, 32.37it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 123\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:14:00.129220Z [info     ] Start Predict                  dataset=497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 31.97it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 143\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:14:05.809742Z [info     ] Start Predict                  dataset=477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 32.81it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 163\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:14:11.358923Z [info     ] Start Predict                  dataset=457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [00:01<00:00, 37.43it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 183\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:14:16.814913Z [info     ] Start Predict                  dataset=437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [00:01<00:00, 38.41it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 203\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:14:22.220989Z [info     ] Start Predict                  dataset=417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 38.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 223\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:14:27.741680Z [info     ] Start Predict                  dataset=397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 36.67it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 243\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:14:33.403293Z [info     ] Start Predict                  dataset=377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 38.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 263\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:14:39.194623Z [info     ] Start Predict                  dataset=357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:01<00:00, 37.98it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 283\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:14:45.211783Z [info     ] Start Predict                  dataset=337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:01<00:00, 38.79it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 303\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:14:51.311819Z [info     ] Start Predict                  dataset=317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 36.91it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 323\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:14:57.847121Z [info     ] Start Predict                  dataset=297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 38.82it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 343\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:15:04.337791Z [info     ] Start Predict                  dataset=277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:00<00:00, 38.08it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 363\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:15:11.015095Z [info     ] Start Predict                  dataset=257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 37.17it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 383\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:15:17.922830Z [info     ] Start Predict                  dataset=237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 37.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 403\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:15:24.831184Z [info     ] Start Predict                  dataset=217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 37.49it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 423\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 00:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:15:32.036881Z [info     ] Start Predict                  dataset=197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 37.34it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 443\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:15:39.472481Z [info     ] Start Predict                  dataset=177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 37.30it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 463\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:15:47.223386Z [info     ] Start Predict                  dataset=157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 38.01it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 483\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:15:54.801158Z [info     ] Start Predict                  dataset=137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 39.03it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 503\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:16:02.831933Z [info     ] Start Predict                  dataset=117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 36.38it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:16:11.075149Z [info     ] Start Predict                  dataset=97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 33.92it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:16:20.314137Z [info     ] Start Predict                  dataset=77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 35.21it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 563\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='71' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/71 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:16:29.137249Z [info     ] Start Predict                  dataset=57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 38.65it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 583\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 295\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316-MainThread  ] [baal.transformers_trainer_wrapper:predict_on_dataset_generator:67] 2022-09-09T16:16:38.210900Z [info     ] Start Predict                  dataset=37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 35.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.30847457627118646, 0.29152542372881357, 0.376271186440678, 0.3864406779661017, 0.38305084745762713, 0.4101694915254237, 0.5016949152542373, 0.5050847457627119, 0.5254237288135594, 0.49491525423728816, 0.5864406779661017, 0.5152542372881356, 0.5796610169491525, 0.5322033898305085, 0.5796610169491525, 0.5627118644067797, 0.5864406779661017, 0.5728813559322034, 0.576271186440678, 0.5796610169491525, 0.576271186440678, 0.5830508474576271, 0.5830508474576271, 0.5830508474576271, 0.5864406779661017, 0.5830508474576271, 0.5796610169491525, 0.5830508474576271, 0.5796610169491525, 0.5830508474576271, 0.5830508474576271]\n"
     ]
    }
   ],
   "source": [
    "active_mc_hillary2 = []\n",
    "mcrun = 0\n",
    "al_epochs=30\n",
    "np.random.seed()\n",
    "while mcrun != 5:\n",
    "    n_labeled_examples = np.unique(train_dataset_hillary['text']).size\n",
    "    training_indices0 = np.random.randint(low=0, high=n_labeled_examples + 1, size=3)\n",
    "    print(training_indices0)\n",
    "    active_set_hillary =active_huggingface_dataset(train_dataset_hillary,tokenizer,'label','text')\n",
    "    valid_set_hillary = HuggingFaceDatasets(test_dataset_hillary,tokenizer,'label','text')\n",
    "    # # lets randomly label 100 samples, therefore len(active_set) should be 100\n",
    "    active_set_hillary.can_label = False\n",
    "    active_set_hillary.label(training_indices0)\n",
    "    from baal.active import get_heuristic\n",
    "    heuristic = get_heuristic('entropy')\n",
    "    model = patch_module(model_original)\n",
    "    init_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        label = p.label_ids\n",
    "        preds = np.argmax(p.predictions, axis=-1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(label, preds),\n",
    "        }\n",
    "    model = BaalTransformersTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=active_set_hillary,\n",
    "            eval_dataset=valid_set_hillary,\n",
    "            tokenizer=None,\n",
    "            compute_metrics=compute_metrics)\n",
    "    active_loop_hillary = ActiveLearningLoop(active_set_hillary,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic, 20, iterations=1)\n",
    "    model.train()\n",
    "    unqueried_score=model.evaluate()['eval_accuracy']\n",
    "    performance_history_hillary=[unqueried_score]\n",
    "    for epoch in range(al_epochs):\n",
    "        model.train()\n",
    "        eval_metrics = model.evaluate()\n",
    "        should_continue = active_loop_hillary.step()\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.lr_scheduler = None\n",
    "        if not should_continue:\n",
    "                break\n",
    "        active_logs = {\n",
    "            \"epoch\": epoch,\n",
    "            \"labeled_data\": active_set_hillary.labelled_map,\n",
    "            \"Next Training set size\": len(active_set_hillary),\n",
    "        }\n",
    "\n",
    "        logs = {**eval_metrics, **active_logs}\n",
    "        performance_history_hillary.append(eval_metrics['eval_accuracy'])\n",
    "    print(performance_history_hillary)\n",
    "    active_mc_hillary2.append(performance_history_hillary)\n",
    "    mcrun = mcrun + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f97914a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_hillary2, min_hillary2,max_hillary2= calculate(active_mc_hillary2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e46a8a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1105x1040 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(8.5, 8), dpi=130)\n",
    "ax.plot(median_hillary1,label=\"No Monte Carlo\")\n",
    "ax.fill_between(range(31),min_hillary1,max_hillary1,color='blue', alpha=0.1)\n",
    "ax.plot(median_hillary2,label=\"Monte Carlo\")\n",
    "ax.fill_between(range(31),min_hillary2,max_hillary2,color='orange', alpha=0.1)\n",
    "\n",
    "\n",
    "ax.scatter(range(31), median_hillary1, s=8,marker = \"v\")\n",
    "ax.scatter(range(31), median_hillary2, s=8,marker=\"^\")\n",
    "\n",
    "ax.xaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=5, integer=True))\n",
    "ax.yaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=10))\n",
    "ax.yaxis.set_major_formatter(mpl.ticker.PercentFormatter(xmax=1))\n",
    "\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "ax.set_title('Different query queue sizes in hillary target')\n",
    "ax.set_xlabel('Query iteration')\n",
    "ax.set_ylabel('Performance(median)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c87c897",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analytics_course0",
   "language": "python",
   "name": "data_analytics_course0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
